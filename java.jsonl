{"diff_id": 44, "repo": "oracle/graal\n", "sha": "80c597d0510090d7b278ff0890db3ce303776f5f\n", "time": "2020-02-14T16:11:58Z\n", "diff": "mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / nodes / EspressoRootNode . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / nodes / EspressoRootNode . java <nl> public Object execute ( VirtualFrame frame ) { <nl> BytecodeNode bytecodeNode = getBytecodeNode ( ) ; <nl> bytecodeNode . methodMonitorEnter ( frame , monitor ) ; <nl> } else { <nl> + / / TODO ( Gregersen ) - register monitors on frames for non - bytecode methods <nl> InterpreterToVM . monitorEnter ( monitor ) ; <nl> } <nl> Object result ; <nl> public Object execute ( VirtualFrame frame ) { <nl> getBytecodeNode ( ) . monitorExit ( frame , monitor ) ; <nl> } <nl> } else { <nl> + / / TODO ( Gregersen ) - exit monitors on frames for non - bytecode methods <nl> InterpreterToVM . monitorExit ( monitor ) ; <nl> } <nl> } <nl>\n", "msg": "Add a few todos for implementing monitor lookup ownership on native method frames\n"}
{"diff_id": 159, "repo": "oracle/graal\n", "sha": "23930cdcc41bafbbfaa0e0bf169179f4ba0b7761\n", "time": "2020-03-25T08:03:22Z\n", "diff": "mmm a / sulong / projects / com . oracle . truffle . llvm / src / com / oracle / truffle / llvm / Runner . java <nl> ppp b / sulong / projects / com . oracle . truffle . llvm / src / com / oracle / truffle / llvm / Runner . java <nl> private static void resolveRenamedSymbols ( LLVMParserResult parserResult , ParseCo <nl> libToRes . put ( res . getRuntime ( ) . getLibrary ( ) , res ) ; <nl> } <nl> EconomicMap < String , LLVMScope > scopes = EconomicMap . create ( ) ; <nl> + EconomicMap < String , ExternalLibrary > libs = EconomicMap . create ( ) ; <nl> / / TODO ( je ) we should probably do this in symbol resolution order - let ' s fix that when we <nl> / / fix symbol resolution [ GR - 21400 ] <nl> for ( ExternalLibrary dep : parserResult . getDependencies ( ) ) { <nl> LLVMParserResult depResult = libToRes . get ( dep ) ; <nl> if ( depResult ! = null ) { <nl> scopes . put ( getSimpleLibraryName ( dep . getName ( ) ) , depResult . getRuntime ( ) . getFileScope ( ) ) ; <nl> + libs . put ( getSimpleLibraryName ( dep . getName ( ) ) , dep ) ; <nl> } <nl> } <nl> ListIterator < FunctionSymbol > it = parserResult . getExternalFunctions ( ) . listIterator ( ) ; <nl> private static void resolveRenamedSymbols ( LLVMParserResult parserResult , ParseCo <nl> String originalName = name . substring ( idx + 1 ) ; <nl> LLVMFunction originalSymbol = scope . getFunction ( originalName ) ; <nl> if ( originalSymbol = = null ) { <nl> - throw new LLVMLinkerException ( String . format ( \" The % s could not be imported because the symbol % s was not found in library % s \" , external . getName ( ) , originalName , lib ) ) ; <nl> + throw new LLVMLinkerException ( <nl> + String . format ( \" The % s could not be imported because the symbol % s was not found in library % s \" , external . getName ( ) , originalName , libs . get ( lib ) ) ) ; <nl> } <nl> LLVMAlias alias = new LLVMAlias ( parserResult . getRuntime ( ) . getLibrary ( ) , name , originalSymbol ) ; <nl> parserResult . getRuntime ( ) . getFileScope ( ) . register ( alias ) ; <nl> it . remove ( ) ; <nl> } else { <nl> - throw new LLVMLinkerException ( String . format ( \" The % s could not be imported because library % s was not found \" , external . getName ( ) , lib ) ) ; <nl> + throw new LLVMLinkerException ( String . format ( \" The % s could not be imported because library % s was not found \" , external . getName ( ) , libs . get ( lib ) ) ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "sulong : resolveRenamedSymbols should print ExternalLibrary on failure\n"}
{"diff_id": 253, "repo": "apache/flink\n", "sha": "8fcadbff7c80832626b317dc8cf75bc49b2a47d7\n", "time": "2020-03-26T08:59:22Z\n", "diff": "mmm a / flink - runtime / src / main / java / org / apache / flink / runtime / clusterframework / TaskExecutorProcessUtils . java <nl> ppp b / flink - runtime / src / main / java / org / apache / flink / runtime / clusterframework / TaskExecutorProcessUtils . java <nl> public static ResourceProfile generateDefaultSlotResourceProfile ( <nl> . build ( ) ; <nl> } <nl> <nl> - public static ResourceProfile generateTotalAvailableResourceProfile ( TaskExecutorProcessSpec taskExecutorProcessSpec ) { <nl> - return ResourceProfile . newBuilder ( ) <nl> - . setCpuCores ( taskExecutorProcessSpec . getCpuCores ( ) ) <nl> - . setTaskHeapMemory ( taskExecutorProcessSpec . getTaskHeapSize ( ) ) <nl> - . setTaskOffHeapMemory ( taskExecutorProcessSpec . getTaskOffHeapSize ( ) ) <nl> - . setManagedMemory ( taskExecutorProcessSpec . getManagedMemorySize ( ) ) <nl> - . setNetworkMemory ( taskExecutorProcessSpec . getNetworkMemSize ( ) ) <nl> - . build ( ) ; <nl> - } <nl> - <nl> / / mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm <nl> / / Memory Configuration Calculations <nl> / / mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm <nl>\n", "msg": "[ hotfix ] Remove unused method in TaskExecutorProcessUtils\n"}
{"diff_id": 269, "repo": "google/ExoPlayer\n", "sha": "494b6f6f3bcc854ab4d224c426b5d6b3546623e8\n", "time": "2019-09-05T09:44:26Z\n", "diff": "mmm a / library / core / src / main / java / com / google / android / exoplayer2 / video / MediaCodecVideoRenderer . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / video / MediaCodecVideoRenderer . java <nl> protected int supportsFormat ( <nl> if ( ! MimeTypes . isVideo ( mimeType ) ) { <nl> return FORMAT_UNSUPPORTED_TYPE ; <nl> } <nl> - DrmInitData drmInitData = format . drmInitData ; <nl> + @ Nullable DrmInitData drmInitData = format . drmInitData ; <nl> / / Assume encrypted content requires secure decoders . <nl> boolean requiresSecureDecryption = drmInitData ! = null ; <nl> List < MediaCodecInfo > decoderInfos = <nl> protected int supportsFormat ( <nl> return FORMAT_UNSUPPORTED_SUBTYPE ; <nl> } <nl> boolean supportsFormatDrm = <nl> - format . drmInitData = = null <nl> + drmInitData = = null <nl> | | FrameworkMediaCrypto . class . equals ( format . exoMediaCryptoType ) <nl> | | ( format . exoMediaCryptoType = = null <nl> - & & supportsFormatDrm ( drmSessionManager , format . drmInitData ) ) ; <nl> + & & supportsFormatDrm ( drmSessionManager , drmInitData ) ) ; <nl> if ( ! supportsFormatDrm ) { <nl> return FORMAT_UNSUPPORTED_DRM ; <nl> } <nl>\n", "msg": "Re - use local variable in replacement of unnecessary indirections\n"}
{"diff_id": 407, "repo": "ReactiveX/RxJava\n", "sha": "61e6eb97e8d7141e41b40222a8eb4b2f0508b9ba\n", "time": "2013-04-04T00:22:23Z\n", "diff": "mmm a / rxjava - core / src / main / java / rx / operators / OperationConcat . java <nl> ppp b / rxjava - core / src / main / java / rx / operators / OperationConcat . java <nl> <nl> import java . util . concurrent . atomic . AtomicBoolean ; <nl> import java . util . concurrent . atomic . AtomicReference ; <nl> <nl> - import org . junit . Assert ; <nl> - import org . junit . Before ; <nl> import org . junit . Test ; <nl> <nl> import org . mockito . InOrder ; <nl> <nl> * < p / > <nl> * <nl> * Beware that concat ( o1 , o2 ) . subscribe ( ) is a blocking call from <nl> - * which it is impossible to unsubscribe . <nl> + * which it is impossible to unsubscribe if observables are running on same thread . <nl> * <nl> * @ param sequences An observable sequence of elements to project . <nl> * @ return An observable sequence whose elements are the result of combining the output from the list of Observables . <nl> public void testConcatWithList ( ) { <nl> } <nl> <nl> @ Test <nl> - public void testConcatUnsubscribe ( ) { <nl> - final CountDownLatch callOnce = new CountDownLatch ( 1 ) ; <nl> - final CountDownLatch okToContinue = new CountDownLatch ( 1 ) ; <nl> - final TestObservable < String > w1 = new TestObservable < String > ( \" one \" , \" two \" , \" three \" ) ; <nl> - final TestObservable < String > w2 = new TestObservable < String > ( callOnce , okToContinue , \" four \" , \" five \" , \" six \" ) ; <nl> - <nl> - @ SuppressWarnings ( \" unchecked \" ) <nl> - final Observer < String > aObserver = mock ( Observer . class ) ; <nl> - @ SuppressWarnings ( \" unchecked \" ) <nl> - final Observable < String > concat = Observable . create ( concat ( w1 , w2 ) ) ; <nl> - final AtomicObservableSubscription s1 = new AtomicObservableSubscription ( ) ; <nl> - Thread t = new Thread ( ) { <nl> - @ Override <nl> - public void run ( ) { <nl> - / / NB : this statement does not complete until after \" six \" has been delivered . <nl> - s1 . wrap ( concat . subscribe ( aObserver ) ) ; <nl> - } <nl> - } ; <nl> - t . start ( ) ; <nl> - try { <nl> - / / Block main thread to allow observable \" w1 \" to complete and observable \" w2 \" to call onNext once . <nl> - callOnce . await ( ) ; <nl> - / / NB : This statement has no effect , since s1 cannot possibly <nl> - / / wrap anything until \" six \" has been delivered , which cannot <nl> - / / happen until we okToContinue . countDown ( ) <nl> - s1 . unsubscribe ( ) ; <nl> - / / Unblock the observable to continue . <nl> - okToContinue . countDown ( ) ; <nl> - w1 . t . join ( ) ; <nl> - w2 . t . join ( ) ; <nl> - } catch ( Exception e ) { <nl> - e . printStackTrace ( ) ; <nl> - fail ( e . getMessage ( ) ) ; <nl> - } <nl> - <nl> - InOrder inOrder = inOrder ( aObserver ) ; <nl> - inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" one \" ) ; <nl> - inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" two \" ) ; <nl> - inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" three \" ) ; <nl> - inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" four \" ) ; <nl> - / / NB : you might hope that five and six are not delivered , but see above . <nl> - inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" five \" ) ; <nl> - inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" six \" ) ; <nl> - inOrder . verify ( aObserver , times ( 1 ) ) . onCompleted ( ) ; <nl> - <nl> - } <nl> - <nl> - @ Test <nl> - public void testMergeObservableOfObservables ( ) { <nl> + public void testConcatObservableOfObservables ( ) { <nl> @ SuppressWarnings ( \" unchecked \" ) <nl> Observer < String > observer = mock ( Observer . class ) ; <nl> <nl> public void unsubscribe ( ) { <nl> } <nl> <nl> } ) ; <nl> - Observable < String > concat = Observable . create ( concat ( observableOfObservables ) ) ; <nl> + Observable < String > concat = Observable . create ( concat ( observableOfObservables ) ) ; <nl> + <nl> concat . subscribe ( observer ) ; <nl> + <nl> verify ( observer , times ( 7 ) ) . onNext ( anyString ( ) ) ; <nl> } <nl> <nl> public void testBlockedObservableOfObservables ( ) { <nl> verify ( observer , times ( 1 ) ) . onNext ( \" 4 \" ) ; <nl> verify ( observer , times ( 1 ) ) . onNext ( \" 6 \" ) ; <nl> } <nl> + <nl> + @ Test <nl> + public void testConcatConcurrentWithInfinity ( ) { <nl> + final TestObservable < String > w1 = new TestObservable < String > ( \" one \" , \" two \" , \" three \" ) ; <nl> + / / This observable will send \" hello \" MAX_VALUE time . <nl> + final TestObservable < String > w2 = new TestObservable < String > ( \" hello \" , Integer . MAX_VALUE ) ; <nl> <nl> + @ SuppressWarnings ( \" unchecked \" ) <nl> + Observer < String > aObserver = mock ( Observer . class ) ; <nl> + @ SuppressWarnings ( \" unchecked \" ) <nl> + TestObservable < Observable < String > > observableOfObservables = new TestObservable < Observable < String > > ( w1 , w2 ) ; <nl> + Func1 < Observer < String > , Subscription > concatF = concat ( observableOfObservables ) ; <nl> + <nl> + Observable < String > concat = Observable . create ( concatF ) ; <nl> + <nl> + concat . take ( 50 ) . subscribe ( aObserver ) ; <nl> + <nl> + / / Wait for the thread to start up . <nl> + try { <nl> + Thread . sleep ( 25 ) ; <nl> + w1 . t . join ( ) ; <nl> + w2 . t . join ( ) ; <nl> + } catch ( InterruptedException e ) { <nl> + / / TODO Auto - generated catch block <nl> + e . printStackTrace ( ) ; <nl> + } <nl> + <nl> + InOrder inOrder = inOrder ( aObserver ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" one \" ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" two \" ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" three \" ) ; <nl> + inOrder . verify ( aObserver , times ( 47 ) ) . onNext ( \" hello \" ) ; <nl> + verify ( aObserver , times ( 1 ) ) . onCompleted ( ) ; <nl> + verify ( aObserver , never ( ) ) . onError ( any ( Exception . class ) ) ; <nl> + <nl> + } <nl> + <nl> + <nl> + / * * <nl> + * The outer observable is running on the same thread and subscribe ( ) in this case is a blocking call . Calling unsubscribe ( ) is no - op because the sequence is complete . <nl> + * / <nl> + @ Test <nl> + public void testConcatUnsubscribe ( ) { <nl> + final CountDownLatch callOnce = new CountDownLatch ( 1 ) ; <nl> + final CountDownLatch okToContinue = new CountDownLatch ( 1 ) ; <nl> + final TestObservable < String > w1 = new TestObservable < String > ( \" one \" , \" two \" , \" three \" ) ; <nl> + final TestObservable < String > w2 = new TestObservable < String > ( callOnce , okToContinue , \" four \" , \" five \" , \" six \" ) ; <nl> + <nl> + @ SuppressWarnings ( \" unchecked \" ) <nl> + final Observer < String > aObserver = mock ( Observer . class ) ; <nl> + @ SuppressWarnings ( \" unchecked \" ) <nl> + final Observable < String > concat = Observable . create ( concat ( w1 , w2 ) ) ; <nl> + final AtomicObservableSubscription s1 = new AtomicObservableSubscription ( ) ; <nl> + Thread t = new Thread ( ) { <nl> + @ Override <nl> + public void run ( ) { <nl> + / / NB : this statement does not complete until after \" six \" has been delivered . <nl> + s1 . wrap ( concat . subscribe ( aObserver ) ) ; <nl> + } <nl> + } ; <nl> + t . start ( ) ; <nl> + try { <nl> + / / Block main thread to allow observable \" w1 \" to complete and observable \" w2 \" to call onNext once . <nl> + callOnce . await ( ) ; <nl> + / / NB : This statement has no effect , since s1 cannot possibly <nl> + / / wrap anything until \" six \" has been delivered , which cannot <nl> + / / happen until we okToContinue . countDown ( ) <nl> + s1 . unsubscribe ( ) ; <nl> + / / Unblock the observable to continue . <nl> + okToContinue . countDown ( ) ; <nl> + w1 . t . join ( ) ; <nl> + w2 . t . join ( ) ; <nl> + } catch ( Exception e ) { <nl> + e . printStackTrace ( ) ; <nl> + fail ( e . getMessage ( ) ) ; <nl> + } <nl> + <nl> + InOrder inOrder = inOrder ( aObserver ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" one \" ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" two \" ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" three \" ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" four \" ) ; <nl> + / / NB : you might hope that five and six are not delivered , but see above . <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" five \" ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" six \" ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onCompleted ( ) ; <nl> + <nl> + } <nl> + <nl> + / * * <nl> + * All observables will be running in different threads so subscribe ( ) is unblocked . CountDownLatch is only used in order to call unsubscribe ( ) in a predictable manner . <nl> + * / <nl> + @ Test <nl> + public void testConcatUnsubscribeConcurrent ( ) { <nl> + final CountDownLatch callOnce = new CountDownLatch ( 1 ) ; <nl> + final CountDownLatch okToContinue = new CountDownLatch ( 1 ) ; <nl> + final TestObservable < String > w1 = new TestObservable < String > ( \" one \" , \" two \" , \" three \" ) ; <nl> + final TestObservable < String > w2 = new TestObservable < String > ( callOnce , okToContinue , \" four \" , \" five \" , \" six \" ) ; <nl> + <nl> + @ SuppressWarnings ( \" unchecked \" ) <nl> + Observer < String > aObserver = mock ( Observer . class ) ; <nl> + @ SuppressWarnings ( \" unchecked \" ) <nl> + TestObservable < Observable < String > > observableOfObservables = new TestObservable < Observable < String > > ( w1 , w2 ) ; <nl> + Func1 < Observer < String > , Subscription > concatF = concat ( observableOfObservables ) ; <nl> + <nl> + Observable < String > concat = Observable . create ( concatF ) ; <nl> + <nl> + Subscription s1 = concat . subscribe ( aObserver ) ; <nl> + <nl> + try { <nl> + / / Block main thread to allow observable \" w1 \" to complete and observable \" w2 \" to call onNext exactly once . <nl> + callOnce . await ( ) ; <nl> + / / \" four \" from w2 has been processed by onNext ( ) <nl> + s1 . unsubscribe ( ) ; <nl> + / / \" five \" and \" six \" will NOT be processed by onNext ( ) <nl> + / / Unblock the observable to continue . <nl> + okToContinue . countDown ( ) ; <nl> + w1 . t . join ( ) ; <nl> + w2 . t . join ( ) ; <nl> + } catch ( Exception e ) { <nl> + e . printStackTrace ( ) ; <nl> + fail ( e . getMessage ( ) ) ; <nl> + } <nl> + <nl> + InOrder inOrder = inOrder ( aObserver ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" one \" ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" two \" ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" three \" ) ; <nl> + inOrder . verify ( aObserver , times ( 1 ) ) . onNext ( \" four \" ) ; <nl> + inOrder . verify ( aObserver , never ( ) ) . onNext ( \" five \" ) ; <nl> + inOrder . verify ( aObserver , never ( ) ) . onNext ( \" six \" ) ; <nl> + verify ( aObserver , never ( ) ) . onCompleted ( ) ; <nl> + verify ( aObserver , never ( ) ) . onError ( any ( Exception . class ) ) ; <nl> + } <nl> + <nl> private static class TestObservable < T > extends Observable < T > { <nl> <nl> private final Subscription s = new Subscription ( ) { <nl> public void unsubscribe ( ) { <nl> private boolean subscribed = true ; <nl> private final CountDownLatch once ; <nl> private final CountDownLatch okToContinue ; <nl> - <nl> + private final T seed ; <nl> + private final int size ; <nl> + <nl> public TestObservable ( T . . . values ) { <nl> this ( null , null , values ) ; <nl> } <nl> <nl> public TestObservable ( CountDownLatch once , CountDownLatch okToContinue , T . . . values ) { <nl> this . values = Arrays . asList ( values ) ; <nl> + this . size = this . values . size ( ) ; <nl> this . once = once ; <nl> this . okToContinue = okToContinue ; <nl> + this . seed = null ; <nl> } <nl> <nl> + public TestObservable ( T seed , int size ) { <nl> + values = null ; <nl> + once = null ; <nl> + okToContinue = null ; <nl> + this . seed = seed ; <nl> + this . size = size ; <nl> + } <nl> + <nl> + <nl> @ Override <nl> public Subscription subscribe ( final Observer < T > observer ) { <nl> t = new Thread ( new Runnable ( ) { <nl> public Subscription subscribe ( final Observer < T > observer ) { <nl> @ Override <nl> public void run ( ) { <nl> try { <nl> - while ( count < values . size ( ) & & subscribed ) { <nl> - observer . onNext ( values . get ( count ) ) ; <nl> + while ( count < size & & subscribed ) { <nl> + if ( null ! = values ) <nl> + observer . onNext ( values . get ( count ) ) ; <nl> + else <nl> + observer . onNext ( seed ) ; <nl> count + + ; <nl> / / Unblock the main thread to call unsubscribe . <nl> if ( null ! = once ) <nl> once . countDown ( ) ; <nl> / / Block until the main thread has called unsubscribe . <nl> - if ( null ! = once ) <nl> + if ( null ! = okToContinue ) <nl> okToContinue . await ( ) ; <nl> } <nl> if ( subscribed ) <nl>\n", "msg": "1 . Update javadoc on subscribe ( ) blocking if observables are running on the same thread .\n"}
{"diff_id": 441, "repo": "apache/flink\n", "sha": "a3890103d2fb1319d289b83d2451136751ca59c4\n", "time": "2019-10-01T09:32:07Z\n", "diff": "mmm a / flink - runtime / src / main / java / org / apache / flink / runtime / util / ZooKeeperUtils . java <nl> ppp b / flink - runtime / src / main / java / org / apache / flink / runtime / util / ZooKeeperUtils . java <nl> public static String getZooKeeperEnsemble ( Configuration flinkConf ) <nl> * @ param client The { @ link CuratorFramework } ZooKeeper client to use <nl> * @ param configuration { @ link Configuration } object containing the configuration values <nl> * @ return { @ link ZooKeeperLeaderRetrievalService } instance . <nl> - * @ throws Exception <nl> * / <nl> public static ZooKeeperLeaderRetrievalService createLeaderRetrievalService ( <nl> final CuratorFramework client , <nl> - final Configuration configuration ) throws Exception { <nl> + final Configuration configuration ) { <nl> return createLeaderRetrievalService ( client , configuration , \" \" ) ; <nl> } <nl> <nl>\n", "msg": "[ hotfix ] Remove Exception from ZooKeeperUtils # createLeaderRetrievalService\n"}
{"diff_id": 451, "repo": "bazelbuild/bazel\n", "sha": "c6ced2b530c192b454f91eefa5cb9ca91089deb4\n", "time": "2020-04-21T11:55:03Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / profiler / Profiler . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / profiler / Profiler . java <nl> TaskData getAndReset ( ) { <nl> } <nl> <nl> private void writeTask ( JsonWriter writer , TaskData data ) throws IOException { <nl> + Preconditions . checkNotNull ( data ) ; <nl> String eventType = data . duration = = 0 ? \" i \" : \" X \" ; <nl> writer . setIndent ( \" \" ) ; <nl> writer . beginObject ( ) ; <nl> writer . setIndent ( \" \" ) ; <nl> - if ( data = = null | | data . type = = null ) { <nl> + if ( data . type = = null ) { <nl> writer . setIndent ( \" \" ) ; <nl> + } else { <nl> + writer . name ( \" cat \" ) . value ( data . type . description ) ; <nl> } <nl> - writer . name ( \" cat \" ) . value ( data . type . description ) ; <nl> writer . name ( \" name \" ) . value ( data . description ) ; <nl> writer . name ( \" ph \" ) . value ( eventType ) ; <nl> writer <nl> public void run ( ) { <nl> HashMap < Long , MergedEvent > eventsPerThread = new HashMap < > ( ) ; <nl> int eventCount = 0 ; <nl> while ( ( data = queue . take ( ) ) ! = POISON_PILL ) { <nl> + Preconditions . checkNotNull ( data ) ; <nl> eventCount + + ; <nl> if ( data . type = = ProfilerTask . THREAD_NAME ) { <nl> writer . setIndent ( \" \" ) ; <nl>\n", "msg": "Profiler : clean up handling of null values .\n"}
{"diff_id": 492, "repo": "elastic/elasticsearch\n", "sha": "365c29b902fc41488faaa39fd60100f6865c5b96\n", "time": "2012-03-22T18:16:07Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / cluster / ClusterChangedEvent . java <nl> ppp b / src / main / java / org / elasticsearch / cluster / ClusterChangedEvent . java <nl> public boolean indexMetaDataChanged ( IndexMetaData current ) { <nl> if ( previousIndexMetaData = = current ) { <nl> return false ; <nl> } <nl> - return false ; <nl> + return true ; <nl> } <nl> <nl> public boolean blocksChanged ( ) { <nl>\n", "msg": "Index Update Settings API does not update settings in real time , closes .\n"}
{"diff_id": 523, "repo": "bumptech/glide\n", "sha": "17102eb50277f999ffce4307cfe20b81cb331080\n", "time": "2017-06-20T18:16:40Z\n", "diff": "mmm a / library / src / main / java / com / bumptech / glide / request / RequestOptions . java <nl> ppp b / library / src / main / java / com / bumptech / glide / request / RequestOptions . java <nl> public static RequestOptions circleCropTransform ( ) { <nl> return circleCropOptions ; <nl> } <nl> <nl> - / * * <nl> - * Returns a { @ link RequestOptions } object with { @ link # transform ( Transformation ) } set . <nl> - * <nl> - * @ deprecated Use { @ link # bitmapTransform ( Transformation ) } . <nl> - * / <nl> - @ Deprecated <nl> - public static RequestOptions bitmapTransform ( <nl> - Context context , @ NonNull Transformation < Bitmap > transformation ) { <nl> - return bitmapTransform ( transformation ) ; <nl> - } <nl> - <nl> / * * <nl> * Returns a { @ link RequestOptions } object with { @ link # transform ( Transformation ) } set . <nl> * / <nl>\n", "msg": "Remove deprecated bitmapTransform method from Glide\n"}
{"diff_id": 550, "repo": "bazelbuild/bazel\n", "sha": "1a592765f3fc116ac5c83b80784dcf0c043ccb5e\n", "time": "2016-12-23T09:43:01Z\n", "diff": "mmm a / third_party / java / aosp_gradle_core / java / com / android / build / gradle / tasks / ResourceUsageAnalyzer . java <nl> ppp b / third_party / java / aosp_gradle_core / java / com / android / build / gradle / tasks / ResourceUsageAnalyzer . java <nl> <nl> * / <nl> package com . android . build . gradle . tasks ; <nl> <nl> - import static com . android . SdkConstants . ANDROID_STYLE_RESOURCE_PREFIX ; <nl> - import static com . android . SdkConstants . ANDROID_URI ; <nl> import static com . android . SdkConstants . ATTR_NAME ; <nl> - import static com . android . SdkConstants . ATTR_PARENT ; <nl> import static com . android . SdkConstants . ATTR_TYPE ; <nl> import static com . android . SdkConstants . DOT_CLASS ; <nl> + import static com . android . SdkConstants . DOT_JAR ; <nl> import static com . android . SdkConstants . DOT_XML ; <nl> import static com . android . SdkConstants . FD_RES_VALUES ; <nl> - import static com . android . SdkConstants . PREFIX_ANDROID ; <nl> - import static com . android . SdkConstants . STYLE_RESOURCE_PREFIX ; <nl> import static com . android . SdkConstants . TAG_ITEM ; <nl> import static com . android . SdkConstants . TAG_RESOURCES ; <nl> - import static com . android . SdkConstants . TAG_STYLE ; <nl> import static com . android . utils . SdkUtils . endsWithIgnoreCase ; <nl> import static java . nio . charset . StandardCharsets . UTF_8 ; <nl> + import static org . objectweb . asm . ClassReader . SKIP_DEBUG ; <nl> + import static org . objectweb . asm . ClassReader . SKIP_FRAMES ; <nl> <nl> + import com . android . SdkConstants ; <nl> import com . android . annotations . NonNull ; <nl> import com . android . annotations . Nullable ; <nl> import com . android . annotations . VisibleForTesting ; <nl> import com . android . ide . common . resources . ResourceUrl ; <nl> - import com . android . ide . common . resources . configuration . DensityQualifier ; <nl> - import com . android . ide . common . resources . configuration . FolderConfiguration ; <nl> - import com . android . ide . common . resources . configuration . ResourceQualifier ; <nl> import com . android . ide . common . xml . XmlPrettyPrinter ; <nl> - import com . android . resources . FolderTypeRelationship ; <nl> import com . android . resources . ResourceFolderType ; <nl> import com . android . resources . ResourceType ; <nl> + import com . android . tools . lint . checks . ResourceUsageModel ; <nl> + import com . android . tools . lint . checks . ResourceUsageModel . Resource ; <nl> + import com . android . tools . lint . checks . StringFormatDetector ; <nl> + import com . android . utils . AsmUtils ; <nl> import com . android . utils . Pair ; <nl> import com . android . utils . XmlUtils ; <nl> import com . google . common . base . Joiner ; <nl> <nl> import java . nio . file . Path ; <nl> import java . util . ArrayList ; <nl> import java . util . Collections ; <nl> - import java . util . IdentityHashMap ; <nl> import java . util . List ; <nl> import java . util . Map ; <nl> import java . util . Set ; <nl> <nl> import java . util . logging . Level ; <nl> import java . util . logging . LogRecord ; <nl> import java . util . logging . Logger ; <nl> + import java . util . regex . Matcher ; <nl> + import java . util . regex . Pattern ; <nl> + import java . util . regex . PatternSyntaxException ; <nl> import java . util . zip . ZipEntry ; <nl> import java . util . zip . ZipInputStream ; <nl> import javax . xml . parsers . ParserConfigurationException ; <nl> + import javax . xml . xpath . XPathConstants ; <nl> + import javax . xml . xpath . XPathException ; <nl> + import javax . xml . xpath . XPathExpression ; <nl> + import javax . xml . xpath . XPathFactory ; <nl> + import org . objectweb . asm . AnnotationVisitor ; <nl> import org . objectweb . asm . ClassReader ; <nl> import org . objectweb . asm . ClassVisitor ; <nl> + import org . objectweb . asm . FieldVisitor ; <nl> import org . objectweb . asm . MethodVisitor ; <nl> import org . objectweb . asm . Opcodes ; <nl> import org . w3c . dom . Attr ; <nl> <nl> * menus and drawables , not value - based resources like strings and dimensions . <nl> * / <nl> public class ResourceUsageAnalyzer { <nl> + private static final String ANDROID_RES = \" android_res / \" ; <nl> + <nl> + / * * Special marker regexp which does not match a resource name * / <nl> + static final String NO_MATCH = \" - nomatch - \" ; <nl> <nl> - public static final int TYPICAL_RESOURCE_COUNT = 200 ; <nl> private final Set < String > resourcePackages ; <nl> private final Path rTxt ; <nl> private final Path proguardMapping ; <nl> - private final Path classesJar ; <nl> + private final Path classes ; <nl> private final Path mergedManifest ; <nl> private final Path mergedResourceDir ; <nl> private final Logger logger ; <nl> <nl> * / <nl> private List < Resource > unused ; <nl> / * * <nl> - * List of all known resources ( parsed from R . java ) <nl> - * / <nl> - private List < Resource > resources = Lists . newArrayListWithExpectedSize ( TYPICAL_RESOURCE_COUNT ) ; <nl> - / * * <nl> - * Map from R field value to corresponding resource <nl> - * / <nl> - private Map < Integer , Resource > valueToResource = <nl> - Maps . newHashMapWithExpectedSize ( TYPICAL_RESOURCE_COUNT ) ; <nl> - / * * <nl> - * Map from resource type to map from resource name to resource object <nl> + * Map from resource class owners ( VM format class ) to corresponding resource entries . This lets <nl> + * us map back from code references ( obfuscated class and possibly obfuscated field reference ) <nl> + * back to the corresponding resource type and name . <nl> * / <nl> - private Map < ResourceType , Map < String , Resource > > typeToName = <nl> - Maps . newEnumMap ( ResourceType . class ) ; <nl> - / * * <nl> - * Map from resource class owners ( VM format class ) to corresponding resource entries . <nl> - * This lets us map back from code references ( obfuscated class and possibly obfuscated field <nl> - * reference ) back to the corresponding resource type and name . <nl> - * / <nl> - private final Map < String , Pair < ResourceType , Map < String , String > > > resourceObfuscation = <nl> + private Map < String , Pair < ResourceType , Map < String , String > > > resourceObfuscation = <nl> Maps . newHashMapWithExpectedSize ( 30 ) ; <nl> + / * * Obfuscated name of android / support / v7 / widget / SuggestionsAdapter . java * / <nl> + private String suggestionsAdapter ; <nl> + / * * Obfuscated name of android / support / v7 / internal / widget / ResourcesWrapper . java * / <nl> + private String resourcesWrapper ; <nl> <nl> public ResourceUsageAnalyzer ( <nl> Set < String > resourcePackages , <nl> @ NonNull Path rTxt , <nl> - @ NonNull Path classesJar , <nl> + @ NonNull Path classes , <nl> @ NonNull Path manifest , <nl> @ Nullable Path mapping , <nl> @ NonNull Path resources , <nl> - Path logFile ) { <nl> + @ Nullable Path logFile ) { <nl> this . resourcePackages = resourcePackages ; <nl> this . rTxt = rTxt ; <nl> this . proguardMapping = mapping ; <nl> - this . classesJar = classesJar ; <nl> + this . classes = classes ; <nl> this . mergedManifest = manifest ; <nl> this . mergedResourceDir = resources ; <nl> <nl> public void shrink ( Path destinationDir ) throws IOException , <nl> ParserConfigurationException , SAXException { <nl> parseResourceTxtFile ( rTxt , resourcePackages ) ; <nl> recordMapping ( proguardMapping ) ; <nl> - recordUsages ( classesJar ) ; <nl> + recordClassUsages ( classes ) ; <nl> recordManifestUsages ( mergedManifest ) ; <nl> recordResources ( mergedResourceDir ) ; <nl> keepPossiblyReferencedResources ( ) ; <nl> dumpReferences ( ) ; <nl> - findUnused ( ) ; <nl> + model . processToolsAttributes ( ) ; <nl> + unused = model . findUnused ( ) ; <nl> removeUnused ( destinationDir ) ; <nl> } <nl> <nl> public void shrink ( Path destinationDir ) throws IOException , <nl> * new reduced resource directory and removes unused values from all value xml files . <nl> * <nl> * @ param destination directory to copy resources into ; if null , delete resources in place <nl> + * @ throws IOException <nl> + * @ throws ParserConfigurationException <nl> + * @ throws SAXException <nl> * / <nl> private void removeUnused ( Path destination ) throws IOException , <nl> ParserConfigurationException , SAXException { <nl> private void removeUnused ( Path destination ) throws IOException , <nl> String folder = file . getParentFile ( ) . getName ( ) ; <nl> ResourceFolderType folderType = ResourceFolderType . getFolderType ( folder ) ; <nl> if ( folderType ! = null & & folderType ! = ResourceFolderType . VALUES ) { <nl> - logger . fine ( \" Deleted unused resource \" + file ) ; <nl> + logger . fine ( \" Deleted unused resource \" + file + \" for resource \" + resource ) ; <nl> assert skip ! = null ; <nl> skip . add ( file ) ; <nl> } else { <nl> private void removeUnused ( Path destination ) throws IOException , <nl> / / accurately removed from public . xml , but the declarations may be deleted if they occur in <nl> / / other files . IDs should be added to values . xml so that there are no definitions in public . xml <nl> / / without declarations . <nl> - createStubIds ( values , rewritten ) ; <nl> - <nl> File publicXml = new File ( mergedResourceDir . toFile ( ) , <nl> FD_RES_VALUES + File . separatorChar + \" public . xml \" ) ; <nl> + createStubIds ( values , rewritten , publicXml ) ; <nl> + <nl> trimPublicResources ( publicXml , deleted , rewritten ) ; <nl> <nl> filteredCopy ( mergedResourceDir . toFile ( ) , destination , skip , rewritten ) ; <nl> private void rewriteXml ( Set < File > rewrite , Map < File , String > rewritten ) <nl> / * * <nl> * Write stub values for IDs to values . xml to match those available in public . xml . <nl> * / <nl> - private void createStubIds ( File values , Map < File , String > rewritten ) <nl> + private void createStubIds ( File values , Map < File , String > rewritten , File publicXml ) <nl> throws IOException , ParserConfigurationException , SAXException { <nl> if ( values . exists ( ) ) { <nl> String xml = rewritten . get ( values ) ; <nl> private void createStubIds ( File values , Map < File , String > rewritten ) <nl> List < String > stubbed = Lists . newArrayList ( ) ; <nl> Document document = XmlUtils . parseDocument ( xml , true ) ; <nl> Element root = document . getDocumentElement ( ) ; <nl> - for ( Resource resource : resources ) { <nl> - if ( resource . type = = ResourceType . ID & & ! resource . hasDefault ) { <nl> + for ( Resource resource : model . getResources ( ) ) { <nl> + boolean inPublicXml = false ; <nl> + if ( resource . declarations ! = null ) { <nl> + for ( File file : resource . declarations ) { <nl> + if ( file . equals ( publicXml ) ) { <nl> + inPublicXml = true ; <nl> + } <nl> + } <nl> + } <nl> + NodeList existing = null ; <nl> + try { <nl> + XPathExpression expr = XPathFactory . newInstance ( ) . newXPath ( ) . compile ( <nl> + String . format ( \" / / item [ @ type = \\ \" id \\ \" ] [ @ name = \\ \" % s \\ \" ] \" , resource . name ) ) ; <nl> + existing = ( NodeList ) expr . evaluate ( document , XPathConstants . NODESET ) ; <nl> + } catch ( XPathException e ) { <nl> + / / Failed to retrieve any existing declarations for resource . <nl> + } <nl> + if ( resource . type = = ResourceType . ID & & inPublicXml <nl> + & & ( existing = = null | | existing . getLength ( ) = = 0 ) ) { <nl> Element item = document . createElement ( TAG_ITEM ) ; <nl> item . setAttribute ( ATTR_TYPE , resource . type . getName ( ) ) ; <nl> item . setAttribute ( ATTR_NAME , resource . name ) ; <nl> private void trimPublicResources ( File publicXml , Set < Resource > deleted , <nl> ResourceType type = ResourceType . getEnum ( resourceElement . getAttribute ( ATTR_TYPE ) ) ; <nl> String name = resourceElement . getAttribute ( ATTR_NAME ) ; <nl> if ( type ! = null & & name ! = null ) { <nl> - Resource resource = getResource ( type , name ) ; <nl> + Resource resource = model . getResource ( type , name ) ; <nl> if ( resource ! = null & & deleted . contains ( resource ) ) { <nl> root . removeChild ( child ) ; <nl> } <nl> private static void filteredCopy ( File source , Path destination , Set < File > skip , <nl> } <nl> <nl> private void stripUnused ( Element element , List < String > removed ) { <nl> - ResourceType type = getResourceType ( element ) ; <nl> + ResourceType type = ResourceUsageModel . getResourceType ( element ) ; <nl> if ( type = = ResourceType . ATTR ) { <nl> / / Not yet properly handled <nl> return ; <nl> } <nl> - Resource resource = getResource ( element ) ; <nl> + Resource resource = model . getResource ( element ) ; <nl> if ( resource ! = null ) { <nl> if ( resource . type = = ResourceType . DECLARE_STYLEABLE <nl> | | resource . type = = ResourceType . ATTR ) { <nl> private void stripUnused ( Element element , List < String > removed ) { <nl> / / tracking field references of the R_styleable_attr fields yet <nl> return ; <nl> } <nl> - if ( ! resource . reachable <nl> + if ( ! resource . isReachable ( ) <nl> & & ( resource . type = = ResourceType . STYLE <nl> | | resource . type = = ResourceType . PLURALS <nl> | | resource . type = = ResourceType . ARRAY ) ) { <nl> private void stripUnused ( Element element , List < String > removed ) { <nl> stripUnused ( ( Element ) child , removed ) ; <nl> } <nl> } <nl> - if ( resource ! = null & & ! resource . reachable & & resource . isRelevantType ( ) ) { <nl> + if ( resource ! = null & & ! resource . isReachable ( ) & & resource . type ! = ResourceType . ID ) { <nl> removed . add ( resource . getUrl ( ) ) ; <nl> Node parent = element . getParentNode ( ) ; <nl> parent . removeChild ( element ) ; <nl> } <nl> } <nl> <nl> - private static String getFieldName ( Element element ) { <nl> - return getFieldName ( element . getAttribute ( ATTR_NAME ) ) ; <nl> - } <nl> - <nl> - @ Nullable <nl> - private Resource getResource ( Element element ) { <nl> - ResourceType type = getResourceType ( element ) ; <nl> - if ( type ! = null ) { <nl> - String name = getFieldName ( element ) ; <nl> - return getResource ( type , name ) ; <nl> - } <nl> - return null ; <nl> - } <nl> - <nl> - private static ResourceType getResourceType ( Element element ) { <nl> - String tagName = element . getTagName ( ) ; <nl> - switch ( tagName ) { <nl> - case TAG_ITEM : <nl> - String typeName = element . getAttribute ( ATTR_TYPE ) ; <nl> - if ( ! typeName . isEmpty ( ) ) { <nl> - return ResourceType . getEnum ( typeName ) ; <nl> - } <nl> - break ; <nl> - case \" string - array \" : <nl> - case \" integer - array \" : <nl> - return ResourceType . ARRAY ; <nl> - default : <nl> - return ResourceType . getEnum ( tagName ) ; <nl> - } <nl> - return null ; <nl> - } <nl> - <nl> - private void findUnused ( ) { <nl> - List < Resource > roots = Lists . newArrayList ( ) ; <nl> - for ( Resource resource : resources ) { <nl> - if ( resource . reachable & & resource . type ! = ResourceType . ID <nl> - & & resource . type ! = ResourceType . ATTR ) { <nl> - roots . add ( resource ) ; <nl> - } <nl> - } <nl> - logger . fine ( String . format ( \" The root reachable resources are : \\ n % s \" , <nl> - Joiner . on ( \" , \\ n \" ) . join ( roots ) ) ) ; <nl> - Map < Resource , Boolean > seen = new IdentityHashMap < > ( resources . size ( ) ) ; <nl> - for ( Resource root : roots ) { <nl> - visit ( root , seen ) ; <nl> - } <nl> - List < Resource > unused = Lists . newArrayListWithExpectedSize ( resources . size ( ) ) ; <nl> - for ( Resource resource : resources ) { <nl> - if ( ! resource . reachable & & resource . isRelevantType ( ) ) { <nl> - unused . add ( resource ) ; <nl> - } <nl> - } <nl> - this . unused = unused ; <nl> - } <nl> - <nl> - private static void visit ( Resource root , Map < Resource , Boolean > seen ) { <nl> - if ( seen . containsKey ( root ) ) { <nl> - return ; <nl> - } <nl> - seen . put ( root , Boolean . TRUE ) ; <nl> - root . reachable = true ; <nl> - if ( root . references ! = null ) { <nl> - for ( Resource referenced : root . references ) { <nl> - visit ( referenced , seen ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> private void dumpReferences ( ) { <nl> - for ( Resource resource : resources ) { <nl> - if ( resource . references ! = null ) { <nl> - logger . fine ( resource + \" = > \" + resource . references ) ; <nl> - } <nl> - } <nl> + logger . fine ( model . dumpReferences ( ) ) ; <nl> } <nl> <nl> private void keepPossiblyReferencedResources ( ) { <nl> - if ( ! mFoundGetIdentifier | | mStrings = = null ) { <nl> + if ( ( ! foundGetIdentifier & & ! foundWebContent ) | | strings = = null ) { <nl> / / No calls to android . content . res . Resources # getIdentifier ; no need <nl> / / to worry about string references to resources <nl> return ; <nl> } <nl> - List < String > strings = new ArrayList < String > ( mStrings ) ; <nl> - Collections . sort ( strings ) ; <nl> - logger . fine ( String . format ( \" android . content . res . Resources # getIdentifier present : % s \" , <nl> - mFoundGetIdentifier ) ) ; <nl> + if ( ! model . isSafeMode ( ) ) { <nl> + / / User specifically asked for us not to guess resources to keep ; they will <nl> + / / explicitly mark them as kept if necessary instead <nl> + return ; <nl> + } <nl> + List < String > sortedStrings = new ArrayList < String > ( strings ) ; <nl> + Collections . sort ( sortedStrings ) ; <nl> + logger . fine ( <nl> + \" android . content . res . Resources # getIdentifier present : \" + foundGetIdentifier ) ; <nl> + logger . fine ( \" Web content present : \" + foundWebContent ) ; <nl> logger . fine ( \" Referenced Strings : \" ) ; <nl> - for ( String s : strings ) { <nl> - s = s . trim ( ) . replace ( \" \\ n \" , \" \\ \\ n \" ) ; <nl> - if ( s . length ( ) > 40 ) { <nl> - s = s . substring ( 0 , 37 ) + \" . . . \" ; <nl> - } else if ( s . isEmpty ( ) ) { <nl> + for ( String string : sortedStrings ) { <nl> + string = string . trim ( ) . replace ( \" \\ n \" , \" \\ \\ n \" ) ; <nl> + if ( string . length ( ) > 40 ) { <nl> + string = string . substring ( 0 , 37 ) + \" . . . \" ; <nl> + } else if ( string . isEmpty ( ) ) { <nl> continue ; <nl> } <nl> - logger . fine ( \" \" + s ) ; <nl> + logger . fine ( \" \" + string ) ; <nl> } <nl> - <nl> + int shortest = Integer . MAX_VALUE ; <nl> Set < String > names = Sets . newHashSetWithExpectedSize ( 50 ) ; <nl> - for ( Map < String , Resource > map : typeToName . values ( ) ) { <nl> - names . addAll ( map . keySet ( ) ) ; <nl> + for ( Resource resource : model . getResources ( ) ) { <nl> + String name = resource . name ; <nl> + names . add ( name ) ; <nl> + int length = name . length ( ) ; <nl> + if ( length < shortest ) { <nl> + shortest = length ; <nl> + } <nl> } <nl> - for ( String string : mStrings ) { <nl> + for ( String string : strings ) { <nl> + if ( string . length ( ) < shortest ) { <nl> + continue ; <nl> + } <nl> / / Check whether the string looks relevant <nl> - / / We consider three types of strings : <nl> + / / We consider four types of strings : <nl> / / ( 1 ) simple resource names , e . g . \" foo \" from @ layout / foo <nl> / / These might be the parameter to a getIdentifier ( ) call , or could <nl> / / be composed into a fully qualified resource name for the getIdentifier ( ) <nl> private void keepPossiblyReferencedResources ( ) { <nl> / / These might be composed into a fully qualified resource name for <nl> / / getIdentifier ( ) . <nl> / / ( 3 ) Fully qualified resource names of the form package : type / name . <nl> + / / ( 4 ) If foundWebContent is true , look for android_res / URL strings as well <nl> + if ( foundWebContent ) { <nl> + Resource resource = model . getResourceFromFilePath ( string ) ; <nl> + if ( resource ! = null ) { <nl> + ResourceUsageModel . markReachable ( resource ) ; <nl> + continue ; <nl> + } else { <nl> + int start = 0 ; <nl> + int slash = string . lastIndexOf ( ' / ' ) ; <nl> + if ( slash ! = - 1 ) { <nl> + start = slash + 1 ; <nl> + } <nl> + int dot = string . indexOf ( ' . ' , start ) ; <nl> + String name = string . substring ( start , dot ! = - 1 ? dot : string . length ( ) ) ; <nl> + if ( names . contains ( name ) ) { <nl> + for ( Map < String , Resource > map : model . getResourceMaps ( ) ) { <nl> + resource = map . get ( name ) ; <nl> + if ( resource ! = null ) { <nl> + logger . fine ( String . format ( <nl> + \" Marking % s used because it matches string pool constant % s \" , <nl> + resource , string ) ) ; <nl> + } <nl> + ResourceUsageModel . markReachable ( resource ) ; <nl> + } <nl> + } <nl> + } <nl> + } <nl> + / / Look for normal getIdentifier resource URLs <nl> int n = string . length ( ) ; <nl> boolean justName = true ; <nl> + boolean formatting = false ; <nl> boolean haveSlash = false ; <nl> for ( int i = 0 ; i < n ; i + + ) { <nl> char c = string . charAt ( i ) ; <nl> if ( c = = ' / ' ) { <nl> haveSlash = true ; <nl> justName = false ; <nl> - } else if ( c = = ' . ' | | c = = ' : ' ) { <nl> + } else if ( c = = ' . ' | | c = = ' : ' | | c = = ' % ' ) { <nl> justName = false ; <nl> + if ( c = = ' % ' ) { <nl> + formatting = true ; <nl> + } <nl> } else if ( ! Character . isJavaIdentifierPart ( c ) ) { <nl> / / This shouldn ' t happen ; we ' ve filtered out these strings in <nl> / / the { @ link # referencedString } method <nl> private void keepPossiblyReferencedResources ( ) { <nl> if ( justName ) { <nl> / / Check name ( below ) <nl> name = string ; <nl> + / / Check for a simple prefix match , e . g . as in <nl> + / / getResources ( ) . getIdentifier ( \" ic_video_codec_ \" + codecName , \" drawable \" , . . . ) <nl> + for ( Resource resource : model . getResources ( ) ) { <nl> + if ( resource . name . startsWith ( name ) ) { <nl> + logger . fine ( String . format ( <nl> + \" Marking % s used because its prefix matches string pool constant % s \" , <nl> + resource , string ) ) ; <nl> + ResourceUsageModel . markReachable ( resource ) ; <nl> + } <nl> + } <nl> } else if ( ! haveSlash ) { <nl> + if ( formatting ) { <nl> + / / Possibly a formatting string , e . g . <nl> + / / String name = String . format ( \" my_prefix_ % 1d \" , index ) ; <nl> + / / int res = getContext ( ) . getResources ( ) . getIdentifier ( name , \" drawable \" , . . . ) <nl> + try { <nl> + Pattern pattern = Pattern . compile ( convertFormatStringToRegexp ( string ) ) ; <nl> + for ( Resource resource : model . getResources ( ) ) { <nl> + if ( pattern . matcher ( resource . name ) . matches ( ) ) { <nl> + logger . fine ( String . format ( <nl> + \" Marking % s used because it format - string matches string pool constant % s \" , <nl> + resource , string ) ) ; <nl> + ResourceUsageModel . markReachable ( resource ) ; <nl> + } <nl> + } <nl> + } catch ( PatternSyntaxException ignored ) { <nl> + / / Might not have been a formatting string after all ! <nl> + } <nl> + } <nl> / / If we have more than just a symbol name , we expect to also see a slash <nl> / / noinspection UnnecessaryContinue <nl> continue ; <nl> private void keepPossiblyReferencedResources ( ) { <nl> if ( type = = null ) { <nl> continue ; <nl> } <nl> - Resource resource = getResource ( type , name ) ; <nl> + Resource resource = model . getResource ( type , name ) ; <nl> if ( resource ! = null ) { <nl> - logger . fine ( \" Marking \" + resource + \" used because it \" <nl> - + \" matches string pool constant \" + string ) ; <nl> + logger . fine ( String . format ( <nl> + \" Marking % s used because it matches string pool constant % s \" , <nl> + resource , string ) ) ; <nl> } <nl> - markReachable ( resource ) ; <nl> + ResourceUsageModel . markReachable ( resource ) ; <nl> continue ; <nl> } <nl> / / fall through and check the name <nl> } <nl> if ( names . contains ( name ) ) { <nl> - for ( Map < String , Resource > map : typeToName . values ( ) ) { <nl> - Resource resource = map . get ( string ) ; <nl> + for ( Map < String , Resource > map : model . getResourceMaps ( ) ) { <nl> + Resource resource = map . get ( name ) ; <nl> if ( resource ! = null ) { <nl> - logger . fine ( \" Marking \" + resource + \" used because it \" <nl> - + \" matches string pool constant \" + string ) ; <nl> + logger . fine ( String . format ( <nl> + \" Marking % s used because it matches string pool constant % s \" , <nl> + resource , string ) ) ; <nl> } <nl> - markReachable ( resource ) ; <nl> + ResourceUsageModel . markReachable ( resource ) ; <nl> } <nl> } else if ( Character . isDigit ( name . charAt ( 0 ) ) ) { <nl> / / Just a number ? There are cases where it calls getIdentifier by <nl> private void keepPossiblyReferencedResources ( ) { <nl> try { <nl> int id = Integer . parseInt ( name ) ; <nl> if ( id ! = 0 ) { <nl> - markReachable ( valueToResource . get ( id ) ) ; <nl> + ResourceUsageModel . markReachable ( model . getResource ( id ) ) ; <nl> } <nl> } catch ( NumberFormatException e ) { <nl> / / pass <nl> private void keepPossiblyReferencedResources ( ) { <nl> } <nl> } <nl> <nl> + @ VisibleForTesting <nl> + static String convertFormatStringToRegexp ( String formatString ) { <nl> + StringBuilder regexp = new StringBuilder ( ) ; <nl> + int from = 0 ; <nl> + boolean hasEscapedLetters = false ; <nl> + Matcher matcher = StringFormatDetector . FORMAT . matcher ( formatString ) ; <nl> + int length = formatString . length ( ) ; <nl> + while ( matcher . find ( from ) ) { <nl> + int start = matcher . start ( ) ; <nl> + int end = matcher . end ( ) ; <nl> + if ( start = = 0 & & end = = length ) { <nl> + / / Don ' t match if the entire string literal starts with % and ends with <nl> + / / the a formatting character , such as just \" % d \" : this just matches absolutely <nl> + / / everything and is unlikely to be used in a resource lookup <nl> + return NO_MATCH ; <nl> + } <nl> + if ( start > from ) { <nl> + hasEscapedLetters | = appendEscapedPattern ( formatString , regexp , from , start ) ; <nl> + } <nl> + / / If the wildcard follows a previous wildcard , just skip it <nl> + / / ( e . g . don ' t convert % s % s into . * . * ; . * is enough . <nl> + int regexLength = regexp . length ( ) ; <nl> + if ( regexLength < 2 <nl> + | | regexp . charAt ( regexLength - 1 ) ! = ' * ' <nl> + | | regexp . charAt ( regexLength - 2 ) ! = ' . ' ) { <nl> + regexp . append ( \" . * \" ) ; <nl> + } <nl> + from = end ; <nl> + } <nl> + if ( from < length ) { <nl> + hasEscapedLetters | = appendEscapedPattern ( formatString , regexp , from , length ) ; <nl> + } <nl> + if ( ! hasEscapedLetters ) { <nl> + / / If the regexp contains * only * formatting characters , e . g . \" % . 0f % d \" , or <nl> + / / if it contains only formatting characters and punctuation , e . g . \" % s_ % d \" , <nl> + / / don ' t treat this as a possible resource name pattern string : it is unlikely <nl> + / / to be intended for actual resource names , and has the side effect of matching <nl> + / / most names . <nl> + return NO_MATCH ; <nl> + } <nl> + return regexp . toString ( ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Appends the characters in the range [ from , to > from formatString as escaped regexp characters <nl> + * into the given string builder . Returns true if there were any letters in the appended text . <nl> + * / <nl> + private static boolean appendEscapedPattern ( <nl> + @ NonNull String formatString , @ NonNull StringBuilder regexp , int from , int to ) { <nl> + regexp . append ( Pattern . quote ( formatString . substring ( from , to ) ) ) ; <nl> + for ( int i = from ; i < to ; i + + ) { <nl> + if ( Character . isLetter ( formatString . charAt ( i ) ) ) { <nl> + return true ; <nl> + } <nl> + } <nl> + return false ; <nl> + } <nl> + <nl> private void recordResources ( Path resDir ) <nl> throws IOException , SAXException , ParserConfigurationException { <nl> <nl> private void recordResources ( Path resDir ) <nl> private void recordResources ( @ NonNull ResourceFolderType folderType , File folder ) <nl> throws ParserConfigurationException , SAXException , IOException { <nl> File [ ] files = folder . listFiles ( ) ; <nl> - FolderConfiguration config = FolderConfiguration . getConfigForFolder ( folder . getName ( ) ) ; <nl> - boolean isDefaultFolder = false ; <nl> - if ( config ! = null ) { <nl> - isDefaultFolder = true ; <nl> - for ( int i = 0 , n = FolderConfiguration . getQualifierCount ( ) ; i < n ; i + + ) { <nl> - ResourceQualifier qualifier = config . getQualifier ( i ) ; <nl> - / / Densities are special : even if they ' re present in just ( say ) drawable - hdpi <nl> - / / we ' ll match it on any other density <nl> - if ( qualifier ! = null & & ! ( qualifier instanceof DensityQualifier ) ) { <nl> - isDefaultFolder = false ; <nl> - break ; <nl> - } <nl> - } <nl> - } <nl> if ( files ! = null ) { <nl> for ( File file : files ) { <nl> String path = file . getPath ( ) ; <nl> - boolean isXml = endsWithIgnoreCase ( path , DOT_XML ) ; <nl> - Resource from = null ; <nl> - / / Record resource for the whole file <nl> - if ( folderType ! = ResourceFolderType . VALUES ) { <nl> - List < ResourceType > types = FolderTypeRelationship . getRelatedResourceTypes ( <nl> - folderType ) ; <nl> - ResourceType type = types . get ( 0 ) ; <nl> - assert type ! = ResourceType . ID : folderType ; <nl> - String name = file . getName ( ) ; <nl> - int extension = name . indexOf ( ' . ' ) ; <nl> - if ( extension > 0 ) { <nl> - name = name . substring ( 0 , extension ) ; <nl> - } <nl> - Resource resource = getResource ( type , name ) ; <nl> - if ( resource ! = null ) { <nl> - resource . addLocation ( file ) ; <nl> - if ( isDefaultFolder ) { <nl> - resource . hasDefault = true ; <nl> - } <nl> - from = resource ; <nl> + model . file = file ; <nl> + try { <nl> + boolean isXml = endsWithIgnoreCase ( path , DOT_XML ) ; <nl> + if ( isXml ) { <nl> + String xml = Files . toString ( file , UTF_8 ) ; <nl> + Document document = XmlUtils . parseDocument ( xml , true ) ; <nl> + model . visitXmlDocument ( file , folderType , document ) ; <nl> + } else { <nl> + model . visitBinaryResource ( folderType , file ) ; <nl> } <nl> - } <nl> - if ( isXml ) { <nl> - / / For value files , and drawables and colors etc also pull in resource <nl> - / / references inside the file <nl> - recordResourcesUsages ( file , isDefaultFolder , from ) ; <nl> + } finally { <nl> + model . file = null ; <nl> } <nl> } <nl> } <nl> private void recordMapping ( @ Nullable Path mapping ) throws IOException { <nl> } <nl> int index = line . indexOf ( resourceIndicator ) ; <nl> if ( index = = - 1 ) { <nl> + / / Record obfuscated names of a few known appcompat usages of <nl> + / / Resources # getIdentifier that are unlikely to be used for general <nl> + / / resource name reflection <nl> + if ( line . startsWith ( \" android . support . v7 . widget . SuggestionsAdapter \" ) ) { <nl> + suggestionsAdapter = <nl> + line . substring ( <nl> + line . indexOf ( arrowIndicator ) + arrowIndicator . length ( ) , <nl> + line . indexOf ( ' : ' ) ! = - 1 ? line . indexOf ( ' : ' ) : line . length ( ) ) <nl> + . trim ( ) <nl> + . replace ( ' . ' , ' / ' ) <nl> + + DOT_CLASS ; <nl> + } else if ( line . startsWith ( \" android . support . v7 . internal . widget . ResourcesWrapper \" ) <nl> + | | line . startsWith ( \" android . support . v7 . widget . ResourcesWrapper \" ) <nl> + | | ( resourcesWrapper = = null / / Recently wrapper moved <nl> + & & line . startsWith ( <nl> + \" android . support . v7 . widget . TintContextWrapper $ TintResources \" ) ) ) { <nl> + resourcesWrapper = <nl> + line . substring ( <nl> + line . indexOf ( arrowIndicator ) + arrowIndicator . length ( ) , <nl> + line . indexOf ( ' : ' ) ! = - 1 ? line . indexOf ( ' : ' ) : line . length ( ) ) <nl> + . trim ( ) <nl> + . replace ( ' . ' , ' / ' ) <nl> + + DOT_CLASS ; <nl> + } <nl> continue ; <nl> } <nl> int arrow = line . indexOf ( arrowIndicator , index + 3 ) ; <nl> private void recordMapping ( @ Nullable Path mapping ) throws IOException { <nl> end = line . length ( ) ; <nl> } <nl> String target = line . substring ( arrow + arrowIndicator . length ( ) , end ) . trim ( ) ; <nl> - String ownerName = target . replace ( ' . ' , ' / ' ) ; <nl> - <nl> + String ownerName = AsmUtils . toInternalName ( target ) ; <nl> nameMap = Maps . newHashMap ( ) ; <nl> Pair < ResourceType , Map < String , String > > pair = Pair . of ( type , nameMap ) ; <nl> resourceObfuscation . put ( ownerName , pair ) ; <nl> + / / For fast lookup in isResourceClass <nl> + resourceObfuscation . put ( ownerName + DOT_CLASS , pair ) ; <nl> } <nl> } <nl> <nl> private void recordManifestUsages ( Path manifest ) <nl> throws IOException , ParserConfigurationException , SAXException { <nl> String xml = Files . toString ( manifest . toFile ( ) , UTF_8 ) ; <nl> Document document = XmlUtils . parseDocument ( xml , true ) ; <nl> - recordManifestUsages ( document . getDocumentElement ( ) ) ; <nl> - } <nl> - <nl> - private void recordResourcesUsages ( @ NonNull File file , boolean isDefaultFolder , <nl> - @ Nullable Resource from ) <nl> - throws IOException , ParserConfigurationException , SAXException { <nl> - String xml = Files . toString ( file , UTF_8 ) ; <nl> - Document document = XmlUtils . parseDocument ( xml , true ) ; <nl> - recordResourceReferences ( file , isDefaultFolder , document . getDocumentElement ( ) , from ) ; <nl> - } <nl> - <nl> - @ Nullable <nl> - private Resource getResource ( @ NonNull ResourceType type , @ NonNull String name ) { <nl> - Map < String , Resource > nameMap = typeToName . get ( type ) ; <nl> - if ( nameMap ! = null ) { <nl> - return nameMap . get ( getFieldName ( name ) ) ; <nl> - } <nl> - return null ; <nl> - } <nl> - <nl> - @ Nullable <nl> - private Resource getResource ( @ NonNull String possibleUrlReference ) { <nl> - ResourceUrl url = ResourceUrl . parse ( possibleUrlReference ) ; <nl> - if ( url ! = null & & ! url . framework ) { <nl> - return getResource ( url . type , url . name ) ; <nl> - } <nl> - return null ; <nl> - } <nl> - <nl> - @ VisibleForTesting <nl> - @ Nullable <nl> - Resource getResourceFromCode ( @ NonNull String owner , @ NonNull String name ) { <nl> - Pair < ResourceType , Map < String , String > > pair = resourceObfuscation . get ( owner ) ; <nl> - if ( pair ! = null ) { <nl> - ResourceType type = pair . getFirst ( ) ; <nl> - Map < String , String > nameMap = pair . getSecond ( ) ; <nl> - String renamedField = nameMap . get ( name ) ; <nl> - if ( renamedField ! = null ) { <nl> - name = renamedField ; <nl> - } <nl> - return getResource ( type , name ) ; <nl> - } <nl> - return null ; <nl> - } <nl> - <nl> - private void recordManifestUsages ( Node node ) { <nl> - short nodeType = node . getNodeType ( ) ; <nl> - if ( nodeType = = Node . ELEMENT_NODE ) { <nl> - Element element = ( Element ) node ; <nl> - NamedNodeMap attributes = element . getAttributes ( ) ; <nl> - for ( int i = 0 , n = attributes . getLength ( ) ; i < n ; i + + ) { <nl> - Attr attr = ( Attr ) attributes . item ( i ) ; <nl> - markReachable ( getResource ( attr . getValue ( ) ) ) ; <nl> - } <nl> - } else if ( nodeType = = Node . TEXT_NODE ) { <nl> - / / Does this apply to any manifests ? ? <nl> - String text = node . getNodeValue ( ) . trim ( ) ; <nl> - markReachable ( getResource ( text ) ) ; <nl> - } <nl> - NodeList children = node . getChildNodes ( ) ; <nl> - for ( int i = 0 , n = children . getLength ( ) ; i < n ; i + + ) { <nl> - Node child = children . item ( i ) ; <nl> - recordManifestUsages ( child ) ; <nl> - } <nl> - } <nl> - <nl> - private void recordResourceReferences ( @ NonNull File file , boolean isDefaultFolder , <nl> - @ NonNull Node node , @ Nullable Resource from ) { <nl> - short nodeType = node . getNodeType ( ) ; <nl> - if ( nodeType = = Node . ELEMENT_NODE ) { <nl> - Element element = ( Element ) node ; <nl> - if ( from ! = null ) { <nl> - NamedNodeMap attributes = element . getAttributes ( ) ; <nl> - for ( int i = 0 , n = attributes . getLength ( ) ; i < n ; i + + ) { <nl> - Attr attr = ( Attr ) attributes . item ( i ) ; <nl> - Resource resource = getResource ( attr . getValue ( ) ) ; <nl> - if ( resource ! = null ) { <nl> - from . addReference ( resource ) ; <nl> - } <nl> - } <nl> - / / Android Wear . We * could * limit ourselves to only doing this in files <nl> - / / referenced from a manifest meta - data element , e . g . <nl> - / / < meta - data android : name = \" com . google . android . wearable . beta . app \" <nl> - / / android : resource = \" @ xml / wearable_app_desc \" / > <nl> - / / but given that that property has \" beta \" in the name , it seems likely <nl> - / / to change and therefore hardcoding it for that key risks breakage <nl> - / / in the future . <nl> - if ( \" rawPathResId \" . equals ( element . getTagName ( ) ) ) { <nl> - StringBuilder sb = new StringBuilder ( ) ; <nl> - NodeList children = node . getChildNodes ( ) ; <nl> - for ( int i = 0 , n = children . getLength ( ) ; i < n ; i + + ) { <nl> - Node child = children . item ( i ) ; <nl> - if ( child . getNodeType ( ) = = Element . TEXT_NODE <nl> - | | child . getNodeType ( ) = = Element . CDATA_SECTION_NODE ) { <nl> - sb . append ( child . getNodeValue ( ) ) ; <nl> - } <nl> - } <nl> - if ( sb . length ( ) > 0 ) { <nl> - Resource resource = getResource ( ResourceType . RAW , sb . toString ( ) . trim ( ) ) ; <nl> - from . addReference ( resource ) ; <nl> - } <nl> - } <nl> - } <nl> - Resource definition = getResource ( element ) ; <nl> - if ( definition ! = null ) { <nl> - from = definition ; <nl> - definition . addLocation ( file ) ; <nl> - if ( isDefaultFolder ) { <nl> - definition . hasDefault = true ; <nl> - } <nl> - } <nl> - String tagName = element . getTagName ( ) ; <nl> - if ( TAG_STYLE . equals ( tagName ) ) { <nl> - if ( element . hasAttribute ( ATTR_PARENT ) ) { <nl> - String parent = element . getAttribute ( ATTR_PARENT ) ; <nl> - if ( ! parent . isEmpty ( ) & & ! parent . startsWith ( ANDROID_STYLE_RESOURCE_PREFIX ) <nl> - & & ! parent . startsWith ( PREFIX_ANDROID ) ) { <nl> - String parentStyle = parent ; <nl> - if ( ! parentStyle . startsWith ( STYLE_RESOURCE_PREFIX ) ) { <nl> - parentStyle = STYLE_RESOURCE_PREFIX + parentStyle ; <nl> - } <nl> - Resource ps = getResource ( getFieldName ( parentStyle ) ) ; <nl> - if ( ps ! = null & & definition ! = null ) { <nl> - definition . addReference ( ps ) ; <nl> - } <nl> - } <nl> - } else { <nl> - / / Implicit parent styles by name <nl> - String name = getFieldName ( element ) ; <nl> - while ( true ) { <nl> - int index = name . lastIndexOf ( ' _ ' ) ; <nl> - if ( index ! = - 1 ) { <nl> - name = name . substring ( 0 , index ) ; <nl> - Resource ps = getResource ( STYLE_RESOURCE_PREFIX + getFieldName ( name ) ) ; <nl> - if ( ps ! = null & & definition ! = null ) { <nl> - definition . addReference ( ps ) ; <nl> - } <nl> - } else { <nl> - break ; <nl> - } <nl> - } <nl> - } <nl> - } <nl> - if ( TAG_ITEM . equals ( tagName ) ) { <nl> - / / In style ? If so the name : attribute can be a reference <nl> - if ( element . getParentNode ( ) ! = null <nl> - & & element . getParentNode ( ) . getNodeName ( ) . equals ( TAG_STYLE ) ) { <nl> - String name = element . getAttributeNS ( ANDROID_URI , ATTR_NAME ) ; <nl> - if ( ! name . isEmpty ( ) & & ! name . startsWith ( \" android : \" ) ) { <nl> - Resource resource = getResource ( ResourceType . ATTR , name ) ; <nl> - if ( definition = = null ) { <nl> - Element style = ( Element ) element . getParentNode ( ) ; <nl> - definition = getResource ( style ) ; <nl> - if ( definition ! = null ) { <nl> - from = definition ; <nl> - definition . addReference ( resource ) ; <nl> - } <nl> - } <nl> - } <nl> - } <nl> - } <nl> - } else if ( nodeType = = Node . TEXT_NODE | | nodeType = = Node . CDATA_SECTION_NODE ) { <nl> - String text = node . getNodeValue ( ) . trim ( ) ; <nl> - Resource textResource = getResource ( getFieldName ( text ) ) ; <nl> - if ( textResource ! = null & & from ! = null ) { <nl> - from . addReference ( textResource ) ; <nl> - } <nl> - } <nl> - NodeList children = node . getChildNodes ( ) ; <nl> - for ( int i = 0 , n = children . getLength ( ) ; i < n ; i + + ) { <nl> - Node child = children . item ( i ) ; <nl> - recordResourceReferences ( file , isDefaultFolder , child , from ) ; <nl> - } <nl> + model . visitXmlDocument ( manifest . toFile ( ) , null , document ) ; <nl> } <nl> <nl> public static String getFieldName ( @ NonNull String styleName ) { <nl> return styleName . replace ( ' . ' , ' _ ' ) . replace ( ' - ' , ' _ ' ) . replace ( ' : ' , ' _ ' ) ; <nl> } <nl> <nl> - private static void markReachable ( @ Nullable Resource resource ) { <nl> - if ( resource ! = null ) { <nl> - resource . reachable = true ; <nl> - } <nl> - } <nl> - <nl> - private Set < String > mStrings ; <nl> - private boolean mFoundGetIdentifier ; <nl> + private Set < String > strings ; <nl> + private boolean foundGetIdentifier ; <nl> + private boolean foundWebContent ; <nl> <nl> private void referencedString ( @ NonNull String string ) { <nl> / / See if the string is at all eligible ; ignore strings that aren ' t <nl> / / identifiers ( has java identifier chars and nothing but . : / ) , or are empty or too long <nl> + / / We also allow \" % \" , used for formatting strings . <nl> if ( string . isEmpty ( ) | | string . length ( ) > 80 ) { <nl> return ; <nl> } <nl> private void referencedString ( @ NonNull String string ) { <nl> for ( int i = 0 , n = string . length ( ) ; i < n ; i + + ) { <nl> char c = string . charAt ( i ) ; <nl> boolean identifierChar = Character . isJavaIdentifierPart ( c ) ; <nl> - if ( ! identifierChar & & c ! = ' . ' & & c ! = ' : ' & & c ! = ' / ' ) { <nl> - / / . : / are for the fully qualified resuorce names <nl> + if ( ! identifierChar & & c ! = ' . ' & & c ! = ' : ' & & c ! = ' / ' & & c ! = ' % ' ) { <nl> + / / . : / are for the fully qualified resource names , or for resource URLs or <nl> + / / relative file names <nl> return ; <nl> } else if ( identifierChar ) { <nl> haveIdentifierChar = true ; <nl> private void referencedString ( @ NonNull String string ) { <nl> if ( ! haveIdentifierChar ) { <nl> return ; <nl> } <nl> - if ( mStrings = = null ) { <nl> - mStrings = Sets . newHashSetWithExpectedSize ( 300 ) ; <nl> + if ( strings = = null ) { <nl> + strings = Sets . newHashSetWithExpectedSize ( 300 ) ; <nl> } <nl> - mStrings . add ( string ) ; <nl> - } <nl> + strings . add ( string ) ; <nl> <nl> - private void recordUsages ( Path jarFile ) throws IOException { <nl> - if ( ! jarFile . toFile ( ) . exists ( ) ) { <nl> - return ; <nl> + if ( ! foundWebContent & & string . contains ( ANDROID_RES ) ) { <nl> + foundWebContent = true ; <nl> } <nl> - ZipInputStream zis = null ; <nl> - try { <nl> - FileInputStream fis = new FileInputStream ( jarFile . toFile ( ) ) ; <nl> - try { <nl> - zis = new ZipInputStream ( fis ) ; <nl> - ZipEntry entry = zis . getNextEntry ( ) ; <nl> - while ( entry ! = null ) { <nl> - String name = entry . getName ( ) ; <nl> - if ( name . endsWith ( DOT_CLASS ) ) { <nl> - byte [ ] bytes = ByteStreams . toByteArray ( zis ) ; <nl> - if ( bytes ! = null ) { <nl> - ClassReader classReader = new ClassReader ( bytes ) ; <nl> - classReader . accept ( new UsageVisitor ( ) , 0 ) ; <nl> + } <nl> + <nl> + private void recordClassUsages ( Path file ) throws IOException { <nl> + if ( file . toFile ( ) . isDirectory ( ) ) { <nl> + File [ ] children = file . toFile ( ) . listFiles ( ) ; <nl> + if ( children ! = null ) { <nl> + for ( File child : children ) { <nl> + recordClassUsages ( child . toPath ( ) ) ; <nl> + } <nl> + } <nl> + } else if ( file . toFile ( ) . isFile ( ) ) { <nl> + if ( file . toFile ( ) . getPath ( ) . endsWith ( DOT_CLASS ) ) { <nl> + byte [ ] bytes = Files . toByteArray ( file . toFile ( ) ) ; <nl> + recordClassUsages ( file . toFile ( ) , file . toFile ( ) . getName ( ) , bytes ) ; <nl> + } else if ( file . toFile ( ) . getPath ( ) . endsWith ( DOT_JAR ) ) { <nl> + ZipInputStream zis = null ; <nl> + try { <nl> + FileInputStream fis = new FileInputStream ( file . toFile ( ) ) ; <nl> + try { <nl> + zis = new ZipInputStream ( fis ) ; <nl> + ZipEntry entry = zis . getNextEntry ( ) ; <nl> + while ( entry ! = null ) { <nl> + String name = entry . getName ( ) ; <nl> + if ( name . endsWith ( DOT_CLASS ) <nl> + & & <nl> + / / Skip resource type classes like R $ drawable ; they will <nl> + / / reference the integer id ' s we ' re looking for , but these aren ' t <nl> + / / actual usages we need to track ; if somebody references the <nl> + / / field elsewhere , we ' ll catch that <nl> + ! isResourceClass ( name ) ) { <nl> + byte [ ] bytes = ByteStreams . toByteArray ( zis ) ; <nl> + if ( bytes ! = null ) { <nl> + recordClassUsages ( file . toFile ( ) , name , bytes ) ; <nl> + } <nl> + } <nl> + entry = zis . getNextEntry ( ) ; <nl> } <nl> + } finally { <nl> + Closeables . close ( fis , true ) ; <nl> } <nl> - entry = zis . getNextEntry ( ) ; <nl> + } finally { <nl> + Closeables . close ( zis , true ) ; <nl> } <nl> - } finally { <nl> - Closeables . close ( fis , true ) ; <nl> } <nl> - } finally { <nl> - Closeables . close ( zis , true ) ; <nl> } <nl> } <nl> <nl> + private void recordClassUsages ( File file , String name , byte [ ] bytes ) { <nl> + ClassReader classReader = new ClassReader ( bytes ) ; <nl> + classReader . accept ( new UsageVisitor ( file , name ) , SKIP_DEBUG | SKIP_FRAMES ) ; <nl> + } <nl> + <nl> private void parseResourceTxtFile ( Path rTxt , Set < String > resourcePackages ) throws IOException { <nl> BufferedReader reader = java . nio . file . Files . newBufferedReader ( rTxt , UTF_8 ) ; <nl> String line ; <nl> private void parseResourceTxtFile ( Path rTxt , Set < String > resourcePackages ) throw <nl> String [ ] tokens = line . split ( \" \" ) ; <nl> ResourceType type = ResourceType . getEnum ( tokens [ 1 ] ) ; <nl> for ( String resourcePackage : resourcePackages ) { <nl> - resourceObfuscation . put ( resourcePackage . replace ( ' . ' , ' / ' ) + \" / R $ \" + type . getName ( ) , <nl> - Pair . < ResourceType , Map < String , String > > of ( type , Maps . < String , String > newHashMap ( ) ) ) ; <nl> + String owner = resourcePackage . replace ( ' . ' , ' / ' ) + \" / R $ \" + type . getName ( ) ; <nl> + Pair < ResourceType , Map < String , String > > pair = resourceObfuscation . get ( owner ) ; <nl> + if ( pair = = null ) { <nl> + Map < String , String > nameMap = Maps . newHashMap ( ) ; <nl> + pair = Pair . of ( type , nameMap ) ; <nl> + } <nl> + resourceObfuscation . put ( owner , pair ) ; <nl> } <nl> if ( type = = ResourceType . STYLEABLE ) { <nl> if ( tokens [ 0 ] . equals ( \" int [ ] \" ) ) { <nl> - addResource ( ResourceType . DECLARE_STYLEABLE , tokens [ 2 ] , null ) ; <nl> + model . addResource ( ResourceType . DECLARE_STYLEABLE , tokens [ 2 ] , null ) ; <nl> } else { <nl> / / TODO ( jongerrish ) : Implement stripping of styleables . <nl> } <nl> } else { <nl> - addResource ( type , tokens [ 2 ] , tokens [ 3 ] ) ; <nl> + model . addResource ( type , tokens [ 2 ] , tokens [ 3 ] ) ; <nl> } <nl> } <nl> } <nl> <nl> - private void addResource ( @ NonNull ResourceType type , @ NonNull String name , <nl> - @ Nullable String value ) { <nl> - int realValue = value ! = null ? Integer . decode ( value ) : - 1 ; <nl> - Resource resource = getResource ( type , name ) ; <nl> - if ( resource ! = null ) { <nl> - / / noinspection VariableNotUsedInsideIf <nl> - if ( value ! = null ) { <nl> - if ( resource . value = = - 1 ) { <nl> - resource . value = realValue ; <nl> - } else { <nl> - assert realValue = = resource . value ; <nl> - } <nl> - } <nl> - return ; <nl> - } <nl> - resource = new Resource ( type , name , realValue ) ; <nl> - resources . add ( resource ) ; <nl> - if ( realValue ! = - 1 ) { <nl> - valueToResource . put ( realValue , resource ) ; <nl> - } <nl> - Map < String , Resource > nameMap = typeToName . get ( type ) ; <nl> - if ( nameMap = = null ) { <nl> - nameMap = Maps . newHashMapWithExpectedSize ( 30 ) ; <nl> - typeToName . put ( type , nameMap ) ; <nl> - } <nl> - nameMap . put ( name , resource ) ; <nl> - / / TODO : Assert that we don ' t set the same resource multiple times to different values . <nl> - / / Could happen if you pass in stale data ! <nl> - } <nl> - <nl> + / * * Returns whether the given class file name points to an aapt - generated compiled R class * / <nl> @ VisibleForTesting <nl> - List < Resource > getAllResources ( ) { <nl> - return resources ; <nl> - } <nl> - <nl> - / * * <nl> - * Metadata about an Android resource <nl> - * / <nl> - public static class Resource { <nl> - <nl> - / * * <nl> - * Type of resource <nl> - * / <nl> - public ResourceType type ; <nl> - / * * <nl> - * Name of resource <nl> - * / <nl> - public String name ; <nl> - / * * <nl> - * Integer id location <nl> - * / <nl> - public int value ; <nl> - / * * <nl> - * Whether this resource can be reached from one of the roots ( manifest , code ) <nl> - * / <nl> - public boolean reachable ; <nl> - / * * <nl> - * Whether this resource has a default definition ( e . g . present in a resource folder with no <nl> - * qualifiers ) . For id references , an inline definition ( @ + id ) does not count as a default <nl> - * definition . <nl> - * / <nl> - public boolean hasDefault ; <nl> - / * * <nl> - * Resources this resource references . For example , a layout can reference another via an <nl> - * include ; a style reference in a layout references that layout style , and so on . <nl> - * / <nl> - public List < Resource > references ; <nl> - public final List < File > declarations = Lists . newArrayList ( ) ; <nl> - <nl> - private Resource ( ResourceType type , String name , int value ) { <nl> - this . type = type ; <nl> - this . name = name ; <nl> - this . value = value ; <nl> - } <nl> - <nl> - @ Override <nl> - public String toString ( ) { <nl> - return type + \" : \" + name + \" : \" + value ; <nl> - } <nl> - <nl> - @ SuppressWarnings ( \" RedundantIfStatement \" ) / / Generated by IDE <nl> - @ Override <nl> - public boolean equals ( Object o ) { <nl> - if ( this = = o ) { <nl> - return true ; <nl> - } <nl> - if ( o = = null | | getClass ( ) ! = o . getClass ( ) ) { <nl> - return false ; <nl> - } <nl> - Resource resource = ( Resource ) o ; <nl> - if ( name ! = null ? ! name . equals ( resource . name ) : resource . name ! = null ) { <nl> - return false ; <nl> - } <nl> - if ( type ! = resource . type ) { <nl> - return false ; <nl> - } <nl> + boolean isResourceClass ( @ NonNull String name ) { <nl> + if ( resourceObfuscation . containsKey ( name ) ) { <nl> return true ; <nl> } <nl> - <nl> - @ Override <nl> - public int hashCode ( ) { <nl> - int result = type ! = null ? type . hashCode ( ) : 0 ; <nl> - result = 31 * result + ( name ! = null ? name . hashCode ( ) : 0 ) ; <nl> - return result ; <nl> - } <nl> - <nl> - public void addLocation ( @ NonNull File file ) { <nl> - declarations . add ( file ) ; <nl> + assert name . endsWith ( DOT_CLASS ) : name ; <nl> + int index = name . lastIndexOf ( ' / ' ) ; <nl> + if ( index ! = - 1 & & name . startsWith ( \" R $ \" , index + 1 ) ) { <nl> + String typeName = name . substring ( index + 3 , name . length ( ) - DOT_CLASS . length ( ) ) ; <nl> + return ResourceType . getEnum ( typeName ) ! = null ; <nl> } <nl> + return false ; <nl> + } <nl> <nl> - public void addReference ( @ Nullable Resource resource ) { <nl> - if ( resource ! = null ) { <nl> - if ( references = = null ) { <nl> - references = Lists . newArrayList ( ) ; <nl> - } else if ( references . contains ( resource ) ) { <nl> - return ; <nl> - } <nl> - references . add ( resource ) ; <nl> + @ VisibleForTesting <nl> + @ Nullable <nl> + Resource getResourceFromCode ( @ NonNull String owner , @ NonNull String name ) { <nl> + Pair < ResourceType , Map < String , String > > pair = resourceObfuscation . get ( owner ) ; <nl> + if ( pair ! = null ) { <nl> + ResourceType type = pair . getFirst ( ) ; <nl> + Map < String , String > nameMap = pair . getSecond ( ) ; <nl> + String renamedField = nameMap . get ( name ) ; <nl> + if ( renamedField ! = null ) { <nl> + name = renamedField ; <nl> } <nl> + return model . getResource ( type , name ) ; <nl> } <nl> + return null ; <nl> + } <nl> <nl> - public String getUrl ( ) { <nl> - return ' @ ' + type . getName ( ) + ' / ' + name ; <nl> - } <nl> + public int getUnusedResourceCount ( ) { <nl> + return unused . size ( ) ; <nl> + } <nl> <nl> - public boolean isRelevantType ( ) { <nl> - return type ! = ResourceType . ID ; / / & & getFolderType ( ) ! = ResourceFolderType . VALUES ; <nl> - } <nl> + @ VisibleForTesting <nl> + ResourceUsageModel getModel ( ) { <nl> + return model ; <nl> } <nl> <nl> + / * * <nl> + * Class visitor responsible for looking for resource references in code . It looks for R . type . name <nl> + * references ( as well as inlined constants for these , in the case of non - library code ) , as well <nl> + * as looking both for Resources # getIdentifier calls and recording string literals , used to handle <nl> + * dynamic lookup of resources . <nl> + * / <nl> private class UsageVisitor extends ClassVisitor { <nl> + private final File jarFile ; <nl> + private final String currentClass ; <nl> <nl> - public UsageVisitor ( ) { <nl> + public UsageVisitor ( File jarFile , String name ) { <nl> super ( Opcodes . ASM5 ) ; <nl> + this . jarFile = jarFile ; <nl> + currentClass = name ; <nl> } <nl> <nl> @ Override <nl> - public MethodVisitor visitMethod ( int access , final String name , <nl> - String desc , String signature , String [ ] exceptions ) { <nl> + public MethodVisitor visitMethod ( <nl> + int access , final String name , String desc , String signature , String [ ] exceptions ) { <nl> return new MethodVisitor ( Opcodes . ASM5 ) { <nl> @ Override <nl> public void visitLdcInsn ( Object cst ) { <nl> - if ( cst instanceof Integer ) { <nl> - Integer value = ( Integer ) cst ; <nl> - markReachable ( valueToResource . get ( value ) ) ; <nl> - } else if ( cst instanceof String ) { <nl> - String string = ( String ) cst ; <nl> - referencedString ( string ) ; <nl> - } <nl> + handleCodeConstant ( cst , \" ldc \" ) ; <nl> } <nl> <nl> @ Override <nl> public void visitFieldInsn ( int opcode , String owner , String name , String desc ) { <nl> if ( opcode = = Opcodes . GETSTATIC ) { <nl> Resource resource = getResourceFromCode ( owner , name ) ; <nl> if ( resource ! = null ) { <nl> - markReachable ( resource ) ; <nl> + ResourceUsageModel . markReachable ( resource ) ; <nl> } <nl> } <nl> } <nl> <nl> @ Override <nl> public void visitMethodInsn ( <nl> - int opcode , String owner , String name , String desc , boolean isInterface ) { <nl> - super . visitMethodInsn ( opcode , owner , name , desc , isInterface ) ; <nl> + int opcode , String owner , String name , String desc , boolean itf ) { <nl> + super . visitMethodInsn ( opcode , owner , name , desc , itf ) ; <nl> if ( owner . equals ( \" android / content / res / Resources \" ) <nl> & & name . equals ( \" getIdentifier \" ) <nl> & & desc . equals ( \" ( Ljava / lang / String ; Ljava / lang / String ; Ljava / lang / String ; ) I \" ) ) { <nl> - mFoundGetIdentifier = true ; <nl> + if ( currentClass . equals ( resourcesWrapper ) <nl> + | | currentClass . equals ( suggestionsAdapter ) ) { <nl> + / / \" benign \" usages : don ' t trigger reflection mode just because <nl> + / / the user has included appcompat <nl> + return ; <nl> + } <nl> + foundGetIdentifier = true ; <nl> / / TODO : Check previous instruction and see if we can find a literal <nl> / / String ; if so , we can more accurately dispatch the resource here <nl> / / rather than having to check the whole string pool ! <nl> } <nl> + if ( owner . equals ( \" android / webkit / WebView \" ) & & name . startsWith ( \" load \" ) ) { <nl> + foundWebContent = true ; <nl> + } <nl> + } <nl> + <nl> + @ Override <nl> + public AnnotationVisitor visitAnnotationDefault ( ) { <nl> + return new AnnotationUsageVisitor ( ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public AnnotationVisitor visitAnnotation ( String desc , boolean visible ) { <nl> + return new AnnotationUsageVisitor ( ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public AnnotationVisitor visitParameterAnnotation ( <nl> + int parameter , String desc , boolean visible ) { <nl> + return new AnnotationUsageVisitor ( ) ; <nl> } <nl> } ; <nl> } <nl> + <nl> + @ Override <nl> + public AnnotationVisitor visitAnnotation ( String desc , boolean visible ) { <nl> + return new AnnotationUsageVisitor ( ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public FieldVisitor visitField ( <nl> + int access , String name , String desc , String signature , Object value ) { <nl> + handleCodeConstant ( value , \" field \" ) ; <nl> + return new FieldVisitor ( Opcodes . ASM5 ) { <nl> + @ Override <nl> + public AnnotationVisitor visitAnnotation ( String desc , boolean visible ) { <nl> + return new AnnotationUsageVisitor ( ) ; <nl> + } <nl> + } ; <nl> + } <nl> + <nl> + private class AnnotationUsageVisitor extends AnnotationVisitor { <nl> + public AnnotationUsageVisitor ( ) { <nl> + super ( Opcodes . ASM5 ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public AnnotationVisitor visitAnnotation ( String name , String desc ) { <nl> + return new AnnotationUsageVisitor ( ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public AnnotationVisitor visitArray ( String name ) { <nl> + return new AnnotationUsageVisitor ( ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public void visit ( String name , Object value ) { <nl> + handleCodeConstant ( value , \" annotation \" ) ; <nl> + super . visit ( name , value ) ; <nl> + } <nl> + } <nl> + / * * Invoked when an ASM visitor encounters a constant : record corresponding reference * / <nl> + private void handleCodeConstant ( @ Nullable Object cst , @ NonNull String context ) { <nl> + if ( cst instanceof Integer ) { <nl> + Integer value = ( Integer ) cst ; <nl> + Resource resource = model . getResource ( value ) ; <nl> + if ( ResourceUsageModel . markReachable ( resource ) ) { <nl> + logger . fine ( String . format ( \" Marking % s reachable : referenced from % s in % s : % s \" , <nl> + resource , context , jarFile , currentClass ) ) ; <nl> + } <nl> + } else if ( cst instanceof int [ ] ) { <nl> + int [ ] values = ( int [ ] ) cst ; <nl> + for ( int value : values ) { <nl> + Resource resource = model . getResource ( value ) ; <nl> + if ( ResourceUsageModel . markReachable ( resource ) ) { <nl> + logger . fine ( String . format ( \" Marking % s reachable : referenced from % s in % s : % s \" , <nl> + resource , context , jarFile , currentClass ) ) ; <nl> + } <nl> + } <nl> + } else if ( cst instanceof String ) { <nl> + String string = ( String ) cst ; <nl> + referencedString ( string ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + private final ResourceShrinkerUsageModel model = new ResourceShrinkerUsageModel ( ) ; <nl> + <nl> + private class ResourceShrinkerUsageModel extends ResourceUsageModel { <nl> + public File file ; <nl> + <nl> + @ NonNull <nl> + @ Override <nl> + protected List < Resource > findRoots ( @ NonNull List < Resource > resources ) { <nl> + List < Resource > roots = super . findRoots ( resources ) ; <nl> + logger . fine ( \" The root reachable resources are : \\ n \" + Joiner . on ( \" , \\ n \" ) . join ( roots ) + \" \\ n \" ) ; <nl> + return roots ; <nl> + } <nl> + <nl> + @ Override <nl> + protected Resource declareResource ( ResourceType type , String name , Node node ) { <nl> + Resource resource = super . declareResource ( type , name , node ) ; <nl> + resource . addLocation ( file ) ; <nl> + return resource ; <nl> + } <nl> + <nl> + @ Override <nl> + protected void referencedString ( @ NonNull String string ) { <nl> + ResourceUsageAnalyzer . this . referencedString ( string ) ; <nl> + foundWebContent = true ; <nl> + } <nl> + <nl> + @ Override <nl> + public Resource getResource ( Element element ) { <nl> + if ( isPublic ( element ) ) { <nl> + ResourceType type = getTypeFromPublic ( element ) ; <nl> + if ( type ! = null ) { <nl> + String name = getFieldName ( element ) ; <nl> + Resource resource = getResource ( type , name ) ; <nl> + return resource ; <nl> + } <nl> + return null ; <nl> + } else { <nl> + return super . getResource ( element ) ; <nl> + } <nl> + } <nl> + <nl> + public boolean isPublic ( Element element ) { <nl> + return element . getTagName ( ) . equals ( ResourceType . PUBLIC . getName ( ) ) ; <nl> + } <nl> + <nl> + public ResourceType getTypeFromPublic ( Element element ) { <nl> + String typeName = element . getAttribute ( ATTR_TYPE ) ; <nl> + if ( ! typeName . isEmpty ( ) ) { <nl> + return ResourceType . getEnum ( typeName ) ; <nl> + } <nl> + return null ; <nl> + } <nl> + <nl> + @ Override <nl> + public void recordResourceReferences ( ResourceFolderType folderType , Node node , Resource from ) { <nl> + super . recordResourceReferences ( folderType , node , from ) ; <nl> + / / The parent class does not consider id declarations in xml files to also be uses , which is <nl> + / / wrong . Fix that behavior here by adding a reference to any id declarations . <nl> + if ( from ! = null & & node . getNodeType ( ) = = Node . ELEMENT_NODE ) { <nl> + NamedNodeMap attributes = ( ( Element ) node ) . getAttributes ( ) ; <nl> + for ( int i = 0 ; i < attributes . getLength ( ) ; i + + ) { <nl> + Attr attr = ( Attr ) attributes . item ( i ) ; <nl> + if ( attr . getValue ( ) . startsWith ( SdkConstants . PREFIX_RESOURCE_REF ) <nl> + & & SdkConstants . ATTR_ID . equals ( attr . getLocalName ( ) ) <nl> + & & SdkConstants . ANDROID_URI . equals ( attr . getNamespaceURI ( ) ) ) { <nl> + ResourceUrl url = ResourceUrl . parse ( attr . getValue ( ) ) ; <nl> + if ( url ! = null ) { <nl> + Resource resource = getResource ( url . type , url . name ) ; <nl> + if ( resource ! = null ) { <nl> + from . addReference ( resource ) ; <nl> + } <nl> + } <nl> + } <nl> + } <nl> + } <nl> + } <nl> } <nl> } <nl>\n", "msg": "Update depot version of ResourceUsageAnalyzer . java from the public Gradle source . This version includes :\n"}
{"diff_id": 731, "repo": "Netflix/Hystrix\n", "sha": "f383c1e0ba0832b8034e7c08a6a0aafc213ef6cc\n", "time": "2012-12-11T16:01:54Z\n", "diff": "mmm a / hystrix - core / src / main / java / com / netflix / hystrix / HystrixCommandProperties . java <nl> ppp b / hystrix - core / src / main / java / com / netflix / hystrix / HystrixCommandProperties . java <nl> <nl> private final HystrixProperty < Integer > metricsRollingStatisticalWindowInMilliseconds ; / / milliseconds back that will be tracked <nl> private final HystrixProperty < Integer > metricsRollingStatisticalWindowBuckets ; / / number of buckets in the statisticalWindow <nl> private final HystrixProperty < Boolean > metricsRollingPercentileEnabled ; / / Whether monitoring should be enabled ( SLA and Tracers ) . <nl> - private final HystrixProperty < Integer > metricsRollingPercentileWindow ; / / number of milliseconds that will be tracked in RollingPercentile <nl> + private final HystrixProperty < Integer > metricsRollingPercentileWindowInMilliseconds ; / / number of milliseconds that will be tracked in RollingPercentile <nl> private final HystrixProperty < Integer > metricsRollingPercentileWindowBuckets ; / / number of buckets percentileWindow will be divided into <nl> private final HystrixProperty < Integer > metricsRollingPercentileBucketSize ; / / how many values will be stored in each percentileWindowBucket <nl> private final HystrixProperty < Integer > metricsHealthSnapshotIntervalInMilliseconds ; / / time between health snapshots <nl> protected HystrixCommandProperties ( HystrixCommandKey key , HystrixCommandProperti <nl> this . metricsRollingStatisticalWindowInMilliseconds = getProperty ( propertyPrefix , key , \" metrics . rollingStats . timeInMilliseconds \" , builder . getMetricsRollingStatisticalWindowInMilliseconds ( ) , default_metricsRollingStatisticalWindow ) ; <nl> this . metricsRollingStatisticalWindowBuckets = getProperty ( propertyPrefix , key , \" metrics . rollingStats . numBuckets \" , builder . getMetricsRollingStatisticalWindowBuckets ( ) , default_metricsRollingStatisticalWindowBuckets ) ; <nl> this . metricsRollingPercentileEnabled = getProperty ( propertyPrefix , key , \" metrics . rollingPercentile . enabled \" , builder . getMetricsRollingPercentileEnabled ( ) , default_metricsRollingPercentileEnabled ) ; <nl> - this . metricsRollingPercentileWindow = getProperty ( propertyPrefix , key , \" metrics . rollingPercentile . timeInMilliseconds \" , builder . getMetricsRollingPercentileWindowInMilliseconds ( ) , default_metricsRollingPercentileWindow ) ; <nl> + this . metricsRollingPercentileWindowInMilliseconds = getProperty ( propertyPrefix , key , \" metrics . rollingPercentile . timeInMilliseconds \" , builder . getMetricsRollingPercentileWindowInMilliseconds ( ) , default_metricsRollingPercentileWindow ) ; <nl> this . metricsRollingPercentileWindowBuckets = getProperty ( propertyPrefix , key , \" metrics . rollingPercentile . numBuckets \" , builder . getMetricsRollingPercentileWindowBuckets ( ) , default_metricsRollingPercentileWindowBuckets ) ; <nl> this . metricsRollingPercentileBucketSize = getProperty ( propertyPrefix , key , \" metrics . rollingPercentile . bucketSize \" , builder . getMetricsRollingPercentileBucketSize ( ) , default_metricsRollingPercentileBucketSize ) ; <nl> this . metricsHealthSnapshotIntervalInMilliseconds = getProperty ( propertyPrefix , key , \" metrics . healthSnapshot . intervalInMilliseconds \" , builder . getMetricsHealthSnapshotIntervalInMilliseconds ( ) , default_metricsHealthSnapshotIntervalInMilliseconds ) ; <nl> protected HystrixCommandProperties ( HystrixCommandKey key , HystrixCommandProperti <nl> * Duration of percentile rolling window in milliseconds . This is passed into { @ link HystrixRollingPercentile } inside { @ link HystrixCommandMetrics } . <nl> * <nl> * @ return { @ code HystrixProperty < Integer > } <nl> + * @ deprecated Use { @ link # metricsRollingPercentileWindowInMilliseconds ( ) } <nl> * / <nl> public HystrixProperty < Integer > metricsRollingPercentileWindow ( ) { <nl> - return metricsRollingPercentileWindow ; <nl> + return metricsRollingPercentileWindowInMilliseconds ; <nl> + } <nl> + <nl> + / * * <nl> + * Duration of percentile rolling window in milliseconds . This is passed into { @ link HystrixRollingPercentile } inside { @ link HystrixCommandMetrics } . <nl> + * <nl> + * @ return { @ code HystrixProperty < Integer > } <nl> + * / <nl> + public HystrixProperty < Integer > metricsRollingPercentileWindowInMilliseconds ( ) { <nl> + return metricsRollingPercentileWindowInMilliseconds ; <nl> } <nl> <nl> / * * <nl>\n", "msg": "Refactory of method name to match convention used elsewhere\n"}
{"diff_id": 752, "repo": "SeleniumHQ/selenium\n", "sha": "9c333e9b62bff90e216a18d17346a6144a37d905\n", "time": "2011-12-11T20:36:28Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / remote / RemoteWebDriver . java <nl> ppp b / java / client / src / org / openqa / selenium / remote / RemoteWebDriver . java <nl> <nl> import com . google . common . collect . Lists ; <nl> import com . google . common . collect . Maps ; <nl> <nl> - import org . openqa . selenium . * ; <nl> + import org . openqa . selenium . Alert ; <nl> + import org . openqa . selenium . Beta ; <nl> + import org . openqa . selenium . By ; <nl> + import org . openqa . selenium . Capabilities ; <nl> + import org . openqa . selenium . Cookie ; <nl> + import org . openqa . selenium . Dimension ; <nl> + import org . openqa . selenium . HasCapabilities ; <nl> + import org . openqa . selenium . HasInputDevices ; <nl> + import org . openqa . selenium . JavascriptExecutor ; <nl> + import org . openqa . selenium . Keyboard ; <nl> + import org . openqa . selenium . Mouse ; <nl> + import org . openqa . selenium . Platform ; <nl> + import org . openqa . selenium . Point ; <nl> + import org . openqa . selenium . WebDriver ; <nl> + import org . openqa . selenium . WebDriverException ; <nl> + import org . openqa . selenium . WebElement ; <nl> import org . openqa . selenium . internal . FindsByClassName ; <nl> import org . openqa . selenium . internal . FindsByCssSelector ; <nl> import org . openqa . selenium . internal . FindsById ; <nl> protected Response execute ( String driverCommand , Map < String , ? > parameters ) { <nl> try { <nl> log ( sessionId , command . getName ( ) , command ) ; <nl> <nl> - logger . info ( \" Executing : \" + command ) ; <nl> + logger . fine ( \" Executing : \" + command ) ; <nl> response = executor . execute ( command ) ; <nl> <nl> if ( response = = null ) { <nl>\n", "msg": "JasonLeyba : Logging every executed command at INFO is far too verbose . Scaling it back to FINE .\n"}
{"diff_id": 792, "repo": "apache/rocketmq\n", "sha": "6a466402d9cfc9fb131cad922b265157dbfcc625\n", "time": "2020-08-19T07:47:31Z\n", "diff": "mmm a / client / src / main / java / org / apache / rocketmq / client / consumer / DefaultLitePullConsumer . java <nl> ppp b / client / src / main / java / org / apache / rocketmq / client / consumer / DefaultLitePullConsumer . java <nl> public void setAutoCommit ( boolean autoCommit ) { <nl> this . autoCommit = autoCommit ; <nl> } <nl> <nl> + public boolean isConnectBrokerByUser ( ) { <nl> + return this . defaultLitePullConsumerImpl . getPullAPIWrapper ( ) . isConnectBrokerByUser ( ) ; <nl> + } <nl> + <nl> + public void setConnectBrokerByUser ( boolean connectBrokerByUser ) { <nl> + this . defaultLitePullConsumerImpl . getPullAPIWrapper ( ) . setConnectBrokerByUser ( connectBrokerByUser ) ; <nl> + } <nl> + <nl> + public long getDefaultBrokerId ( ) { <nl> + return this . defaultLitePullConsumerImpl . getPullAPIWrapper ( ) . getDefaultBrokerId ( ) ; <nl> + } <nl> + <nl> + public void setDefaultBrokerId ( long defaultBrokerId ) { <nl> + this . defaultLitePullConsumerImpl . getPullAPIWrapper ( ) . setDefaultBrokerId ( defaultBrokerId ) ; <nl> + } <nl> + <nl> public int getPullThreadNums ( ) { <nl> return pullThreadNums ; <nl> } <nl>\n", "msg": "[ ISSUE ] enhancement : expose config defaultBrokerId and connectBrokerByUser for DefaultLitePullConsumer ( )\n"}
{"diff_id": 907, "repo": "jenkinsci/jenkins\n", "sha": "a6661f152be558c76e64504a21e7faa62d849f03\n", "time": "2009-08-15T06:04:23Z\n", "diff": "mmm a / core / src / main / java / hudson / model / UpdateCenter . java <nl> ppp b / core / src / main / java / hudson / model / UpdateCenter . java <nl> public File download ( DownloadJob job , URL src ) throws IOException { <nl> <nl> in . close ( ) ; <nl> out . close ( ) ; <nl> + <nl> + if ( total ! = - 1 & & total ! = tmp . length ( ) ) { <nl> + / / don ' t know exactly how this happens , but report like <nl> + / / http : / / www . ashlux . com / wordpress / 2009 / 08 / 14 / hudson - and - the - sonar - plugin - fail - maveninstallation - nosuchmethoderror / <nl> + / / indicates that this kind of inconsistency can happen . So let ' s be defensive <nl> + throw new IOException ( \" Inconsistent file length : expected \" + total + \" but only got \" + tmp . length ( ) ) ; <nl> + } <nl> <nl> return tmp ; <nl> } <nl>\n", "msg": "Plugin installation / Hudson upgrade are made more robust in the face of possible connection abortion .\n"}
{"diff_id": 945, "repo": "oracle/graal\n", "sha": "096d01ed8d8fe28b12ea0b54f199e30eea7b263d\n", "time": "2020-09-28T22:06:27Z\n", "diff": "mmm a / substratevm / src / com . oracle . svm . reflect / src / com / oracle / svm / reflect / hosted / ReflectionDataBuilder . java <nl> ppp b / substratevm / src / com . oracle . svm . reflect / src / com / oracle / svm / reflect / hosted / ReflectionDataBuilder . java <nl> private void processClass ( DuringAnalysisAccessImpl access , Class < ? > clazz ) { <nl> clazz . getConstructors ( ) ; <nl> clazz . getDeclaredClasses ( ) ; <nl> clazz . getClasses ( ) ; <nl> - } catch ( NoClassDefFoundError e ) { <nl> + } catch ( TypeNotPresentException | NoClassDefFoundError e ) { <nl> / * <nl> * If any of the methods or fields reference missing types in their signatures a <nl> * NoClassDefFoundError is thrown . Skip registering reflection metadata for this class . <nl> private Executable enclosingMethodOrConstructor ( Class < ? > clazz ) { <nl> try { <nl> enclosingMethod = clazz . getEnclosingMethod ( ) ; <nl> enclosingConstructor = clazz . getEnclosingConstructor ( ) ; <nl> - } catch ( NoClassDefFoundError e ) { <nl> + } catch ( TypeNotPresentException | NoClassDefFoundError e ) { <nl> / * <nl> * If any of the methods or fields in the class of the enclosing method reference <nl> * missing types in their signatures a NoClassDefFoundError is thrown . Skip the class . <nl>\n", "msg": "Defend against TypeNotPresentException in reflection data builder .\n"}
{"diff_id": 972, "repo": "signalapp/Signal-Android\n", "sha": "954b2f22f6d5e6ba0aea029eabd2eb3a003b7212\n", "time": "2018-03-09T18:41:43Z\n", "diff": "mmm a / src / org / thoughtcrime / securesms / RegistrationActivity . java <nl> ppp b / src / org / thoughtcrime / securesms / RegistrationActivity . java <nl> <nl> import org . thoughtcrime . securesms . database . NoExternalStorageException ; <nl> import org . thoughtcrime . securesms . jobs . DirectoryRefreshJob ; <nl> import org . thoughtcrime . securesms . jobs . GcmRefreshJob ; <nl> + import org . thoughtcrime . securesms . lock . RegistrationLockReminders ; <nl> import org . thoughtcrime . securesms . permissions . Permissions ; <nl> import org . thoughtcrime . securesms . push . AccountManagerFactory ; <nl> import org . thoughtcrime . securesms . service . DirectoryRefreshListener ; <nl> protected void onPostExecute ( Integer result ) { <nl> if ( result = = 1 ) { <nl> TextSecurePreferences . setRegistrationLockPin ( RegistrationActivity . this , pin ) ; <nl> TextSecurePreferences . setRegistrationtLockEnabled ( RegistrationActivity . this , true ) ; <nl> + TextSecurePreferences . setRegistrationLockLastReminderTime ( RegistrationActivity . this , System . currentTimeMillis ( ) ) ; <nl> + TextSecurePreferences . setRegistrationLockNextReminderInterval ( RegistrationActivity . this , RegistrationLockReminders . INITIAL_INTERVAL ) ; <nl> + <nl> handleSuccessfulRegistration ( ) ; <nl> } else if ( result = = 2 ) { <nl> RegistrationActivity . this . pin . setText ( \" \" ) ; <nl>\n", "msg": "Don ' t immediately prompt for registration lock pin after reregistration\n"}
{"diff_id": 1059, "repo": "material-components/material-components-android\n", "sha": "74508c89c87f3f17db8f952319ccb4daee60a260\n", "time": "2020-06-19T18:09:34Z\n", "diff": "mmm a / lib / java / com / google / android / material / internal / CollapsingTextHelper . java <nl> ppp b / lib / java / com / google / android / material / internal / CollapsingTextHelper . java <nl> private void drawMultinlineTransition ( <nl> / / Collapsed text <nl> textPaint . setAlpha ( ( int ) ( collapsedTextBlend * originalAlpha ) ) ; <nl> canvas . drawText ( <nl> - textToDrawCollapsed , 0 , textToDrawCollapsed . length ( ) , 0 , - ascent / scale , textPaint ) ; <nl> + textToDrawCollapsed , 0 , textToDrawCollapsed . length ( ) , 0 , - ascent , textPaint ) ; <nl> / / Remove ellipsis for Cross - section animation <nl> String tmp = textToDrawCollapsed . toString ( ) . trim ( ) ; <nl> if ( tmp . endsWith ( ELLIPSIS_NORMAL ) ) { <nl> private void drawMultinlineTransition ( <nl> / / Cross - section between both texts ( should stay at original alpha ) <nl> textPaint . setAlpha ( originalAlpha ) ; <nl> canvas . drawText ( <nl> - tmp , 0 , Math . min ( textLayout . getLineEnd ( 0 ) , tmp . length ( ) ) , 0 , - ascent / scale , textPaint ) ; <nl> + tmp , 0 , Math . min ( textLayout . getLineEnd ( 0 ) , tmp . length ( ) ) , 0 , - ascent , textPaint ) ; <nl> } <nl> <nl> private boolean calculateIsRtl ( @ NonNull CharSequence text ) { <nl>\n", "msg": "[ CollapsingToolbarLayout ] Fixed slight misalignment during transition in multiline mode\n"}
{"diff_id": 1123, "repo": "elastic/elasticsearch\n", "sha": "976d14705a866529b3dd6ec926bac485010f336d\n", "time": "2010-12-30T11:18:00Z\n", "diff": "mmm a / plugins / cloud / aws / src / main / java / org / elasticsearch / discovery / ec2 / Ec2Discovery . java <nl> ppp b / plugins / cloud / aws / src / main / java / org / elasticsearch / discovery / ec2 / Ec2Discovery . java <nl> <nl> break ; <nl> } <nl> } <nl> - / / update the unicast zen ping to add cloud hosts provider <nl> - / / and , while we are at it , use only it and not the multicast for example <nl> - unicastZenPing . addHostsProvider ( new AwsEc2UnicastHostsProvider ( settings , ec2Service . client ( ) ) ) ; <nl> - pingService . zenPings ( ImmutableList . of ( unicastZenPing ) ) ; <nl> + if ( unicastZenPing ! = null ) { <nl> + / / update the unicast zen ping to add cloud hosts provider <nl> + / / and , while we are at it , use only it and not the multicast for example <nl> + unicastZenPing . addHostsProvider ( new AwsEc2UnicastHostsProvider ( settings , ec2Service . client ( ) ) ) ; <nl> + pingService . zenPings ( ImmutableList . of ( unicastZenPing ) ) ; <nl> + } else { <nl> + logger . warn ( \" failed to apply ec2 unicast discovery , no unicast ping found \" ) ; <nl> + } <nl> } <nl> } <nl> } <nl>\n", "msg": "add a warn and don ' t apply ec2 unicast discovery if not found ( will not really happen )\n"}
{"diff_id": 1435, "repo": "oracle/graal\n", "sha": "443d12c113aaf523c78f4e28eb4bf0c61830cf6e\n", "time": "2011-04-27T19:38:22Z\n", "diff": "mmm a / graal / GraalCompiler / src / com / sun / c1x / gen / LIRGenerator . java <nl> ppp b / graal / GraalCompiler / src / com / sun / c1x / gen / LIRGenerator . java <nl> public boolean isNonNull ( XirArgument argument ) { <nl> } <nl> <nl> public boolean requiresNullCheck ( ) { <nl> - return current = = null | | current instanceof InstanceOf | | current instanceof CheckCast ; / / current . canTrap ( ) ; <nl> + return current = = null | | current . canTrap ( ) ; <nl> } <nl> <nl> public boolean requiresBoundsCheck ( ) { <nl> public boolean requiresBoundsCheck ( ) { <nl> } <nl> <nl> public boolean requiresReadBarrier ( ) { <nl> - return current = = null | | current . kind = = CiKind . Object ; <nl> + return current = = null | | true ; <nl> } <nl> <nl> public boolean requiresWriteBarrier ( ) { <nl> - return current = = null | | current . kind = = CiKind . Object ; <nl> + return current = = null | | true ; <nl> } <nl> <nl> public boolean requiresArrayStoreCheck ( ) { <nl>\n", "msg": "Fixed regression wrt write barriers .\n"}
{"diff_id": 1508, "repo": "apache/flink\n", "sha": "ca0fa96bfacdc3a3a9e149b68c282c19fea2e2db\n", "time": "2018-07-12T19:15:29Z\n", "diff": "mmm a / flink - state - backends / flink - statebackend - rocksdb / src / main / java / org / apache / flink / contrib / streaming / state / RocksDBKeyedStateBackend . java <nl> ppp b / flink - state - backends / flink - statebackend - rocksdb / src / main / java / org / apache / flink / contrib / streaming / state / RocksDBKeyedStateBackend . java <nl> <nl> import org . apache . flink . runtime . state . heap . HeapPriorityQueueSetFactory ; <nl> import org . apache . flink . runtime . state . heap . KeyGroupPartitionedPriorityQueue ; <nl> import org . apache . flink . runtime . state . heap . TreeOrderedSetCache ; <nl> - import org . apache . flink . runtime . state . ttl . TtlTimeProvider ; <nl> import org . apache . flink . runtime . state . metainfo . StateMetaInfoSnapshot ; <nl> + import org . apache . flink . runtime . state . ttl . TtlTimeProvider ; <nl> import org . apache . flink . util . ExceptionUtils ; <nl> import org . apache . flink . util . FileUtils ; <nl> import org . apache . flink . util . FlinkRuntimeException ; <nl>\n", "msg": "[ hotfix ] Fixed import order in RocksDBKeyedStateBackend .\n"}
{"diff_id": 1516, "repo": "oracle/graal\n", "sha": "722b0375c419825c58da5a171c64c47f406807c2\n", "time": "2014-10-03T11:29:32Z\n", "diff": "mmm a / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / LIRIntrospection . java <nl> ppp b / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / LIRIntrospection . java <nl> protected static void forEach ( LIRInstruction inst , Object obj , Values values , Op <nl> <nl> if ( i < values . getDirectCount ( ) ) { <nl> Value value = values . getValue ( obj , i ) ; <nl> - doForValue ( inst , mode , proc , outerPosition , i , ValuePosition . NO_SUBINDEX , value ) ; <nl> + doForValue ( inst , values , mode , proc , outerPosition , i , ValuePosition . NO_SUBINDEX , value ) ; <nl> } else { <nl> Value [ ] valueArray = values . getValueArray ( obj , i ) ; <nl> for ( int j = 0 ; j < valueArray . length ; j + + ) { <nl> Value value = valueArray [ j ] ; <nl> - doForValue ( inst , mode , proc , outerPosition , i , j , value ) ; <nl> + doForValue ( inst , values , mode , proc , outerPosition , i , j , value ) ; <nl> } <nl> } <nl> } <nl> } <nl> <nl> - private static void doForValue ( LIRInstruction inst , OperandMode mode , ValuePositionProcedure proc , ValuePosition outerPosition , int index , int subIndex , Value value ) { <nl> - Values values = inst . getLIRInstructionClass ( ) . getValues ( mode ) ; <nl> + private static void doForValue ( LIRInstruction inst , Values values , OperandMode mode , ValuePositionProcedure proc , ValuePosition outerPosition , int index , int subIndex , Value value ) { <nl> ValuePosition position = new ValuePosition ( values , index , subIndex , outerPosition ) ; <nl> if ( value instanceof CompositeValue ) { <nl> CompositeValue composite = ( CompositeValue ) value ; <nl>\n", "msg": "LIRIntrospection : pass the right Values to ValuePositions .\n"}
{"diff_id": 1571, "repo": "elastic/elasticsearch\n", "sha": "7bcee7660a0c43f4692b6965db3bd5ab95cf5868\n", "time": "2012-01-24T10:56:47Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / action / support / master / TransportMasterNodeOperationAction . java <nl> ppp b / src / main / java / org / elasticsearch / action / support / master / TransportMasterNodeOperationAction . java <nl> public void onClose ( ) { <nl> @ Override <nl> public void onTimeout ( TimeValue timeout ) { <nl> clusterService . remove ( this ) ; <nl> - listener . onFailure ( new MasterNotDiscoveredException ( ) ) ; <nl> + listener . onFailure ( new MasterNotDiscoveredException ( \" waited for [ \" + timeout + \" ] \" ) ) ; <nl> } <nl> <nl> @ Override <nl>\n", "msg": "better failure message when no master found ( how long we waited for it )\n"}
{"diff_id": 1783, "repo": "SeleniumHQ/selenium\n", "sha": "194cba59d2bf0999a386b9f50b3dad17d2338f0e\n", "time": "2011-02-12T11:40:42Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / remote / RemoteWebDriver . java <nl> ppp b / java / client / src / org / openqa / selenium / remote / RemoteWebDriver . java <nl> protected WebElement findElement ( String by , String using ) { <nl> <nl> Response response = execute ( DriverCommand . FIND_ELEMENT , <nl> ImmutableMap . of ( \" using \" , by , \" value \" , using ) ) ; <nl> - System . out . println ( \" response = \" + response ) ; <nl> return ( WebElement ) response . getValue ( ) ; <nl> } <nl> <nl>\n", "msg": "SimonStewart : Remove spurious logging to sysout\n"}
{"diff_id": 1786, "repo": "dbeaver/dbeaver\n", "sha": "f8258307a5916ef3574fe4c6d01752d73224e761\n", "time": "2018-11-06T20:34:16Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . core / src / org / jkiss / dbeaver / ui / editors / entity / properties / TabbedFolderPageForm . java <nl> ppp b / plugins / org . jkiss . dbeaver . core / src / org / jkiss / dbeaver / ui / editors / entity / properties / TabbedFolderPageForm . java <nl> private void createPropertyEditor ( Composite group , DBPPropertyDescriptor prop ) { <nl> } <nl> if ( editControl instanceof Text | | editControl instanceof Combo ) { <nl> gd . widthHint = Math . max ( <nl> - UIUtils . getFontHeight ( group ) * 10 , <nl> + UIUtils . getFontHeight ( group ) * 15 , <nl> editControl . computeSize ( SWT . DEFAULT , SWT . DEFAULT ) . x ) ; <nl> } <nl> <nl>\n", "msg": "Entity editor form render fix ( default control width )\n"}
{"diff_id": 2040, "repo": "mybatis/mybatis-3\n", "sha": "288734921bdea5c615e3602c454be67689116d5f\n", "time": "2014-03-30T08:01:34Z\n", "diff": "mmm a / src / main / java / org / apache / ibatis / mapping / CacheBuilder . java <nl> ppp b / src / main / java / org / apache / ibatis / mapping / CacheBuilder . java <nl> public Cache build ( ) { <nl> setCacheProperties ( cache ) ; <nl> } <nl> cache = setStandardDecorators ( cache ) ; <nl> + } else if ( ! LoggingCache . class . isAssignableFrom ( cache . getClass ( ) ) ) { <nl> + cache = new LoggingCache ( cache ) ; <nl> } <nl> return cache ; <nl> } <nl>\n", "msg": "Fixes . Set logging decorator to all caches .\n"}
{"diff_id": 2114, "repo": "elastic/elasticsearch\n", "sha": "8a87448758e3ec2b6ec5a182ae7ea7f97ef27a34\n", "time": "2015-10-15T12:28:39Z\n", "diff": "mmm a / core / src / main / java / org / elasticsearch / index / query / IdsQueryBuilder . java <nl> ppp b / core / src / main / java / org / elasticsearch / index / query / IdsQueryBuilder . java <nl> <nl> import org . elasticsearch . index . mapper . internal . UidFieldMapper ; <nl> <nl> import java . io . IOException ; <nl> - import java . util . Arrays ; <nl> - import java . util . Collection ; <nl> - import java . util . Collections ; <nl> - import java . util . HashSet ; <nl> - import java . util . Objects ; <nl> - import java . util . Set ; <nl> + import java . util . * ; <nl> <nl> / * * <nl> * A query that will return only documents matching specific ids ( and a type ) . <nl> protected Query doToQuery ( QueryShardContext context ) throws IOException { <nl> <nl> @ Override <nl> protected IdsQueryBuilder doReadFrom ( StreamInput in ) throws IOException { <nl> - IdsQueryBuilder idsQueryBuilder = new IdsQueryBuilder ( in . readOptionalStringArray ( ) ) ; <nl> + IdsQueryBuilder idsQueryBuilder = new IdsQueryBuilder ( in . readStringArray ( ) ) ; <nl> idsQueryBuilder . addIds ( in . readStringArray ( ) ) ; <nl> return idsQueryBuilder ; <nl> } <nl> <nl> @ Override <nl> protected void doWriteTo ( StreamOutput out ) throws IOException { <nl> - out . writeOptionalStringArray ( types ) ; <nl> + out . writeStringArray ( types ) ; <nl> out . writeStringArray ( ids . toArray ( new String [ ids . size ( ) ] ) ) ; <nl> } <nl> <nl>\n", "msg": "Revert changes made to IdsQueryBuilder , fixed upstream meanwhile\n"}
{"diff_id": 2139, "repo": "eclipse-vertx/vert.x\n", "sha": "90a08b0681e722645271f34fb1ac100f568a2ec7\n", "time": "2014-02-13T14:53:31Z\n", "diff": "mmm a / vertx - platform / src / main / java / org / vertx / java / platform / impl / DefaultPlatformManager . java <nl> ppp b / vertx - platform / src / main / java / org / vertx / java / platform / impl / DefaultPlatformManager . java <nl> public void run ( ) { <nl> <nl> @ Override <nl> public void exit ( ) { <nl> + / / We tell the cluster manager to leave - this is because Hazelcast uses non daemon threads which will prevent <nl> + / / JVM exit and shutdown hooks to be called <nl> + vertx . clusterManager ( ) . leave ( ) ; <nl> if ( exitHandler ! = null ) { <nl> exitHandler . handle ( null ) ; <nl> } <nl>\n", "msg": "Shutdown cluster manager before exit otherwise hazelcast non - daemon threads will prevent exit\n"}
{"diff_id": 2143, "repo": "signalapp/Signal-Android\n", "sha": "a80fe178ea88d4e5b787fab47d454a5a1ae985e8\n", "time": "2017-08-10T19:30:13Z\n", "diff": "mmm a / src / org / thoughtcrime / securesms / database / SmsMigrator . java <nl> ppp b / src / org / thoughtcrime / securesms / database / SmsMigrator . java <nl> <nl> import android . database . sqlite . SQLiteException ; <nl> import android . database . sqlite . SQLiteStatement ; <nl> import android . net . Uri ; <nl> + import android . text . TextUtils ; <nl> import android . util . Log ; <nl> <nl> import org . thoughtcrime . securesms . crypto . MasterCipher ; <nl> private static void getContentValuesForRow ( Context context , MasterSecret masterS <nl> Cursor cursor , long threadId , <nl> SQLiteStatement statement ) <nl> { <nl> - addStringToStatement ( statement , cursor , 1 , SmsDatabase . ADDRESS ) ; <nl> + String theirAddress = cursor . getString ( cursor . getColumnIndexOrThrow ( SmsDatabase . ADDRESS ) ) ; <nl> + statement . bindString ( 1 , Address . fromExternal ( context , theirAddress ) . serialize ( ) ) ; <nl> + <nl> addIntToStatement ( statement , cursor , 2 , SmsDatabase . PERSON ) ; <nl> addIntToStatement ( statement , cursor , 3 , SmsDatabase . DATE_RECEIVED ) ; <nl> addIntToStatement ( statement , cursor , 4 , SmsDatabase . DATE_RECEIVED ) ; <nl>\n", "msg": "Canonicalize addresses during import from system SMS database\n"}
{"diff_id": 2203, "repo": "google/ExoPlayer\n", "sha": "bfc8f9c4d8a063202d0fa858a7f2e94f917fbbdb\n", "time": "2019-01-08T07:33:42Z\n", "diff": "mmm a / library / core / src / main / java / com / google / android / exoplayer2 / video / MediaCodecVideoRenderer . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / video / MediaCodecVideoRenderer . java <nl> protected boolean codecNeedsSetOutputSurfaceWorkaround ( String name ) { <nl> / / https : / / github . com / google / ExoPlayer / issues / 4315 , <nl> / / https : / / github . com / google / ExoPlayer / issues / 4419 , <nl> / / https : / / github . com / google / ExoPlayer / issues / 4460 , <nl> - / / https : / / github . com / google / ExoPlayer / issues / 4468 . <nl> + / / https : / / github . com / google / ExoPlayer / issues / 4468 , <nl> + / / https : / / github . com / google / ExoPlayer / issues / 5312 . <nl> switch ( Util . DEVICE ) { <nl> case \" 1601 \" : <nl> case \" 1713 \" : <nl> protected boolean codecNeedsSetOutputSurfaceWorkaround ( String name ) { <nl> case \" HWBLN - H \" : <nl> case \" HWCAM - H \" : <nl> case \" HWVNS - H \" : <nl> + case \" HWWAS - H \" : <nl> case \" i9031 \" : <nl> case \" iball8735_9806 \" : <nl> case \" Infinix - X572 \" : <nl>\n", "msg": "Enable setOutputSurfaceWorkaround for Huawei P10 lite\n"}
{"diff_id": 2218, "repo": "signalapp/Signal-Android\n", "sha": "bcebf58b76a7061663d930af28592c1ca9ebf2f6\n", "time": "2018-09-27T17:35:56Z\n", "diff": "new file mode 100644 <nl> index 0000000000 . . 58aa34a3c8 <nl> mmm / dev / null <nl> ppp b / src / org / thoughtcrime / securesms / util / Stopwatch . java <nl> <nl> + package org . thoughtcrime . securesms . util ; <nl> + <nl> + import android . support . annotation . NonNull ; <nl> + <nl> + import org . thoughtcrime . securesms . logging . Log ; <nl> + <nl> + import java . util . LinkedList ; <nl> + import java . util . List ; <nl> + <nl> + public class Stopwatch { <nl> + <nl> + private final long startTime ; <nl> + private final String title ; <nl> + private final List < Split > splits ; <nl> + <nl> + public Stopwatch ( @ NonNull String title ) { <nl> + this . startTime = System . currentTimeMillis ( ) ; <nl> + this . title = title ; <nl> + this . splits = new LinkedList < > ( ) ; <nl> + } <nl> + <nl> + public void split ( @ NonNull String label ) { <nl> + splits . add ( new Split ( System . currentTimeMillis ( ) , label ) ) ; <nl> + } <nl> + <nl> + public void stop ( @ NonNull String tag ) { <nl> + StringBuilder out = new StringBuilder ( ) ; <nl> + out . append ( \" [ \" ) . append ( title ) . append ( \" ] \" ) ; <nl> + <nl> + if ( splits . size ( ) > 0 ) { <nl> + out . append ( splits . get ( 0 ) . label ) . append ( \" : \" ) ; <nl> + out . append ( splits . get ( 0 ) . time - startTime ) ; <nl> + out . append ( \" \" ) ; <nl> + } <nl> + <nl> + if ( splits . size ( ) > 1 ) { <nl> + for ( int i = 1 ; i < splits . size ( ) ; i + + ) { <nl> + out . append ( splits . get ( i ) . label ) . append ( \" : \" ) ; <nl> + out . append ( splits . get ( i ) . time - splits . get ( i - 1 ) . time ) ; <nl> + out . append ( \" \" ) ; <nl> + } <nl> + <nl> + out . append ( \" total : \" ) . append ( splits . get ( splits . size ( ) - 1 ) . time - startTime ) ; <nl> + } <nl> + <nl> + Log . d ( tag , out . toString ( ) ) ; <nl> + } <nl> + <nl> + private static class Split { <nl> + final long time ; <nl> + final String label ; <nl> + <nl> + Split ( long time , String label ) { <nl> + this . time = time ; <nl> + this . label = label ; <nl> + } <nl> + } <nl> + } <nl>\n", "msg": "Added a new Stopwatch class to easily log timings .\n"}
{"diff_id": 2243, "repo": "bazelbuild/bazel\n", "sha": "6c3e983def9f49db05c14b5150b487f4ae62c331\n", "time": "2020-08-05T00:33:38Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / skyframe / InMemoryNodeEntry . java <nl> ppp b / src / main / java / com / google / devtools / build / skyframe / InMemoryNodeEntry . java <nl> protected DirtyBuildingState createDirtyBuildingStateForDoneNode ( <nl> return DirtyBuildingState . create ( dirtyType , directDeps , value ) ; <nl> } <nl> <nl> + private static final GroupedList < SkyKey > EMPTY_LIST = new GroupedList < > ( ) ; <nl> + <nl> @ Override <nl> public synchronized MarkedDirtyResult markDirty ( DirtyType dirtyType ) { <nl> - / / Can ' t process a dirty node without its deps . <nl> - assertKeepDeps ( ) ; <nl> + if ( ! DirtyType . FORCE_REBUILD . equals ( dirtyType ) ) { <nl> + / / A node can ' t be found to be dirty without deps unless it ' s force - rebuilt . <nl> + assertKeepDeps ( ) ; <nl> + } <nl> if ( isDone ( ) ) { <nl> - dirtyBuildingState = <nl> - createDirtyBuildingStateForDoneNode ( <nl> - dirtyType , GroupedList . create ( getCompressedDirectDepsForDoneEntry ( ) ) , value ) ; <nl> + GroupedList < SkyKey > directDeps = <nl> + KeepEdgesPolicy . NONE . equals ( keepEdges ( ) ) <nl> + ? EMPTY_LIST <nl> + : GroupedList . create ( getCompressedDirectDepsForDoneEntry ( ) ) ; <nl> + dirtyBuildingState = createDirtyBuildingStateForDoneNode ( dirtyType , directDeps , value ) ; <nl> value = null ; <nl> - directDeps = null ; <nl> - return new MarkedDirtyResult ( ReverseDepsUtility . getReverseDeps ( this ) ) ; <nl> + this . directDeps = null ; <nl> + return new MarkedDirtyResult ( <nl> + KeepEdgesPolicy . ALL . equals ( keepEdges ( ) ) <nl> + ? ReverseDepsUtility . getReverseDeps ( this ) <nl> + : ImmutableList . of ( ) ) ; <nl> } <nl> if ( dirtyType . equals ( DirtyType . FORCE_REBUILD ) ) { <nl> if ( dirtyBuildingState ! = null ) { <nl>\n", "msg": "Enable rewinding for edgeless node entries .\n"}
{"diff_id": 2256, "repo": "oracle/graal\n", "sha": "7fcf7755c2bbe1871552b03aab488a6ba8c207a2\n", "time": "2018-08-30T10:48:25Z\n", "diff": "mmm a / compiler / src / org . graalvm . compiler . hotspot . test / src / org / graalvm / compiler / hotspot / test / CompilationWrapperTest . java <nl> ppp b / compiler / src / org . graalvm . compiler . hotspot . test / src / org / graalvm / compiler / hotspot / test / CompilationWrapperTest . java <nl> public void testVMCompilation1 ( ) throws IOException , InterruptedException { <nl> \" - XX : + UseJVMCICompiler \" , <nl> \" - Dgraal . CompilationFailureAction = ExitVM \" , <nl> \" - Dgraal . CrashAt = Object . * , String . * \" , <nl> + \" - Dgraal . ShowDumpFiles = true \" , <nl> \" - version \" ) ) ; <nl> } <nl> <nl> public void testVMCompilation2 ( ) throws IOException , InterruptedException { <nl> \" - XX : + UseJVMCICompiler \" , <nl> \" - Dgraal . ExitVMOnException = true \" , <nl> \" - Dgraal . CrashAt = Object . * , String . * \" , <nl> + \" - Dgraal . ShowDumpFiles = true \" , <nl> \" - version \" ) ) ; <nl> } <nl> <nl> String test ( ) { <nl> \" - Dgraal . CompilationFailureAction = Diagnose \" , <nl> \" - Dgraal . MaxCompilationProblemsPerAction = \" + maxProblems , <nl> \" - Dgraal . CrashAt = Object . * , String . * \" , <nl> + \" - Dgraal . ShowDumpFiles = true \" , <nl> \" - version \" ) ) ; <nl> } <nl> <nl> public void testTruffleCompilation1 ( ) throws IOException , InterruptedException { <nl> Arrays . asList ( <nl> \" - Dgraal . CompilationFailureAction = ExitVM \" , <nl> \" - Dgraal . TrufflePerformanceWarningsAreFatal = true \" , <nl> + \" - Dgraal . ShowDumpFiles = true \" , <nl> \" - Dgraal . CrashAt = root test1 \" ) , <nl> \" org . graalvm . compiler . truffle . test . SLTruffleGraalTestSuite \" , \" test \" ) ; <nl> } <nl> public void testTruffleCompilation2 ( ) throws IOException , InterruptedException { <nl> Arrays . asList ( <nl> \" - Dgraal . CompilationFailureAction = Silent \" , <nl> \" - Dgraal . TruffleCompilationExceptionsAreFatal = true \" , <nl> + \" - Dgraal . ShowDumpFiles = true \" , <nl> \" - Dgraal . CrashAt = root test1 \" ) , <nl> \" org . graalvm . compiler . truffle . test . SLTruffleGraalTestSuite \" , \" test \" ) ; <nl> } <nl> public void testTruffleCompilation3 ( ) throws IOException , InterruptedException { <nl> Arrays . asList ( <nl> \" - Dgraal . CompilationFailureAction = Silent \" , <nl> \" - Dgraal . TrufflePerformanceWarningsAreFatal = true \" , <nl> + \" - Dgraal . ShowDumpFiles = true \" , <nl> \" - Dgraal . CrashAt = root test1 : PermanentBailout \" ) , <nl> \" org . graalvm . compiler . truffle . test . SLTruffleGraalTestSuite \" , \" test \" ) ; <nl> } <nl>\n", "msg": "increase verbosity of CompilationWrapperTest to diagnose transient failures\n"}
{"diff_id": 2315, "repo": "oracle/graal\n", "sha": "0f51eef77238a426d9eca7b9f17b486aa5a9a6bc\n", "time": "2019-09-26T13:54:32Z\n", "diff": "mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / Target_java_lang_reflect_Array . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / Target_java_lang_reflect_Array . java <nl> public static Object newArray ( @ Host ( Class . class ) StaticObject componentType , int <nl> throw meta . throwEx ( meta . NegativeArraySizeException ) ; <nl> } <nl> } <nl> + if ( dimensions . length = = 1 ) { <nl> + / / getArrayClass ( 0 ) is undefined . <nl> + return meta . getInterpreterToVM ( ) . newMultiArray ( component , dimensions ) ; <nl> + } <nl> return meta . getInterpreterToVM ( ) . newMultiArray ( component . getArrayClass ( dimensions . length - 1 ) , dimensions ) ; <nl> } <nl> <nl>\n", "msg": "[ GR - 18478 ] j . l . reflect . Array . newMultiArray returns incorrect type with single dimension .\n"}
{"diff_id": 2371, "repo": "spring-projects/spring-boot\n", "sha": "2a1bca6806a696dadf7f470086e21d55f66ac953\n", "time": "2015-05-19T15:41:24Z\n", "diff": "mmm a / spring - boot - actuator / src / test / java / org / springframework / boot / actuate / autoconfigure / EndpointWebMvcAutoConfigurationTests . java <nl> ppp b / spring - boot - actuator / src / test / java / org / springframework / boot / actuate / autoconfigure / EndpointWebMvcAutoConfigurationTests . java <nl> public void onDifferentPort ( ) throws Exception { <nl> assertContent ( \" / endpoint \" , ports . get ( ) . management , \" endpointoutput \" ) ; <nl> List < ? > interceptors = ( List < ? > ) ReflectionTestUtils . getField ( <nl> this . applicationContext . getBean ( EndpointHandlerMapping . class ) , <nl> - \" interceptors \" ) ; <nl> + \" handlerInterceptors \" ) ; <nl> assertEquals ( 1 , interceptors . size ( ) ) ; <nl> this . applicationContext . close ( ) ; <nl> assertAllClosed ( ) ; <nl>\n", "msg": "Update field that  s checked reflectively to match Spring MVC  s internals\n"}
{"diff_id": 2404, "repo": "elastic/elasticsearch\n", "sha": "6db5b5033cfd84c89a7be1d4ece7654de87ad514\n", "time": "2016-01-19T17:01:54Z\n", "diff": "mmm a / plugins / repository - azure / src / main / java / org / elasticsearch / cloud / azure / storage / AzureStorageServiceImpl . java <nl> ppp b / plugins / repository - azure / src / main / java / org / elasticsearch / cloud / azure / storage / AzureStorageServiceImpl . java <nl> CloudBlobClient getSelectedClient ( String account , LocationMode mode ) { <nl> int timeout = ( int ) azureStorageSettings . getTimeout ( ) . getMillis ( ) ; <nl> client . getDefaultRequestOptions ( ) . setTimeoutIntervalInMs ( timeout ) ; <nl> } catch ( ClassCastException e ) { <nl> - throw new IllegalArgumentException ( \" Can not cast [ \" + azureStorageSettings . getTimeout ( ) + \" ] to int . \" ) ; <nl> + throw new IllegalArgumentException ( \" Can not convert [ \" + azureStorageSettings . getTimeout ( ) + <nl> + \" ] . It can not be longer than 2 , 147 , 483 , 647ms . \" ) ; <nl> } <nl> return client ; <nl> } <nl>\n", "msg": "Change exception message for wrong timeout in azure repository settings\n"}
{"diff_id": 2517, "repo": "square/okhttp\n", "sha": "7cefceb1ff51390397524474ca59f9d5e7ef3eca\n", "time": "2016-09-04T05:05:25Z\n", "diff": "mmm a / okhttp / src / main / java / okhttp3 / HttpUrl . java <nl> ppp b / okhttp / src / main / java / okhttp3 / HttpUrl . java <nl> static String percentDecode ( String encoded , boolean plusIsSpace ) { <nl> } <nl> <nl> private List < String > percentDecode ( List < String > list , boolean plusIsSpace ) { <nl> - List < String > result = new ArrayList < > ( list . size ( ) ) ; <nl> - for ( String s : list ) { <nl> + int size = list . size ( ) ; <nl> + List < String > result = new ArrayList < > ( size ) ; <nl> + for ( int i = 0 ; i < size ; i + + ) { <nl> + String s = list . get ( i ) ; <nl> result . add ( s ! = null ? percentDecode ( s , plusIsSpace ) : null ) ; <nl> } <nl> return Collections . unmodifiableList ( result ) ; <nl>\n", "msg": "Modify for - loop more performance sensitively\n"}
{"diff_id": 2535, "repo": "oracle/graal\n", "sha": "f5b3f66be415dbf7585336239adad6b64afb2f33\n", "time": "2015-01-21T19:00:48Z\n", "diff": "mmm a / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / GraalDebugConfig . java <nl> ppp b / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / GraalDebugConfig . java <nl> <nl> public static final OptionValue < String > Log = new OptionValue < > ( null ) ; <nl> @ Option ( help = \" Pattern for filtering debug scope output based on method context ( see MethodFilter ) \" , type = OptionType . Debug ) <nl> public static final OptionValue < String > MethodFilter = new OptionValue < > ( null ) ; <nl> + @ Option ( help = \" Only check MethodFilter against the root method in the context if true , otherwise check all methods \" , type = OptionType . Debug ) <nl> + public static final OptionValue < Boolean > MethodFilterRootOnly = new OptionValue < > ( false ) ; <nl> + <nl> @ Option ( help = \" How to print metric and timing values : % n \" + <nl> \" Name - aggregate by unqualified name % n \" + <nl> \" Partial - aggregate by partially qualified name ( e . g . , A . B . C . D . Counter and X . Y . Z . D . Counter will be merged to D . Counter ) % n \" + <nl> private boolean checkMethodFilter ( ) { <nl> if ( methodFilter = = null & & extraFilters . isEmpty ( ) ) { <nl> return true ; <nl> } else { <nl> + JavaMethod lastMethod = null ; <nl> for ( Object o : Debug . context ( ) ) { <nl> if ( extraFilters . contains ( o ) ) { <nl> return true ; <nl> } else if ( methodFilter ! = null ) { <nl> JavaMethod method = asJavaMethod ( o ) ; <nl> if ( method ! = null ) { <nl> - if ( com . oracle . graal . compiler . MethodFilter . matches ( methodFilter , method ) ) { <nl> - return true ; <nl> + if ( ! MethodFilterRootOnly . getValue ( ) ) { <nl> + if ( com . oracle . graal . compiler . MethodFilter . matches ( methodFilter , method ) ) { <nl> + return true ; <nl> + } <nl> + } else { <nl> + / * <nl> + * The context values operate as a stack so if we want MethodFilter to <nl> + * only apply to the root method we have to check only the last method <nl> + * seen . <nl> + * / <nl> + lastMethod = method ; <nl> } <nl> } <nl> } <nl> } <nl> + if ( lastMethod ! = null & & com . oracle . graal . compiler . MethodFilter . matches ( methodFilter , lastMethod ) ) { <nl> + return true ; <nl> + } <nl> return false ; <nl> } <nl> } <nl>\n", "msg": "Add option to restrict MethodFilter to the root method\n"}
{"diff_id": 2668, "repo": "jenkinsci/jenkins\n", "sha": "f5209cd4dec101f7f56d512d4085eb5804000c1c\n", "time": "2011-04-21T22:21:33Z\n", "diff": "mmm a / test / src / main / java / org / jvnet / hudson / test / HudsonTestCase . java <nl> ppp b / test / src / main / java / org / jvnet / hudson / test / HudsonTestCase . java <nl> public void assertEqualDataBoundBeans ( Object lhs , Object rhs ) throws Exception { <nl> } <nl> assertFalse ( \" collection size mismatch between \" + lhs + \" and \" + rhs , ltr . hasNext ( ) ^ rtr . hasNext ( ) ) ; <nl> } else <nl> - if ( findDataBoundConstructor ( types [ i ] ) ! = null ) { <nl> + if ( findDataBoundConstructor ( types [ i ] ) ! = null | | ( lv ! = null & & findDataBoundConstructor ( lv . getClass ( ) ) ! = null ) | | ( rv ! = null & & findDataBoundConstructor ( rv . getClass ( ) ) ! = null ) ) { <nl> / / recurse into nested databound objects <nl> assertEqualDataBoundBeans ( lv , rv ) ; <nl> } else { <nl>\n", "msg": "More aggressive search for data - bound beans .\n"}
{"diff_id": 2698, "repo": "apache/flink\n", "sha": "c9e0761dec904d42e0876a7731eb62d690abd738\n", "time": "2016-03-11T14:30:33Z\n", "diff": "mmm a / flink - tests / src / test / java / org / apache / flink / test / checkpointing / SavepointITCase . java <nl> ppp b / flink - tests / src / test / java / org / apache / flink / test / checkpointing / SavepointITCase . java <nl> public Integer map ( Integer value ) throws Exception { <nl> <nl> @ Override <nl> public byte [ ] snapshotState ( long checkpointId , long checkpointTimestamp ) throws Exception { <nl> - LOG . info ( \" snapshotState ( \" + checkpointId + \" ) : \" + Arrays . toString ( data ) ) ; <nl> return data ; <nl> } <nl> <nl> @ Override <nl> public void restoreState ( byte [ ] data ) throws Exception { <nl> - LOG . info ( \" restoreState : \" + Arrays . toString ( data ) ) ; <nl> this . data = data ; <nl> } <nl> } <nl>\n", "msg": "[ hotfix ] [ tests ] Remove verbose logging in SavepointITCase\n"}
{"diff_id": 2796, "repo": "oracle/graal\n", "sha": "d6c8fcda2dfc2289f041abf7a4fc9352c6c6373b\n", "time": "2014-08-14T13:35:20Z\n", "diff": "mmm a / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / CompileTheWorld . java <nl> ppp b / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / CompileTheWorld . java <nl> private boolean canBeCompiled ( HotSpotResolvedJavaMethod javaMethod , int modifier <nl> if ( c . dontCompileHugeMethods & & javaMethod . getCodeSize ( ) > c . hugeMethodLimit ) { <nl> return false ; <nl> } <nl> + / / Allow use of - XX : CompileCommand = dontinline to exclude problematic methods <nl> + if ( ! javaMethod . canBeInlined ( ) ) { <nl> + return false ; <nl> + } <nl> / / Skip @ Snippets for now <nl> if ( javaMethod . getAnnotation ( Snippet . class ) ! = null ) { <nl> return false ; <nl>\n", "msg": "support use of - XX : CompileCommand = dontinline to exclude problematic methods from CompileTheWorld\n"}
{"diff_id": 2801, "repo": "jenkinsci/jenkins\n", "sha": "6a928f5537534d0fe55d774c4b9b262b8c3da041\n", "time": "2012-07-16T17:37:21Z\n", "diff": "mmm a / core / src / main / java / hudson / model / RunMap . java <nl> ppp b / core / src / main / java / hudson / model / RunMap . java <nl> <nl> package hudson . model ; <nl> <nl> import com . google . common . collect . Maps ; <nl> - <nl> import java . io . File ; <nl> import java . io . FilenameFilter ; <nl> import java . io . IOException ; <nl> + import java . text . ParseException ; <nl> + import java . text . SimpleDateFormat ; <nl> import java . util . AbstractMap ; <nl> import java . util . Collections ; <nl> import java . util . Comparator ; <nl> <nl> import java . util . Set ; <nl> import java . util . SortedMap ; <nl> import java . util . TreeMap ; <nl> + import java . util . logging . Level ; <nl> import java . util . logging . Logger ; <nl> - import java . text . SimpleDateFormat ; <nl> - import java . text . ParseException ; <nl> <nl> / * * <nl> * { @ link Map } from build number to { @ link Run } . <nl> private boolean isCorrectDate ( String name ) { <nl> / / if the build result file isn ' t in the directory , ignore it . <nl> try { <nl> R b = cons . create ( d ) ; <nl> - builds . put ( b . getNumber ( ) , b ) ; <nl> + R existing = builds . put ( b . getNumber ( ) , b ) ; <nl> + if ( existing ! = null ) { <nl> + LOGGER . log ( Level . WARNING , \" multiple runs claiming to be # { 0 } ; using run from { 1 } \" , new Object [ ] { b . getNumber ( ) , d } ) ; <nl> + } <nl> } catch ( IOException e ) { <nl> - e . printStackTrace ( ) ; <nl> + LOGGER . log ( Level . WARNING , \" could not load \" + d , e ) ; <nl> } catch ( InstantiationError e ) { <nl> - e . printStackTrace ( ) ; <nl> + LOGGER . log ( Level . WARNING , \" could not load \" + d , e ) ; <nl> } <nl> } <nl> } <nl> <nl> / / overlay what ' s currently building on top of what ' s loaded <nl> builds . putAll ( building ) ; <nl> - if ( false ) { <nl> + / * <nl> / / we probably aren ' t saving every little changes during the build to disk , <nl> / / so it ' s risky to reload these from disk . <nl> for ( R b : building . values ( ) ) { <nl> private boolean isCorrectDate ( String name ) { <nl> e . printStackTrace ( ) ; <nl> } <nl> } <nl> - } <nl> + * / <nl> <nl> reset ( builds ) ; <nl> <nl>\n", "msg": "Produce more informative logging in case build records overlap or are corrupt .\n"}
{"diff_id": 2803, "repo": "netty/netty\n", "sha": "7d9374a582edd47f973255618a35d36d032059eb\n", "time": "2014-06-02T09:25:25Z\n", "diff": "mmm a / buffer / src / main / java / io / netty / buffer / PoolThreadCache . java <nl> ppp b / buffer / src / main / java / io / netty / buffer / PoolThreadCache . java <nl> private static int free ( MemoryRegionCache < ? > [ ] caches ) { <nl> } <nl> <nl> int numFreed = 0 ; <nl> - for ( int i = 0 ; i < caches . length ; i + + ) { <nl> - numFreed + = free ( caches [ i ] ) ; <nl> + for ( MemoryRegionCache < ? > c : caches ) { <nl> + numFreed + = free ( c ) ; <nl> } <nl> return numFreed ; <nl> } <nl> private static void trim ( MemoryRegionCache < ? > [ ] caches ) { <nl> if ( caches = = null ) { <nl> return ; <nl> } <nl> - for ( int i = 0 ; i < caches . length ; i + + ) { <nl> - trim ( caches [ i ] ) ; <nl> + for ( MemoryRegionCache < ? > c : caches ) { <nl> + trim ( c ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "Use Java 5 foreach for arrays for brevity at no cost\n"}
{"diff_id": 2829, "repo": "spring-projects/spring-framework\n", "sha": "19eecb151b8a0e2b2dad1aa4baf4c552587342fb\n", "time": "2013-02-11T02:54:28Z\n", "diff": "mmm a / spring - context / src / test / java / org / springframework / validation / beanvalidation / ValidatorFactoryTests . java <nl> ppp b / spring - context / src / test / java / org / springframework / validation / beanvalidation / ValidatorFactoryTests . java <nl> <nl> import javax . validation . constraints . NotNull ; <nl> <nl> import org . hibernate . validator . HibernateValidator ; <nl> + import org . junit . Ignore ; <nl> import org . junit . Test ; <nl> <nl> import org . springframework . validation . BeanPropertyBindingResult ; <nl> <nl> import org . springframework . validation . FieldError ; <nl> import org . springframework . validation . ObjectError ; <nl> <nl> + import static org . hamcrest . Matchers . instanceOf ; <nl> import static org . junit . Assert . * ; <nl> <nl> / * * <nl> public void testSimpleValidationWithClassLevel ( ) throws Exception { <nl> assertTrue ( cv . getConstraintDescriptor ( ) . getAnnotation ( ) instanceof NameAddressValid ) ; <nl> } <nl> <nl> + @ Test <nl> + @ Ignore <nl> + public void testSpringValidationFieldType ( ) throws Exception { <nl> + LocalValidatorFactoryBean validator = new LocalValidatorFactoryBean ( ) ; <nl> + validator . afterPropertiesSet ( ) ; <nl> + ValidPerson person = new ValidPerson ( ) ; <nl> + person . setName ( \" Phil \" ) ; <nl> + person . getAddress ( ) . setStreet ( \" Phil ' s Street \" ) ; <nl> + BeanPropertyBindingResult errors = new BeanPropertyBindingResult ( person , \" person \" ) ; <nl> + validator . validate ( person , errors ) ; <nl> + assertEquals ( 1 , errors . getErrorCount ( ) ) ; <nl> + assertThat ( \" Field / Value type missmatch \" , <nl> + errors . getFieldError ( \" address \" ) . getRejectedValue ( ) , <nl> + instanceOf ( ValidAddress . class ) ) ; <nl> + } <nl> + <nl> @ Test <nl> public void testSpringValidation ( ) throws Exception { <nl> LocalValidatorFactoryBean validator = new LocalValidatorFactoryBean ( ) ; <nl> public void initialize ( NameAddressValid constraintAnnotation ) { <nl> } <nl> <nl> @ Override <nl> - public boolean isValid ( ValidPerson value , ConstraintValidatorContext constraintValidatorContext ) { <nl> - return ( value . name = = null | | ! value . address . street . contains ( value . name ) ) ; <nl> + public boolean isValid ( ValidPerson value , ConstraintValidatorContext context ) { <nl> + boolean valid = ( value . name = = null | | ! value . address . street . contains ( value . name ) ) ; <nl> + if ( ! valid & & \" Phil \" . equals ( value . name ) ) { <nl> + context . buildConstraintViolationWithTemplate ( <nl> + context . getDefaultConstraintMessageTemplate ( ) ) . addNode ( \" address \" ) . addConstraintViolation ( ) . disableDefaultConstraintViolation ( ) ; <nl> + } <nl> + return valid ; <nl> } <nl> } <nl> <nl>\n", "msg": "Add @ Ignored Test case to reproduce SPR - 10243\n"}
{"diff_id": 3127, "repo": "elastic/elasticsearch\n", "sha": "6df767790f838b4ca81c0aa29abc75e7e6ee20d3\n", "time": "2015-01-10T10:50:25Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / shield / authz / indicesresolver / DefaultIndicesResolver . java <nl> ppp b / src / main / java / org / elasticsearch / shield / authz / indicesresolver / DefaultIndicesResolver . java <nl> <nl> <nl> import org . elasticsearch . action . CompositeIndicesRequest ; <nl> import org . elasticsearch . action . IndicesRequest ; <nl> + import org . elasticsearch . action . admin . indices . alias . IndicesAliasesRequest ; <nl> import org . elasticsearch . action . support . IndicesOptions ; <nl> import org . elasticsearch . cluster . metadata . IndexMetaData ; <nl> import org . elasticsearch . cluster . metadata . MetaData ; <nl> public DefaultIndicesResolver ( AuthorizationService authzService ) { <nl> / / indices resulted in no indices . This is important as we always need to replace wildcards for security reason , <nl> / / to make sure that the operation is executed on the indices that we authorized it to execute on . <nl> / / If we can ' t replace because we got an empty set , we can only throw exception . <nl> - / / Downside of this is that a single item exception is going to its composite requests fail as a whole . <nl> + / / Downside of this is that a single item exception is going to make fail the composite request that holds it as a whole . <nl> if ( indices = = null | | indices . isEmpty ( ) ) { <nl> if ( MetaData . isAllIndices ( indicesRequest . indices ( ) ) ) { <nl> throw new IndexMissingException ( new Index ( MetaData . ALL ) ) ; <nl> public DefaultIndicesResolver ( AuthorizationService authzService ) { <nl> ( ( IndicesRequest . Replaceable ) indicesRequest ) . indices ( indices . toArray ( new String [ indices . size ( ) ] ) ) ; <nl> return Sets . newHashSet ( indices ) ; <nl> } <nl> - return Sets . newHashSet ( explodeWildcards ( indicesRequest , metaData ) ) ; <nl> + <nl> + if ( containsWildcards ( indicesRequest ) ) { <nl> + / / used for requests that support wildcards but don ' t allow to replace their indices ( e . g . IndicesAliasesRequest ) <nl> + / / potentially insecure as cluster state may change hence we may end up resolving to different indices on different nodes <nl> + assert indicesRequest instanceof IndicesAliasesRequest <nl> + : \" IndicesAliasesRequest is the only request known to support wildcards that doesn ' t support replacing its indices \" ; <nl> + return Sets . newHashSet ( explodeWildcards ( indicesRequest , metaData ) ) ; <nl> + } <nl> + / / NOTE : shard level requests do support wildcards ( as they hold the original indices options ) but don ' t support replacing their indices . <nl> + / / That is fine though because they never contain wildcards , as they get replaced as part of the authorization of their <nl> + / / corresponding parent request on the coordinating node . Hence wildcards don ' t get replaced nor exploded for shard level requests . <nl> } <nl> return Sets . newHashSet ( indicesRequest . indices ( ) ) ; <nl> } <nl> <nl> + / * <nl> + * Explodes wildcards based on default core behaviour . Used for IndicesAliasesRequest only as it doesn ' t support <nl> + * replacing its indices . It will go away once that gets fixed . <nl> + * / <nl> private String [ ] explodeWildcards ( IndicesRequest indicesRequest , MetaData metaData ) { <nl> / / note that \" _all \" will map to concrete indices only , as the same happens in core <nl> / / which is different from \" * \" as the latter expands to all indices and aliases <nl> public DefaultIndicesResolver ( AuthorizationService authzService ) { <nl> return metaData . convertFromWildcards ( indicesRequest . indices ( ) , indicesRequest . indicesOptions ( ) ) ; <nl> } <nl> <nl> + private boolean containsWildcards ( IndicesRequest indicesRequest ) { <nl> + if ( MetaData . isAllIndices ( indicesRequest . indices ( ) ) ) { <nl> + return true ; <nl> + } <nl> + for ( String index : indicesRequest . indices ( ) ) { <nl> + if ( index . startsWith ( \" + \" ) | | index . startsWith ( \" - \" ) | | Regex . isSimpleMatchPattern ( index ) ) { <nl> + return true ; <nl> + } <nl> + } <nl> + return false ; <nl> + } <nl> + <nl> private List < String > replaceWildcardsWithAuthorizedIndices ( IndicesRequest indicesRequest , MetaData metaData , List < String > authorizedIndices ) { <nl> <nl> if ( MetaData . isAllIndices ( indicesRequest . indices ( ) ) ) { <nl>\n", "msg": "Indices resolution : don ' t go over the indices for requests that don ' t contain wildcards , just return them as they are\n"}
{"diff_id": 3200, "repo": "libgdx/libgdx\n", "sha": "8913f5807cabb5d5a429bbc30e5d03ec4e9761cc\n", "time": "2014-04-09T20:44:32Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / math / Quaternion . java <nl> ppp b / gdx / src / com / badlogic / gdx / math / Quaternion . java <nl> <nl> <nl> import java . io . Serializable ; <nl> <nl> + import com . badlogic . gdx . utils . NumberUtils ; <nl> + <nl> / * * A simple quaternion class . <nl> * @ see < a href = \" http : / / en . wikipedia . org / wiki / Quaternion \" > http : / / en . wikipedia . org / wiki / Quaternion < / a > <nl> * @ author badlogicgames @ gmail . com <nl> public Quaternion slerp ( Quaternion end , float alpha ) { <nl> public int hashCode ( ) { <nl> final int prime = 31 ; <nl> int result = 1 ; <nl> - result = prime * result + Float . floatToIntBits ( w ) ; <nl> - result = prime * result + Float . floatToIntBits ( x ) ; <nl> - result = prime * result + Float . floatToIntBits ( y ) ; <nl> - result = prime * result + Float . floatToIntBits ( z ) ; <nl> + result = prime * result + NumberUtils . floatToRawIntBits ( w ) ; <nl> + result = prime * result + NumberUtils . floatToRawIntBits ( x ) ; <nl> + result = prime * result + NumberUtils . floatToRawIntBits ( y ) ; <nl> + result = prime * result + NumberUtils . floatToRawIntBits ( z ) ; <nl> return result ; <nl> } <nl> <nl> public boolean equals ( Object obj ) { <nl> return false ; <nl> } <nl> Quaternion other = ( Quaternion ) obj ; <nl> - return ( Float . floatToIntBits ( w ) = = Float . floatToIntBits ( other . w ) ) <nl> - & & ( Float . floatToIntBits ( x ) = = Float . floatToIntBits ( other . x ) ) <nl> - & & ( Float . floatToIntBits ( y ) = = Float . floatToIntBits ( other . y ) ) <nl> - & & ( Float . floatToIntBits ( z ) = = Float . floatToIntBits ( other . z ) ) ; <nl> + return ( NumberUtils . floatToRawIntBits ( w ) = = NumberUtils . floatToRawIntBits ( other . w ) ) <nl> + & & ( NumberUtils . floatToRawIntBits ( x ) = = NumberUtils . floatToRawIntBits ( other . x ) ) <nl> + & & ( NumberUtils . floatToRawIntBits ( y ) = = NumberUtils . floatToRawIntBits ( other . y ) ) <nl> + & & ( NumberUtils . floatToRawIntBits ( z ) = = NumberUtils . floatToRawIntBits ( other . z ) ) ; <nl> } <nl> <nl> / * * Get the dot product between the two quaternions ( commutative ) . <nl>\n", "msg": "fixed up PR , made things compatible with GWT\n"}
{"diff_id": 3248, "repo": "bazelbuild/bazel\n", "sha": "52811e0c555b83aa9506bd1051547d2ded069441\n", "time": "2015-06-12T11:45:42Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / skyframe / NodeEntry . java <nl> ppp b / src / main / java / com / google / devtools / build / skyframe / NodeEntry . java <nl> <nl> boolean isChanged ( ) ; <nl> <nl> / * * <nl> - * Marks this node dirty , or changed if { @ code isChanged } is true . The node is put in the <nl> + * Marks this node dirty , or changed if { @ code isChanged } is true . The node is put in the <nl> * just - created state . It will be re - evaluated if necessary during the evaluation phase , <nl> * but if it has not changed , it will not force a re - evaluation of its parents . <nl> * <nl> + * < p > { @ code markDirty ( b ) } must not be called on an undone node if { @ code isChanged ( ) = = b } . <nl> + * It is the caller ' s responsibility to ensure that this does not happen . Calling <nl> + * { @ code markDirty ( false ) } when { @ code isChanged ( ) = = true } has no effect . The idea here is that <nl> + * the caller will only ever want to call { @ code markDirty ( ) } a second time if a transition from a <nl> + * dirty - unchanged state to a dirty - changed state is required . <nl> + * <nl> * @ return The direct deps and value of this entry , or null if the entry has already been marked <nl> * dirty . In the latter case , the caller should abort its handling of this node , since another <nl> * thread is already dealing with it . <nl>\n", "msg": "Change the description of NodeEntry # markDirty to better align with the InMemoryNodeEntry # markDirty implementation .\n"}
{"diff_id": 3290, "repo": "dbeaver/dbeaver\n", "sha": "7cf7c0fc60f00e77c0603849b7fd87de9f700d62\n", "time": "2019-10-04T13:43:22Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . data . transfer / src / org / jkiss / dbeaver / tools / transfer / DataTransferSettings . java <nl> ppp b / plugins / org . jkiss . dbeaver . data . transfer / src / org / jkiss / dbeaver / tools / transfer / DataTransferSettings . java <nl> private void loadConfiguration ( DBRRunnableContext runnableContext , Map < String , O <nl> { <nl> / / Restore consumer / producer from saved configuration <nl> / / Do this only if consumer / producer weren ' t set explicitly <nl> - if ( this . consumer = = null ) { <nl> + { <nl> String consumerId = CommonUtils . toString ( config . get ( \" consumer \" ) ) ; <nl> if ( ! CommonUtils . isEmpty ( consumerId ) ) { <nl> DataTransferNodeDescriptor consumerNode = DataTransferRegistry . getInstance ( ) . getNodeById ( consumerId ) ; <nl> if ( consumerNode ! = null ) { <nl> - savedConsumer = consumerNode ; <nl> - this . setConsumer ( consumerNode ) ; <nl> + if ( this . consumer = = null ) { <nl> + savedConsumer = consumerNode ; <nl> + this . setConsumer ( consumerNode ) ; <nl> + } else { <nl> + savedConsumer = this . consumer ; <nl> + } <nl> if ( this . isConsumerOptional ( ) ) { <nl> processorNode = consumerNode ; <nl> } <nl> } <nl> } <nl> } <nl> - if ( this . producer = = null ) { <nl> + { <nl> String producerId = CommonUtils . toString ( config . get ( \" producer \" ) ) ; <nl> if ( ! CommonUtils . isEmpty ( producerId ) ) { <nl> DataTransferNodeDescriptor producerNode = DataTransferRegistry . getInstance ( ) . getNodeById ( producerId ) ; <nl> if ( producerNode ! = null ) { <nl> - savedProducer = producerNode ; <nl> - this . setProducer ( producerNode ) ; <nl> + if ( this . producer = = null ) { <nl> + savedProducer = producerNode ; <nl> + this . setProducer ( producerNode ) ; <nl> + } else { <nl> + savedProducer = this . producer ; <nl> + } <nl> if ( this . isProducerOptional ( ) ) { <nl> processorNode = producerNode ; <nl> } <nl>\n", "msg": "CSV import column mappings detection fix\n"}
{"diff_id": 3349, "repo": "libgdx/libgdx\n", "sha": "062a3d63c631a4a3187adc6db579ea91e2b66897\n", "time": "2011-06-22T23:30:58Z\n", "diff": "mmm a / backends / gdx - backend - android / src / com / badlogic / gdx / backends / android / AndroidAudio . java <nl> ppp b / backends / gdx - backend - android / src / com / badlogic / gdx / backends / android / AndroidAudio . java <nl> protected void resume ( ) { <nl> * / <nl> public void dispose ( ) { <nl> synchronized ( musics ) { <nl> - for ( AndroidMusic music : musics ) { <nl> + / / gah i hate myself . . . . music . dispose ( ) removes the music from the list . . . <nl> + ArrayList < AndroidMusic > musicsCopy = new ArrayList < AndroidMusic > ( musics ) ; <nl> + for ( AndroidMusic music : musicsCopy ) { <nl> music . dispose ( ) ; <nl> } <nl> } <nl>\n", "msg": "[ fixed ] concurrentmodification exception in AndroidAudio . dispose ( ) . Cause you shall not remove stuff from a list while you use an iterator of that list . I ' m stupid . . .\n"}
{"diff_id": 3601, "repo": "oracle/graal\n", "sha": "91756fe8591c1964e72f80c5636c4a67e31ac3b8\n", "time": "2020-08-07T15:23:43Z\n", "diff": "mmm a / compiler / src / org . graalvm . compiler . truffle . test / src / org / graalvm / compiler / truffle / test / MultiTierCompilationTest . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . test / src / org / graalvm / compiler / truffle / test / MultiTierCompilationTest . java <nl> <nl> import static org . graalvm . compiler . truffle . options . PolyglotCompilerOptions . CompilationThreshold ; <nl> import static org . graalvm . compiler . truffle . options . PolyglotCompilerOptions . FirstTierCompilationThreshold ; <nl> <nl> + import com . oracle . truffle . api . nodes . LoopNode ; <nl> + import com . oracle . truffle . api . nodes . Node ; <nl> + import com . oracle . truffle . api . nodes . RepeatingNode ; <nl> import org . graalvm . compiler . truffle . runtime . OptimizedCallTarget ; <nl> import org . graalvm . compiler . truffle . runtime . TruffleRuntimeOptions ; <nl> import org . junit . Assert ; <nl> public Object execute ( VirtualFrame frame ) { <nl> } <nl> } <nl> <nl> + private static class MultiTierWithLoopRootNode extends RootNode { <nl> + @ Child private LoopNode loop ; <nl> + private final MultiTierCompilationTest . MultiTierLoopBodyNode body ; <nl> + <nl> + MultiTierWithLoopRootNode ( MultiTierLoopBodyNode body ) { <nl> + super ( null ) ; <nl> + this . loop = Truffle . getRuntime ( ) . createLoopNode ( body ) ; <nl> + this . body = body ; <nl> + } <nl> + <nl> + @ Override <nl> + public Object execute ( VirtualFrame frame ) { <nl> + body . iteration = 0 ; <nl> + final Object result = loop . execute ( frame ) ; <nl> + return result ; <nl> + } <nl> + } <nl> + <nl> + private static class MultiTierLoopBodyNode extends Node implements RepeatingNode { <nl> + private final int total ; <nl> + public int iteration = 0 ; <nl> + <nl> + private MultiTierLoopBodyNode ( int total ) { <nl> + this . total = total ; <nl> + } <nl> + <nl> + @ Override <nl> + public boolean executeRepeating ( VirtualFrame frame ) { <nl> + throw new RuntimeException ( \" This method must not be called . \" ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public Object initialLoopStatus ( ) { <nl> + return \" continue \" ; <nl> + } <nl> + <nl> + @ Override <nl> + public boolean shouldContinue ( Object returnValue ) { <nl> + String value = ( String ) returnValue ; <nl> + return value . startsWith ( \" continue \" ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public Object executeRepeatingWithValue ( VirtualFrame frame ) { <nl> + iteration + = 1 ; <nl> + if ( iteration = = total ) { <nl> + if ( CompilerDirectives . inInterpreter ( ) ) { <nl> + return \" break : interpreter \" ; <nl> + } <nl> + if ( CompilerDirectives . inFirstTier ( ) ) { <nl> + return \" break : first - tier \" ; <nl> + } <nl> + return \" break : second - tier \" ; <nl> + } <nl> + if ( CompilerDirectives . inInterpreter ( ) ) { <nl> + return \" continue : interpreter \" ; <nl> + } <nl> + if ( CompilerDirectives . inFirstTier ( ) ) { <nl> + return \" continue : first - tier \" ; <nl> + } <nl> + return \" continue : last - tier \" ; <nl> + } <nl> + } <nl> + <nl> @ CompilerDirectives . TruffleBoundary <nl> private static void boundary ( ) { <nl> } <nl> private static void boundary ( ) { <nl> public void testDefault ( ) { <nl> setupContext ( Context . newBuilder ( ) . allowExperimentalOptions ( true ) . option ( \" engine . CompileImmediately \" , \" false \" ) . option ( \" engine . BackgroundCompilation \" , \" false \" ) . option ( \" engine . MultiTier \" , <nl> \" true \" ) . option ( \" engine . FirstTierInlining \" , \" false \" ) . option ( \" engine . Splitting \" , \" false \" ) . option ( \" engine . FirstTierCompilationThreshold \" , \" 100 \" ) . option ( <nl> - \" engine . CompilationThreshold \" , \" 1000 \" ) . build ( ) ) ; <nl> + \" engine . CompilationThreshold \" , \" 1000 \" ) <nl> + . build ( ) ) ; <nl> <nl> OptimizedCallTarget calleeTarget = ( OptimizedCallTarget ) Truffle . getRuntime ( ) . createCallTarget ( new MultiTierCalleeNode ( ) ) ; <nl> OptimizedCallTarget multiTierTarget = ( OptimizedCallTarget ) Truffle . getRuntime ( ) . createCallTarget ( new MultiTierRootNode ( calleeTarget ) ) ; <nl> public void testDefault ( ) { <nl> public void testFirstTierInlining ( ) { <nl> setupContext ( Context . newBuilder ( ) . allowExperimentalOptions ( true ) . option ( \" engine . CompileImmediately \" , \" false \" ) . option ( \" engine . BackgroundCompilation \" , \" false \" ) . option ( \" engine . MultiTier \" , <nl> \" true \" ) . option ( \" engine . FirstTierInlining \" , \" true \" ) . option ( \" engine . Splitting \" , \" false \" ) . option ( \" engine . FirstTierCompilationThreshold \" , \" 100 \" ) . option ( <nl> - \" engine . CompilationThreshold \" , \" 1000 \" ) . build ( ) ) ; <nl> + \" engine . CompilationThreshold \" , \" 1000 \" ) <nl> + . build ( ) ) ; <nl> <nl> OptimizedCallTarget calleeTarget = ( OptimizedCallTarget ) Truffle . getRuntime ( ) . createCallTarget ( new MultiTierCalleeNode ( ) ) ; <nl> OptimizedCallTarget multiTierTarget = ( OptimizedCallTarget ) Truffle . getRuntime ( ) . createCallTarget ( new MultiTierRootNode ( calleeTarget ) ) ; <nl> public void testFirstTierInlining ( ) { <nl> public void testWhenCalleeCompiledFirst ( ) { <nl> setupContext ( Context . newBuilder ( ) . allowExperimentalOptions ( true ) . option ( \" engine . CompileImmediately \" , \" false \" ) . option ( \" engine . BackgroundCompilation \" , \" false \" ) . option ( \" engine . MultiTier \" , <nl> \" true \" ) . option ( \" engine . FirstTierInlining \" , \" false \" ) . option ( \" engine . Splitting \" , \" false \" ) . option ( \" engine . FirstTierCompilationThreshold \" , \" 100 \" ) . option ( <nl> - \" engine . CompilationThreshold \" , \" 1000 \" ) . build ( ) ) ; <nl> + \" engine . CompilationThreshold \" , \" 1000 \" ) <nl> + . build ( ) ) ; <nl> <nl> OptimizedCallTarget calleeTarget = ( OptimizedCallTarget ) Truffle . getRuntime ( ) . createCallTarget ( new MultiTierCalleeNode ( ) ) ; <nl> final int firstTierCompilationThreshold = TruffleRuntimeOptions . getPolyglotOptionValue ( calleeTarget . getOptionValues ( ) , FirstTierCompilationThreshold ) ; <nl> public void testWhenCalleeCompiledFirst ( ) { <nl> } <nl> Assert . assertEquals ( \" callee : inlined \" , multiTierTarget . call ( ) ) ; <nl> } <nl> + <nl> + @ SuppressWarnings ( \" try \" ) <nl> + @ Test <nl> + public void testLoop ( ) { <nl> + int firstThreshold = 100 ; <nl> + int secondThreshold = 1000 ; <nl> + setupContext ( Context . newBuilder ( ) . allowExperimentalOptions ( true ) <nl> + . option ( \" engine . CompileImmediately \" , \" false \" ) <nl> + . option ( \" engine . BackgroundCompilation \" , \" false \" ) <nl> + . option ( \" engine . MultiTier \" , \" true \" ) <nl> + . option ( \" engine . FirstTierInlining \" , \" false \" ) <nl> + . option ( \" engine . Splitting \" , \" false \" ) <nl> + . option ( \" engine . FirstTierCompilationThreshold \" , String . valueOf ( firstThreshold ) ) <nl> + . option ( \" engine . CompilationThreshold \" , String . valueOf ( secondThreshold ) ) <nl> + . build ( ) ) ; <nl> + <nl> + MultiTierLoopBodyNode body = new MultiTierLoopBodyNode ( 100 ) ; <nl> + OptimizedCallTarget rootTarget = ( OptimizedCallTarget ) Truffle . getRuntime ( ) . createCallTarget ( new MultiTierWithLoopRootNode ( body ) ) ; <nl> + <nl> + Assert . assertEquals ( \" break : interpreter \" , rootTarget . call ( ) ) ; <nl> + Assert . assertEquals ( \" break : first - tier \" , rootTarget . call ( ) ) ; <nl> + for ( int i = 0 ; i < secondThreshold / firstThreshold - 2 ; i + + ) { <nl> + Assert . assertEquals ( \" at iteration \" + i , \" break : first - tier \" , rootTarget . call ( ) ) ; <nl> + } <nl> + rootTarget . call ( ) ; <nl> + Assert . assertEquals ( \" break : second - tier \" , rootTarget . call ( ) ) ; <nl> + } <nl> + <nl> } <nl>\n", "msg": "Add test for backedge - counter - triggered compilations in the first tier .\n"}
{"diff_id": 3674, "repo": "spring-projects/spring-framework\n", "sha": "cfb380d653547f36591d5407e4e60448fb4718cc\n", "time": "2011-10-11T02:08:26Z\n", "diff": "mmm a / org . springframework . orm / src / main / java / org / springframework / orm / jpa / vendor / HibernateJpaDialect . java <nl> ppp b / org . springframework . orm / src / main / java / org / springframework / orm / jpa / vendor / HibernateJpaDialect . java <nl> public SessionTransactionData ( Session session , FlushMode previousFlushMode ) { <nl> } <nl> <nl> public void cleanup ( ) { <nl> - TransactionSynchronizationManager . unbindResource ( this . session . getSessionFactory ( ) ) ; <nl> + SessionFactory sessionFactory = this . session . getSessionFactory ( ) ; <nl> + if ( TransactionSynchronizationManager . hasResource ( sessionFactory ) ) { <nl> + TransactionSynchronizationManager . unbindResource ( sessionFactory ) ; <nl> + } <nl> if ( this . previousFlushMode ! = null ) { <nl> this . session . setFlushMode ( this . previousFlushMode ) ; <nl> } <nl>\n", "msg": "fixed unbind failure through appropriate guard\n"}
{"diff_id": 3696, "repo": "oracle/graal\n", "sha": "8d5f717907b9c0c55876b42b83471d0951652820\n", "time": "2013-03-17T21:57:47Z\n", "diff": "mmm a / graal / com . oracle . graal . hotspot . amd64 / src / com / oracle / graal / hotspot / amd64 / AMD64DeoptimizeOp . java <nl> ppp b / graal / com . oracle . graal . hotspot . amd64 / src / com / oracle / graal / hotspot / amd64 / AMD64DeoptimizeOp . java <nl> <nl> * / <nl> package com . oracle . graal . hotspot . amd64 ; <nl> <nl> + import com . oracle . graal . amd64 . * ; <nl> import com . oracle . graal . api . code . * ; <nl> import com . oracle . graal . api . code . RuntimeCallTarget . Descriptor ; <nl> import com . oracle . graal . api . meta . * ; <nl> import com . oracle . graal . asm . amd64 . * ; <nl> import com . oracle . graal . lir . * ; <nl> - import com . oracle . graal . lir . LIRInstruction . Opcode ; <nl> + import com . oracle . graal . lir . LIRInstruction . * ; <nl> import com . oracle . graal . lir . amd64 . * ; <nl> import com . oracle . graal . lir . asm . * ; <nl> <nl> <nl> private DeoptimizationAction action ; <nl> private DeoptimizationReason reason ; <nl> @ State private LIRFrameState info ; <nl> + @ Temp protected RegisterValue deoptimizationReason ; <nl> <nl> AMD64DeoptimizeOp ( DeoptimizationAction action , DeoptimizationReason reason , LIRFrameState info ) { <nl> this . action = action ; <nl> this . reason = reason ; <nl> this . info = info ; <nl> + this . deoptimizationReason = AMD64 . r10 . asValue ( Kind . Int ) ; <nl> } <nl> <nl> @ Override <nl> public void emitCode ( TargetMethodAssembler tasm , AMD64MacroAssembler masm ) { <nl> - Register scratch = tasm . frameMap . registerConfig . getScratchRegister ( ) ; <nl> - masm . movl ( scratch , tasm . runtime . encodeDeoptActionAndReason ( action , reason ) ) ; <nl> + masm . movl ( deoptimizationReason . getRegister ( ) , tasm . runtime . encodeDeoptActionAndReason ( action , reason ) ) ; <nl> AMD64Call . directCall ( tasm , masm , tasm . runtime . lookupRuntimeCall ( DEOPTIMIZE ) , info ) ; <nl> } <nl> } <nl>\n", "msg": "Explicitely allocate r10 for deoptimization operation .\n"}
{"diff_id": 3819, "repo": "oracle/graal\n", "sha": "03b08d1c1c3dc105406d2497ff8c6e091e35d101\n", "time": "2016-05-17T11:59:35Z\n", "diff": "mmm a / truffle / com . oracle . truffle . api / src / com / oracle / truffle / api / source / AppendableLiteralSourceImpl . java <nl> ppp b / truffle / com . oracle . truffle . api / src / com / oracle / truffle / api / source / AppendableLiteralSourceImpl . java <nl> <nl> import java . io . Reader ; <nl> import java . io . StringReader ; <nl> import java . net . URL ; <nl> - import java . util . ArrayList ; <nl> - import java . util . List ; <nl> <nl> final class AppendableLiteralSourceImpl extends Content { <nl> <nl> private final String name ; <nl> - final List < CharSequence > codeList = new ArrayList < > ( ) ; <nl> + private final StringBuffer text = new StringBuffer ( ) ; <nl> <nl> AppendableLiteralSourceImpl ( String name ) { <nl> this . name = name ; <nl> public String getShortName ( ) { <nl> <nl> @ Override <nl> public String getCode ( ) { <nl> - return getCodeFromIndex ( 0 ) ; <nl> + return text . toString ( ) ; <nl> } <nl> <nl> @ Override <nl> public Reader getReader ( ) { <nl> void reset ( ) { <nl> } <nl> <nl> - private String getCodeFromIndex ( int index ) { <nl> - StringBuilder sb = new StringBuilder ( ) ; <nl> - for ( int i = index ; i < codeList . size ( ) ; i + + ) { <nl> - CharSequence s = codeList . get ( i ) ; <nl> - sb . append ( s ) ; <nl> - } <nl> - return sb . toString ( ) ; <nl> - } <nl> - <nl> @ Override <nl> public void appendCode ( CharSequence chars ) { <nl> - codeList . add ( chars ) ; <nl> + text . append ( chars ) ; <nl> } <nl> <nl> @ Override <nl>\n", "msg": "Keeping StringBuffer in a field makes the code simpler and more thread safe\n"}
{"diff_id": 3866, "repo": "SeleniumHQ/selenium\n", "sha": "cf5fd162183c6f25a925539ec5fb5948c158a2ea\n", "time": "2019-09-25T12:01:51Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / firefox / GeckoDriverService . java <nl> ppp b / java / client / src / org / openqa / selenium / firefox / GeckoDriverService . java <nl> static GeckoDriverService createDefaultService ( Capabilities caps ) { <nl> builder . usingFirefoxBinary ( actualBinary ) ; <nl> } <nl> <nl> - return new Builder ( ) . build ( ) ; <nl> + return builder . build ( ) ; <nl> } <nl> <nl> @ Override <nl> protected File findDefaultExecutable ( ) { <nl> protected GeckoDriverService createDriverService ( File exe , int port , <nl> ImmutableList < String > args , <nl> ImmutableMap < String , String > environment ) { <nl> + System . err . println ( \" Starting GeckoDriverService on port \" + port ) ; <nl> try { <nl> GeckoDriverService service = new GeckoDriverService ( exe , port , args , environment ) ; <nl> String firefoxLogFile = System . getProperty ( FirefoxDriver . SystemProperty . BROWSER_LOGFILE ) ; <nl>\n", "msg": "[ java ] Fixing GeckoDriverService builder to use passed capabilities\n"}
{"diff_id": 3883, "repo": "elastic/elasticsearch\n", "sha": "d5e6eb58a8120d42341b7dad6669f47ce81c3e86\n", "time": "2016-01-07T13:04:35Z\n", "diff": "mmm a / core / src / main / java / org / elasticsearch / threadpool / ThreadPool . java <nl> ppp b / core / src / main / java / org / elasticsearch / threadpool / ThreadPool . java <nl> public ScheduledExecutorService scheduler ( ) { <nl> if ( ! Names . SAME . equals ( name ) ) { <nl> command = new ThreadedRunnable ( command , executor ( name ) ) ; <nl> } <nl> - return scheduler . schedule ( command , delay . millis ( ) , TimeUnit . MILLISECONDS ) ; <nl> + return scheduler . schedule ( new LoggingRunnable ( command ) , delay . millis ( ) , TimeUnit . MILLISECONDS ) ; <nl> } <nl> <nl> public void shutdown ( ) { <nl> public void run ( ) { <nl> runnable . run ( ) ; <nl> } catch ( Throwable t ) { <nl> logger . warn ( \" failed to run { } \" , t , runnable . toString ( ) ) ; <nl> + throw t ; <nl> } <nl> } <nl> <nl>\n", "msg": "Log uncaught exceptions from scheduled once tasks\n"}
{"diff_id": 3959, "repo": "netty/netty\n", "sha": "c43b424f56ef013fce638c647e8367796ff90ae4\n", "time": "2016-05-31T12:05:03Z\n", "diff": "mmm a / transport / src / main / java / io / netty / channel / embedded / EmbeddedChannel . java <nl> ppp b / transport / src / main / java / io / netty / channel / embedded / EmbeddedChannel . java <nl> public EmbeddedChannel ( ChannelId channelId , boolean hasDisconnect , final Channel <nl> final ChannelHandler . . . handlers ) { <nl> super ( null , channelId ) ; <nl> metadata = metadata ( hasDisconnect ) ; <nl> - this . config = config ; <nl> + this . config = ObjectUtil . checkNotNull ( config , \" config \" ) ; <nl> setup ( handlers ) ; <nl> } <nl> <nl>\n", "msg": "Add missing null check that was missed in 844976a0a2a940eb28293e3f74bc133cbbde0bac\n"}
{"diff_id": 4166, "repo": "SeleniumHQ/selenium\n", "sha": "e17bfdeec9a3de783ee50ac94b2fcc562078a662\n", "time": "2009-12-16T05:44:41Z\n", "diff": "mmm a / remote / server / src / java / org / openqa / selenium / server / SeleniumServer . java <nl> ppp b / remote / server / src / java / org / openqa / selenium / server / SeleniumServer . java <nl> private HttpContext createWebDriverRemoteContext ( ) { <nl> HttpContext webdriverContext = new HttpContext ( ) ; <nl> webdriverContext . setContextPath ( \" / wd \" ) ; <nl> ServletHandler handler = new ServletHandler ( ) ; <nl> - handler . addServlet ( \" WebDriver remote server \" , \" / hub \" , DriverServlet . class . getName ( ) ) ; <nl> + handler . addServlet ( \" WebDriver remote server \" , \" / hub / * \" , DriverServlet . class . getName ( ) ) ; <nl> webdriverContext . addHandler ( handler ) ; <nl> <nl> LOGGER . info ( format ( \" RemoteWebDriver instances should connect to : http : / / % s : % d / wd / hub \" , <nl>\n", "msg": "SimonStewart : Fixing the mapping of the webdriver remote server in the standalone servlet\n"}
{"diff_id": 4229, "repo": "SeleniumHQ/selenium\n", "sha": "b095a45f95e494e1c1ccbc9c6b8a383a885fb625\n", "time": "2020-11-29T10:39:17Z\n", "diff": "mmm a / java / client / test / org / openqa / selenium / remote / RemoteWebDriverUnitTest . java <nl> ppp b / java / client / test / org / openqa / selenium / remote / RemoteWebDriverUnitTest . java <nl> public void constructorShouldThrowIfExecutorIsNull ( ) { <nl> } <nl> <nl> @ Test <nl> - public void constructorShouldThrowIfExecutorThrowsOnAnAttemptToStartASession ( ) throws IOException { <nl> + public void constructorShouldThrowIfExecutorThrowsOnAnAttemptToStartASession ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( exceptionResponder ) ; <nl> assertThatExceptionOfType ( SessionNotCreatedException . class ) <nl> . isThrownBy ( ( ) - > new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ) ; <nl> <nl> - verify ( executor ) . execute ( argThat ( <nl> - command - > command . getName ( ) . equals ( DriverCommand . NEW_SESSION ) ) ) ; <nl> - verifyNoMoreInteractions ( executor ) ; <nl> + verifyCommands ( executor , null ) ; / / no commands <nl> } <nl> <nl> @ Test <nl> - public void constructorShouldThrowIfExecutorReturnsNullOnAnAttemptToStartASession ( ) throws IOException { <nl> + public void constructorShouldThrowIfExecutorReturnsNullOnAnAttemptToStartASession ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( nullResponder ) ; <nl> assertThatExceptionOfType ( SessionNotCreatedException . class ) <nl> . isThrownBy ( ( ) - > new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ) ; <nl> <nl> - verify ( executor ) . execute ( argThat ( <nl> - command - > command . getName ( ) . equals ( DriverCommand . NEW_SESSION ) ) ) ; <nl> - verifyNoMoreInteractions ( executor ) ; <nl> + verifyCommands ( executor , null ) ; / / no commands <nl> } <nl> <nl> @ Test <nl> - public void constructorShouldThrowIfExecutorReturnsAResponseWithNullValueOnAnAttemptToStartASession ( ) throws IOException { <nl> + public void constructorShouldThrowIfExecutorReturnsAResponseWithNullValueOnAnAttemptToStartASession ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( nullValueResponder ) ; <nl> assertThatExceptionOfType ( SessionNotCreatedException . class ) <nl> . isThrownBy ( ( ) - > new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ) ; <nl> <nl> - verify ( executor ) . execute ( argThat ( <nl> - command - > command . getName ( ) . equals ( DriverCommand . NEW_SESSION ) ) ) ; <nl> - verifyNoMoreInteractions ( executor ) ; <nl> + verifyCommands ( executor , null ) ; / / no commands <nl> } <nl> <nl> @ Test <nl> - public void constructorShouldThrowIfExecutorReturnsSomethingButNotCapabilitiesOnAnAttemptToStartASession ( ) throws IOException { <nl> + public void constructorShouldThrowIfExecutorReturnsSomethingButNotCapabilitiesOnAnAttemptToStartASession ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( valueResponder ( \" OK \" ) ) ; <nl> assertThatExceptionOfType ( SessionNotCreatedException . class ) <nl> . isThrownBy ( ( ) - > new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ) ; <nl> <nl> - verify ( executor ) . execute ( argThat ( <nl> - command - > command . getName ( ) . equals ( DriverCommand . NEW_SESSION ) ) ) ; <nl> - verifyNoMoreInteractions ( executor ) ; <nl> + verifyCommands ( executor , null ) ; / / no commands <nl> } <nl> <nl> @ Test <nl> public void canHandleUnknownPlatformNameAndFallsBackToUnix ( ) { <nl> } <nl> <nl> @ Test <nl> - public void canHandleGetCommand ( ) throws IOException { <nl> + public void canHandleGetCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleGetCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleGetCurrentUrlCommand ( ) throws IOException { <nl> + public void canHandleGetCurrentUrlCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( \" http : / / some . host . com \" ) ) ; <nl> <nl> public void canHandleGetCurrentUrlCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleGetTitleCommand ( ) throws IOException { <nl> + public void canHandleGetTitleCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( \" Hello , world ! \" ) ) ; <nl> <nl> public void canHandleGetTitleCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleGetPageSourceCommand ( ) throws IOException { <nl> + public void canHandleGetPageSourceCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( \" Hello , world ! \" ) ) ; <nl> <nl> public void canHandleGetPageSourceCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleExecuteScriptCommand ( ) throws IOException { <nl> + public void canHandleExecuteScriptCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( \" Hello , world ! \" ) ) ; <nl> <nl> public void canHandleExecuteScriptCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleExecuteAsyncScriptCommand ( ) throws IOException { <nl> + public void canHandleExecuteAsyncScriptCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( \" Hello , world ! \" ) ) ; <nl> <nl> public void canHandleExecuteAsyncScriptCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleFindElementOSSCommand ( ) throws IOException { <nl> + public void canHandleFindElementOSSCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , <nl> valueResponder ( ImmutableMap . of ( \" ELEMENT \" , UUID . randomUUID ( ) . toString ( ) ) ) ) ; <nl> public void canHandleFindElementOSSCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleFindElementW3CCommand ( ) throws IOException { <nl> + public void canHandleFindElementW3CCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , <nl> valueResponder ( ImmutableMap . of ( ELEMENT_KEY , UUID . randomUUID ( ) . toString ( ) ) ) ) ; <nl> public void canHandleFindElementW3CCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleFindElementCommandWithNonStandardLocator ( ) throws IOException { <nl> + public void canHandleFindElementCommandWithNonStandardLocator ( ) { <nl> WebElement element1 = mock ( WebElement . class ) ; <nl> WebElement element2 = mock ( WebElement . class ) ; <nl> By locator = new By ( ) { <nl> public void canHandleFindElementCommandWithNonStandardLocator ( ) throws IOExcepti <nl> WebElement found = driver . findElement ( locator ) ; <nl> <nl> assertThat ( found ) . isSameAs ( element1 ) ; <nl> - verifyCommands ( executor , driver . getSessionId ( ) ) ; <nl> + verifyCommands ( executor , driver . getSessionId ( ) / * no commands * / ) ; <nl> } <nl> <nl> @ Test <nl> - public void canHandleFindElementsOSSCommand ( ) throws IOException { <nl> + public void canHandleFindElementsOSSCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , <nl> valueResponder ( Arrays . asList ( <nl> public void canHandleFindElementsOSSCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleFindElementsW3CCommand ( ) throws IOException { <nl> + public void canHandleFindElementsW3CCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , <nl> valueResponder ( Arrays . asList ( <nl> public void canHandleFindElementsW3CCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleFindElementsCommandWithNonStandardLocator ( ) throws IOException { <nl> + public void canHandleFindElementsCommandWithNonStandardLocator ( ) { <nl> WebElement element1 = mock ( WebElement . class ) ; <nl> WebElement element2 = mock ( WebElement . class ) ; <nl> By locator = new By ( ) { <nl> public void throwIfRemoteEndReturnsNullFromFindChild ( ) { <nl> } <nl> <nl> @ Test <nl> - public void canHandleGetWindowHandleCommand ( ) throws IOException { <nl> + public void canHandleGetWindowHandleCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( \" Hello , world ! \" ) ) ; <nl> <nl> public void canHandleGetWindowHandleCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleGetWindowHandlesCommand ( ) throws IOException { <nl> + public void canHandleGetWindowHandlesCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( Arrays . asList ( \" window 1 \" , \" window 2 \" ) ) ) ; <nl> <nl> public void canHandleGetWindowHandlesCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleCloseCommand ( ) throws IOException { <nl> + public void canHandleCloseCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleCloseCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleQuitCommand ( ) throws IOException { <nl> + public void canHandleQuitCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleQuitCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleQuitCommandAfterQuit ( ) throws IOException { <nl> + public void canHandleQuitCommandAfterQuit ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleQuitCommandAfterQuit ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSwitchToWindowCommand ( ) throws IOException { <nl> + public void canHandleSwitchToWindowCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleSwitchToWindowCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSwitchToNewWindowCommand ( ) throws IOException { <nl> + public void canHandleSwitchToNewWindowCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( ImmutableMap . of ( \" handle \" , \" new window \" ) ) ) ; <nl> <nl> public void canHandleSwitchToNewWindowCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSwitchToFrameByIndexCommand ( ) throws IOException { <nl> + public void canHandleSwitchToFrameByIndexCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleSwitchToFrameByNameCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSwitchToNonExistingFrameCommand ( ) throws IOException { <nl> + public void canHandleSwitchToNonExistingFrameCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( EMPTY_LIST ) ) ; <nl> <nl> public void canHandleSwitchToNonExistingFrameCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSwitchToParentFrameCommand ( ) throws IOException { <nl> + public void canHandleSwitchToParentFrameCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleSwitchToParentFrameCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSwitchToTopCommand ( ) throws IOException { <nl> + public void canHandleSwitchToTopCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleSwitchToTopCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSwitchToAlertCommand ( ) throws IOException { <nl> + public void canHandleSwitchToAlertCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( \" Alarm ! \" ) ) ; <nl> <nl> public void canHandleSwitchToAlertCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleAlertAcceptCommand ( ) throws IOException { <nl> + public void canHandleAlertAcceptCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( \" Alarm ! \" ) , nullValueResponder ) ; <nl> <nl> public void canHandleAlertAcceptCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleAlertDismissCommand ( ) throws IOException { <nl> + public void canHandleAlertDismissCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( \" Alarm ! \" ) , nullValueResponder ) ; <nl> <nl> public void canHandleAlertDismissCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleAlertSendKeysCommand ( ) throws IOException { <nl> + public void canHandleAlertSendKeysCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( \" Are you sure ? \" ) , nullValueResponder ) ; <nl> <nl> public void canHandleAlertSendKeysCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleRefreshCommand ( ) throws IOException { <nl> + public void canHandleRefreshCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleRefreshCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleBackCommand ( ) throws IOException { <nl> + public void canHandleBackCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleBackCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleForwardCommand ( ) throws IOException { <nl> + public void canHandleForwardCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleNavigateToCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleGetCookiesCommand ( ) throws IOException { <nl> + public void canHandleGetCookiesCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , <nl> valueResponder ( Arrays . asList ( <nl> public void canHandleGetCookiesCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleGetCookieNamedCommand ( ) throws IOException { <nl> + public void canHandleGetCookieNamedCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , <nl> valueResponder ( Arrays . asList ( <nl> public void canHandleGetCookieNamedCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleAddCookieCommand ( ) throws IOException { <nl> + public void canHandleAddCookieCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> Cookie cookie = new Cookie ( \" x \" , \" y \" ) ; <nl> public void canHandleAddCookieCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleDeleteCookieCommand ( ) throws IOException { <nl> + public void canHandleDeleteCookieCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> Cookie cookie = new Cookie ( \" x \" , \" y \" ) ; <nl> public void canHandleDeleteCookieCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleDeleteAllCookiesCommand ( ) throws IOException { <nl> + public void canHandleDeleteAllCookiesCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleDeleteAllCookiesCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleGetWindowSizeCommand ( ) throws IOException { <nl> + public void canHandleGetWindowSizeCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , <nl> valueResponder ( ImmutableMap . of ( \" width \" , 400 , \" height \" , 600 ) ) ) ; <nl> public void canHandleGetWindowSizeCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSetWindowSizeCommand ( ) throws IOException { <nl> + public void canHandleSetWindowSizeCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleSetWindowSizeCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleGetWindowPositionCommand ( ) throws IOException { <nl> + public void canHandleGetWindowPositionCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , <nl> valueResponder ( ImmutableMap . of ( \" x \" , 100 , \" y \" , 200 ) ) ) ; <nl> public void canHandleGetWindowPositionCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSetWindowPositionCommand ( ) throws IOException { <nl> + public void canHandleSetWindowPositionCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleSetWindowPositionCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleMaximizeCommand ( ) throws IOException { <nl> + public void canHandleMaximizeCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleMaximizeCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleFullscreenCommand ( ) throws IOException { <nl> + public void canHandleFullscreenCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleFullscreenCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSetImplicitWaitCommand ( ) throws IOException { <nl> + public void canHandleSetImplicitWaitCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleSetImplicitWaitCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSetScriptTimeoutCommand ( ) throws IOException { <nl> + public void canHandleSetScriptTimeoutCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleSetScriptTimeoutCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleSetPageLoadTimeoutCommand ( ) throws IOException { <nl> + public void canHandleSetPageLoadTimeoutCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleSetPageLoadTimeoutCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleIME ( ) throws IOException { <nl> + public void canHandleIME ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( singletonList ( \" cheese \" ) ) ) ; <nl> <nl> public void canHandleIME ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementClickCommand ( ) throws IOException { <nl> + public void canHandleElementClickCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleElementClickCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleWebDriverExceptionThrownByCommandExecutor ( ) throws IOException { <nl> + public void canHandleWebDriverExceptionThrownByCommandExecutor ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , webDriverExceptionResponder ) ; <nl> <nl> public void canHandleWebDriverExceptionThrownByCommandExecutor ( ) throws IOExcept <nl> } <nl> <nl> @ Test <nl> - public void canHandleGeneralExceptionThrownByCommandExecutor ( ) throws IOException { <nl> + public void canHandleGeneralExceptionThrownByCommandExecutor ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , exceptionResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( <nl> public void canHandleGeneralExceptionThrownByCommandExecutor ( ) throws IOExceptio <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementClearCommand ( ) throws IOException { <nl> + public void canHandleElementClearCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleElementClearCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementSubmitCommand ( ) throws IOException { <nl> + public void canHandleElementSubmitCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleElementSubmitCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementSendKeysCommand ( ) throws IOException { <nl> + public void canHandleElementSendKeysCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , nullValueResponder ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleElementSendKeysCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementGetAttributeCommand ( ) throws IOException { <nl> + public void canHandleElementGetAttributeCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , valueResponder ( \" test \" ) ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleElementGetAttributeCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementIsSelectedCommand ( ) throws IOException { <nl> + public void canHandleElementIsSelectedCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , valueResponder ( true ) ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleElementIsSelectedCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementIsEnabledCommand ( ) throws IOException { <nl> + public void canHandleElementIsEnabledCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , valueResponder ( true ) ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleElementIsEnabledCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementIsDisplayedCommand ( ) throws IOException { <nl> + public void canHandleElementIsDisplayedCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , valueResponder ( true ) ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleElementIsDisplayedCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementGeTextCommand ( ) throws IOException { <nl> + public void canHandleElementGeTextCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , valueResponder ( \" test \" ) ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleElementGeTextCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementGetTagNameCommand ( ) throws IOException { <nl> + public void canHandleElementGetTagNameCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , valueResponder ( \" div \" ) ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public void canHandleElementGetTagNameCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementGetLocationCommand ( ) throws IOException { <nl> + public void canHandleElementGetLocationCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( ImmutableMap . of ( \" x \" , 10 , \" y \" , 20 ) ) ) ; <nl> <nl> public void canHandleElementGetLocationCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementGetSizeCommand ( ) throws IOException { <nl> + public void canHandleElementGetSizeCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , valueResponder ( ImmutableMap . of ( \" width \" , 100 , \" height \" , 200 ) ) ) ; <nl> <nl> public void canHandleElementGetSizeCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementGetRectCommand ( ) throws IOException { <nl> + public void canHandleElementGetRectCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( <nl> echoCapabilities , <nl> valueResponder ( ImmutableMap . of ( \" x \" , 10 , \" y \" , 20 , \" width \" , 100 , \" height \" , 200 ) ) ) ; <nl> public void canHandleElementGetRectCommand ( ) throws IOException { <nl> } <nl> <nl> @ Test <nl> - public void canHandleElementCssPropertyCommand ( ) throws IOException { <nl> + public void canHandleElementCssPropertyCommand ( ) { <nl> CommandExecutor executor = prepareExecutorMock ( echoCapabilities , valueResponder ( \" red \" ) ) ; <nl> <nl> RemoteWebDriver driver = new RemoteWebDriver ( executor , new ImmutableCapabilities ( ) ) ; <nl> public int getTimes ( ) { <nl> } <nl> } <nl> <nl> - private void verifyCommands ( CommandExecutor executor , SessionId sid , CommandPayload . . . commands ) <nl> - throws IOException <nl> - { <nl> + private void verifyCommands ( CommandExecutor executor , SessionId sid , CommandPayload . . . commands ) { <nl> InOrder inOrder = Mockito . inOrder ( executor ) ; <nl> - inOrder . verify ( executor ) . execute ( argThat ( <nl> - command - > command . getName ( ) . equals ( DriverCommand . NEW_SESSION ) ) ) ; <nl> - for ( CommandPayload target : commands ) { <nl> - int x = target instanceof MultiCommandPayload ? ( ( MultiCommandPayload ) target ) . getTimes ( ) : 1 ; <nl> - inOrder . verify ( executor , times ( x ) ) . execute ( argThat ( <nl> - cmd - > cmd . getSessionId ( ) . equals ( sid ) <nl> - & & cmd . getName ( ) . equals ( target . getName ( ) ) <nl> - & & areEqual ( cmd . getParameters ( ) , target . getParameters ( ) ) ) ) ; <nl> + try { <nl> + inOrder . verify ( executor ) . execute ( argThat ( <nl> + command - > command . getName ( ) . equals ( DriverCommand . NEW_SESSION ) ) ) ; <nl> + for ( CommandPayload target : commands ) { <nl> + int <nl> + x = <nl> + target instanceof MultiCommandPayload ? ( ( MultiCommandPayload ) target ) . getTimes ( ) : 1 ; <nl> + inOrder . verify ( executor , times ( x ) ) . execute ( argThat ( <nl> + cmd - > cmd . getSessionId ( ) . equals ( sid ) <nl> + & & cmd . getName ( ) . equals ( target . getName ( ) ) <nl> + & & areEqual ( cmd . getParameters ( ) , target . getParameters ( ) ) ) ) ; <nl> + } <nl> + } catch ( IOException ex ) { <nl> + throw new UncheckedIOException ( ex ) ; <nl> } <nl> verifyNoMoreInteractions ( executor ) ; <nl> } <nl>\n", "msg": "[ java ] Code simplification , no functional changes\n"}
{"diff_id": 4421, "repo": "libgdx/libgdx\n", "sha": "10f70fe96b7b93074f8366718c8330a78fc21923\n", "time": "2013-08-04T19:19:58Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / utils / SharedLibraryLoader . java <nl> ppp b / gdx / src / com / badlogic / gdx / utils / SharedLibraryLoader . java <nl> public String crc ( InputStream input ) { <nl> } catch ( Exception ignored ) { <nl> } <nl> } <nl> - return Long . toString ( crc . getValue ( ) ) ; <nl> + return Long . toString ( crc . getValue ( ) , 16 ) ; <nl> } <nl> <nl> / * * Maps a platform independent library name to a platform dependent name . * / <nl> public synchronized void load ( String libraryName ) { <nl> if ( isAndroid ) <nl> System . loadLibrary ( libraryName ) ; <nl> else <nl> - System . load ( extractFile ( libraryName , null ) . getAbsolutePath ( ) ) ; <nl> + loadFile ( libraryName ) ; <nl> } catch ( Throwable ex ) { <nl> throw new GdxRuntimeException ( \" Couldn ' t load shared library ' \" + libraryName + \" ' for target : \" <nl> + System . getProperty ( \" os . name \" ) + ( is64Bit ? \" , 64 - bit \" : \" , 32 - bit \" ) , ex ) ; <nl> public File extractFile ( String sourcePath , String dirName ) throws IOException { <nl> String sourceCrc = crc ( readFile ( sourcePath ) ) ; <nl> if ( dirName = = null ) dirName = sourceCrc ; <nl> <nl> - File extractedDir = new File ( System . getProperty ( \" java . io . tmpdir \" ) + \" / libgdx \" + System . getProperty ( \" user . name \" ) + \" / \" <nl> - + dirName ) ; <nl> - File extractedFile = new File ( extractedDir , new File ( sourcePath ) . getName ( ) ) ; <nl> + File extractedFile = getExtractedFile ( dirName , new File ( sourcePath ) . getName ( ) ) ; <nl> + return extractFile ( sourcePath , sourceCrc , extractedFile ) ; <nl> + } catch ( RuntimeException ex ) { <nl> + / / Fallback to file at java . library . path location , eg for applets . <nl> + File file = new File ( System . getProperty ( \" java . library . path \" ) , sourcePath ) ; <nl> + if ( file . exists ( ) ) return file ; <nl> + throw ex ; <nl> + } <nl> + } <nl> <nl> - String extractedCrc = null ; <nl> - if ( extractedFile . exists ( ) ) { <nl> - try { <nl> - extractedCrc = crc ( new FileInputStream ( extractedFile ) ) ; <nl> - } catch ( FileNotFoundException ignored ) { <nl> - } <nl> + / * * Returns a path to a file that can be written . Tries multiple locations and verifies writing succeeds . * / <nl> + private File getExtractedFile ( String dirName , String fileName ) { <nl> + / / Temp directory with username in path . <nl> + File idealFile = new File ( System . getProperty ( \" java . io . tmpdir \" ) + \" / libgdx \" + System . getProperty ( \" user . name \" ) + \" / \" <nl> + + dirName , fileName ) ; <nl> + if ( canWrite ( idealFile ) ) return idealFile ; <nl> + <nl> + / / System provided temp directory . <nl> + try { <nl> + File file = File . createTempFile ( dirName , null ) ; <nl> + if ( file . delete ( ) ) { <nl> + file = new File ( file , fileName ) ; <nl> + if ( canWrite ( file ) ) return file ; <nl> } <nl> + } catch ( IOException ignored ) { <nl> + } <nl> + <nl> + / / User home . <nl> + File file = new File ( System . getProperty ( \" user . home \" ) + \" / . libgdx / \" + dirName , fileName ) ; <nl> + if ( canWrite ( file ) ) return file ; <nl> + <nl> + / / Relative directory . <nl> + file = new File ( \" . temp / \" + dirName , fileName ) ; <nl> + if ( canWrite ( file ) ) return file ; <nl> + <nl> + return idealFile ; / / Will likely fail , but we did our best . <nl> + } <nl> + <nl> + / * * Returns true if the parent directories of the file can be created and the file can be written . * / <nl> + private boolean canWrite ( File file ) { <nl> + if ( file . canWrite ( ) ) return true ; / / File exists and is writable . <nl> + File parent = file . getParentFile ( ) ; <nl> + parent . mkdirs ( ) ; <nl> + if ( ! parent . isDirectory ( ) ) return false ; <nl> + try { <nl> + new FileOutputStream ( file ) . close ( ) ; <nl> + file . delete ( ) ; <nl> + return true ; <nl> + } catch ( Throwable ex ) { <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> + private File extractFile ( String sourcePath , String sourceCrc , File extractedFile ) throws IOException { <nl> + String extractedCrc = null ; <nl> + if ( extractedFile . exists ( ) ) { <nl> + try { <nl> + extractedCrc = crc ( new FileInputStream ( extractedFile ) ) ; <nl> + } catch ( FileNotFoundException ignored ) { <nl> + } <nl> + } <nl> <nl> - / / If file doesn ' t exist or the CRC doesn ' t match , extract it to the temp dir . <nl> - if ( extractedCrc = = null | | ! extractedCrc . equals ( sourceCrc ) ) { <nl> - try { <nl> - InputStream input = readFile ( sourcePath ) ; <nl> - extractedDir . mkdirs ( ) ; <nl> - FileOutputStream output = new FileOutputStream ( extractedFile ) ; <nl> - byte [ ] buffer = new byte [ 4096 ] ; <nl> - while ( true ) { <nl> - int length = input . read ( buffer ) ; <nl> - if ( length = = - 1 ) break ; <nl> - output . write ( buffer , 0 , length ) ; <nl> - } <nl> - input . close ( ) ; <nl> - output . close ( ) ; <nl> - } catch ( IOException ex ) { <nl> - throw new GdxRuntimeException ( \" Error extracting file : \" + sourcePath , ex ) ; <nl> + / / If file doesn ' t exist or the CRC doesn ' t match , extract it to the temp dir . <nl> + if ( extractedCrc = = null | | ! extractedCrc . equals ( sourceCrc ) ) { <nl> + try { <nl> + InputStream input = readFile ( sourcePath ) ; <nl> + extractedFile . getParentFile ( ) . mkdirs ( ) ; <nl> + FileOutputStream output = new FileOutputStream ( extractedFile ) ; <nl> + byte [ ] buffer = new byte [ 4096 ] ; <nl> + while ( true ) { <nl> + int length = input . read ( buffer ) ; <nl> + if ( length = = - 1 ) break ; <nl> + output . write ( buffer , 0 , length ) ; <nl> } <nl> + input . close ( ) ; <nl> + output . close ( ) ; <nl> + } catch ( IOException ex ) { <nl> + throw new GdxRuntimeException ( \" Error extracting file : \" + sourcePath + \" \\ nTo : \" + extractedFile . getAbsolutePath ( ) , ex ) ; <nl> } <nl> + } <nl> <nl> - return extractedFile ; <nl> - } catch ( RuntimeException ex ) { <nl> - / / Attempt to fallback to file at java . library . path location , eg for applets . <nl> - File file = new File ( System . getProperty ( \" java . library . path \" ) , sourcePath ) ; <nl> - if ( file . exists ( ) ) return file ; <nl> - throw ex ; <nl> + return extractedFile ; <nl> + } <nl> + <nl> + / * * Extracts the source file and calls System . load . Attemps to extract and load from multiple locations . Throws runtime <nl> + * exception if all fail . * / <nl> + private void loadFile ( String sourcePath ) { <nl> + String sourceCrc = crc ( readFile ( sourcePath ) ) ; <nl> + <nl> + String fileName = new File ( sourcePath ) . getName ( ) ; <nl> + <nl> + / / Temp directory with username in path . <nl> + File file = new File ( System . getProperty ( \" java . io . tmpdir \" ) + \" / libgdx \" + System . getProperty ( \" user . name \" ) + \" / \" + sourceCrc , <nl> + fileName ) ; <nl> + Throwable ex = loadFile ( sourcePath , sourceCrc , file ) ; <nl> + if ( ex = = null ) return ; <nl> + <nl> + / / System provided temp directory . <nl> + try { <nl> + file = File . createTempFile ( sourceCrc , null ) ; <nl> + if ( file . delete ( ) & & loadFile ( sourcePath , sourceCrc , file ) = = null ) return ; <nl> + } catch ( Throwable ignored ) { <nl> + } <nl> + <nl> + / / User home . <nl> + file = new File ( System . getProperty ( \" user . home \" ) + \" / . libgdx / \" + sourceCrc , fileName ) ; <nl> + if ( loadFile ( sourcePath , sourceCrc , file ) = = null ) return ; <nl> + <nl> + / / Relative directory . <nl> + file = new File ( \" . temp / \" + sourceCrc , fileName ) ; <nl> + if ( loadFile ( sourcePath , sourceCrc , file ) = = null ) return ; <nl> + <nl> + / / Fallback to java . library . path location , eg for applets . <nl> + file = new File ( System . getProperty ( \" java . library . path \" ) , sourcePath ) ; <nl> + if ( file . exists ( ) ) { <nl> + System . load ( file . getAbsolutePath ( ) ) ; <nl> + return ; <nl> + } <nl> + <nl> + throw new GdxRuntimeException ( ex ) ; <nl> + } <nl> + <nl> + / * * @ return null if the file was extracted and loaded . * / <nl> + private Throwable loadFile ( String sourcePath , String sourceCrc , File extractedFile ) { <nl> + try { <nl> + System . load ( extractFile ( sourcePath , sourceCrc , extractedFile ) . getAbsolutePath ( ) ) ; <nl> + return null ; <nl> + } catch ( Throwable ex ) { <nl> + ex . printStackTrace ( ) ; <nl> + return ex ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Improved native library extraction and loading .\n"}
{"diff_id": 4431, "repo": "bazelbuild/bazel\n", "sha": "e905ec3b99dd98c2c99929a6cda0b99cca328c24\n", "time": "2015-07-01T09:14:14Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / skyframe / ActionExecutionFunction . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / ActionExecutionFunction . java <nl> <nl> import com . google . common . base . Preconditions ; <nl> import com . google . common . base . Predicates ; <nl> import com . google . common . collect . Collections2 ; <nl> + import com . google . common . collect . ImmutableSet ; <nl> import com . google . common . collect . Iterables ; <nl> import com . google . common . collect . Maps ; <nl> import com . google . common . collect . Sets ; <nl> private ActionExecutionValue checkCacheAndExecuteIfNeeded ( <nl> / / This may be recreated if we discover inputs . <nl> PerActionFileCache perActionFileCache = new PerActionFileCache ( state . inputArtifactData ) ; <nl> ActionExecutionContext actionExecutionContext = null ; <nl> - boolean inputsDiscoveredDuringActionExecution = false ; <nl> try { <nl> if ( action . discoversInputs ( ) ) { <nl> if ( ! state . hasDiscoveredInputs ( ) ) { <nl> private ActionExecutionValue checkCacheAndExecuteIfNeeded ( <nl> Preconditions . checkState ( env . valuesMissing ( ) , action ) ; <nl> return null ; <nl> } <nl> - if ( state . discoveredInputs = = null ) { <nl> - / / Action had nothing to tell us about discovered inputs before execution . We ' ll have to <nl> - / / add them afterwards . <nl> - inputsDiscoveredDuringActionExecution = true ; <nl> - } <nl> } <nl> / / state . discoveredInputs can be null even after include scanning if action discovers them <nl> / / during execution . <nl> private ActionExecutionValue checkCacheAndExecuteIfNeeded ( <nl> } <nl> } <nl> } <nl> - if ( inputsDiscoveredDuringActionExecution ) { <nl> + if ( action . discoversInputs ( ) ) { <nl> Map < Artifact , FileArtifactValue > metadataFoundDuringActionExecution = <nl> declareAdditionalDependencies ( env , action , state . inputArtifactData . keySet ( ) ) ; <nl> - state . discoveredInputs = metadataFoundDuringActionExecution . keySet ( ) ; <nl> + if ( state . discoveredInputs = = null ) { <nl> + / / Include scanning didn ' t find anything beforehand - - these are the definitive discovered <nl> + / / inputs . <nl> + state . discoveredInputs = metadataFoundDuringActionExecution . keySet ( ) ; <nl> + } else { <nl> + / / Sadly , even if we discovered inputs , sometimes the action runs and discovers more inputs . <nl> + / / Technically , this means our pre - execution input discovery is buggy , but it turns out this <nl> + / / is impractical to fix . <nl> + / / Any new inputs should already have been built - - this is a check that our input <nl> + / / discovery code is not missing too much . It may have to be removed if further input <nl> + / / discovery quirks are found . <nl> + Preconditions . checkState ( ! env . valuesMissing ( ) , \" % s % s % s \" , <nl> + action , metadataFoundDuringActionExecution , state ) ; <nl> + Set < FileArtifactValue > knownMetadata = <nl> + ImmutableSet . copyOf ( state . inputArtifactData . values ( ) ) ; <nl> + ImmutableSet . Builder < Artifact > discoveredInputBuilder = <nl> + ImmutableSet . < Artifact > builder ( ) . addAll ( state . discoveredInputs ) ; <nl> + for ( Map . Entry < Artifact , FileArtifactValue > entry : <nl> + metadataFoundDuringActionExecution . entrySet ( ) ) { <nl> + Preconditions . checkState ( knownMetadata . contains ( entry . getValue ( ) ) , <nl> + \" % s % s \" , action , entry ) ; <nl> + discoveredInputBuilder . add ( entry . getKey ( ) ) ; <nl> + } <nl> + state . discoveredInputs = discoveredInputBuilder . build ( ) ; <nl> + } <nl> if ( env . valuesMissing ( ) ) { <nl> return null ; <nl> } <nl>\n", "msg": "Relax invariant that an action ' s inputs discovered during execution must be included in the action ' s inputs as found during the input discovery phase .\n"}
{"diff_id": 4471, "repo": "jenkinsci/jenkins\n", "sha": "8bdbf7a5b223675750ed27d5beb29ac30d7c61c4\n", "time": "2006-11-12T20:53:02Z\n", "diff": "mmm a / core / src / main / java / hudson / model / Project . java <nl> ppp b / core / src / main / java / hudson / model / Project . java <nl> public String getIconColor ( ) { <nl> return Descriptor . toMap ( publishers ) ; <nl> } <nl> <nl> - / * * <nl> - * Adds a new { @ link BuildStep } to this { @ link Project } and saves the configuration . <nl> - * / <nl> - private synchronized void addPublisher ( Publisher buildStep ) throws IOException { <nl> - for ( int i = 0 ; i < publishers . size ( ) ; i + + ) { <nl> - if ( publishers . get ( i ) . getDescriptor ( ) = = buildStep . getDescriptor ( ) ) { <nl> + private synchronized < T extends Describable < T > > <nl> + void addToList ( T item , List < T > collection ) throws IOException { <nl> + for ( int i = 0 ; i < collection . size ( ) ; i + + ) { <nl> + if ( collection . get ( i ) . getDescriptor ( ) = = item . getDescriptor ( ) ) { <nl> / / replace <nl> - publishers . set ( i , buildStep ) ; <nl> + collection . set ( i , item ) ; <nl> save ( ) ; <nl> return ; <nl> } <nl> } <nl> - <nl> / / add <nl> - publishers . add ( buildStep ) ; <nl> + collection . add ( item ) ; <nl> save ( ) ; <nl> } <nl> <nl> - / * * <nl> - * Removes a publisher from this project , if it ' s active . <nl> - * / <nl> - private void removePublisher ( Descriptor < Publisher > descriptor ) throws IOException { <nl> - for ( int i = 0 ; i < publishers . size ( ) ; i + + ) { <nl> - if ( publishers . get ( i ) . getDescriptor ( ) = = descriptor ) { <nl> + private synchronized < T extends Describable < T > > <nl> + void removeFromList ( Descriptor < T > item , List < T > collection ) throws IOException { <nl> + for ( int i = 0 ; i < collection . size ( ) ; i + + ) { <nl> + if ( collection . get ( i ) . getDescriptor ( ) = = item ) { <nl> / / found it <nl> - publishers . remove ( i ) ; <nl> + collection . remove ( i ) ; <nl> save ( ) ; <nl> return ; <nl> } <nl> } <nl> } <nl> <nl> + / * * <nl> + * Adds a new { @ link Trigger } to this { @ link Project } if not active yet . <nl> + * / <nl> + public void addTrigger ( Trigger trigger ) throws IOException { <nl> + addToList ( trigger , triggers ) ; <nl> + } <nl> + <nl> + public void removeTrigger ( Descriptor < Trigger > trigger ) throws IOException { <nl> + removeFromList ( trigger , triggers ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Adds a new { @ link BuildStep } to this { @ link Project } and saves the configuration . <nl> + * / <nl> + private void addPublisher ( Publisher buildStep ) throws IOException { <nl> + addToList ( buildStep , publishers ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Removes a publisher from this project , if it ' s active . <nl> + * / <nl> + private void removePublisher ( Descriptor < Publisher > descriptor ) throws IOException { <nl> + removeFromList ( descriptor , publishers ) ; <nl> + } <nl> + <nl> public SortedMap < Integer , ? extends Build > _getRuns ( ) { <nl> return builds . getView ( ) ; <nl> } <nl>\n", "msg": "supported methods to add / remove triggers externally .\n"}
{"diff_id": 4630, "repo": "google/guava\n", "sha": "bf6a7fe2ec6c516bc7a1b6c2968db4666dca2b66\n", "time": "2014-09-23T20:04:03Z\n", "diff": "mmm a / guava / src / com / google / common / collect / ImmutableSortedMap . java <nl> ppp b / guava / src / com / google / common / collect / ImmutableSortedMap . java <nl> <nl> return emptyMap ( comparator ) ; <nl> } <nl> <nl> - ImmutableList . Builder < K > keyBuilder = ImmutableList . builder ( ) ; <nl> - ImmutableList . Builder < V > valueBuilder = ImmutableList . builder ( ) ; <nl> + ImmutableList . Builder < K > keyBuilder = new ImmutableList . Builder < K > ( size ) ; <nl> + ImmutableList . Builder < V > valueBuilder = new ImmutableList . Builder < V > ( size ) ; <nl> for ( int i = 0 ; i < size ; i + + ) { <nl> Entry < K , V > entry = entries [ i ] ; <nl> keyBuilder . add ( entry . getKey ( ) ) ; <nl>\n", "msg": "Use presized ImmutableList . Builder in ImmutableSortedMap creation .\n"}
{"diff_id": 4664, "repo": "oracle/graal\n", "sha": "171a162e21887955fea9d66d4ece843542cb1a39\n", "time": "2018-04-05T22:42:19Z\n", "diff": "mmm a / projects / com . oracle . truffle . llvm . test / src / com / oracle / truffle / llvm / test / interop / LLVMInteropTest . java <nl> ppp b / projects / com . oracle . truffle . llvm . test / src / com / oracle / truffle / llvm / test / interop / LLVMInteropTest . java <nl> public void test039 ( ) throws Exception { <nl> } <nl> <nl> @ Test <nl> + @ Ignore ( value = \" test semantics not clear \" ) <nl> public void test040 ( ) throws Exception { <nl> try ( Runner runner = new Runner ( \" interop040 \" ) ) { <nl> runner . run ( ) ; <nl> public void test040 ( ) throws Exception { <nl> } <nl> } <nl> <nl> - / / llvm array to foreign language <nl> @ Test <nl> + @ Ignore ( value = \" test semantics not clear \" ) <nl> public void test041 ( ) throws Exception { <nl> try ( Runner runner = new Runner ( \" interop041 \" ) ) { <nl> runner . run ( ) ; <nl>\n", "msg": "Ignore interop tests with unclear semantics .\n"}
{"diff_id": 4762, "repo": "elastic/elasticsearch\n", "sha": "eb21526552ad42988350245716b5cd6a6cdd97dd\n", "time": "2013-04-13T20:58:30Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / index / fielddata / ScriptDocValues . java <nl> ppp b / src / main / java / org / elasticsearch / index / fielddata / ScriptDocValues . java <nl> public boolean isEmpty ( ) { <nl> public GeoPoint getValue ( ) { <nl> return values . getValue ( docId ) ; <nl> } <nl> + <nl> + public double getLat ( ) { <nl> + return getValue ( ) . lat ( ) ; <nl> + } <nl> + <nl> + public double [ ] getLats ( ) { <nl> + List < GeoPoint > points = getValues ( ) ; <nl> + double [ ] lats = new double [ points . size ( ) ] ; <nl> + for ( int i = 0 ; i < points . size ( ) ; i + + ) { <nl> + lats [ i ] = points . get ( i ) . lat ( ) ; <nl> + } <nl> + return lats ; <nl> + } <nl> + <nl> + public double [ ] getLons ( ) { <nl> + List < GeoPoint > points = getValues ( ) ; <nl> + double [ ] lons = new double [ points . size ( ) ] ; <nl> + for ( int i = 0 ; i < points . size ( ) ; i + + ) { <nl> + lons [ i ] = points . get ( i ) . lon ( ) ; <nl> + } <nl> + return lons ; <nl> + } <nl> + <nl> + public double getLon ( ) { <nl> + return getValue ( ) . lon ( ) ; <nl> + } <nl> + <nl> <nl> public List < GeoPoint > getValues ( ) { <nl> if ( ! listLoaded ) { <nl>\n", "msg": "Added missing support for lat , lats , lon , lons for doc notation in scripts\n"}
{"diff_id": 4769, "repo": "spring-projects/spring-boot\n", "sha": "3786dbc86961af17901b69804568c9154ff7920d\n", "time": "2019-04-24T12:59:53Z\n", "diff": "mmm a / spring - boot - project / spring - boot / src / main / java / org / springframework / boot / context / properties / source / ConfigurationPropertyName . java <nl> ppp b / spring - boot - project / spring - boot / src / main / java / org / springframework / boot / context / properties / source / ConfigurationPropertyName . java <nl> public boolean isAncestorOf ( ConfigurationPropertyName name ) { <nl> if ( this . getNumberOfElements ( ) > = name . getNumberOfElements ( ) ) { <nl> return false ; <nl> } <nl> - for ( int i = this . elements . getSize ( ) - 1 ; i > = 0 ; i - - ) { <nl> - if ( ! elementEquals ( this . elements , name . elements , i ) ) { <nl> - return false ; <nl> - } <nl> - } <nl> - return true ; <nl> + return elementsEqual ( name ) ; <nl> } <nl> <nl> @ Override <nl> public boolean equals ( Object obj ) { <nl> & & other . elements . canShortcutWithSource ( ElementType . UNIFORM ) ) { <nl> return toString ( ) . equals ( other . toString ( ) ) ; <nl> } <nl> + return elementsEqual ( other ) ; <nl> + } <nl> + <nl> + private boolean elementsEqual ( ConfigurationPropertyName name ) { <nl> for ( int i = this . elements . getSize ( ) - 1 ; i > = 0 ; i - - ) { <nl> - if ( ! elementEquals ( this . elements , other . elements , i ) ) { <nl> + if ( elementDiffers ( this . elements , name . elements , i ) ) { <nl> return false ; <nl> } <nl> } <nl> return true ; <nl> } <nl> <nl> - private boolean elementEquals ( Elements e1 , Elements e2 , int i ) { <nl> + private boolean elementDiffers ( Elements e1 , Elements e2 , int i ) { <nl> + ElementType type1 = e1 . getType ( i ) ; <nl> + ElementType type2 = e2 . getType ( i ) ; <nl> + if ( type1 . allowsFastEqualityCheck ( ) & & type2 . allowsFastEqualityCheck ( ) ) { <nl> + return ! fastElementEquals ( e1 , e2 , i ) ; <nl> + } <nl> + else if ( type1 . allowsDashIgnoringEqualityCheck ( ) <nl> + & & type2 . allowsDashIgnoringEqualityCheck ( ) ) { <nl> + return ! dashIgnoringElementEquals ( e1 , e2 , i ) ; <nl> + } <nl> + else { <nl> + return ! defaultElementEquals ( e1 , e2 , i ) ; <nl> + } <nl> + } <nl> + <nl> + private boolean defaultElementEquals ( Elements e1 , Elements e2 , int i ) { <nl> int l1 = e1 . getLength ( i ) ; <nl> int l2 = e2 . getLength ( i ) ; <nl> boolean indexed1 = e1 . getType ( i ) . isIndexed ( ) ; <nl> else if ( ch1 ! = ch2 ) { <nl> return true ; <nl> } <nl> <nl> + private boolean dashIgnoringElementEquals ( Elements e1 , Elements e2 , int i ) { <nl> + int l1 = e1 . getLength ( i ) ; <nl> + int l2 = e2 . getLength ( i ) ; <nl> + int i1 = 0 ; <nl> + int i2 = 0 ; <nl> + while ( i1 < l1 ) { <nl> + if ( i2 > = l2 ) { <nl> + return false ; <nl> + } <nl> + char ch1 = e1 . charAt ( i , i1 ) ; <nl> + char ch2 = e2 . charAt ( i , i2 ) ; <nl> + if ( ch1 = = ' - ' ) { <nl> + i1 + + ; <nl> + } <nl> + else if ( ch2 = = ' - ' ) { <nl> + i2 + + ; <nl> + } <nl> + else if ( ch1 ! = ch2 ) { <nl> + return false ; <nl> + } <nl> + else { <nl> + i1 + + ; <nl> + i2 + + ; <nl> + } <nl> + } <nl> + boolean indexed2 = e2 . getType ( i ) . isIndexed ( ) ; <nl> + while ( i2 < l2 ) { <nl> + char ch2 = e2 . charAt ( i , i2 + + ) ; <nl> + if ( indexed2 | | ch2 = = ' - ' ) { <nl> + return false ; <nl> + } <nl> + } <nl> + return true ; <nl> + } <nl> + <nl> + private boolean fastElementEquals ( Elements e1 , Elements e2 , int i ) { <nl> + int length1 = e1 . getLength ( i ) ; <nl> + int length2 = e2 . getLength ( i ) ; <nl> + if ( length1 = = length2 ) { <nl> + int i1 = 0 ; <nl> + while ( length1 - - ! = 0 ) { <nl> + char ch1 = e1 . charAt ( i , i1 ) ; <nl> + char ch2 = e2 . charAt ( i , i1 ) ; <nl> + if ( ch1 ! = ch2 ) { <nl> + return false ; <nl> + } <nl> + i1 + + ; <nl> + } <nl> + return true ; <nl> + } <nl> + return false ; <nl> + } <nl> + <nl> @ Override <nl> public int hashCode ( ) { <nl> return 0 ; <nl> public boolean isIndexed ( ) { <nl> return this . indexed ; <nl> } <nl> <nl> + public boolean allowsFastEqualityCheck ( ) { <nl> + return this = = UNIFORM | | this = = NUMERICALLY_INDEXED ; <nl> + } <nl> + <nl> + public boolean allowsDashIgnoringEqualityCheck ( ) { <nl> + return allowsFastEqualityCheck ( ) | | this = = DASHED ; <nl> + } <nl> + <nl> } <nl> <nl> / * * <nl>\n", "msg": "Speed up element equality checks in ConfigurationPropertyName\n"}
{"diff_id": 4790, "repo": "elastic/elasticsearch\n", "sha": "0244ddb0cda278b9c48326985304e26c60cb858f\n", "time": "2014-08-27T13:47:39Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / discovery / zen / ZenDiscovery . java <nl> ppp b / src / main / java / org / elasticsearch / discovery / zen / ZenDiscovery . java <nl> <nl> import com . google . common . collect . Sets ; <nl> import org . elasticsearch . ElasticsearchException ; <nl> import org . elasticsearch . ElasticsearchIllegalStateException ; <nl> + import org . elasticsearch . ExceptionsHelper ; <nl> import org . elasticsearch . Version ; <nl> import org . elasticsearch . cluster . * ; <nl> import org . elasticsearch . cluster . block . ClusterBlocks ; <nl> private boolean joinElectedMaster ( DiscoveryNode masterNode ) { <nl> logger . warn ( \" failed to connect to master [ { } ] , retrying . . . \" , e , masterNode ) ; <nl> return false ; <nl> } <nl> - for ( int joinAttempt = 0 ; joinAttempt < this . joinRetryAttempts ; joinAttempt + + ) { <nl> + int joinAttempt = 0 ; / / we retry on illegal state if the master is not yet ready <nl> + while ( true ) { <nl> try { <nl> logger . trace ( \" joining master { } \" , masterNode ) ; <nl> membership . sendJoinRequestBlocking ( masterNode , localNode , joinTimeout ) ; <nl> return true ; <nl> - } catch ( ElasticsearchIllegalStateException e ) { <nl> - if ( joinAttempt > = this . joinRetryAttempts ) { <nl> - logger . info ( \" failed to send join request to master [ { } ] , reason [ { } ] . Tried [ { } ] times \" , <nl> - masterNode , e . getDetailedMessage ( ) , joinAttempt + 1 ) ; <nl> - return false ; <nl> - } else { <nl> - logger . trace ( \" master { } failed with [ { } ] . retrying . . . ( attempts done : [ { } ] ) \" , masterNode , e . getDetailedMessage ( ) , joinAttempt + 1 ) ; <nl> - } <nl> - } catch ( Exception e ) { <nl> - if ( logger . isTraceEnabled ( ) ) { <nl> - logger . trace ( \" failed to send join request to master [ { } ] \" , e ) ; <nl> - } else if ( e instanceof ElasticsearchException ) { <nl> - logger . info ( \" failed to send join request to master [ { } ] , reason [ { } ] \" , masterNode , ( ( ElasticsearchException ) e ) . getDetailedMessage ( ) ) ; <nl> + } catch ( Throwable t ) { <nl> + Throwable unwrap = ExceptionsHelper . unwrapCause ( t ) ; <nl> + if ( unwrap instanceof ElasticsearchIllegalStateException ) { <nl> + if ( + + joinAttempt = = this . joinRetryAttempts ) { <nl> + logger . info ( \" failed to send join request to master [ { } ] , reason [ { } ] , tried [ { } ] times \" , masterNode , ExceptionsHelper . detailedMessage ( t ) , joinAttempt ) ; <nl> + return false ; <nl> + } else { <nl> + logger . trace ( \" master { } failed with [ { } ] . retrying . . . ( attempts done : [ { } ] ) \" , masterNode , ExceptionsHelper . detailedMessage ( t ) , joinAttempt ) ; <nl> + } <nl> } else { <nl> - logger . info ( \" failed to send join request to master [ { } ] , reason [ { } ] \" , masterNode , e . getMessage ( ) ) ; <nl> + if ( logger . isTraceEnabled ( ) ) { <nl> + logger . trace ( \" failed to send join request to master [ { } ] \" , t ) ; <nl> + } else { <nl> + logger . info ( \" failed to send join request to master [ { } ] , reason [ { } ] \" , masterNode , ExceptionsHelper . detailedMessage ( t ) ) ; <nl> + } <nl> + return false ; <nl> } <nl> - return false ; <nl> } <nl> <nl> try { <nl> private boolean joinElectedMaster ( DiscoveryNode masterNode ) { <nl> Thread . currentThread ( ) . interrupt ( ) ; <nl> } <nl> } <nl> - return false ; <nl> } <nl> <nl> private void handleLeaveRequest ( final DiscoveryNode node ) { <nl>\n", "msg": "retry logic to unwrap exception to check for illegal state\n"}
{"diff_id": 4825, "repo": "netty/netty\n", "sha": "f6e14b636f537b03f751bd7c6572b0130e45045a\n", "time": "2012-06-03T20:21:57Z\n", "diff": "mmm a / transport / src / test / java / io / netty / channel / local / LocalTransportThreadModelTest . java <nl> ppp b / transport / src / test / java / io / netty / channel / local / LocalTransportThreadModelTest . java <nl> public void testStagedExecution ( ) throws Throwable { <nl> } <nl> <nl> @ Test <nl> - public void testConcurrentMessageBufferAccess ( ) throws Exception { <nl> + public void testConcurrentMessageBufferAccess ( ) throws Throwable { <nl> EventLoop l = new LocalEventLoop ( 4 , new PrefixThreadFactory ( \" l \" ) ) ; <nl> EventExecutor e1 = new DefaultEventExecutor ( 4 , new PrefixThreadFactory ( \" e1 \" ) ) ; <nl> EventExecutor e2 = new DefaultEventExecutor ( 4 , new PrefixThreadFactory ( \" e2 \" ) ) ; <nl> public void testConcurrentMessageBufferAccess ( ) throws Exception { <nl> <nl> l . register ( ch ) . sync ( ) . channel ( ) . connect ( ADDR ) . sync ( ) ; <nl> <nl> - for ( int i = 0 ; i < 10000 ; i + + ) { <nl> - ch . pipeline ( ) . inboundMessageBuffer ( ) . add ( Integer . valueOf ( i ) ) ; <nl> + final int COUNT = 10485760 ; <nl> + for ( int i = 0 ; i < COUNT ; ) { <nl> + for ( int j = 0 ; i < COUNT & & j < COUNT / 8 ; j + + ) { <nl> + ch . pipeline ( ) . inboundMessageBuffer ( ) . add ( Integer . valueOf ( i + + ) ) ; <nl> + if ( h1 . exception . get ( ) ! = null ) { <nl> + throw h1 . exception . get ( ) ; <nl> + } <nl> + if ( h2 . exception . get ( ) ! = null ) { <nl> + throw h2 . exception . get ( ) ; <nl> + } <nl> + if ( h3 . exception . get ( ) ! = null ) { <nl> + throw h3 . exception . get ( ) ; <nl> + } <nl> + } <nl> + ch . pipeline ( ) . fireInboundBufferUpdated ( ) ; <nl> } <nl> - ch . pipeline ( ) . fireInboundBufferUpdated ( ) ; <nl> } <nl> <nl> private static class ThreadNameAuditor extends ChannelHandlerAdapter < Object , Object > { <nl>\n", "msg": "Improve concurrent message buffer access test to reproduce known issue\n"}
{"diff_id": 4944, "repo": "bazelbuild/bazel\n", "sha": "548207485b54cb240eb6859c5190afaede0b6650\n", "time": "2015-08-04T09:02:50Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / syntax / MethodLibrary . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / syntax / MethodLibrary . java <nl> public String invoke ( String self , String oldString , String newString , Object max <nl> useEnvironment = true , <nl> useLocation = true ) <nl> private static BuiltinFunction split = new BuiltinFunction ( \" split \" ) { <nl> - public Object invoke ( String self , String sep , Object maxSplitO , Location loc , <nl> + public Object invoke ( String self , String sep , Object maxSplitO , Location loc , <nl> Environment env ) throws ConversionException , EvalException { <nl> int maxSplit = Type . INTEGER . convertOptional ( <nl> maxSplitO , \" ' split ' argument of ' split ' \" , / * label * / null , - 2 ) ; <nl> public Object invoke ( String self , String sep , Object maxSplitO , Location loc , <nl> return convert ( Arrays . < String > asList ( ss ) , env , loc ) ; <nl> } <nl> } ; <nl> - <nl> + <nl> @ SkylarkSignature ( name = \" rsplit \" , objectType = StringModule . class , <nl> returnType = HackHackEitherList . class , <nl> doc = \" Returns a list of all the words in the string , using < code > sep < / code > \" <nl> public Object invoke ( String self , String sep , Object maxSplitO , Location loc , <nl> @ Param ( name = \" sep \" , type = String . class , doc = \" The string to split on . \" ) } , <nl> optionalPositionals = { <nl> @ Param ( name = \" maxsplit \" , type = Integer . class , noneable = true , <nl> - defaultValue = \" None \" , doc = \" The maximum number of splits . \" ) } , <nl> + defaultValue = \" None \" , doc = \" The maximum number of splits . \" ) } , <nl> useEnvironment = true , <nl> useLocation = true ) <nl> private static BuiltinFunction rsplit = new BuiltinFunction ( \" rsplit \" ) { <nl> public Object invoke ( String self , String sep , Object maxSplitO , Location loc , En <nl> return convert ( result , env , loc ) ; <nl> } <nl> } ; <nl> - <nl> + <nl> / * * <nl> - * Splits the given string into a list of words , using { @ code separator } as a <nl> + * Splits the given string into a list of words , using { @ code separator } as a <nl> * delimiter . <nl> - * <nl> + * <nl> * < p > At most { @ code maxSplits } will be performed , going from right to left . <nl> * <nl> * @ param input The input string . <nl> public Object invoke ( String self , String sep , Object maxSplitO , Location loc , En <nl> LinkedList < String > result = new LinkedList < > ( ) ; <nl> String [ ] parts = input . split ( Pattern . quote ( separator ) , - 1 ) ; <nl> int sepLen = separator . length ( ) ; <nl> - int remainingLength = input . length ( ) ; <nl> + int remainingLength = input . length ( ) ; <nl> int splitsSoFar = 0 ; <nl> <nl> - / / Copies parts from the array into the final list , starting at the end ( because <nl> - / / it ' s rsplit ) , as long as fewer than maxSplits splits are performed . The <nl> - / / last spot in the list is reserved for the remaining string , whose length <nl> + / / Copies parts from the array into the final list , starting at the end ( because <nl> + / / it ' s rsplit ) , as long as fewer than maxSplits splits are performed . The <nl> + / / last spot in the list is reserved for the remaining string , whose length <nl> / / has to be tracked throughout the loop . <nl> for ( int pos = parts . length - 1 ; ( pos > = 0 ) & & ( splitsSoFar < maxSplits ) ; - - pos ) { <nl> String current = parts [ pos ] ; <nl> public Object invoke ( String self , String sep , Object maxSplitO , Location loc , En <nl> } <nl> <nl> if ( splitsSoFar = = maxSplits & & remainingLength > = 0 ) { <nl> - result . addFirst ( input . substring ( 0 , remainingLength ) ) ; <nl> + result . addFirst ( input . substring ( 0 , remainingLength ) ) ; <nl> } <nl> - <nl> - return result ; <nl> + <nl> + return result ; <nl> } <nl> - <nl> + <nl> @ SkylarkSignature ( name = \" partition \" , objectType = StringModule . class , <nl> returnType = HackHackEitherList . class , <nl> doc = \" Splits the input string at the first occurrence of the separator \" <nl> public Object invoke ( String self , String sep , Location loc , Environment env ) <nl> } ; <nl> <nl> / * * <nl> - * Wraps the stringPartition ( ) method and converts its results and exceptions <nl> + * Wraps the stringPartition ( ) method and converts its results and exceptions <nl> * to the expected types . <nl> * <nl> * @ param self The input string <nl> * @ param separator The string to split on <nl> - * @ param forward A flag that controls whether the input string is split around <nl> - * the first ( { @ code true } ) or last ( { @ code false } ) occurrence of the separator . <nl> + * @ param forward A flag that controls whether the input string is split around <nl> + * the first ( { @ code true } ) or last ( { @ code false } ) occurrence of the separator . <nl> * @ param env The current environment <nl> * @ param loc The location that is used for potential exceptions <nl> * @ return A list with three elements <nl> private static Object partitionWrapper ( String self , String separator , boolean fo <nl> <nl> / * * <nl> * Splits the input string at the { first | last } occurrence of the given separator <nl> - * and returns the resulting partition as a three - tuple of Strings , contained <nl> + * and returns the resulting partition as a three - tuple of Strings , contained <nl> * in a { @ code List } . <nl> - * <nl> + * <nl> * < p > If the input string does not contain the separator , the tuple will <nl> * consist of the original input string and two empty strings . <nl> - * <nl> - * < p > This method emulates the behavior of Python ' s str . partition ( ) and <nl> + * <nl> + * < p > This method emulates the behavior of Python ' s str . partition ( ) and <nl> * str . rpartition ( ) , depending on the value of the { @ code forward } flag . <nl> - * <nl> + * <nl> * @ param input The input string <nl> * @ param separator The string to split on <nl> - * @ param forward A flag that controls whether the input string is split around <nl> - * the first ( { @ code true } ) or last ( { @ code false } ) occurrence of the separator . <nl> - * @ return A three - tuple ( List ) of the form [ part_before_separator , separator , <nl> + * @ param forward A flag that controls whether the input string is split around <nl> + * the first ( { @ code true } ) or last ( { @ code false } ) occurrence of the separator . <nl> + * @ return A three - tuple ( List ) of the form [ part_before_separator , separator , <nl> * part_after_separator ] . <nl> - * <nl> + * <nl> * / <nl> private static List < String > stringPartition ( String input , String separator , boolean forward ) <nl> throws IllegalArgumentException { <nl> private static Object partitionWrapper ( String self , String separator , boolean fo <nl> <nl> return result ; <nl> } <nl> - <nl> + <nl> / * * <nl> * Common implementation for find , rfind , index , rindex . <nl> * @ param forward true if we want to return the last matching index . <nl> public SkylarkClassObject invoke ( Map < String , Object > kwargs , Location loc ) <nl> @ Param ( name = \" order \" , type = String . class , defaultValue = \" \\ \" stable \\ \" \" , <nl> doc = \" The ordering strategy for the set if it ' s nested , \" <nl> + \" possible values are : < code > stable < / code > ( default ) , < code > compile < / code > , \" <nl> - + \" < code > link < / code > or < code > naive_link < / code > . An explanation of the \" <nl> + + \" < code > link < / code > or < code > naive_link < / code > . An explanation of the \" <nl> + \" values can be found < a href = \\ \" # modules . set \\ \" > here < / a > . \" ) } , <nl> useLocation = true ) <nl> private static final BuiltinFunction set = new BuiltinFunction ( \" set \" ) { <nl> public SkylarkNestedSet invoke ( SkylarkNestedSet input , Iterable < Object > newEleme <nl> return new SkylarkNestedSet ( input , newElements , loc ) ; <nl> } <nl> } ; <nl> - <nl> - @ SkylarkSignature ( name = \" enumerate \" , returnType = SkylarkList . class , <nl> + <nl> + @ SkylarkSignature ( name = \" enumerate \" , returnType = HackHackEitherList . class , <nl> doc = \" Return a list of pairs ( two - element tuples ) , with the index ( int ) and the item from \" <nl> + \" the input list . \\ n < pre class = \\ \" language - python \\ \" > \" <nl> + \" enumerate ( [ 24 , 21 , 84 ] ) = = [ ( 0 , 24 ) , ( 1 , 21 ) , ( 2 , 84 ) ] < / pre > \\ n \" , <nl> - mandatoryPositionals = { @ Param ( name = \" list \" , type = SkylarkList . class , doc = \" input list \" ) } , <nl> - useLocation = true ) <nl> + mandatoryPositionals = { <nl> + @ Param ( name = \" list \" , type = HackHackEitherList . class , doc = \" input list \" ) <nl> + } , <nl> + useLocation = true , <nl> + useEnvironment = true ) <nl> private static BuiltinFunction enumerate = new BuiltinFunction ( \" enumerate \" ) { <nl> - public SkylarkList invoke ( SkylarkList input , Location loc ) <nl> + public Object invoke ( Object input , Location loc , Environment env ) <nl> throws EvalException , ConversionException , InterruptedException { <nl> int count = 0 ; <nl> List < SkylarkList > result = Lists . newArrayList ( ) ; <nl> - for ( Object obj : input ) { <nl> + for ( Object obj : Type . OBJECT_LIST . convert ( input , \" input \" ) ) { <nl> result . add ( SkylarkList . tuple ( count , obj ) ) ; <nl> count + + ; <nl> } <nl> - return SkylarkList . list ( result , loc ) ; <nl> + return convert ( result , env , loc ) ; <nl> } <nl> } ; <nl> <nl> - @ SkylarkSignature ( name = \" range \" , returnType = SkylarkList . class , <nl> + @ SkylarkSignature ( name = \" range \" , returnType = HackHackEitherList . class , <nl> doc = \" Creates a list where items go from < code > start < / code > to < code > stop < / code > , using a \" <nl> + \" < code > step < / code > increment . If a single argument is provided , items will \" <nl> + \" range from 0 to that element . \" <nl> public SkylarkList invoke ( SkylarkList input , Location loc ) <nl> + \" resulting list ; generation of the list stops before < code > stop < / code > is reached . \" ) , <nl> @ Param ( name = \" step \" , type = Integer . class , defaultValue = \" 1 \" , <nl> doc = \" The increment ( default is 1 ) . It may be negative . \" ) } , <nl> - useLocation = true ) <nl> + useLocation = true , <nl> + useEnvironment = true ) <nl> private static final BuiltinFunction range = new BuiltinFunction ( \" range \" ) { <nl> - public SkylarkList invoke ( Integer startOrStop , Object stopOrNone , Integer step , Location loc ) <nl> + public Object invoke ( Integer startOrStop , Object stopOrNone , Integer step , Location loc , <nl> + Environment env ) <nl> throws EvalException , ConversionException , InterruptedException { <nl> int start ; <nl> int stop ; <nl> public SkylarkList invoke ( Integer startOrStop , Object stopOrNone , Integer step , <nl> start + = step ; <nl> } <nl> } <nl> - return SkylarkList . list ( result , Integer . class ) ; <nl> + return convert ( result , env , loc ) ; <nl> } <nl> } ; <nl> <nl> public SkylarkList invoke ( SkylarkList args , Location loc ) <nl> items , get , keys , values ) ; <nl> <nl> private static final List < BaseFunction > pureGlobalFunctions = ImmutableList . < BaseFunction > of ( <nl> - bool , int_ , len , minus , repr , select , sorted , str ) ; <nl> + bool , enumerate , int_ , len , minus , range , repr , select , sorted , str ) ; <nl> <nl> private static final List < BaseFunction > skylarkGlobalFunctions = <nl> ImmutableList . < BaseFunction > builder ( ) <nl> . addAll ( pureGlobalFunctions ) <nl> - . add ( list , struct , hasattr , getattr , set , dir , enumerate , range , type , fail , print , zip ) <nl> + . add ( list , struct , hasattr , getattr , set , dir , type , fail , print , zip ) <nl> . build ( ) ; <nl> <nl> / * * <nl>\n", "msg": "Make range and enumerate functions available in BUILD files .\n"}
{"diff_id": 4972, "repo": "apache/flink\n", "sha": "15d8cd5458a7a940cef16760b465abee4f20a06c\n", "time": "2019-07-10T09:12:25Z\n", "diff": "old mode 100644 <nl> new mode 100755 <nl> index 994db34b7026 . . 98bc66b312a9 <nl> mmm a / flink - runtime / src / main / java / org / apache / flink / runtime / resourcemanager / JobLeaderIdService . java <nl> ppp b / flink - runtime / src / main / java / org / apache / flink / runtime / resourcemanager / JobLeaderIdService . java <nl> <nl> public JobLeaderIdService ( <nl> HighAvailabilityServices highAvailabilityServices , <nl> ScheduledExecutor scheduledExecutor , <nl> - Time jobTimeout ) throws Exception { <nl> + Time jobTimeout ) { <nl> this . highAvailabilityServices = Preconditions . checkNotNull ( highAvailabilityServices , \" highAvailabilityServices \" ) ; <nl> this . scheduledExecutor = Preconditions . checkNotNull ( scheduledExecutor , \" scheduledExecutor \" ) ; <nl> this . jobTimeout = Preconditions . checkNotNull ( jobTimeout , \" jobTimeout \" ) ; <nl>\n", "msg": "[ hotfix ] [ runtime ] Remove obsolete Exception from JobLeaderIdService signature\n"}
{"diff_id": 5087, "repo": "dbeaver/dbeaver\n", "sha": "37c666a8a3ab6253d3c64d37d35bfd25b6e5746a\n", "time": "2018-02-02T22:48:17Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . ext . mockdata / src / org / jkiss / dbeaver / ext / mockdata / MockDataGenerateTool . java <nl> ppp b / plugins / org . jkiss . dbeaver . ext . mockdata / src / org / jkiss / dbeaver / ext / mockdata / MockDataGenerateTool . java <nl> public void execute ( IWorkbenchWindow window , IWorkbenchPart activePart , Collecti <nl> <nl> @ Override <nl> protected void finishPressed ( ) { <nl> - if ( doValidationConfirmation ( ( MockDataWizardPageSettings ) getCurrentPage ( ) ) ) { <nl> + if ( doValidationConfirmation ( getCurrentPage ( ) ) ) { <nl> return ; <nl> } <nl> super . finishPressed ( ) ; <nl> protected void finishPressed ( ) { <nl> protected void nextPressed ( ) { <nl> IWizardPage currentPage = getCurrentPage ( ) ; <nl> if ( currentPage instanceof MockDataWizardPageSettings ) { <nl> - if ( doValidationConfirmation ( ( MockDataWizardPageSettings ) currentPage ) ) { <nl> + if ( doValidationConfirmation ( currentPage ) ) { <nl> return ; <nl> } <nl> } <nl> super . nextPressed ( ) ; <nl> } <nl> <nl> - private boolean doValidationConfirmation ( MockDataWizardPageSettings currentPage ) { <nl> - if ( ! currentPage . validateProperties ( ) ) { <nl> - this . setErrorMessage ( \" All numeric properties should be positive . \" ) ; <nl> - return true ; <nl> + private boolean doValidationConfirmation ( IWizardPage currentPage ) { <nl> + if ( currentPage instanceof MockDataWizardPageSettings ) { <nl> + if ( ! ( ( MockDataWizardPageSettings ) currentPage ) . validateProperties ( ) ) { <nl> + this . setErrorMessage ( \" All numeric properties should be positive . \" ) ; <nl> + return true ; <nl> + } <nl> } <nl> if ( mockDataSettings . isRemoveOldData ( ) & & ! removeOldDataConfirmed ) { <nl> if ( UIUtils . confirmAction ( getShell ( ) , MockDataMessages . tools_mockdata_wizard_title , MockDataMessages . tools_mockdata_confirm_delete_old_data_message ) ) { <nl>\n", "msg": "Mock Data . Properties validation . Cast exception is fixed .\n"}
{"diff_id": 5157, "repo": "oracle/graal\n", "sha": "c192be0bdaac200520e438b6b33abb2a7d0652a5\n", "time": "2018-04-05T23:38:15Z\n", "diff": "mmm a / projects / com . oracle . truffle . llvm . runtime / src / com / oracle / truffle / llvm / runtime / interop / export / LLVMTruffleObjectMessageResolution . java <nl> ppp b / projects / com . oracle . truffle . llvm . runtime / src / com / oracle / truffle / llvm / runtime / interop / export / LLVMTruffleObjectMessageResolution . java <nl> <nl> package com . oracle . truffle . llvm . runtime . interop . export ; <nl> <nl> import com . oracle . truffle . api . CompilerDirectives ; <nl> + import com . oracle . truffle . api . dsl . Cached ; <nl> + import com . oracle . truffle . api . dsl . Specialization ; <nl> import com . oracle . truffle . api . interop . ForeignAccess ; <nl> + import com . oracle . truffle . api . interop . InteropException ; <nl> import com . oracle . truffle . api . interop . KeyInfo ; <nl> import com . oracle . truffle . api . interop . Message ; <nl> import com . oracle . truffle . api . interop . MessageResolution ; <nl> <nl> import com . oracle . truffle . api . nodes . Node ; <nl> import com . oracle . truffle . llvm . runtime . LLVMTruffleObject ; <nl> import com . oracle . truffle . llvm . runtime . interop . access . LLVMInteropType ; <nl> + import com . oracle . truffle . llvm . runtime . interop . export . LLVMTruffleObjectMessageResolutionFactory . AsPointerCachedNodeGen ; <nl> + import com . oracle . truffle . llvm . runtime . interop . export . LLVMTruffleObjectMessageResolutionFactory . IsPointerCachedNodeGen ; <nl> + import com . oracle . truffle . llvm . runtime . interop . export . LLVMTruffleObjectMessageResolutionFactory . ToNativeCachedNodeGen ; <nl> + import com . oracle . truffle . llvm . runtime . nodes . api . LLVMObjectNativeLibrary ; <nl> <nl> @ MessageResolution ( receiverType = LLVMTruffleObject . class ) <nl> public class LLVMTruffleObjectMessageResolution { <nl> protected boolean access ( LLVMTruffleObject receiver ) { <nl> @ Resolve ( message = \" IS_POINTER \" ) <nl> public abstract static class IsPointer extends Node { <nl> <nl> + @ Child IsPointerCached isPointer = IsPointerCachedNodeGen . create ( ) ; <nl> + <nl> protected boolean access ( LLVMTruffleObject receiver ) { <nl> - return receiver . getObject ( ) = = null ; <nl> + return isPointer . execute ( receiver ) ; <nl> + } <nl> + } <nl> + <nl> + abstract static class IsPointerCached extends Node { <nl> + <nl> + protected abstract boolean execute ( Object receiver ) ; <nl> + <nl> + @ Specialization ( guards = \" lib . guard ( receiver ) \" ) <nl> + boolean doCached ( Object receiver , <nl> + @ Cached ( \" createCached ( receiver ) \" ) LLVMObjectNativeLibrary lib ) { <nl> + return lib . isPointer ( receiver ) ; <nl> + } <nl> + <nl> + @ Specialization ( replaces = \" doCached \" ) <nl> + boolean doGeneric ( Object receiver , <nl> + @ Cached ( \" createGeneric ( ) \" ) LLVMObjectNativeLibrary lib ) { <nl> + return lib . isPointer ( receiver ) ; <nl> } <nl> } <nl> <nl> @ Resolve ( message = \" AS_POINTER \" ) <nl> public abstract static class AsPointer extends Node { <nl> <nl> + @ Child AsPointerCached asPointer = AsPointerCachedNodeGen . create ( ) ; <nl> + <nl> protected long access ( LLVMTruffleObject receiver ) { <nl> - if ( receiver . getObject ( ) = = null ) { <nl> - return receiver . getOffset ( ) ; <nl> - } else { <nl> - CompilerDirectives . transferToInterpreter ( ) ; <nl> - throw UnsupportedMessageException . raise ( Message . AS_POINTER ) ; <nl> + return asPointer . execute ( receiver ) ; <nl> + } <nl> + } <nl> + <nl> + abstract static class AsPointerCached extends Node { <nl> + <nl> + protected abstract long execute ( Object receiver ) ; <nl> + <nl> + @ Specialization ( guards = \" lib . guard ( receiver ) \" ) <nl> + long doCached ( Object receiver , <nl> + @ Cached ( \" createCached ( receiver ) \" ) LLVMObjectNativeLibrary lib ) { <nl> + try { <nl> + return lib . asPointer ( receiver ) ; <nl> + } catch ( InteropException ex ) { <nl> + throw ex . raise ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ Specialization ( replaces = \" doCached \" ) <nl> + long doGeneric ( Object receiver , <nl> + @ Cached ( \" createGeneric ( ) \" ) LLVMObjectNativeLibrary lib ) { <nl> + try { <nl> + return lib . asPointer ( receiver ) ; <nl> + } catch ( InteropException ex ) { <nl> + throw ex . raise ( ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + @ Resolve ( message = \" TO_NATIVE \" ) <nl> + public abstract static class ToNative extends Node { <nl> + <nl> + @ Child ToNativeCached toNative = ToNativeCachedNodeGen . create ( ) ; <nl> + <nl> + protected Object access ( LLVMTruffleObject receiver ) { <nl> + return toNative . execute ( receiver ) ; <nl> + } <nl> + } <nl> + <nl> + abstract static class ToNativeCached extends Node { <nl> + <nl> + protected abstract Object execute ( Object receiver ) ; <nl> + <nl> + @ Specialization ( guards = \" lib . guard ( receiver ) \" ) <nl> + Object doCached ( Object receiver , <nl> + @ Cached ( \" createCached ( receiver ) \" ) LLVMObjectNativeLibrary lib ) { <nl> + try { <nl> + return lib . toNative ( receiver ) ; <nl> + } catch ( InteropException ex ) { <nl> + throw ex . raise ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ Specialization ( replaces = \" doCached \" ) <nl> + Object doGeneric ( Object receiver , <nl> + @ Cached ( \" createGeneric ( ) \" ) LLVMObjectNativeLibrary lib ) { <nl> + try { <nl> + return lib . toNative ( receiver ) ; <nl> + } catch ( InteropException ex ) { <nl> + throw ex . raise ( ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Implement pointer interop messages of LLVMTruffleObject with LLVMObjectNativeLibrary .\n"}
{"diff_id": 5161, "repo": "square/okhttp\n", "sha": "18ef05d70d3b5ac90e8df8b80cd83af82b82197b\n", "time": "2014-02-01T19:09:25Z\n", "diff": "mmm a / benchmarks / src / main / java / com / squareup / okhttp / benchmarks / NettyHttpClient . java <nl> ppp b / benchmarks / src / main / java / com / squareup / okhttp / benchmarks / NettyHttpClient . java <nl> <nl> import com . squareup . okhttp . internal . Util ; <nl> import io . netty . bootstrap . Bootstrap ; <nl> import io . netty . buffer . ByteBuf ; <nl> + import io . netty . buffer . PooledByteBufAllocator ; <nl> import io . netty . channel . Channel ; <nl> import io . netty . channel . ChannelHandlerContext ; <nl> import io . netty . channel . ChannelInitializer ; <nl> + import io . netty . channel . ChannelOption ; <nl> import io . netty . channel . ChannelPipeline ; <nl> import io . netty . channel . EventLoopGroup ; <nl> import io . netty . channel . SimpleChannelInboundHandler ; <nl> <nl> EventLoopGroup group = new NioEventLoopGroup ( ) ; <nl> bootstrap = new Bootstrap ( ) ; <nl> bootstrap . group ( group ) <nl> + . option ( ChannelOption . ALLOCATOR , PooledByteBufAllocator . DEFAULT ) <nl> . channel ( NioSocketChannel . class ) <nl> . handler ( channelInitializer ) ; <nl> } <nl>\n", "msg": "Use the pooled allocator for performance reasons\n"}
{"diff_id": 5247, "repo": "LMAX-Exchange/disruptor\n", "sha": "4bc202deca5a3bf500cc5c8ef16c9e4d7e04edf4\n", "time": "2014-03-10T00:45:32Z\n", "diff": "mmm a / src / main / java / com / lmax / disruptor / LiteBlockingWaitStrategy . java <nl> ppp b / src / main / java / com / lmax / disruptor / LiteBlockingWaitStrategy . java <nl> public long waitFor ( long sequence , Sequence cursorSequence , Sequence dependentSe <nl> { <nl> do <nl> { <nl> - signalNeeded . set ( true ) ; <nl> + signalNeeded . getAndSet ( true ) ; <nl> <nl> if ( ( availableSequence = cursorSequence . get ( ) ) > = sequence ) <nl> { <nl>\n", "msg": "Update LiteBlockingWaitStrategy with getAndSet for signalNeeded flag\n"}
{"diff_id": 5257, "repo": "netty/netty\n", "sha": "2fc18a00f6ac61a365b73dd498dd2e38f1efa823\n", "time": "2011-08-19T02:11:45Z\n", "diff": "new file mode 100644 <nl> index 00000000000 . . ccd1bfe4630 <nl> mmm / dev / null <nl> ppp b / src / test / java / org / jboss / netty / handler / codec / frame / DelimiterBasedFrameDecoderTest . java <nl> <nl> + / * <nl> + * Copyright 2009 Red Hat , Inc . <nl> + * <nl> + * Red Hat licenses this file to you under the Apache License , version 2 . 0 <nl> + * ( the \" License \" ) ; you may not use this file except in compliance with the <nl> + * License . You may obtain a copy of the License at : <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , software <nl> + * distributed under the License is distributed on an \" AS IS \" BASIS , WITHOUT <nl> + * WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . See the <nl> + * License for the specific language governing permissions and limitations <nl> + * under the License . <nl> + * / <nl> + package org . jboss . netty . handler . codec . frame ; <nl> + <nl> + import org . jboss . netty . buffer . ChannelBuffer ; <nl> + import org . jboss . netty . buffer . ChannelBuffers ; <nl> + import org . jboss . netty . handler . codec . embedder . CodecEmbedderException ; <nl> + import org . jboss . netty . handler . codec . embedder . DecoderEmbedder ; <nl> + import org . jboss . netty . util . CharsetUtil ; <nl> + import org . junit . Assert ; <nl> + import org . junit . Test ; <nl> + <nl> + / * * <nl> + * @ author < a href = \" http : / / gleamynode . net / \" > Trustin Lee < / a > <nl> + * / <nl> + public class DelimiterBasedFrameDecoderTest { <nl> + @ Test <nl> + public void testTooLongFrameRecovery ( ) throws Exception { <nl> + DecoderEmbedder < ChannelBuffer > embedder = new DecoderEmbedder < ChannelBuffer > ( <nl> + new DelimiterBasedFrameDecoder ( 1 , Delimiters . nulDelimiter ( ) ) ) ; <nl> + <nl> + for ( int i = 0 ; i < 2 ; i + + ) { <nl> + try { <nl> + embedder . offer ( ChannelBuffers . wrappedBuffer ( new byte [ ] { 1 , 2 , 0 } ) ) ; <nl> + Assert . fail ( CodecEmbedderException . class . getSimpleName ( ) + \" must be raised . \" ) ; <nl> + } catch ( CodecEmbedderException e ) { <nl> + Assert . assertTrue ( e . getCause ( ) instanceof TooLongFrameException ) ; <nl> + / / Expected <nl> + } <nl> + <nl> + embedder . offer ( ChannelBuffers . wrappedBuffer ( new byte [ ] { ' A ' , 0 } ) ) ; <nl> + ChannelBuffer buf = embedder . poll ( ) ; <nl> + Assert . assertEquals ( \" A \" , buf . toString ( CharsetUtil . ISO_8859_1 ) ) ; <nl> + } <nl> + } <nl> + } <nl>\n", "msg": "Added a TooLongFrameException recovery test for DelimiterBasedFrameDecoder\n"}
{"diff_id": 5282, "repo": "google/ExoPlayer\n", "sha": "0a6f81a2ccd5b29ed20565dc8ec9630205062979\n", "time": "2019-05-15T17:09:12Z\n", "diff": "mmm a / library / core / src / main / java / com / google / android / exoplayer2 / SimpleExoPlayer . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / SimpleExoPlayer . java <nl> private void verifyApplicationThread ( ) { <nl> Log . w ( <nl> TAG , <nl> \" Player is accessed on the wrong thread . See \" <nl> - + \" https : / / exoplayer . dev / faqs . html # \" <nl> + + \" https : / / exoplayer . dev / troubleshooting . html # \" <nl> + \" what - do - player - is - accessed - on - the - wrong - thread - warnings - mean \" , <nl> hasNotifiedFullWrongThreadWarning ? null : new IllegalStateException ( ) ) ; <nl> hasNotifiedFullWrongThreadWarning = true ; <nl>\n", "msg": "Update player accessed on wrong thread URL\n"}
{"diff_id": 5315, "repo": "spring-projects/spring-framework\n", "sha": "96d6963d61cfa00a02ea26655db5075300647d6a\n", "time": "2014-01-21T00:22:43Z\n", "diff": "mmm a / spring - webmvc / src / main / java / org / springframework / web / servlet / view / document / AbstractJExcelView . java <nl> ppp b / spring - webmvc / src / main / java / org / springframework / web / servlet / view / document / AbstractJExcelView . java <nl> <nl> / * <nl> - * Copyright 2002 - 2012 the original author or authors . <nl> + * Copyright 2002 - 2013 the original author or authors . <nl> * <nl> * Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> * you may not use this file except in compliance with the License . <nl> <nl> import java . io . OutputStream ; <nl> import java . util . Locale ; <nl> import java . util . Map ; <nl> - <nl> import javax . servlet . http . HttpServletRequest ; <nl> import javax . servlet . http . HttpServletResponse ; <nl> <nl> <nl> / * * <nl> * Convenient superclass for Excel document views . <nl> * <nl> - * < p > This class uses the < i > JExcelAPI < / i > instead of < i > POI < / i > . More <nl> - * information on < i > JExcelAPI < / i > can be found on their < a <nl> - * href = \" http : / / www . andykhan . com / jexcelapi / \" target = \" _blank \" > website < / a > . <nl> + * < p > This class uses the < i > JExcelAPI < / i > instead of < i > POI < / i > . <nl> + * More information on < i > JExcelAPI < / i > can be found on their <nl> + * < a href = \" http : / / www . andykhan . com / jexcelapi / \" target = \" _blank \" > website < / a > . <nl> * <nl> * < p > Properties : <nl> * < ul > <nl> <nl> * <nl> * < pre class = \" code \" > <nl> * protected void buildExcelDocument ( <nl> - * Map & lt ; String , Object & gt ; model , WritableWorkbook workbook , <nl> - * HttpServletRequest request , HttpServletResponse response ) { <nl> + * Map & lt ; String , Object & gt ; model , WritableWorkbook workbook , <nl> + * HttpServletRequest request , HttpServletResponse response ) { <nl> * <nl> * if ( workbook . getNumberOfSheets ( ) = = 0 ) { <nl> - * workbook . createSheet ( & quot ; Spring & quot ; , 0 ) ; <nl> + * workbook . createSheet ( & quot ; Spring & quot ; , 0 ) ; <nl> * } <nl> * <nl> * WritableSheet sheet = workbook . getSheet ( & quot ; Spring & quot ; ) ; <nl> <nl> * sheet . addCell ( label ) ; <nl> * } < / pre > <nl> * <nl> - * The use of this view is close to the AbstractExcelView class , <nl> + * The use of this view is close to the { @ link AbstractExcelView } class , <nl> * just using the JExcel API instead of the Apache POI API . <nl> * <nl> * @ author Bram Smeets <nl> <nl> * @ since 1 . 2 . 5 <nl> * @ see AbstractExcelView <nl> * @ see AbstractPdfView <nl> + * @ deprecated as of Spring 4 . 0 , since JExcelAPI is an abandoned project <nl> + * ( no release since 2009 , with serious bugs remaining ) <nl> * / <nl> + @ Deprecated <nl> public abstract class AbstractJExcelView extends AbstractView { <nl> <nl> / * * The content type for an Excel response * / <nl>\n", "msg": "Deprecated AbstractJExcelView since JExcelAPI is an abandoned project\n"}
{"diff_id": 5346, "repo": "oracle/graal\n", "sha": "16c946177763f8ba72f66efcc1ec5fa320d546bd\n", "time": "2013-05-01T16:09:08Z\n", "diff": "mmm a / graal / com . oracle . graal . api . meta / src / com / oracle / graal / api / meta / MetaUtil . java <nl> ppp b / graal / com . oracle . graal . api . meta / src / com / oracle / graal / api / meta / MetaUtil . java <nl> public static String toJavaName ( JavaType type ) { <nl> return ( type = = null ) ? null : internalNameToJava ( type . getName ( ) , true , false ) ; <nl> } <nl> <nl> + / * * <nl> + * Returns the type name in the same format as { @ link Class # getName ( ) } . <nl> + * / <nl> + public static String toClassName ( JavaType type ) { <nl> + return internalNameToJava ( type . getName ( ) , true , true ) ; <nl> + } <nl> + <nl> private static String internalNameToJava ( String name , boolean qualified , boolean classForNameCompatible ) { <nl> switch ( name . charAt ( 0 ) ) { <nl> case ' L ' : { <nl>\n", "msg": "Add JavaType - to - String that produces same result as Class . getName ( )\n"}
{"diff_id": 5534, "repo": "signalapp/Signal-Android\n", "sha": "de72eceecfd04ae41bd2970c131283bfd3eb950c\n", "time": "2019-03-13T21:19:33Z\n", "diff": "mmm a / src / org / thoughtcrime / securesms / ConversationListActivity . java <nl> ppp b / src / org / thoughtcrime / securesms / ConversationListActivity . java <nl> private void handleInvite ( ) { <nl> <nl> private void handleHelp ( ) { <nl> try { <nl> - startActivity ( new Intent ( Intent . ACTION_VIEW , Uri . parse ( \" https : / / support . whispersystems . org \" ) ) ) ; <nl> + startActivity ( new Intent ( Intent . ACTION_VIEW , Uri . parse ( \" https : / / support . signal . org \" ) ) ) ; <nl> } catch ( ActivityNotFoundException e ) { <nl> Toast . makeText ( this , R . string . ConversationListActivity_there_is_no_browser_installed_on_your_device , Toast . LENGTH_LONG ) . show ( ) ; <nl> } <nl>\n", "msg": "Update help URL to avoid redirect .\n"}
{"diff_id": 5591, "repo": "libgdx/libgdx\n", "sha": "19de37aedab319aa44807a3e3c62ebfcfeefa0f1\n", "time": "2016-01-19T18:27:15Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / scenes / scene2d / ui / TextArea . java <nl> ppp b / gdx / src / com / badlogic / gdx / scenes / scene2d / ui / TextArea . java <nl> protected void setCursorPosition ( float x , float y ) { <nl> <nl> @ Override <nl> public boolean keyDown ( InputEvent event , int keycode ) { <nl> - super . keyDown ( event , keycode ) ; <nl> + boolean result = super . keyDown ( event , keycode ) ; <nl> Stage stage = getStage ( ) ; <nl> if ( stage ! = null & & stage . getKeyboardFocus ( ) = = TextArea . this ) { <nl> boolean repeat = false ; <nl> public boolean keyDown ( InputEvent event , int keycode ) { <nl> showCursor ( ) ; <nl> return true ; <nl> } <nl> - return false ; <nl> + return result ; <nl> } <nl> <nl> @ Override <nl>\n", "msg": "Get result when calling super in keyDown for later return .\n"}
{"diff_id": 5883, "repo": "libgdx/libgdx\n", "sha": "7ba94991e1a432fc35d4131d0c5b29aa01370d46\n", "time": "2011-04-04T06:40:35Z\n", "diff": "mmm a / extensions / model - loaders / src / com / badlogic / gdx / graphics / g3d / obj / ObjLoader . java <nl> ppp b / extensions / model - loaders / src / com / badlogic / gdx / graphics / g3d / obj / ObjLoader . java <nl> public Mesh loadObj ( FileHandle file , boolean flipV ) { <nl> : Float . parseFloat ( tokens [ 2 ] ) ) ) ; <nl> } <nl> } else if ( firstChar = = ' f ' ) { <nl> - String [ ] parts = tokens [ 1 ] . split ( \" / \" ) ; <nl> - faces . add ( getIndex ( parts [ 0 ] , verts . size ( ) ) ) ; <nl> - if ( parts . length > 2 ) <nl> - faces . add ( getIndex ( parts [ 2 ] , norms . size ( ) ) ) ; <nl> - if ( parts . length > 1 & & parts [ 1 ] . length ( ) > 0 ) <nl> - faces . add ( getIndex ( parts [ 1 ] , uvs . size ( ) ) ) ; <nl> - parts = tokens [ 2 ] . split ( \" / \" ) ; <nl> - faces . add ( getIndex ( parts [ 0 ] , verts . size ( ) ) ) ; <nl> - if ( parts . length > 2 ) <nl> - faces . add ( getIndex ( parts [ 2 ] , norms . size ( ) ) ) ; <nl> - if ( parts . length > 1 & & parts [ 1 ] . length ( ) > 0 ) <nl> - faces . add ( getIndex ( parts [ 1 ] , uvs . size ( ) ) ) ; <nl> - parts = tokens [ 3 ] . split ( \" / \" ) ; <nl> - faces . add ( getIndex ( parts [ 0 ] , verts . size ( ) ) ) ; <nl> - if ( parts . length > 2 ) <nl> - faces . add ( getIndex ( parts [ 2 ] , norms . size ( ) ) ) ; <nl> - if ( parts . length > 1 & & parts [ 1 ] . length ( ) > 0 ) <nl> - faces . add ( getIndex ( parts [ 1 ] , uvs . size ( ) ) ) ; <nl> - numFaces + + ; <nl> + String [ ] parts ; <nl> + for ( int i = 1 ; i < tokens . length - 2 ; i - - ) { <nl> + parts = tokens [ 1 ] . split ( \" / \" ) ; <nl> + faces . add ( getIndex ( parts [ 0 ] , verts . size ( ) ) ) ; <nl> + if ( parts . length > 2 ) faces . add ( getIndex ( parts [ 2 ] , norms . size ( ) ) ) ; <nl> + if ( parts . length > 1 & & parts [ 1 ] . length ( ) > 0 ) faces . add ( getIndex ( parts [ 1 ] , uvs . size ( ) ) ) ; <nl> + parts = tokens [ + + i ] . split ( \" / \" ) ; <nl> + faces . add ( getIndex ( parts [ 0 ] , verts . size ( ) ) ) ; <nl> + if ( parts . length > 2 ) faces . add ( getIndex ( parts [ 2 ] , norms . size ( ) ) ) ; <nl> + if ( parts . length > 1 & & parts [ 1 ] . length ( ) > 0 ) faces . add ( getIndex ( parts [ 1 ] , uvs . size ( ) ) ) ; <nl> + parts = tokens [ + + i ] . split ( \" / \" ) ; <nl> + faces . add ( getIndex ( parts [ 0 ] , verts . size ( ) ) ) ; <nl> + if ( parts . length > 2 ) faces . add ( getIndex ( parts [ 2 ] , norms . size ( ) ) ) ; <nl> + if ( parts . length > 1 & & parts [ 1 ] . length ( ) > 0 ) faces . add ( getIndex ( parts [ 1 ] , uvs . size ( ) ) ) ; <nl> + numFaces + + ; <nl> + } <nl> } <nl> } <nl> reader . close ( ) ; <nl>\n", "msg": "[ update ] added support for n - gons in ObjLoader - not optimized but still functional .\n"}
{"diff_id": 6075, "repo": "oracle/graal\n", "sha": "34a2d57f11bd77b5ff75a0f88457dad9a4d9593b\n", "time": "2017-06-06T00:38:23Z\n", "diff": "mmm a / compiler / src / org . graalvm . compiler . truffle / src / org / graalvm / compiler / truffle / PartialEvaluator . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle / src / org / graalvm / compiler / truffle / PartialEvaluator . java <nl> <nl> import static org . graalvm . compiler . nodes . graphbuilderconf . InlineInvokePlugin . InlineInfo . createStandardInlineInfo ; <nl> import static org . graalvm . compiler . truffle . TruffleCompilerOptions . PrintTruffleExpansionHistogram ; <nl> import static org . graalvm . compiler . truffle . TruffleCompilerOptions . TraceTrufflePerformanceWarnings ; <nl> + import static org . graalvm . compiler . truffle . TruffleCompilerOptions . TraceTruffleStackTraceLimit ; <nl> import static org . graalvm . compiler . truffle . TruffleCompilerOptions . TruffleFunctionInlining ; <nl> import static org . graalvm . compiler . truffle . TruffleCompilerOptions . TruffleInlineAcrossTruffleBoundary ; <nl> import static org . graalvm . compiler . truffle . TruffleCompilerOptions . TruffleInstrumentBoundaries ; <nl> <nl> import static org . graalvm . compiler . truffle . TruffleCompilerOptions . TruffleIterativePartialEscape ; <nl> import static org . graalvm . compiler . truffle . TruffleCompilerOptions . TrufflePerformanceWarningsAreFatal ; <nl> <nl> - import java . io . PrintWriter ; <nl> - import java . io . StringWriter ; <nl> import java . lang . invoke . MethodHandle ; <nl> import java . util . ArrayDeque ; <nl> import java . util . ArrayList ; <nl> <nl> import java . util . Map ; <nl> <nl> import org . graalvm . compiler . api . replacements . SnippetReflectionProvider ; <nl> - import org . graalvm . compiler . code . SourceStackTraceBailoutException ; <nl> import org . graalvm . compiler . core . common . CompilationIdentifier ; <nl> import org . graalvm . compiler . core . common . type . StampPair ; <nl> import org . graalvm . compiler . debug . Debug ; <nl> <nl> import org . graalvm . compiler . phases . OptimisticOptimizations ; <nl> import org . graalvm . compiler . phases . PhaseSuite ; <nl> import org . graalvm . compiler . phases . common . CanonicalizerPhase ; <nl> - import org . graalvm . compiler . phases . common . ConvertDeoptimizeToGuardPhase ; <nl> import org . graalvm . compiler . phases . common . ConditionalEliminationPhase ; <nl> + import org . graalvm . compiler . phases . common . ConvertDeoptimizeToGuardPhase ; <nl> import org . graalvm . compiler . phases . common . inlining . InliningUtil ; <nl> import org . graalvm . compiler . phases . tiers . HighTierContext ; <nl> import org . graalvm . compiler . phases . tiers . PhaseContext ; <nl> private static void logPerformanceStackTrace ( List < ? extends Node > locations ) { <nl> if ( locations = = null | | locations . isEmpty ( ) ) { <nl> return ; <nl> } <nl> + int limit = TruffleCompilerOptions . getValue ( TraceTruffleStackTraceLimit ) ; <nl> + if ( limit < = 0 ) { <nl> + return ; <nl> + } <nl> + <nl> + EconomicMap < String , List < Node > > groupedByStackTrace = EconomicMap . create ( Equivalence . DEFAULT ) ; <nl> for ( Node location : locations ) { <nl> StackTraceElement [ ] stackTrace = GraphUtil . approxSourceStackTraceElement ( location ) ; <nl> - if ( stackTrace = = null | | stackTrace . length = = 0 ) { <nl> - GraalTruffleRuntime . getRuntime ( ) . log ( String . format ( \" No stack trace available for % s . \" , location ) ) ; <nl> + StringBuilder sb = new StringBuilder ( ) ; <nl> + String indent = \" \" ; <nl> + for ( int i = 0 ; i < stackTrace . length & & i < limit ; i + + ) { <nl> + if ( i ! = 0 ) { <nl> + sb . append ( ' \\ n ' ) ; <nl> + } <nl> + sb . append ( indent ) . append ( \" at \" ) . append ( stackTrace [ i ] ) ; <nl> + } <nl> + if ( stackTrace . length > limit ) { <nl> + sb . append ( ' \\ n ' ) . append ( indent ) . append ( \" . . . \" ) ; <nl> + } <nl> + String stackTraceAsString = sb . toString ( ) ; <nl> + if ( ! groupedByStackTrace . containsKey ( stackTraceAsString ) ) { <nl> + groupedByStackTrace . put ( stackTraceAsString , new ArrayList < > ( ) ) ; <nl> + } <nl> + groupedByStackTrace . get ( stackTraceAsString ) . add ( location ) ; <nl> + } <nl> + MapCursor < String , List < Node > > entry = groupedByStackTrace . getEntries ( ) ; <nl> + while ( entry . advance ( ) ) { <nl> + String stackTrace = entry . getKey ( ) ; <nl> + List < Node > locationGroup = entry . getValue ( ) ; <nl> + if ( stackTrace . isEmpty ( ) ) { <nl> + GraalTruffleRuntime . getRuntime ( ) . log ( String . format ( \" No stack trace available for % s . \" , locationGroup ) ) ; <nl> } else { <nl> - GraalTruffleRuntime . getRuntime ( ) . log ( String . format ( \" Approximated stack trace for % s : \" , location ) ) ; <nl> - SourceStackTraceBailoutException exception = SourceStackTraceBailoutException . create ( null , \" \" , stackTrace ) ; <nl> - StringWriter sw = new StringWriter ( ) ; <nl> - exception . printStackTrace ( new PrintWriter ( sw ) ) ; <nl> - GraalTruffleRuntime . getRuntime ( ) . log ( sw . toString ( ) ) ; <nl> + GraalTruffleRuntime . getRuntime ( ) . log ( String . format ( \" Approximated stack trace for % s : \" , locationGroup ) ) ; <nl> + GraalTruffleRuntime . getRuntime ( ) . log ( stackTrace ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Improve TraceTrufflePerformanceWarnings stack trace reporting .\n"}
{"diff_id": 6091, "repo": "jenkinsci/jenkins\n", "sha": "c0e51ace4652b8e40b8788391c94a2f118041c22\n", "time": "2009-10-30T16:24:49Z\n", "diff": "mmm a / core / src / main / java / hudson / util / XStream2 . java <nl> ppp b / core / src / main / java / hudson / util / XStream2 . java <nl> <nl> import com . thoughtworks . xstream . mapper . MapperWrapper ; <nl> import com . thoughtworks . xstream . mapper . ImmutableTypesMapper ; <nl> import com . thoughtworks . xstream . converters . Converter ; <nl> + import com . thoughtworks . xstream . converters . ConverterMatcher ; <nl> import com . thoughtworks . xstream . converters . DataHolder ; <nl> import com . thoughtworks . xstream . converters . MarshallingContext ; <nl> + import com . thoughtworks . xstream . converters . SingleValueConverter ; <nl> + import com . thoughtworks . xstream . converters . SingleValueConverterWrapper ; <nl> import com . thoughtworks . xstream . converters . UnmarshallingContext ; <nl> import com . thoughtworks . xstream . core . JVM ; <nl> import com . thoughtworks . xstream . io . HierarchicalStreamDriver ; <nl> else if ( p [ i ] = = Mapper . class ) <nl> throw new InstantiationError ( \" Unrecognized constructor parameter : \" + p [ i ] ) ; <nl> <nl> } <nl> - return ( Converter ) c . newInstance ( args ) ; <nl> + ConverterMatcher cm = ( ConverterMatcher ) c . newInstance ( args ) ; <nl> + return cm instanceof SingleValueConverter <nl> + ? new SingleValueConverterWrapper ( ( SingleValueConverter ) cm ) <nl> + : ( Converter ) cm ; <nl> } catch ( ClassNotFoundException e ) { <nl> return null ; <nl> } catch ( IllegalAccessException e ) { <nl>\n", "msg": "Add support in XStream2 . AssociatedConverterImpl for SingleValueConverter\n"}
{"diff_id": 6117, "repo": "SeleniumHQ/selenium\n", "sha": "7108f3abff15313202a1df4ab216a4295534db50\n", "time": "2019-09-29T12:08:06Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / By . java <nl> ppp b / java / client / src / org / openqa / selenium / By . java <nl> <nl> import java . util . HashMap ; <nl> import java . util . List ; <nl> import java . util . Map ; <nl> - import java . util . Scanner ; <nl> - import java . util . stream . Collectors ; <nl> import java . util . stream . Stream ; <nl> <nl> import static java . util . stream . Collectors . joining ; <nl>\n", "msg": "[ java ] Deleting unused imports\n"}
{"diff_id": 6182, "repo": "jenkinsci/jenkins\n", "sha": "4f2626aaac65a6e96693cb22fc3ca42380efb2e7\n", "time": "2013-07-03T14:11:15Z\n", "diff": "mmm a / core / src / main / java / hudson / Functions . java <nl> ppp b / core / src / main / java / hudson / Functions . java <nl> <nl> import hudson . cli . CLICommand ; <nl> import hudson . console . ConsoleAnnotationDescriptor ; <nl> import hudson . console . ConsoleAnnotatorFactory ; <nl> + import hudson . matrix . MatrixProject ; <nl> import hudson . model . AbstractProject ; <nl> import hudson . model . Action ; <nl> import hudson . model . Describable ; <nl> public static boolean isModelWithContextMenu ( Object o ) { <nl> public static boolean isModelWithChildren ( Object o ) { <nl> return o instanceof ModelObjectWithChildren ; <nl> } <nl> + <nl> + public static boolean isMatrixProject ( Object o ) { <nl> + return o instanceof MatrixProject ; <nl> + } <nl> <nl> public static String xsDate ( Calendar cal ) { <nl> return Util . XS_DATETIME_FORMATTER . format ( cal . getTime ( ) ) ; <nl>\n", "msg": "Add convenient method for checking if object is MatrixProject\n"}
{"diff_id": 6241, "repo": "libgdx/libgdx\n", "sha": "f54ac5cb10016250962b3a1acc665caf8edfd352\n", "time": "2019-12-12T11:00:11Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / utils / Array . java <nl> ppp b / gdx / src / com / badlogic / gdx / utils / Array . java <nl> public void shuffle ( ) { <nl> * < p > <nl> * If { @ link Collections # allocateIterators } is false , the same iterator instance is returned each time this method is called . <nl> * Use the { @ link ArrayIterator } constructor for nested or multithreaded iteration . * / <nl> - public Iterator < T > iterator ( ) { <nl> + public ArrayIterator < T > iterator ( ) { <nl> if ( Collections . allocateIterators ) return new ArrayIterator ( this , true ) ; <nl> if ( iterable = = null ) iterable = new ArrayIterable ( this ) ; <nl> return iterable . iterator ( ) ; <nl> public void reset ( ) { <nl> index = 0 ; <nl> } <nl> <nl> - public Iterator < T > iterator ( ) { <nl> + public ArrayIterator < T > iterator ( ) { <nl> return this ; <nl> } <nl> } <nl> public ArrayIterable ( Array < T > array , boolean allowRemove ) { <nl> } <nl> <nl> / * * @ see Collections # allocateIterators * / <nl> - public Iterator < T > iterator ( ) { <nl> + public ArrayIterator < T > iterator ( ) { <nl> if ( Collections . allocateIterators ) return new ArrayIterator ( array , allowRemove ) ; <nl> / / lastAcquire . getBuffer ( ) . setLength ( 0 ) ; <nl> / / new Throwable ( ) . printStackTrace ( new java . io . PrintWriter ( lastAcquire ) ) ; <nl>\n", "msg": "Return ArrayIterable type so reset ( ) can be accessed .\n"}
{"diff_id": 6334, "repo": "SeleniumHQ/selenium\n", "sha": "218b22d810b021baf6f038f8aa810a21e02d8269\n", "time": "2012-04-23T22:07:44Z\n", "diff": "mmm a / java / server / test / org / openqa / grid / e2e / misc / Issue1586 . java <nl> ppp b / java / server / test / org / openqa / grid / e2e / misc / Issue1586 . java <nl> public void prepare ( ) throws Exception { <nl> RegistryTestHelper . waitForNode ( hub . getRegistry ( ) , 1 ) ; <nl> } <nl> <nl> - @ Test <nl> + / / extremely slow test , for issue1586 . Excluding from regression . <nl> + @ Test ( enabled = false ) <nl> public void test ( ) throws MalformedURLException { <nl> DesiredCapabilities ff = DesiredCapabilities . firefox ( ) ; <nl> WebDriver driver = null ; <nl>\n", "msg": "FrancoisReynaud : removing the test from the regression suite as it accesses a slow external site . Need to find a replacement .\n"}
{"diff_id": 6376, "repo": "oracle/graal\n", "sha": "4a3545bb35a717fccc43deeefcbcc5b2694eee7c\n", "time": "2018-07-31T20:21:46Z\n", "diff": "mmm a / substratevm / src / com . oracle . svm . core . graal / src / com / oracle / svm / core / graal / code / amd64 / SubstrateAMD64Backend . java <nl> ppp b / substratevm / src / com . oracle . svm . core . graal / src / com / oracle / svm / core / graal / code / amd64 / SubstrateAMD64Backend . java <nl> <nl> import jdk . vm . ci . amd64 . AMD64 ; <nl> import jdk . vm . ci . amd64 . AMD64Kind ; <nl> import jdk . vm . ci . code . CallingConvention ; <nl> - import jdk . vm . ci . code . CodeCacheProvider ; <nl> import jdk . vm . ci . code . CodeUtil ; <nl> import jdk . vm . ci . code . CompilationRequest ; <nl> import jdk . vm . ci . code . CompiledCode ; <nl> import jdk . vm . ci . code . Register ; <nl> - import jdk . vm . ci . code . RegisterArray ; <nl> import jdk . vm . ci . code . RegisterConfig ; <nl> import jdk . vm . ci . code . RegisterValue ; <nl> import jdk . vm . ci . meta . AllocatableValue ; <nl> public void emitCGlobalDataLoadAddress ( CGlobalDataLoadAddressNode node ) { <nl> <nl> @ Override <nl> public void enter ( CompilationResultBuilder tasm ) { <nl> - SubstrateAMD64FrameMap frameMap = ( SubstrateAMD64FrameMap ) tasm . frameMap ; <nl> - int frameSize = frameMap . frameSize ( ) ; <nl> - <nl> AMD64MacroAssembler asm = ( AMD64MacroAssembler ) tasm . asm ; <nl> + int frameSize = tasm . frameMap . frameSize ( ) ; <nl> <nl> asm . decrementq ( rsp , frameSize ) ; <nl> tasm . recordMark ( MARK_PROLOGUE_DECD_RSP ) ; <nl> - <nl> - RegisterConfig registerConfig = frameMap . getRegisterConfig ( ) ; <nl> - RegisterArray csr = registerConfig . getCalleeSaveRegisters ( ) ; <nl> - if ( csr ! = null & & csr . size ( ) ! = 0 ) { <nl> - int frameToCSA = frameMap . offsetToCalleeSaveArea ( ) ; <nl> - assert frameToCSA > = 0 ; <nl> - int offset = 0 ; <nl> - Register frameRegister = registerConfig . getFrameRegister ( ) ; <nl> - <nl> - for ( Register r : csr ) { <nl> - asm . movq ( new AMD64Address ( frameRegister , frameToCSA + offset ) , r ) ; <nl> - offset + = FrameAccess . wordSize ( ) ; <nl> - } <nl> - <nl> - tasm . recordMark ( MARK_PROLOGUE_SAVED_REGS ) ; <nl> - } <nl> tasm . recordMark ( MARK_PROLOGUE_END ) ; <nl> } <nl> <nl> @ Override <nl> public void leave ( CompilationResultBuilder tasm ) { <nl> - SubstrateAMD64FrameMap frameMap = ( SubstrateAMD64FrameMap ) tasm . frameMap ; <nl> - int frameSize = frameMap . frameSize ( ) ; <nl> AMD64MacroAssembler asm = ( AMD64MacroAssembler ) tasm . asm ; <nl> - <nl> - RegisterConfig registerConfig = frameMap . getRegisterConfig ( ) ; <nl> - RegisterArray csr = registerConfig . getCalleeSaveRegisters ( ) ; <nl> - if ( csr ! = null & & csr . size ( ) ! = 0 ) { <nl> - / / saved all registers , restore all registers <nl> - int frameToCSA = frameMap . offsetToCalleeSaveArea ( ) ; <nl> - int offset = 0 ; <nl> - Register frameRegister = registerConfig . getFrameRegister ( ) ; <nl> - <nl> - for ( Register r : csr ) { <nl> - asm . movq ( r , new AMD64Address ( frameRegister , frameToCSA + offset ) ) ; <nl> - offset + = FrameAccess . wordSize ( ) ; <nl> - } <nl> - } <nl> + int frameSize = tasm . frameMap . frameSize ( ) ; <nl> <nl> tasm . recordMark ( MARK_EPILOGUE_START ) ; <nl> asm . incrementq ( rsp , frameSize ) ; <nl> - boolean genIncRsp = frameSize ! = 0 ; <nl> - if ( genIncRsp ) { <nl> + if ( frameSize ! = 0 ) { <nl> tasm . recordMark ( MARK_EPILOGUE_INCD_RSP ) ; <nl> } <nl> tasm . recordMark ( MARK_EPILOGUE_END ) ; <nl> public void emitCode ( CompilationResultBuilder crb , AMD64MacroAssembler masm ) { <nl> } <nl> } <nl> <nl> - static class SubstrateAMD64FrameMap extends AMD64FrameMap { <nl> - <nl> - SubstrateAMD64FrameMap ( CodeCacheProvider codeCache , RegisterConfig registerConfig , ReferenceMapBuilderFactory referenceMapFactory ) { <nl> - super ( codeCache , registerConfig , referenceMapFactory ) ; <nl> - initialSpillSize + = calleeSaveAreaSize ( ) ; <nl> - spillSize = initialSpillSize ; <nl> - } <nl> - <nl> - protected int calleeSaveAreaSize ( ) { <nl> - return getRegisterConfig ( ) . getCalleeSaveRegisters ( ) . size ( ) * FrameAccess . wordSize ( ) ; <nl> - } <nl> - <nl> - public int offsetToCalleeSaveArea ( ) { <nl> - return frameSize ( ) - calleeSaveAreaSize ( ) ; <nl> - } <nl> - } <nl> - <nl> @ Override <nl> public FrameMapBuilder newFrameMapBuilder ( RegisterConfig registerConfig ) { <nl> RegisterConfig registerConfigNonNull = registerConfig = = null ? getCodeCache ( ) . getRegisterConfig ( ) : registerConfig ; <nl> public FrameMapBuilder newFrameMapBuilder ( RegisterConfig registerConfig ) { <nl> <nl> @ Override <nl> public FrameMap newFrameMap ( RegisterConfig registerConfig ) { <nl> - return new SubstrateAMD64FrameMap ( getProviders ( ) . getCodeCache ( ) , registerConfig , new SubstrateReferenceMapBuilderFactory ( ) ) ; <nl> + return new AMD64FrameMap ( getProviders ( ) . getCodeCache ( ) , registerConfig , new SubstrateReferenceMapBuilderFactory ( ) ) ; <nl> } <nl> <nl> @ Override <nl>\n", "msg": "Drop register - save code made redundant by SaveCalleeSaveRegisters LIR phase\n"}
{"diff_id": 6558, "repo": "oracle/graal\n", "sha": "3f99fb6ba44b739109eddd3de388a56098390d4e\n", "time": "2016-06-22T13:14:11Z\n", "diff": "mmm a / truffle / com . oracle . truffle . api / src / com / oracle / truffle / api / source / Source . java <nl> ppp b / truffle / com . oracle . truffle . api / src / com / oracle / truffle / api / source / Source . java <nl> public static Source fromText ( CharSequence chars , String name ) { <nl> * @ param name name for the newly created source <nl> * @ return a newly created , non - indexed , initially empty , appendable source representation <nl> * @ since 0 . 8 or earlier <nl> + * @ deprecated No replacement . Appendable sources will not be supported in the future . <nl> * / <nl> + @ Deprecated <nl> public static Source fromAppendableText ( String name ) { <nl> CompilerAsserts . neverPartOfCompilation ( \" do not call Source . fromAppendableText from compiled code \" ) ; <nl> Content content = new AppendableLiteralSourceImpl ( name ) ; <nl> public static Source fromReader ( Reader reader , String description ) throws IOExce <nl> * @ param charset how to decode the bytes into Java strings <nl> * @ return a newly created , non - indexed source representation <nl> * @ since 0 . 8 or earlier <nl> + * @ deprecated Use { @ link # newBuilder ( java . lang . String ) } where you construct the string via its <nl> + * { @ link String # String ( byte [ ] , java . nio . charset . Charset ) } constructor <nl> * / <nl> + @ Deprecated <nl> public static Source fromBytes ( byte [ ] bytes , String name , Charset charset ) { <nl> return fromBytes ( bytes , 0 , bytes . length , name , charset ) ; <nl> } <nl> public static Source fromBytes ( byte [ ] bytes , String name , Charset charset ) { <nl> * @ param charset how to decode the bytes into Java strings <nl> * @ return a newly created , non - indexed source representation <nl> * @ since 0 . 8 or earlier <nl> + * @ deprecated Use { @ link # newBuilder ( java . lang . String ) } where you construct the string via its <nl> + * { @ link String # String ( byte [ ] , int , int , java . nio . charset . Charset ) } constructor <nl> * / <nl> + @ Deprecated <nl> public static Source fromBytes ( byte [ ] bytes , int byteIndex , int length , String name , Charset charset ) { <nl> CompilerAsserts . neverPartOfCompilation ( \" do not call Source . fromBytes from compiled code \" ) ; <nl> Content content = new BytesSourceImpl ( name , bytes , byteIndex , length , charset ) ; <nl> public final int getLineLength ( int lineNumber ) throws IllegalArgumentException { <nl> * @ param chars the text to append <nl> * @ throws UnsupportedOperationException by concrete subclasses that do not support appending <nl> * @ since 0 . 8 or earlier <nl> + * @ deprecated No replacement . Appendable sources will not be supported in the future . <nl> * / <nl> + @ Deprecated <nl> public void appendCode ( CharSequence chars ) { <nl> content ( ) . appendCode ( chars ) ; <nl> clearTextMap ( ) ; <nl>\n", "msg": "Deprecating Source . appendCode and all remaining Source . fromXYZ factory methods\n"}
{"diff_id": 6563, "repo": "SeleniumHQ/selenium\n", "sha": "ba676596b873e5992080e69e5635ee7aac92b0a8\n", "time": "2018-02-09T10:40:45Z\n", "diff": "mmm a / java / server / src / org / openqa / selenium / remote / server / ServicedSession . java <nl> ppp b / java / server / src / org / openqa / selenium / remote / server / ServicedSession . java <nl> public ServicedSession ( <nl> new JMXHelper ( ) . register ( this ) ; <nl> } <nl> <nl> + @ Override <nl> + public String toString ( ) { <nl> + return getId ( ) . toString ( ) + \" ( \" + service . getClass ( ) . getName ( ) + \" ) \" ; <nl> + } <nl> + <nl> @ Override <nl> public void stop ( ) { <nl> / / Try and kill the running session . Both W3C and OSS use the same quit endpoint <nl>\n", "msg": "Improving representation of session info in server logs\n"}
{"diff_id": 6806, "repo": "jenkinsci/jenkins\n", "sha": "27e3d514650aa4f498a5f40063dbf1848d4534d7\n", "time": "2019-04-01T19:30:25Z\n", "diff": "mmm a / core / src / main / java / hudson / Launcher . java <nl> ppp b / core / src / main / java / hudson / Launcher . java <nl> public void kill ( final Map < String , String > modelEnvVars ) throws IOException , Inte <nl> getChannel ( ) . call ( new KillTask ( modelEnvVars ) ) ; <nl> } <nl> <nl> + @ Override <nl> + public String toString ( ) { <nl> + return \" RemoteLauncher [ \" + getChannel ( ) + \" ] \" ; <nl> + } <nl> + <nl> private static final class KillTask extends MasterToSlaveCallable < Void , RuntimeException > { <nl> private final Map < String , String > modelEnvVars ; <nl> <nl>\n", "msg": "RemoteLauncher . toString override for easier debugging .\n"}
{"diff_id": 6834, "repo": "facebook/fresco\n", "sha": "8deab0c3634b05ef9c3db40cfdc9f1b620f84651\n", "time": "2018-08-17T20:34:46Z\n", "diff": "mmm a / imagepipeline / src / main / java / com / facebook / imagepipeline / producers / NetworkFetchProducer . java <nl> ppp b / imagepipeline / src / main / java / com / facebook / imagepipeline / producers / NetworkFetchProducer . java <nl> protected void handleFinalResult ( <nl> fetchState . getConsumer ( ) ) ; <nl> } <nl> <nl> - private void notifyConsumer ( <nl> + protected static void notifyConsumer ( <nl> PooledByteBufferOutputStream pooledOutputStream , <nl> @ Consumer . Status int status , <nl> @ Nullable BytesRange responseBytesRange , <nl>\n", "msg": "Network fetcher optimizations 1 / n - add 2 new update modes\n"}
{"diff_id": 6916, "repo": "SeleniumHQ/selenium\n", "sha": "4a76a129b805599da6ccf4917788fe7ea2a3177f\n", "time": "2009-01-15T20:13:50Z\n", "diff": "mmm a / htmlunit / src / java / org / openqa / selenium / htmlunit / HtmlUnitDriver . java <nl> ppp b / htmlunit / src / java / org / openqa / selenium / htmlunit / HtmlUnitDriver . java <nl> <nl> import com . gargoylesoftware . htmlunit . WebWindowEvent ; <nl> import com . gargoylesoftware . htmlunit . WebWindowListener ; <nl> import com . gargoylesoftware . htmlunit . WebWindowNotFoundException ; <nl> + import com . gargoylesoftware . htmlunit . BrowserVersion ; <nl> import com . gargoylesoftware . htmlunit . html . FrameWindow ; <nl> import com . gargoylesoftware . htmlunit . html . HtmlAnchor ; <nl> import com . gargoylesoftware . htmlunit . html . HtmlElement ; <nl> <nl> private boolean enableJavascript ; <nl> private ProxyConfig proxyConfig ; <nl> private AtomicLong windowNamer = new AtomicLong ( System . currentTimeMillis ( ) ) ; <nl> + private final BrowserVersion version ; <nl> <nl> - public HtmlUnitDriver ( boolean enableJavascript ) { <nl> - this . enableJavascript = enableJavascript ; <nl> - <nl> - webClient = newWebClient ( ) ; <nl> + public HtmlUnitDriver ( BrowserVersion version ) { <nl> + this . version = version ; <nl> + webClient = createWebClient ( version ) ; <nl> webClient . addWebWindowListener ( new WebWindowListener ( ) { <nl> private boolean waitingToLoad ; <nl> <nl> public HtmlUnitDriver ( ) { <nl> this ( false ) ; <nl> } <nl> <nl> + public HtmlUnitDriver ( boolean enableJavascript ) { <nl> + this ( BrowserVersion . getDefault ( ) ) ; <nl> + setJavascriptEnabled ( enableJavascript ) ; <nl> + } <nl> + <nl> private HtmlUnitDriver ( boolean enableJavascript , WebWindow currentWindow ) { <nl> this ( enableJavascript ) ; <nl> this . currentWindow = currentWindow ; <nl> } <nl> <nl> - / * * <nl> - * @ return WebClient to use <nl> - * @ deprecated Please override modifyWebClient . This method will become private <nl> - * / <nl> - @ Deprecated <nl> - protected WebClient newWebClient ( ) { <nl> - WebClient client = new WebClient ( ) ; <nl> + private WebClient createWebClient ( BrowserVersion version ) { <nl> + WebClient client = newWebClient ( version ) ; <nl> client . setThrowExceptionOnFailingStatusCode ( false ) ; <nl> client . setPrintContentOnFailingStatusCode ( false ) ; <nl> client . setJavaScriptEnabled ( enableJavascript ) ; <nl> client . setRedirectEnabled ( true ) ; <nl> try { <nl> - client . setUseInsecureSSL ( true ) ; <nl> - } catch ( GeneralSecurityException e ) { <nl> - throw new RuntimeException ( e ) ; <nl> - } <nl> + client . setUseInsecureSSL ( true ) ; <nl> + } catch ( GeneralSecurityException e ) { <nl> + throw new RuntimeException ( e ) ; <nl> + } <nl> <nl> / / Ensure that we ' ve set the proxy if necessary <nl> if ( proxyConfig ! = null ) <nl> protected WebClient newWebClient ( ) { <nl> return modifyWebClient ( client ) ; <nl> } <nl> <nl> + / * * <nl> + * Create the underlying webclient , but don ' t set any fields on it . <nl> + * <nl> + * @ param version Which browser to emulate <nl> + * @ return a new instance of WebClient . <nl> + * / <nl> + protected WebClient newWebClient ( BrowserVersion version ) { <nl> + return new WebClient ( version ) ; <nl> + } <nl> + <nl> / * * <nl> * Child classes can override this method to customise the webclient that <nl> * the HtmlUnit driver uses . <nl> public String getPageSource ( ) { <nl> } <nl> <nl> public void close ( ) { <nl> - webClient = newWebClient ( ) ; <nl> + webClient = createWebClient ( version ) ; <nl> } <nl> <nl> public void quit ( ) { <nl>\n", "msg": "SimonStewart : Exposing the functionality to allow users to change which browser they emulate using the HtmlUnitDriver\n"}
{"diff_id": 6927, "repo": "material-components/material-components-android\n", "sha": "eaa0a7f5100ee787c47ff146871a7ee83c66f1f0\n", "time": "2020-07-29T13:14:09Z\n", "diff": "mmm a / lib / java / com / google / android / material / progressindicator / ProgressIndicator . java <nl> ppp b / lib / java / com / google / android / material / progressindicator / ProgressIndicator . java <nl> private void loadExtraAttributes ( <nl> a . recycle ( ) ; <nl> } <nl> <nl> + / * * <nl> + * Initializes the builtin drawables for LINEAR and CIRCULAR types . <nl> + * <nl> + * @ throws IllegalStateException If it gets called for the CUSTOM type . <nl> + * / <nl> private void initializeDrawables ( ) { <nl> - / / Creates and sets the determinate and indeterminate drawables based on track shape . <nl> - if ( spec . indicatorType = = LINEAR ) { <nl> - DrawingDelegate drawingDelegate = new LinearDrawingDelegate ( ) ; <nl> - IndeterminateAnimatorDelegate < AnimatorSet > animatorDelegate = <nl> - isLinearSeamless ( ) <nl> - ? new LinearIndeterminateSeamlessAnimatorDelegate ( ) <nl> - : new LinearIndeterminateNonSeamlessAnimatorDelegate ( getContext ( ) ) ; <nl> - setIndeterminateDrawable ( <nl> - new IndeterminateDrawable ( getContext ( ) , spec , drawingDelegate , animatorDelegate ) ) ; <nl> - setProgressDrawable ( new DeterminateDrawable ( getContext ( ) , spec , drawingDelegate ) ) ; <nl> - } else { <nl> - DrawingDelegate drawingDelegate = new CircularDrawingDelegate ( ) ; <nl> - setIndeterminateDrawable ( <nl> - new IndeterminateDrawable ( <nl> - getContext ( ) , spec , drawingDelegate , new CircularIndeterminateAnimatorDelegate ( ) ) ) ; <nl> - setProgressDrawable ( new DeterminateDrawable ( getContext ( ) , spec , drawingDelegate ) ) ; <nl> + if ( spec . indicatorType = = CUSTOM ) { <nl> + throw new IllegalStateException ( <nl> + \" Cannot initialize builtin drawables for CUSTOM type . Please use \" <nl> + + \" initializeDrawables ( IndeterminateDrawable , DeterminateDrawable ) instead . \" ) ; <nl> } <nl> + / / Creates and sets the determinate and indeterminate drawables based on track shape . <nl> + DrawingDelegate drawingDelegate = <nl> + spec . indicatorType = = LINEAR ? new LinearDrawingDelegate ( ) : new CircularDrawingDelegate ( ) ; <nl> + IndeterminateAnimatorDelegate < AnimatorSet > indeterminateAnimatorDelegate = <nl> + spec . indicatorType = = LINEAR <nl> + ? isLinearSeamless ( ) <nl> + ? new LinearIndeterminateSeamlessAnimatorDelegate ( ) <nl> + : new LinearIndeterminateNonSeamlessAnimatorDelegate ( getContext ( ) ) <nl> + : new CircularIndeterminateAnimatorDelegate ( ) ; <nl> + <nl> + setIndeterminateDrawable ( <nl> + new IndeterminateDrawable ( <nl> + getContext ( ) , spec , drawingDelegate , indeterminateAnimatorDelegate ) ) ; <nl> + setProgressDrawable ( new DeterminateDrawable ( getContext ( ) , spec , drawingDelegate ) ) ; <nl> <nl> applyNewVisibility ( ) ; <nl> } <nl>\n", "msg": "[ ProgressIndicator ] Improved the readability of initializeDrawables ( ) function .\n"}
{"diff_id": 7015, "repo": "eugenp/tutorials\n", "sha": "ad40040852bf47baf73412d0a6850d4fa75fa122\n", "time": "2018-04-03T10:43:24Z\n", "diff": "new file mode 100644 <nl> index 00000000000 . . 36dee603eb8 <nl> mmm / dev / null <nl> ppp b / core - java / src / main / java / com / baeldung / ssl / SecureConnection . java <nl> <nl> + package com . baeldung . ssl ; <nl> + <nl> + import java . io . InputStream ; <nl> + import java . io . OutputStream ; <nl> + <nl> + import javax . net . ssl . SSLSocket ; <nl> + import javax . net . ssl . SSLSocketFactory ; <nl> + <nl> + public class SecureConnection { <nl> + <nl> + public static void main ( String [ ] args ) { <nl> + if ( args . length ! = 2 ) { <nl> + System . out . println ( \" Use : SecureConnection host port \" ) ; <nl> + System . exit ( 1 ) ; <nl> + } <nl> + try { <nl> + String host = getHost ( args ) ; <nl> + Integer port = getPort ( args ) ; <nl> + SSLSocketFactory sslsocketfactory = ( SSLSocketFactory ) SSLSocketFactory . getDefault ( ) ; <nl> + SSLSocket sslsocket = ( SSLSocket ) sslsocketfactory . createSocket ( host , port ) ; <nl> + InputStream in = sslsocket . getInputStream ( ) ; <nl> + OutputStream out = sslsocket . getOutputStream ( ) ; <nl> + <nl> + out . write ( 1 ) ; <nl> + <nl> + while ( in . available ( ) > 0 ) { <nl> + System . out . print ( in . read ( ) ) ; <nl> + } <nl> + <nl> + System . out . println ( \" Secured connection performed successfully \" ) ; <nl> + <nl> + } catch ( Exception exception ) { <nl> + exception . printStackTrace ( ) ; <nl> + } <nl> + } <nl> + <nl> + / * * <nl> + * Get the host from arguments <nl> + * @ param args the arguments <nl> + * @ return the host <nl> + * / <nl> + private static String getHost ( String [ ] args ) { <nl> + return args [ 0 ] ; <nl> + } <nl> + <nl> + / * * <nl> + * Get the port from arguments <nl> + * @ param args the arguments <nl> + * @ return the port <nl> + * / <nl> + private static Integer getPort ( String [ ] args ) { <nl> + return Integer . parseInt ( args [ 1 ] ) ; <nl> + } <nl> + } <nl> \\ No newline at end of file <nl>\n", "msg": "BAEL - 1531 Add class to connect to secured server ( )\n"}
{"diff_id": 7120, "repo": "elastic/elasticsearch\n", "sha": "86aab98fde8dc4be8843ddb79216061aca0da406\n", "time": "2017-04-28T18:42:56Z\n", "diff": "mmm a / core / src / test / java / org / elasticsearch / discovery / zen / ZenDiscoveryIT . java <nl> ppp b / core / src / test / java / org / elasticsearch / discovery / zen / ZenDiscoveryIT . java <nl> public String getWriteableName ( ) { <nl> } <nl> } <nl> <nl> - public void testDiscoveryStats ( ) throws IOException { <nl> + public void testDiscoveryStats ( ) throws Exception { <nl> String expectedStatsJsonResponse = \" { \\ n \" + <nl> \" \\ \" discovery \\ \" : { \\ n \" + <nl> \" \\ \" cluster_state_queue \\ \" : { \\ n \" + <nl> public void testDiscoveryStats ( ) throws IOException { <nl> <nl> internalCluster ( ) . startNode ( ) ; <nl> ensureGreen ( ) ; / / ensures that all events are processed ( in particular state recovery fully completed ) <nl> + assertBusy ( ( ) - > <nl> + assertThat ( internalCluster ( ) . clusterService ( internalCluster ( ) . getMasterName ( ) ) . getMasterService ( ) . numberOfPendingTasks ( ) , <nl> + equalTo ( 0 ) ) ) ; / / see https : / / github . com / elastic / elasticsearch / issues / 24388 <nl> <nl> logger . info ( \" - - > request node discovery stats \" ) ; <nl> NodesStatsResponse statsResponse = client ( ) . admin ( ) . cluster ( ) . prepareNodesStats ( ) . clear ( ) . setDiscovery ( true ) . get ( ) ; <nl>\n", "msg": "[ TEST ] Fix race condition in ZenDiscoveryIT . testDiscoveryStats\n"}
{"diff_id": 7379, "repo": "oracle/graal\n", "sha": "e9d4aa3feaf969ec657c6ea9a2d6db8629211567\n", "time": "2018-04-16T19:32:49Z\n", "diff": "mmm a / truffle / src / com . oracle . truffle . api / src / com / oracle / truffle / api / TruffleLanguage . java <nl> ppp b / truffle / src / com . oracle . truffle . api / src / com / oracle / truffle / api / TruffleLanguage . java <nl> <nl> import java . lang . annotation . Retention ; <nl> import java . lang . annotation . RetentionPolicy ; <nl> import java . lang . annotation . Target ; <nl> + import java . net . URI ; <nl> + import java . nio . file . FileSystemNotFoundException ; <nl> import java . util . ArrayList ; <nl> import java . util . Collections ; <nl> import java . util . LinkedHashSet ; <nl> <nl> import org . graalvm . options . OptionValues ; <nl> import org . graalvm . polyglot . Context ; <nl> import org . graalvm . polyglot . Value ; <nl> + import org . graalvm . polyglot . io . FileSystem ; <nl> <nl> import com . oracle . truffle . api . CompilerDirectives . CompilationFinal ; <nl> import com . oracle . truffle . api . CompilerDirectives . TruffleBoundary ; <nl> <nl> import com . oracle . truffle . api . nodes . RootNode ; <nl> import com . oracle . truffle . api . source . Source ; <nl> import com . oracle . truffle . api . source . SourceSection ; <nl> - import java . net . URI ; <nl> - import java . nio . file . FileSystemNotFoundException ; <nl> - import org . graalvm . polyglot . io . FileSystem ; <nl> <nl> / * * <nl> * A Truffle language implementation contains all the services a language should provide to make it <nl> <nl> * that is created using the { @ linkplain org . graalvm . polyglot . Engine . Builder # build ( ) engine builder } <nl> * . If a { @ linkplain org . graalvm . polyglot . Context context } is created without a <nl> * { @ linkplain org . graalvm . polyglot . Engine engine } then the language implementation instance is <nl> - * created for each context implicitely . <nl> + * created for each context implicitly . <nl> * < p > <nl> * Global state can be shared between multiple language context instances by saving them as in a <nl> * field of the { @ link TruffleLanguage } subclass . The implementation needs to ensure data isolation <nl> protected TruffleLanguage ( ) { <nl> * { @ link Env # parse ( com . oracle . truffle . api . source . Source , java . lang . String . . . ) calls into other <nl> * languages } and assuming your language is already initialized and others can see it would be <nl> * wrong - until you return from this method , the initialization isn ' t over . The same is true <nl> - * for instrumentation , the instruments can not receive any meta data about code executed during <nl> + * for instrumentation , the instruments cannot receive any meta data about code executed during <nl> * context creation . Should there be a need to perform complex initialization , do it by <nl> * overriding the { @ link # initializeContext ( java . lang . Object ) } method . <nl> + * < p > <nl> + * May return { @ code null } if the language does not need any per - { @ linkplain Context context } <nl> + * state . Otherwise it should return a new object instance every time it is called . <nl> * <nl> * @ param env the environment the language is supposed to operate in <nl> - * @ return internal data of the language in given environment <nl> + * @ return internal data of the language in given environment or { @ code null } <nl> * @ since 0 . 8 or earlier <nl> * / <nl> protected abstract C createContext ( Env env ) ; <nl> public Object getPolyglotBindings ( ) { <nl> } <nl> <nl> / * * <nl> - * Explicitely imports a symbol from the polyglot bindings . The behavior of this method is <nl> + * Explicitly imports a symbol from the polyglot bindings . The behavior of this method is <nl> * equivalent to sending a READ message to the { @ link # getPolyglotBindings ( ) polyglot <nl> * bindings } object . Reading a symbol that does not exist will return < code > null < / code > . <nl> * < p > <nl> public Object importSymbol ( String symbolName ) { <nl> } <nl> <nl> / * * <nl> - * Explicitely exports a symbol to the polyglot bindings object . The behavior of this method <nl> + * Explicitly exports a symbol to the polyglot bindings object . The behavior of this method <nl> * is equivalent to sending a WRITE message to the { @ link # getPolyglotBindings ( ) polyglot <nl> * bindings } object . Exporting a symbol with a < code > null < / code > value will remove the <nl> * symbol from the polyglot object . <nl>\n", "msg": "Clarify javadoc of TruffleLanguage . createContext w . r . t . return value .\n"}
{"diff_id": 7434, "repo": "alibaba/druid\n", "sha": "78751d169d29609bf52a2382ec9487c7892266b2\n", "time": "2012-09-21T06:38:05Z\n", "diff": "mmm a / src / main / java / com / alibaba / druid / filter / stat / StatFilter . java <nl> ppp b / src / main / java / com / alibaba / druid / filter / stat / StatFilter . java <nl> public long getSlowSqlMillis ( ) { <nl> return slowSqlMillis ; <nl> } <nl> <nl> + public void setSlowSqlMillis ( long slowSqlMillis ) { <nl> + this . slowSqlMillis = slowSqlMillis ; <nl> + } <nl> + <nl> + public boolean isLogSlowSql ( ) { <nl> + return logSlowSql ; <nl> + } <nl> + <nl> + public void setLogSlowSql ( boolean logSlowSql ) { <nl> + this . logSlowSql = logSlowSql ; <nl> + } <nl> + <nl> public boolean isConnectionStackTraceEnable ( ) { <nl> return connectionStackTraceEnable ; <nl> } <nl>\n", "msg": "StatFilter add getter & setter for logSlowSql , slowSqlMillis\n"}
{"diff_id": 7460, "repo": "SeleniumHQ/selenium\n", "sha": "4ffc2413000738c9dd91e188245dfa96d4221c1f\n", "time": "2008-02-20T00:58:46Z\n", "diff": "new file mode 100644 <nl> index 00000000000 . . 2ab44437050 <nl> mmm / dev / null <nl> ppp b / common / test / java / com / googlecode / webdriver / Message . java <nl> <nl> + package com . googlecode . webdriver ; <nl> + <nl> + public class Message { <nl> + public static String getString ( String key ) { <nl> + return null ; <nl> + } <nl> + } <nl>\n", "msg": "SimonStewart : Adding missing file to allow tests to compile\n"}
{"diff_id": 7565, "repo": "google/gson\n", "sha": "5fc2db9e7266701959129e88aa7ed8baeb493adc\n", "time": "2011-08-04T22:27:25Z\n", "diff": "mmm a / gson / src / main / java / com / google / gson / internal / bind / ReflectiveTypeAdapter . java <nl> ppp b / gson / src / main / java / com / google / gson / internal / bind / ReflectiveTypeAdapter . java <nl> <nl> import java . util . LinkedHashMap ; <nl> import java . util . Map ; <nl> <nl> - import com . google . gson . FieldAttributes ; <nl> - import com . google . gson . FieldAttributesTest ; <nl> import com . google . gson . internal . $ Gson $ Types ; <nl> import com . google . gson . internal . UnsafeAllocator ; <nl> import com . google . gson . reflect . TypeToken ; <nl> static BoundField createBoundField ( <nl> } <nl> <nl> private static Type getMoreSpecificType ( Type type , Object obj , Object fieldValue ) { <nl> - if ( obj ! = null & & ( Object . class = = type | | type instanceof TypeVariable ) ) { <nl> - if ( fieldValue ! = null ) { <nl> - type = fieldValue . getClass ( ) ; <nl> - } <nl> + if ( obj = = null | | fieldValue = = null ) { <nl> + return type ; <nl> + } <nl> + if ( type = = Object . class | | type instanceof TypeVariable | | type instanceof Class < ? > ) { <nl> + type = ( Class < ? > ) fieldValue . getClass ( ) ; <nl> } <nl> return type ; <nl> } <nl>\n", "msg": "Parity with Gson behavior where we use runtime type of an object while serializing instead of the declared type of the field .\n"}
{"diff_id": 7744, "repo": "SeleniumHQ/selenium\n", "sha": "e914709a4186f16c848fccccbf647da850610d9d\n", "time": "2012-06-20T14:10:56Z\n", "diff": "mmm a / java / server / test / org / openqa / selenium / server / ProxyHanderUnitTest . java <nl> ppp b / java / server / test / org / openqa / selenium / server / ProxyHanderUnitTest . java <nl> <nl> <nl> package org . openqa . selenium . server ; <nl> <nl> - import static org . easymock . EasyMock . expectLastCall ; <nl> - import static org . easymock . classextension . EasyMock . createMock ; <nl> - import static org . easymock . classextension . EasyMock . replay ; <nl> - import static org . easymock . classextension . EasyMock . verify ; <nl> - <nl> - import junit . framework . TestCase ; <nl> - <nl> + import org . junit . Test ; <nl> import org . openqa . jetty . http . HttpRequest ; <nl> import org . openqa . jetty . http . HttpResponse ; <nl> import org . openqa . jetty . util . URI ; <nl> <nl> import java . io . ByteArrayOutputStream ; <nl> import java . io . OutputStream ; <nl> <nl> - public class ProxyHanderUnitTest extends TestCase { <nl> + import static org . easymock . EasyMock . expectLastCall ; <nl> + import static org . easymock . classextension . EasyMock . createMock ; <nl> + import static org . easymock . classextension . EasyMock . replay ; <nl> + import static org . easymock . classextension . EasyMock . verify ; <nl> + import static org . junit . Assert . assertNull ; <nl> + import static org . junit . Assert . assertTrue ; <nl> + <nl> + public class ProxyHanderUnitTest { <nl> <nl> private final int port = 8086 ; <nl> <nl> - public void testSendNotFoundSends404ResponseCode ( ) throws Exception { <nl> + @ Test <nl> + public void sendNotFoundSends404ResponseCode ( ) throws Exception { <nl> ProxyHandler proxyHandler = new ProxyHandler ( true , \" \" , \" \" , false , false , port , new Object ( ) ) ; <nl> HttpResponse httpResponseMock = createMock ( HttpResponse . class ) ; <nl> httpResponseMock . sendError ( HttpResponse . __404_Not_Found , \" Not found \" ) ; <nl> public void testSendNotFoundSends404ResponseCode ( ) throws Exception { <nl> verify ( httpResponseMock ) ; <nl> } <nl> <nl> - public void testUnknownHostExceptionDoesNotBubble ( ) throws Exception { <nl> + @ Test <nl> + public void unknownHostExceptionDoesNotBubble ( ) throws Exception { <nl> ProxyHandler proxyHandler = new ProxyHandler ( true , \" \" , \" \" , false , false , port , new Object ( ) ) ; <nl> final ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; <nl> HttpResponse response = new HttpResponse ( ) { <nl> public OutputStream getOutputStream ( ) { <nl> proxyHandler . handle ( \" foo \" , \" bar \" , request , response ) ; <nl> } <nl> <nl> - public void testUnknownHostExceptionProvidesUsefulErrorMessage ( ) throws Exception { <nl> + @ Test <nl> + public void unknownHostExceptionProvidesUsefulErrorMessage ( ) throws Exception { <nl> ProxyHandler proxyHandler = new ProxyHandler ( true , \" \" , \" \" , false , false , port , new Object ( ) ) ; <nl> final ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; <nl> HttpResponse response = new HttpResponse ( ) { <nl> public OutputStream getOutputStream ( ) { <nl> assertTrue ( responseText . contains ( \" Check the address for typing errors \" ) ) ; <nl> } <nl> <nl> - public void testConnectExceptionDoesNotBubble ( ) throws Exception { <nl> + @ Test <nl> + public void connectExceptionDoesNotBubble ( ) throws Exception { <nl> ProxyHandler proxyHandler = new ProxyHandler ( true , \" \" , \" \" , false , false , port , new Object ( ) ) ; <nl> final ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; <nl> HttpResponse response = new HttpResponse ( ) { <nl> public OutputStream getOutputStream ( ) { <nl> proxyHandler . handle ( \" foo \" , \" bar \" , request , response ) ; <nl> } <nl> <nl> - public void testConnectExceptionProvidesUsefulErrorMessage ( ) throws Exception { <nl> + @ Test <nl> + public void connectExceptionProvidesUsefulErrorMessage ( ) throws Exception { <nl> ProxyHandler proxyHandler = new ProxyHandler ( true , \" \" , \" \" , false , false , port , new Object ( ) ) ; <nl> final ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; <nl> HttpResponse response = new HttpResponse ( ) { <nl> public OutputStream getOutputStream ( ) { <nl> assertTrue ( responseText . contains ( \" The site could be temporarily unavailable or too busy \" ) ) ; <nl> } <nl> <nl> - public void testHandleCallsSendNotFoundWhenAskingForNonExistentResource ( ) <nl> + @ Test <nl> + public void handleCallsSendNotFoundWhenAskingForNonExistentResource ( ) <nl> throws Exception { <nl> ProxyHandler proxyHandlerMock = createMock ( ProxyHandler . class , <nl> ProxyHandler . class . getDeclaredMethod ( <nl>\n", "msg": "SimonStewart : Go , go , Gadget JUnit4 . Converting the ProxyHanderUnitTest to use junit4\n"}
{"diff_id": 7768, "repo": "oracle/graal\n", "sha": "392634642afb8a6c57a6fe26ade818552f3ff00e\n", "time": "2019-09-18T14:13:42Z\n", "diff": "mmm a / wasm / src / com . oracle . truffle . wasm . test / src / com / oracle / truffle / wasm / test / WasmSuiteBase . java <nl> ppp b / wasm / src / com . oracle . truffle . wasm . test / src / com / oracle / truffle / wasm / test / WasmSuiteBase . java <nl> public void test ( ) throws IOException { <nl> System . out . println ( \" mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - - \" ) ; <nl> System . out . println ( \" Using runtime : \" + Truffle . getRuntime ( ) . toString ( ) ) ; <nl> for ( WasmTestCase testCase : qualifyingTestCases ) { <nl> + String statusIcon = \" \\ u003F \" ; <nl> try { <nl> - runTestCase ( testCase ) ; <nl> - System . out . print ( \" \\ uD83D \\ uDE0D \" ) ; <nl> + System . out . print ( \" \" ) ; <nl> + System . out . print ( testCase . name ) ; <nl> System . out . flush ( ) ; <nl> + runTestCase ( testCase ) ; <nl> + statusIcon = \" \\ uD83D \\ uDE0D \" ; <nl> } catch ( Throwable e ) { <nl> - System . out . print ( \" \\ uD83D \\ uDE21 \" ) ; <nl> - System . out . flush ( ) ; <nl> + statusIcon = \" \\ uD83D \\ uDE21 \" ; <nl> errors . put ( testCase , e ) ; <nl> + } finally { <nl> + for ( int i = 0 ; i < testCase . name . length ( ) + 1 ; i + + ) { <nl> + System . out . print ( \" \\ u001b [ 1D \" ) ; <nl> + System . out . print ( \" \" ) ; <nl> + System . out . print ( \" \\ u001b [ 1D \" ) ; <nl> + } <nl> + System . out . print ( statusIcon ) ; <nl> + System . out . flush ( ) ; <nl> } <nl> } <nl> System . out . println ( ) ; <nl> similarity index 100 % <nl> rename from wasm / src / com . oracle . truffle . wasm . test / src / tests / emcc / fact - rec . wat . disabled <nl> rename to wasm / src / com . oracle . truffle . wasm . test / src / tests / emcc / fact - rec . wat <nl> similarity index 100 % <nl> rename from wasm / src / com . oracle . truffle . wasm . test / src / tests / emcc / fib . wat <nl> rename to wasm / src / com . oracle . truffle . wasm . test / src / tests / emcc / fib . wat . disabled <nl> similarity index 100 % <nl> rename from wasm / src / com . oracle . truffle . wasm . test / src / tests / emcc / sum - table . wat <nl> rename to wasm / src / com . oracle . truffle . wasm . test / src / tests / emcc / sum - table . wat . disabled <nl> similarity index 100 % <nl> rename from wasm / src / com . oracle . truffle . wasm . test / src / tests / emcc / superperfect . wat <nl> rename to wasm / src / com . oracle . truffle . wasm . test / src / tests / emcc / superperfect . wat . disabled <nl>\n", "msg": "Improve rendering of the test names in the test suite .\n"}
{"diff_id": 7782, "repo": "TheAlgorithms/Java\n", "sha": "c97d806ba0393c24bdaf8cc4626623b33cc89011\n", "time": "2016-11-23T18:07:18Z\n", "diff": "new file mode 100644 <nl> index 000000000 . . ecf3f7b4b <nl> mmm / dev / null <nl> ppp b / FindingPrimes . java <nl> <nl> + / * <nl> + * The Sieve of Eratosthenes is an algorithm used to find prime numbers , up to a given value . <nl> + * Illustration : https : / / upload . wikimedia . org / wikipedia / commons / b / b9 / Sieve_of_Eratosthenes_animation . gif <nl> + * / <nl> + public class FindingPrimes { <nl> + public static void main ( String args [ ] ) { <nl> + SOE ( 20 ) ; / / Example : Finds all the primes up to 20 <nl> + } <nl> + <nl> + public static void SOE ( int n ) { <nl> + boolean sieve [ ] = new boolean [ n ] ; <nl> + <nl> + int check = ( int ) Math . round ( Math . sqrt ( n ) ) ; / / No need to check for multiples past the square root of n <nl> + <nl> + sieve [ 0 ] = false ; <nl> + sieve [ 1 ] = false ; <nl> + for ( int i = 2 ; i < n ; i + + ) <nl> + sieve [ i ] = true ; / / Set every index to true except index 0 and 1 <nl> + <nl> + for ( int i = 2 ; i < check ; i + + ) { <nl> + if ( sieve [ i ] = = true ) / / If i is a prime <nl> + for ( int j = i + i ; j < n ; j + = i ) / / Step through the array in increments of i ( the multiples of the prime ) <nl> + sieve [ j ] = false ; / / Set every multiple of i to false <nl> + } <nl> + for ( int i = 0 ; i < n ; i + + ) { <nl> + if ( sieve [ i ] = = true ) <nl> + System . out . print ( i + \" \" ) ; / / In this example it will print 2 3 5 7 11 13 17 19 <nl> + } <nl> + } <nl> + } <nl> \\ No newline at end of file <nl>\n", "msg": "Added Sieve of Eratosthenes algorithm for finding primes\n"}
{"diff_id": 7929, "repo": "bazelbuild/bazel\n", "sha": "b853e930228e4e8039c8df2bfac1e55de00230b0\n", "time": "2018-08-06T17:51:55Z\n", "diff": "mmm a / src / tools / android / java / com / google / devtools / build / android / aapt2 / ResourceLinker . java <nl> ppp b / src / tools / android / java / com / google / devtools / build / android / aapt2 / ResourceLinker . java <nl> public PackagedResources link ( CompiledResources compiled ) { <nl> } <nl> } <nl> <nl> + / * * Link a proto apk to produce an apk . * / <nl> + public Path link ( ProtoApk protoApk ) { <nl> + try { <nl> + final Path protoApkPath = protoApk . asApkPath ( ) ; <nl> + final Path working = <nl> + workingDirectory <nl> + . resolve ( \" link - proto \" ) <nl> + . resolve ( replaceExtension ( protoApkPath . getFileName ( ) . toString ( ) , \" working \" ) ) ; <nl> + final Path manifest = protoApk . writeManifestAsXmlTo ( working ) ; <nl> + final Path apk = working . resolve ( \" binary . apk \" ) ; <nl> + logger . fine ( <nl> + new AaptCommandBuilder ( aapt2 ) <nl> + . forBuildToolsVersion ( buildToolsVersion ) <nl> + . forVariantType ( VariantType . DEFAULT ) <nl> + . add ( \" link \" ) <nl> + . when ( Objects . equals ( logger . getLevel ( ) , Level . FINE ) ) <nl> + . thenAdd ( \" - v \" ) <nl> + . add ( \" - - manifest \" , manifest ) <nl> + . addRepeated ( \" - I \" , StaticLibrary . toPathStrings ( linkAgainst ) ) <nl> + . add ( \" - R \" , convertToBinary ( protoApkPath ) ) <nl> + . add ( \" - o \" , apk . toString ( ) ) <nl> + . execute ( String . format ( \" Re - linking % s \" , protoApkPath ) ) ) ; <nl> + return apk ; <nl> + } catch ( IOException e ) { <nl> + throw new LinkError ( e ) ; <nl> + } <nl> + } <nl> + <nl> public ResourceLinker storeUncompressed ( List < String > uncompressedExtensions ) { <nl> this . uncompressedExtensions = uncompressedExtensions ; <nl> return this ; <nl>\n", "msg": "Added functionality to let the ResourceLinker link ProtoApks .\n"}
{"diff_id": 8020, "repo": "spring-projects/spring-boot\n", "sha": "ffcc854d429f6e42d901e63501d1ff6c1af35ef1\n", "time": "2015-05-05T15:40:48Z\n", "diff": "mmm a / spring - boot - actuator / src / main / java / org / springframework / boot / actuate / system / ApplicationPidFileWriter . java <nl> ppp b / spring - boot - actuator / src / main / java / org / springframework / boot / actuate / system / ApplicationPidFileWriter . java <nl> public void onApplicationEvent ( SpringApplicationEvent event ) { <nl> writePidFile ( event ) ; <nl> } <nl> catch ( Exception ex ) { <nl> - logger . warn ( String . format ( \" Cannot create pid file % s \" , this . file ) ) ; <nl> + logger . warn ( String . format ( \" Cannot create pid file % s \" , this . file ) , ex ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Include exception in warning message when pid file cannot be created\n"}
{"diff_id": 8121, "repo": "oracle/graal\n", "sha": "4e4c28029cde6284e7cb78078854112c54ab690c\n", "time": "2016-09-23T07:59:51Z\n", "diff": "mmm a / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / HotSpotGraalCompiler . java <nl> ppp b / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / HotSpotGraalCompiler . java <nl> <nl> import static com . oracle . graal . nodes . StructuredGraph . NO_PROFILING_INFO ; <nl> import static com . oracle . graal . nodes . graphbuilderconf . IntrinsicContext . CompilationContext . ROOT_COMPILATION ; <nl> <nl> + import java . io . PrintStream ; <nl> + import java . util . Arrays ; <nl> + import java . util . IdentityHashMap ; <nl> + import java . util . Map ; <nl> + import java . util . concurrent . locks . ReentrantReadWriteLock ; <nl> + <nl> import com . oracle . graal . api . runtime . GraalJVMCICompiler ; <nl> import com . oracle . graal . code . CompilationResult ; <nl> import com . oracle . graal . compiler . GraalCompiler ; <nl> import com . oracle . graal . debug . Debug ; <nl> import com . oracle . graal . debug . DebugConfigScope ; <nl> import com . oracle . graal . debug . DebugEnvironment ; <nl> + import com . oracle . graal . debug . GraalError ; <nl> import com . oracle . graal . debug . TTY ; <nl> import com . oracle . graal . debug . TopLevelDebugConfig ; <nl> import com . oracle . graal . debug . internal . DebugScope ; <nl> <nl> import com . oracle . graal . nodes . graphbuilderconf . GraphBuilderConfiguration . Plugins ; <nl> import com . oracle . graal . nodes . graphbuilderconf . IntrinsicContext ; <nl> import com . oracle . graal . nodes . spi . Replacements ; <nl> + import com . oracle . graal . options . Option ; <nl> + import com . oracle . graal . options . OptionType ; <nl> + import com . oracle . graal . options . OptionValue ; <nl> + import com . oracle . graal . options . StableOptionValue ; <nl> import com . oracle . graal . phases . OptimisticOptimizations ; <nl> import com . oracle . graal . phases . OptimisticOptimizations . Optimization ; <nl> import com . oracle . graal . phases . PhaseSuite ; <nl> <nl> <nl> public class HotSpotGraalCompiler implements GraalJVMCICompiler { <nl> <nl> + static class CompilationMonitoring { <nl> + <nl> + public static class Options { <nl> + / / @ formatter : off <nl> + @ Option ( help = \" Enable Compilation counters . Compilation counters count the number of compilations for each method . \" , type = OptionType . Debug ) <nl> + public static final OptionValue < Boolean > EnableCompilationCounters = new StableOptionValue < > ( true ) ; <nl> + @ Option ( help = \" \" , type = OptionType . Debug ) <nl> + public static final OptionValue < Integer > CompilationCountersUpperBound = new StableOptionValue < > ( 64 ) ; <nl> + @ Option ( help = \" \" , type = OptionType . Debug ) <nl> + public static final OptionValue < Boolean > CompilationCountersExceededIsFatal = new StableOptionValue < > ( true ) ; <nl> + @ Option ( help = \" \" , type = OptionType . Debug ) <nl> + public static final OptionValue < Boolean > MonitorCompilerThreads = new StableOptionValue < > ( true ) ; <nl> + @ Option ( help = \" Kill a Compiler Thread and Exit VM if N last stack traces are the same \" , type = OptionType . Debug ) <nl> + public static final OptionValue < Boolean > StaleCompilerThreadsAreFatal = new StableOptionValue < > ( true ) ; <nl> + @ Option ( help = \" Number of equal stack traces for the compiler thread until it is killed \" , type = OptionType . Debug ) <nl> + public static final OptionValue < Integer > FatalNumberOfCompilerThreadStackTraces = new StableOptionValue < > ( 8 ) ; <nl> + @ Option ( help = \" Start monitoring after 2 minutes \" , type = OptionType . Debug ) <nl> + public static final OptionValue < Integer > WatchDogStartMonitoringTimeout = new StableOptionValue < > ( 30 * 1000 ) ; <nl> + @ Option ( help = \" Take Stack Trace Every 30s \" , type = OptionType . Debug ) <nl> + public static final OptionValue < Integer > WatchDogStackTraceTimeout = new StableOptionValue < > ( 5 * 1000 ) ; <nl> + / / @ formatter : on <nl> + } <nl> + <nl> + private static final ReentrantReadWriteLock RW_LOCK ; <nl> + <nl> + static { <nl> + if ( Options . EnableCompilationCounters . getValue ( ) ) { <nl> + RW_LOCK = new ReentrantReadWriteLock ( ) ; <nl> + } else { <nl> + RW_LOCK = null ; <nl> + } <nl> + } <nl> + <nl> + private static class CompilationCounters { <nl> + private final IdentityHashMap < ResolvedJavaMethod , Integer > counters = new IdentityHashMap < > ( ) ; <nl> + <nl> + void compilationStarted ( CompilationRequest request ) { <nl> + final ResolvedJavaMethod method = request . getMethod ( ) ; <nl> + Integer val = null ; <nl> + try { <nl> + RW_LOCK . readLock ( ) . lock ( ) ; <nl> + val = counters . get ( method ) ; <nl> + } finally { <nl> + RW_LOCK . readLock ( ) . unlock ( ) ; <nl> + } <nl> + val = val ! = null ? val + 1 : 1 ; <nl> + try { <nl> + RW_LOCK . writeLock ( ) . lock ( ) ; <nl> + counters . put ( method , val ) ; <nl> + } finally { <nl> + RW_LOCK . writeLock ( ) . unlock ( ) ; <nl> + } <nl> + <nl> + if ( val > Options . CompilationCountersUpperBound . getValue ( ) ) { <nl> + throw new CompilationCounterExceededException ( method , val ) ; <nl> + } <nl> + } <nl> + <nl> + void dumpCounters ( PrintStream s ) { <nl> + try { <nl> + RW_LOCK . readLock ( ) . lock ( ) ; <nl> + for ( Map . Entry < ResolvedJavaMethod , Integer > entry : counters . entrySet ( ) ) { <nl> + s . printf ( \" Method % s compiled % d times . % s \" , entry . getKey ( ) , entry . getValue ( ) , System . lineSeparator ( ) ) ; <nl> + } <nl> + } finally { <nl> + RW_LOCK . readLock ( ) . unlock ( ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + private static class CompilationCounterExceededException extends RuntimeException { <nl> + <nl> + private static final long serialVersionUID = - 5202508391961867237L ; <nl> + <nl> + CompilationCounterExceededException ( ResolvedJavaMethod method , int nrOfCompilations ) { <nl> + super ( String . format ( \" Method % s compiled % d times . \" , method , nrOfCompilations ) ) ; <nl> + } <nl> + } <nl> + <nl> + private static class CompilationWatchDogThread extends Thread { <nl> + <nl> + private enum WatchDogState { <nl> + / * * <nl> + * The watchdog thread sleeps currently , either no method is currently compiled , or <nl> + * no method is compiled long enough to be monitored . <nl> + * / <nl> + SLEEPING , <nl> + / * * <nl> + * The watchdog thread identified a compilation that already takes long enough to be <nl> + * interesting . It will sleep and wake up periodically and check if the current <nl> + * compilation takes too long . If it takes too long it will start collecting stack <nl> + * traces from the compiler thread . <nl> + * / <nl> + WATCHING_NO_STACK_INSPECTION , <nl> + / * * <nl> + * The watchdog thread is fully monitoring the compiler thread . It takes stake <nl> + * traces periodically and sleeps again until the next period . If the number of <nl> + * stack traces reaches a certain upper bound and those stack traces are equal it <nl> + * will shut down the entire VM with an error . <nl> + * / <nl> + WATCHING_STACK_INSPECTION <nl> + } <nl> + <nl> + / * <nl> + * Methods below this sleep timeout will , mostly , not even be recognized by the <nl> + * watchdog . The watchdog thread only wakes up each SPIN_TIMEOUT ms to check weather it <nl> + * should change its internal state to monitoring as the same method is compiled enough <nl> + * to be interesting . <nl> + * / <nl> + private static final int SPIN_TIMEOUT = 500 / * ms * / ; <nl> + <nl> + private static final boolean TRACE_WATCHDOG = true ; <nl> + <nl> + private final Thread compilerThread ; <nl> + <nl> + CompilationWatchDogThread ( Thread compilerThread ) { <nl> + this . compilerThread = compilerThread ; <nl> + this . setName ( \" Watch dog thread \" + getId ( ) ) ; <nl> + this . setPriority ( Thread . MAX_PRIORITY ) ; <nl> + this . setDaemon ( true ) ; <nl> + } <nl> + <nl> + private volatile ResolvedJavaMethod lastSet ; <nl> + private ResolvedJavaMethod lastWatched ; <nl> + <nl> + public void startCompilation ( ResolvedJavaMethod newMethod ) { <nl> + TTY . println ( \" % s is notified that compilation started for method % s \" , getTracePrefix ( ) , newMethod ) ; <nl> + this . lastSet = newMethod ; <nl> + } <nl> + <nl> + public void stopCompilation ( ) { <nl> + TTY . println ( \" % s notified that compilation is finished \" , getTracePrefix ( ) ) ; <nl> + this . lastSet = null ; <nl> + } <nl> + <nl> + private long ellapesWatchingNoStackTime ; <nl> + private long ellapsedWatchingTime ; <nl> + private int nrOfStackTraces ; <nl> + private WatchDogState state = WatchDogState . SLEEPING ; <nl> + <nl> + private void sleep ( ) { <nl> + ellapsedWatchingTime = 0 ; <nl> + ellapesWatchingNoStackTime = 0 ; <nl> + nrOfStackTraces = 0 ; <nl> + lastWatched = null ; <nl> + lastStackTrace = null ; <nl> + state = WatchDogState . SLEEPING ; <nl> + } <nl> + <nl> + private void watch ( ) { <nl> + state = WatchDogState . WATCHING_NO_STACK_INSPECTION ; <nl> + } <nl> + <nl> + private void watchStack ( ) { <nl> + state = WatchDogState . WATCHING_STACK_INSPECTION ; <nl> + } <nl> + <nl> + private StackTraceElement [ ] lastStackTrace ; <nl> + <nl> + private boolean recordStackTrace ( StackTraceElement [ ] newStackTrace ) { <nl> + if ( lastStackTrace = = null ) { <nl> + lastStackTrace = newStackTrace ; <nl> + return true ; <nl> + } <nl> + if ( ! Arrays . equals ( lastStackTrace , newStackTrace ) ) { <nl> + lastStackTrace = newStackTrace ; <nl> + return false ; <nl> + } <nl> + return true ; <nl> + } <nl> + <nl> + private static void traceWatchDog ( String s , Object . . . args ) { <nl> + if ( TRACE_WATCHDOG ) { <nl> + TTY . println ( String . format ( s , args ) ) ; <nl> + } <nl> + } <nl> + <nl> + private String getTracePrefix ( ) { <nl> + return \" Watchdog Thread for Compiler thread [ \" + compilerThread . toString ( ) + \" ] \" ; <nl> + } <nl> + <nl> + @ Override <nl> + public void run ( ) { <nl> + try { <nl> + while ( true ) { <nl> + / / get a copy of the last set method <nl> + final ResolvedJavaMethod currentlyCompiled = lastSet ; <nl> + if ( currentlyCompiled = = null ) { <nl> + / / continue sleeping , compilation is either over before starting <nl> + / / to watch the compiler thread or no compilation at all started <nl> + / / ( now ) <nl> + sleep ( ) ; <nl> + } else { <nl> + switch ( state ) { <nl> + case SLEEPING : <nl> + traceWatchDog ( \" % s picked up a method to monitor \" , getTracePrefix ( ) ) ; <nl> + lastWatched = currentlyCompiled ; <nl> + watch ( ) ; <nl> + break ; <nl> + case WATCHING_NO_STACK_INSPECTION : <nl> + if ( currentlyCompiled = = lastWatched ) { <nl> + if ( ellapesWatchingNoStackTime > Options . WatchDogStartMonitoringTimeout . getValue ( ) ) { <nl> + / / we looked at the same thread for a certain time and <nl> + / / it still compiles one method , now we start to take <nl> + / / stake traces <nl> + watchStack ( ) ; <nl> + traceWatchDog ( \" % s changes mode to watching with stack traces \" , getTracePrefix ( ) ) ; <nl> + } else { <nl> + / / we still compile the same method , watch until we <nl> + / / start <nl> + / / to collect stack traces <nl> + traceWatchDog ( \" % s still watching , ellapsed time watching % d \" , getTracePrefix ( ) , ellapesWatchingNoStackTime ) ; <nl> + ellapesWatchingNoStackTime + = SPIN_TIMEOUT ; <nl> + } <nl> + } else { <nl> + / / compilation finished before we exceeded the watching <nl> + / / period of n minutes <nl> + sleep ( ) ; <nl> + } <nl> + break ; <nl> + case WATCHING_STACK_INSPECTION : <nl> + if ( currentlyCompiled = = lastWatched ) { <nl> + if ( ellapsedWatchingTime > Options . WatchDogStackTraceTimeout . getValue ( ) ) { <nl> + traceWatchDog ( \" % s took a stack trace \" , getTracePrefix ( ) ) ; <nl> + boolean newStackTrace = recordStackTrace ( compilerThread . getStackTrace ( ) ) ; <nl> + traceWatchDog ( \" % s : Last stack trace was % b equal ? , took % d equal stack traces \" , getTracePrefix ( ) , newStackTrace , nrOfStackTraces ) ; <nl> + if ( ! newStackTrace ) { <nl> + nrOfStackTraces = 0 ; <nl> + } <nl> + nrOfStackTraces + + ; <nl> + ellapsedWatchingTime = 0 ; <nl> + if ( Options . StaleCompilerThreadsAreFatal . getValue ( ) ) { <nl> + if ( nrOfStackTraces > Options . FatalNumberOfCompilerThreadStackTraces . getValue ( ) ) { <nl> + TTY . println ( \" % s took N stack traces , which is considered fatal , we quit now \" , getTracePrefix ( ) ) ; <nl> + TTY . println ( \" = = = = = = = = = = = = = = = = = = = = = = = STACK TRACE = = = = = = = = = = = = = = = = = = = = = = = \" ) ; <nl> + for ( StackTraceElement e : lastStackTrace ) { <nl> + TTY . println ( e . toString ( ) ) ; <nl> + } <nl> + System . exit ( - 1 ) ; <nl> + } <nl> + } <nl> + } else { <nl> + / / we still compile the same method watch until the <nl> + / / stack trace timeout happens <nl> + traceWatchDog ( \" % s still watching with stack traces , ellapsedtime in watching period \" + ellapsedWatchingTime , getTracePrefix ( ) ) ; <nl> + ellapsedWatchingTime + = SPIN_TIMEOUT ; <nl> + } <nl> + } else { <nl> + / / compilation finished before we are able to collect stack <nl> + / / traces <nl> + sleep ( ) ; <nl> + } <nl> + break ; <nl> + default : <nl> + break ; <nl> + } <nl> + } <nl> + Thread . sleep ( SPIN_TIMEOUT ) ; <nl> + } <nl> + } catch ( <nl> + <nl> + Throwable t ) { <nl> + TTY . println ( \" Watch dog thread encountered an exception . Shutting down . \" ) ; <nl> + t . printStackTrace ( TTY . out ) ; <nl> + System . exit ( - 1 ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + } <nl> + <nl> private final HotSpotJVMCIRuntimeProvider jvmciRuntime ; <nl> private final HotSpotGraalRuntimeProvider graalRuntime ; <nl> + private final CompilationMonitoring . CompilationCounters compilationCounters ; <nl> + private static final IdentityHashMap < Thread , CompilationMonitoring . CompilationWatchDogThread > watchdogs = CompilationMonitoring . Options . MonitorCompilerThreads . getValue ( ) ? new IdentityHashMap < > ( ) <nl> + : null ; <nl> <nl> HotSpotGraalCompiler ( HotSpotJVMCIRuntimeProvider jvmciRuntime , HotSpotGraalRuntimeProvider graalRuntime ) { <nl> this . jvmciRuntime = jvmciRuntime ; <nl> this . graalRuntime = graalRuntime ; <nl> + / * <nl> + * It is sufficient to have one compilation counter object per graal compiler . <nl> + * / <nl> + if ( CompilationMonitoring . Options . EnableCompilationCounters . getValue ( ) ) { <nl> + compilationCounters = new CompilationMonitoring . CompilationCounters ( ) ; <nl> + } else { <nl> + compilationCounters = null ; <nl> + } <nl> } <nl> <nl> @ Override <nl> public HotSpotGraalRuntimeProvider getGraalRuntime ( ) { <nl> @ Override <nl> @ SuppressWarnings ( \" try \" ) <nl> public CompilationRequestResult compileMethod ( CompilationRequest request ) { <nl> + <nl> + if ( CompilationMonitoring . Options . MonitorCompilerThreads . getValue ( ) ) { <nl> + / * <nl> + * lazily get a watch dog thread for the current compiler thread <nl> + * / <nl> + CompilationMonitoring . CompilationWatchDogThread watchDog = watchdogs . get ( Thread . currentThread ( ) ) ; <nl> + if ( watchDog = = null ) { <nl> + watchDog = new CompilationMonitoring . CompilationWatchDogThread ( Thread . currentThread ( ) ) ; <nl> + watchdogs . put ( Thread . currentThread ( ) , watchDog ) ; <nl> + watchDog . start ( ) ; <nl> + } <nl> + watchDog . startCompilation ( request . getMethod ( ) ) ; <nl> + } <nl> + <nl> + if ( CompilationMonitoring . Options . EnableCompilationCounters . getValue ( ) ) { <nl> + assert compilationCounters ! = null ; <nl> + try { <nl> + compilationCounters . compilationStarted ( request ) ; <nl> + } catch ( Throwable t ) { <nl> + if ( t instanceof CompilationMonitoring . CompilationCounterExceededException ) { <nl> + CompilationMonitoring . CompilationCounterExceededException e = ( CompilationMonitoring . CompilationCounterExceededException ) t ; <nl> + if ( CompilationMonitoring . Options . CompilationCountersExceededIsFatal . getValue ( ) ) { <nl> + TTY . println ( \" Error : Option \" + CompilationMonitoring . Options . CompilationCountersExceededIsFatal . getName ( ) + \" is enabled and method \" + request . getMethod ( ) + <nl> + \" was compiled too many times . \" ) ; <nl> + e . printStackTrace ( TTY . out ) ; <nl> + TTY . println ( \" = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = Compilation Counters = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \" ) ; <nl> + compilationCounters . dumpCounters ( TTY . out ) ; <nl> + TTY . flush ( ) ; <nl> + System . exit ( - 1 ) ; <nl> + } <nl> + } else { <nl> + GraalError . shouldNotReachHere ( t . getCause ( ) ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> / / Ensure a debug configuration for this thread is initialized <nl> if ( Debug . isEnabled ( ) & & DebugScope . getConfig ( ) = = null ) { <nl> DebugEnvironment . initialize ( TTY . out ) ; <nl> } <nl> CompilationTask task = new CompilationTask ( jvmciRuntime , this , ( HotSpotCompilationRequest ) request , true , true ) ; <nl> + CompilationRequestResult r = null ; <nl> try ( DebugConfigScope dcs = Debug . setConfig ( new TopLevelDebugConfig ( ) ) ; <nl> Debug . Scope s = Debug . methodMetricsScope ( \" HotSpotGraalCompiler \" , MethodMetricsRootScopeInfo . create ( request . getMethod ( ) ) , true , request . getMethod ( ) ) ) { <nl> - return task . runCompilation ( ) ; <nl> + r = task . runCompilation ( ) ; <nl> + } <nl> + if ( CompilationMonitoring . Options . MonitorCompilerThreads . getValue ( ) ) { <nl> + watchdogs . get ( Thread . currentThread ( ) ) . stopCompilation ( ) ; <nl> } <nl> + return r ; <nl> } <nl> <nl> public void compileTheWorld ( ) throws Throwable { <nl>\n", "msg": "compilation monitoring : initial implementation for compilation counters and compiler thread watch dog\n"}
{"diff_id": 8139, "repo": "SeleniumHQ/selenium\n", "sha": "bc10c8bb177e5bb5973e48604cff8e8595cf4e10\n", "time": "2013-01-22T12:52:48Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / net / NetworkInterface . java <nl> ppp b / java / client / src / org / openqa / selenium / net / NetworkInterface . java <nl> <nl> / * <nl> - Copyright 2007 - 2010 Selenium committers <nl> + Copyright 2007 - 2010 WebDriver committers <nl> + Copyright 2007 - 2010 Google Inc . <nl> <nl> - Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> - you may not use this file except in compliance with the License . <nl> - You may obtain a copy of the License at <nl> + Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> + you may not use this file except in compliance with the License . <nl> + You may obtain a copy of the License at <nl> <nl> - http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> <nl> - Unless required by applicable law or agreed to in writing , software <nl> - distributed under the License is distributed on an \" AS IS \" BASIS , <nl> - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> - See the License for the specific language governing permissions and <nl> - limitations under the License . <nl> + Unless required by applicable law or agreed to in writing , software <nl> + distributed under the License is distributed on an \" AS IS \" BASIS , <nl> + WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + See the License for the specific language governing permissions and <nl> + limitations under the License . <nl> * / <nl> - <nl> package org . openqa . selenium . net ; <nl> <nl> import java . net . InetAddress ; <nl> + import java . net . SocketException ; <nl> import java . util . ArrayList ; <nl> import java . util . Arrays ; <nl> import java . util . Collections ; <nl> import java . util . Enumeration ; <nl> import java . util . Iterator ; <nl> import java . util . List ; <nl> + import java . util . logging . Level ; <nl> + import java . util . logging . Logger ; <nl> <nl> public class NetworkInterface { <nl> + <nl> private final String name ; <nl> private final Iterable < INetAddress > inetAddresses ; <nl> + private boolean isLoopback ; <nl> <nl> public NetworkInterface ( java . net . NetworkInterface networkInterface ) { <nl> this ( networkInterface . getName ( ) , asIterableAddr ( networkInterface . getInetAddresses ( ) ) ) ; <nl> + try { <nl> + / / Issue 1181 : determine wheter this NetworkInterface instance is loopback <nl> + / / from java . net . NetworkInterface API <nl> + this . isLoopback = networkInterface . isLoopback ( ) ; <nl> + } catch ( SocketException ex ) { <nl> + Logger . getLogger ( NetworkInterface . class . getName ( ) ) . log ( Level . WARNING , null , ex ) ; <nl> + / / If an SocketException is caught , determine wheter this NetworkInterface <nl> + / / instance is loopack from computation from its inetAddresses <nl> + this . isLoopback = isLoopBackFromINetAddresses ( asIterableAddr ( networkInterface . getInetAddresses ( ) ) ) ; <nl> + } <nl> } <nl> <nl> NetworkInterface ( String name , Iterable < INetAddress > inetAddresses ) { <nl> public boolean isIp4AddressBindingOnly ( ) { <nl> } <nl> <nl> public boolean isLoopBack ( ) { <nl> + return isLoopback ; <nl> + } <nl> + <nl> + public final boolean isLoopBackFromINetAddresses ( Iterable < INetAddress > inetAddresses ) { <nl> / / Let ' s hope there ' s no such thing as network interfaces with mixed addresses ; ) <nl> Iterator < INetAddress > iterator = inetAddresses . iterator ( ) ; <nl> return iterator . hasNext ( ) & & iterator . next ( ) . isLoopbackAddress ( ) ; <nl> } <nl> <nl> - <nl> public INetAddress getIp4LoopbackOnly ( ) { <nl> / / Goes by the wildly unscientific assumption that if there are more than one set of <nl> / / loopback addresses , firefox will bind to the last one we get . <nl> public INetAddress getIp4LoopbackOnly ( ) { <nl> / / algorithm until it works . <nl> / / See NetworkUtilsTest # testOpenSuseBoxIssue1181 <nl> INetAddress lastFound = null ; <nl> + / / Issue 1181 <nl> + if ( ! isLoopback ) { <nl> + return lastFound ; <nl> + } <nl> for ( INetAddress inetAddress : inetAddresses ) { <nl> if ( inetAddress . isLoopbackAddress ( ) & & inetAddress . isIPv4Address ( ) ) { <nl> lastFound = inetAddress ; <nl>\n", "msg": "Improved loopback detection . fixes issues 1181 .\n"}
{"diff_id": 8180, "repo": "apache/flink\n", "sha": "a455ddf21778cbebf8bc5a651eb647d49c4b77b6\n", "time": "2020-01-06T14:23:37Z\n", "diff": "mmm a / flink - clients / src / main / java / org / apache / flink / client / deployment / ClusterSpecification . java <nl> ppp b / flink - clients / src / main / java / org / apache / flink / client / deployment / ClusterSpecification . java <nl> <nl> <nl> package org . apache . flink . client . deployment ; <nl> <nl> - import org . apache . flink . configuration . Configuration ; <nl> - import org . apache . flink . configuration . ConfigurationUtils ; <nl> - import org . apache . flink . configuration . TaskManagerOptions ; <nl> - import org . apache . flink . runtime . clusterframework . TaskExecutorResourceUtils ; <nl> - <nl> / * * <nl> * Description of the cluster to start by the { @ link ClusterDescriptor } . <nl> * / <nl> public String toString ( ) { <nl> ' } ' ; <nl> } <nl> <nl> - public static ClusterSpecification fromConfiguration ( Configuration configuration ) { <nl> - int slots = configuration . getInteger ( TaskManagerOptions . NUM_TASK_SLOTS , 1 ) ; <nl> - <nl> - int jobManagerMemoryMb = ConfigurationUtils . getJobManagerHeapMemory ( configuration ) . getMebiBytes ( ) ; <nl> - int taskManagerMemoryMb = TaskExecutorResourceUtils <nl> - . resourceSpecFromConfig ( configuration ) <nl> - . getTotalProcessMemorySize ( ) <nl> - . getMebiBytes ( ) ; <nl> - <nl> - return new ClusterSpecificationBuilder ( ) <nl> - . setMasterMemoryMB ( jobManagerMemoryMb ) <nl> - . setTaskManagerMemoryMB ( taskManagerMemoryMb ) <nl> - . setNumberTaskManagers ( 1 ) <nl> - . setSlotsPerTaskManager ( slots ) <nl> - . createClusterSpecification ( ) ; <nl> - } <nl> - <nl> / * * <nl> * Builder for the { @ link ClusterSpecification } instance . <nl> * / <nl>\n", "msg": "[ hotfix ] Remove unused ClusterSpecification # fromConfiguration .\n"}
{"diff_id": 8221, "repo": "google/ExoPlayer\n", "sha": "db7e9a548c019828302a17fb363c01fc0b07a6f4\n", "time": "2017-11-13T20:04:40Z\n", "diff": "mmm a / library / dash / src / main / java / com / google / android / exoplayer2 / source / dash / manifest / DashManifestParser . java <nl> ppp b / library / dash / src / main / java / com / google / android / exoplayer2 / source / dash / manifest / DashManifestParser . java <nl> protected RepresentationInfo parseRepresentation ( XmlPullParser xpp , String baseU <nl> segmentBase = segmentBase ! = null ? segmentBase : new SingleSegmentBase ( ) ; <nl> <nl> return new RepresentationInfo ( format , baseUrl , segmentBase , drmSchemeType , drmSchemeDatas , <nl> - inbandEventStreams ) ; <nl> + inbandEventStreams , Representation . REVISION_ID_DEFAULT ) ; <nl> } <nl> <nl> protected Format buildFormat ( String id , String containerMimeType , int width , int height , <nl> protected Representation buildRepresentation ( RepresentationInfo representationIn <nl> } <nl> ArrayList < Descriptor > inbandEventStreams = representationInfo . inbandEventStreams ; <nl> inbandEventStreams . addAll ( extraInbandEventStreams ) ; <nl> - return Representation . newInstance ( contentId , Representation . REVISION_ID_DEFAULT , format , <nl> + return Representation . newInstance ( contentId , representationInfo . revisionId , format , <nl> representationInfo . baseUrl , representationInfo . segmentBase , inbandEventStreams ) ; <nl> } <nl> <nl> protected static int parseDolbyChannelConfiguration ( XmlPullParser xpp ) { <nl> } <nl> } <nl> <nl> - private static final class RepresentationInfo { <nl> + / * * A parsed Representation element . * / <nl> + protected static final class RepresentationInfo { <nl> <nl> public final Format format ; <nl> public final String baseUrl ; <nl> protected static int parseDolbyChannelConfiguration ( XmlPullParser xpp ) { <nl> public final String drmSchemeType ; <nl> public final ArrayList < SchemeData > drmSchemeDatas ; <nl> public final ArrayList < Descriptor > inbandEventStreams ; <nl> + public final long revisionId ; <nl> <nl> public RepresentationInfo ( Format format , String baseUrl , SegmentBase segmentBase , <nl> String drmSchemeType , ArrayList < SchemeData > drmSchemeDatas , <nl> - ArrayList < Descriptor > inbandEventStreams ) { <nl> + ArrayList < Descriptor > inbandEventStreams , long revisionId ) { <nl> this . format = format ; <nl> this . baseUrl = baseUrl ; <nl> this . segmentBase = segmentBase ; <nl> this . drmSchemeType = drmSchemeType ; <nl> this . drmSchemeDatas = drmSchemeDatas ; <nl> this . inbandEventStreams = inbandEventStreams ; <nl> + this . revisionId = revisionId ; <nl> } <nl> <nl> } <nl>\n", "msg": "Make it possible to extend DashManifestParser to parse revision - id .\n"}
{"diff_id": 8318, "repo": "spring-projects/spring-framework\n", "sha": "e545b20289df650499aeb8f3a30317b5d678cfa5\n", "time": "2016-06-30T08:59:38Z\n", "diff": "mmm a / spring - web - reactive / src / main / java / org / springframework / http / server / reactive / AbstractResponseBodySubscriber . java <nl> ppp b / spring - web - reactive / src / main / java / org / springframework / http / server / reactive / AbstractResponseBodySubscriber . java <nl> private boolean changeState ( State oldState , State newState ) { <nl> * UNSUBSCRIBED <nl> * | <nl> * v <nl> - * REQUESTED < mmm > RECEIVED <nl> - * | | <nl> - * v v <nl> - * COMPLETED <nl> + * REQUESTED mmmmmmmmmmmmmmmmmm - > RECEIVED <nl> + * ^ ^ <nl> + * | | <nl> + * mmmmmmmmm WRITING < mmm - - <nl> + * | <nl> + * v <nl> + * COMPLETED <nl> * < / pre > <nl> * Refer to the individual states for more information . <nl> * / <nl> void onComplete ( AbstractResponseBodySubscriber subscriber ) { <nl> / * * <nl> * State that gets entered after a buffer has been <nl> * { @ linkplain Subscriber # onNext ( Object ) received } . Responds to <nl> - * { @ code onWritePossible } by writing the current buffer , and if it can be <nl> - * written completely , changes state to either { @ link # REQUESTED } if the <nl> - * subscription has not been completed ; or { @ link # COMPLETED } if it has . <nl> + * { @ code onWritePossible } by writing the current buffer and changes <nl> + * the state to { @ link # WRITING } . If it can be written completely , <nl> + * changes the state to either { @ link # REQUESTED } if the subscription <nl> + * has not been completed ; or { @ link # COMPLETED } if it has . If it cannot <nl> + * be written completely the state will be changed to { @ link # RECEIVED } . <nl> * / <nl> RECEIVED { <nl> @ Override <nl> void onWritePossible ( AbstractResponseBodySubscriber subscriber ) { <nl> - DataBuffer dataBuffer = subscriber . currentBuffer ; <nl> - try { <nl> - boolean writeCompleted = subscriber . write ( dataBuffer ) ; <nl> - if ( writeCompleted ) { <nl> - if ( dataBuffer instanceof FlushingDataBuffer ) { <nl> - subscriber . flush ( ) ; <nl> - } <nl> - subscriber . releaseBuffer ( ) ; <nl> - boolean subscriptionCompleted = subscriber . subscriptionCompleted ; <nl> - if ( ! subscriptionCompleted ) { <nl> - if ( subscriber . changeState ( this , REQUESTED ) ) { <nl> + if ( subscriber . changeState ( this , WRITING ) ) { <nl> + DataBuffer dataBuffer = subscriber . currentBuffer ; <nl> + try { <nl> + boolean writeCompleted = subscriber . write ( dataBuffer ) ; <nl> + if ( writeCompleted ) { <nl> + if ( dataBuffer instanceof FlushingDataBuffer ) { <nl> + subscriber . flush ( ) ; <nl> + } <nl> + subscriber . releaseBuffer ( ) ; <nl> + boolean subscriptionCompleted = subscriber . subscriptionCompleted ; <nl> + if ( ! subscriptionCompleted ) { <nl> + subscriber . changeState ( WRITING , REQUESTED ) ; <nl> subscriber . subscription . request ( 1 ) ; <nl> } <nl> - } <nl> - else { <nl> - if ( subscriber . changeState ( this , COMPLETED ) ) { <nl> + else { <nl> + subscriber . changeState ( WRITING , COMPLETED ) ; <nl> subscriber . close ( ) ; <nl> } <nl> } <nl> + else { <nl> + subscriber . changeState ( WRITING , RECEIVED ) ; <nl> + } <nl> + } <nl> + catch ( IOException ex ) { <nl> + subscriber . onError ( ex ) ; <nl> } <nl> - } <nl> - catch ( IOException ex ) { <nl> - subscriber . onError ( ex ) ; <nl> } <nl> } <nl> <nl> void onComplete ( AbstractResponseBodySubscriber subscriber ) { <nl> subscriber . subscriptionCompleted = true ; <nl> } <nl> } , <nl> + / * * <nl> + * State that gets entered after a writing of the current buffer has been <nl> + * { @ code onWritePossible started } . <nl> + * / <nl> + WRITING { <nl> + @ Override <nl> + void onComplete ( AbstractResponseBodySubscriber subscriber ) { <nl> + subscriber . subscriptionCompleted = true ; <nl> + } <nl> + } , <nl> / * * <nl> * The terminal completed state . Does not respond to any events . <nl> * / <nl>\n", "msg": "Make AbstractResponseBodySubscriber . onWritePossible thread - safe\n"}
{"diff_id": 8432, "repo": "SeleniumHQ/selenium\n", "sha": "d44e86d74e985c37325eac89d04cebb2737e3f51\n", "time": "2009-06-05T10:06:52Z\n", "diff": "new file mode 100644 <nl> index 00000000000 . . fc7a6142b7e <nl> mmm / dev / null <nl> ppp b / jobbie / src / java / org / openqa / selenium / ie / TimedOutException . java <nl> <nl> + / * <nl> + Copyright 2009 WebDriver committers <nl> + Copyright 2009 Google Inc . <nl> + <nl> + Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> + you may not use this file except in compliance with the License . <nl> + You may obtain a copy of the License at <nl> + <nl> + http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + <nl> + Unless required by applicable law or agreed to in writing , software <nl> + distributed under the License is distributed on an \" AS IS \" BASIS , <nl> + WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + See the License for the specific language governing permissions and <nl> + limitations under the License . <nl> + * / <nl> + <nl> + package org . openqa . selenium . ie ; <nl> + <nl> + / * * <nl> + * Represents an exception in the underlying IE instance , where the command did <nl> + * not complete in enough time <nl> + * / <nl> + public class TimedOutException extends IllegalStateException { <nl> + public TimedOutException ( String message ) { <nl> + super ( message ) ; <nl> + } <nl> + } <nl>\n", "msg": "SimonStewart : Adding the missing file .\n"}
{"diff_id": 8487, "repo": "facebook/fresco\n", "sha": "a1b993277bc92bdc18e496d76f66e1916491ddb2\n", "time": "2017-02-27T14:18:11Z\n", "diff": "mmm a / imagepipeline - base / src / main / java / com / facebook / cache / disk / DiskStorageCache . java <nl> ppp b / imagepipeline - base / src / main / java / com / facebook / cache / disk / DiskStorageCache . java <nl> public void run ( ) { <nl> } else { <nl> mCountDownLatch = new CountDownLatch ( 0 ) ; <nl> } <nl> - <nl> - executorForBackgrountInit . execute ( new Runnable ( ) { <nl> - <nl> - @ Override <nl> - public void run ( ) { <nl> - maybeDeleteSharedPreferencesFile ( context , mStorage . getStorageName ( ) ) ; <nl> - } <nl> - } ) ; <nl> } <nl> <nl> @ Override <nl> private boolean maybeUpdateFileCacheSizeAndIndex ( ) { <nl> mCacheSizeLastUpdateTime = now ; <nl> return true ; <nl> } <nl> - <nl> - / / TODO ( t12287315 ) : Remove the temp method for deleting created Preference in next release <nl> - private static void maybeDeleteSharedPreferencesFile ( <nl> - Context context , <nl> - String directoryName ) { <nl> - try { <nl> - Context applicationContext = context . getApplicationContext ( ) ; <nl> - String path = <nl> - applicationContext . getFilesDir ( ) . getParent ( ) <nl> - + File . separator <nl> - + \" shared_prefs \" <nl> - + File . separator <nl> - + SHARED_PREFS_FILENAME_PREFIX <nl> - + directoryName ; <nl> - File file = new File ( path + \" . xml \" ) ; <nl> - if ( file . exists ( ) ) { <nl> - file . delete ( ) ; <nl> - } <nl> - } catch ( Exception e ) { <nl> - FLog . e ( TAG , \" Fail to delete SharedPreference from file system . \" ) ; <nl> - } <nl> - } <nl> } <nl>\n", "msg": "Remove cleanup of DiskStorageCache ' s index old shared pref file\n"}
{"diff_id": 8522, "repo": "signalapp/Signal-Android\n", "sha": "0a7970ad0cb6afd0f7576716b5cbbe7d00486549\n", "time": "2019-05-22T16:28:02Z\n", "diff": "mmm a / src / org / thoughtcrime / securesms / imageeditor / model / ElementStack . java <nl> ppp b / src / org / thoughtcrime / securesms / imageeditor / model / ElementStack . java <nl> <nl> * < p > <nl> * Elements are mutable , so this stack serializes the element and keeps a stack of serialized data . <nl> * < p > <nl> - * The stack has a { @ link # limit } and if it exceeds that limit during a push the earliest item is removed . <nl> + * The stack has a { @ link # limit } and if it exceeds that limit during a push the second to earliest item <nl> + * is removed so that it can always go back to the first state . Effectively collapsing the history for <nl> + * the start of the stack . <nl> * / <nl> final class ElementStack implements Parcelable { <nl> <nl> private ElementStack ( @ NonNull Parcel in ) { <nl> / * * <nl> * Pushes an element to the stack iff the element ' s serialized value is different to any found at <nl> * the top of the stack . <nl> + * < p > <nl> + * Removes the second to earliest item if it is overflowing . <nl> * <nl> * @ param element new editor element state . <nl> * @ return true iff the pushed item was different to the top item . <nl> boolean tryPush ( @ NonNull EditorElement element ) { <nl> if ( push ) { <nl> stack . push ( bytes ) ; <nl> if ( stack . size ( ) > limit ) { <nl> - stack . remove ( 0 ) ; <nl> + stack . remove ( 1 ) ; <nl> } <nl> } <nl> return push ; <nl>\n", "msg": "Image Editor - Allow undoing back to the original state when exceeds the undo limit .\n"}
{"diff_id": 8525, "repo": "libgdx/libgdx\n", "sha": "9def89f7003f55b4c3807de130da4a3a0abb6f62\n", "time": "2013-05-24T11:39:22Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / scenes / scene2d / ui / ScrollPane . java <nl> ppp b / gdx / src / com / badlogic / gdx / scenes / scene2d / ui / ScrollPane . java <nl> public float getScrollY ( ) { <nl> return amountY ; <nl> } <nl> <nl> + / * * Sets the visual scroll amount equal to the scroll amount . This can be used when setting the scroll amount without animating . * / <nl> + public void updateVisualScroll ( ) { <nl> + visualAmountX = amountX ; <nl> + visualAmountY = amountY ; <nl> + } <nl> + <nl> public float getVisualScrollX ( ) { <nl> return ! scrollX ? 0 : visualAmountX ; <nl> } <nl>\n", "msg": "Added updateVisualScroll for setting scroll position without animating .\n"}
{"diff_id": 8573, "repo": "jenkinsci/jenkins\n", "sha": "6fd24024d0209b399937ab5b5a90a3859e6a760a\n", "time": "2020-02-17T08:35:51Z\n", "diff": "mmm a / test / src / test / java / hudson / UDPBroadcastThreadTest . java <nl> ppp b / test / src / test / java / hudson / UDPBroadcastThreadTest . java <nl> private static void updatePort ( int newValue ) throws Exception { <nl> * Old unicast based clients should still be able to receive some reply , <nl> * as we haven ' t changed the port . <nl> * / <nl> - @ Test public void legacy ( ) throws Exception { <nl> + / / @ Test ignore all the test related to UDP due to failures with Java 11 , whole feature pending complete removal <nl> + public void legacy ( ) throws Exception { <nl> updatePort ( 33848 ) ; <nl> DatagramSocket s = new DatagramSocket ( ) ; <nl> sendQueryTo ( s , InetAddress . getLocalHost ( ) ) ; <nl> public void multicast ( ) throws Exception { <nl> } <nl> } <nl> <nl> - @ Test <nl> + / / @ Test ignore all the test related to UDP due to failures with Java 11 , whole feature pending complete removal <nl> public void ensureTheThreadIsRunningWithSysProp ( ) throws Exception { <nl> UDPBroadcastThread thread = getPrivateThread ( j . jenkins ) ; <nl> assertNotNull ( thread ) ; <nl>\n", "msg": "Disable failing test in UDP broadcast\n"}
{"diff_id": 8614, "repo": "bazelbuild/bazel\n", "sha": "9fc3deccaae462b726f29d93934fa95cabc4ff9d\n", "time": "2016-11-17T18:18:34Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / bazel / rules / workspace / MavenServerRule . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / bazel / rules / workspace / MavenServerRule . java <nl> public Metadata getMetadata ( ) { <nl> maven_jar ( <nl> name = \" junit \" , <nl> artifact = \" junit : junit - dep : 4 . 10 \" , <nl> - server = \" my - server \" , <nl> + server = \" my_server \" , <nl> ) <nl> <nl> maven_server ( <nl> - name = \" my - server \" , <nl> + name = \" my_server \" , <nl> url = \" http : / / intranet . mycorp . net \" , <nl> ) <nl> < / pre > <nl> <nl> This specifies that junit should be downloaded from http : / / intranet . mycorp . net using the <nl> authentication information found in ~ / . m2 / settings . xml ( specifically , the settings <nl> - for the server with the id < code > my - server < / code > ) . <nl> + for the server with the id < code > my_server < / code > ) . <nl> <nl> < h4 > Specifying a default server < / h4 > <nl> <nl>\n", "msg": "Correct maven_server rule docs to use valid workspace name\n"}
{"diff_id": 8684, "repo": "apache/flink\n", "sha": "1e61e92f59a2bd713cb7813aad56282d2a826bcb\n", "time": "2011-04-05T19:08:40Z\n", "diff": "mmm a / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / taskmanager / bytebuffered / OutgoingConnection . java <nl> ppp b / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / taskmanager / bytebuffered / OutgoingConnection . java <nl> public void dropAllQueuedEnvelopesForChannel ( ChannelID channelID , boolean source <nl> } <nl> } <nl> } <nl> - <nl> + <nl> / / Recycle buffer outside of queuedEnvelopes monitor , otherwise dead locks might occur <nl> final Iterator < Buffer > it = buffersToRecycle . iterator ( ) ; <nl> - while ( it . hasNext ( ) ) { <nl> + while ( it . hasNext ( ) ) { <nl> it . next ( ) . recycleBuffer ( ) ; <nl> } <nl> } <nl>\n", "msg": "Corrected code style of OutgoingConnection . java\n"}
{"diff_id": 8686, "repo": "google/guava\n", "sha": "a4c2141a9d293cb1227f8c72aa31fed522878886\n", "time": "2014-06-25T20:23:37Z\n", "diff": "mmm a / guava - tests / test / com / google / common / net / HttpHeadersTest . java <nl> ppp b / guava - tests / test / com / google / common / net / HttpHeadersTest . java <nl> static void assertConstantNameMatchesString ( Class < ? > clazz , <nl> * fields , they will cause similar problems , and we may want to switch <nl> * this check to isAccessible ( ) . <nl> * / <nl> - if ( ! field . isSynthetic ( ) ) { <nl> + if ( ! field . isSynthetic ( ) & & field . getType ( ) = = String . class ) { <nl> builder . add ( field ) ; <nl> } <nl> } <nl>\n", "msg": "More strictly restrict when fields are added to the set of relevant fields , only supporting non - synthetic String fields .\n"}
{"diff_id": 8755, "repo": "oracle/graal\n", "sha": "2d4b133262f5121cb20d4a9e8a1334baefefedcb\n", "time": "2015-02-25T20:00:59Z\n", "diff": "mmm a / graal / com . oracle . graal . graph / src / com / oracle / graal / graph / Node . java <nl> ppp b / graal / com . oracle . graal . graph / src / com / oracle / graal / graph / Node . java <nl> void initialize ( Graph newGraph ) { <nl> assert assertTrue ( id = = INITIAL_ID , \" unexpected id : % d \" , id ) ; <nl> this . graph = newGraph ; <nl> newGraph . register ( this ) ; <nl> - this . acceptInputs ( ( n , i ) - > n . updateUsages ( null , i ) ) ; <nl> - this . acceptSuccessors ( ( n , s ) - > n . updatePredecessor ( null , s ) ) ; <nl> + this . acceptInputs ( ( n , i ) - > { <nl> + if ( ! i . isAlive ( ) ) { <nl> + throw new IllegalStateException ( String . format ( \" Input % s of newly created node % s is not alive . \" , i , n ) ) ; <nl> + } <nl> + n . updateUsages ( null , i ) ; <nl> + } ) ; <nl> + this . acceptSuccessors ( ( n , s ) - > { <nl> + if ( ! s . isAlive ( ) ) { <nl> + throw new IllegalStateException ( String . format ( \" Successor % s of newly created node % s is not alive . \" , s , n ) ) ; <nl> + } <nl> + n . updatePredecessor ( null , s ) ; <nl> + } ) ; <nl> } <nl> <nl> public final NodeClass < ? extends Node > getNodeClass ( ) { <nl>\n", "msg": "Improve node error messges when nodes are inserted with non - alive inputs or successors .\n"}
{"diff_id": 8767, "repo": "netty/netty\n", "sha": "5de4b23c7aab674ac6b73bfef1e2fca039065758\n", "time": "2013-11-14T08:33:40Z\n", "diff": "mmm a / codec - http / src / main / java / io / netty / handler / codec / http / HttpObjectDecoder . java <nl> ppp b / codec - http / src / main / java / io / netty / handler / codec / http / HttpObjectDecoder . java <nl> <nl> protected StringBuilder initialValue ( ) { <nl> return new StringBuilder ( 512 ) ; <nl> } <nl> - <nl> - @ Override <nl> - public StringBuilder get ( ) { <nl> - StringBuilder builder = super . get ( ) ; <nl> - builder . setLength ( 0 ) ; <nl> - return builder ; <nl> - } <nl> } ; <nl> <nl> private final int maxInitialLineLength ; <nl> public StringBuilder get ( ) { <nl> private long chunkSize ; <nl> private int headerSize ; <nl> private int contentRead ; <nl> + private StringBuilder sb ; <nl> <nl> / * * <nl> * The internal state of { @ link HttpObjectDecoder } . <nl> private LastHttpContent readTrailingHeaders ( ByteBuf buffer ) { <nl> } <nl> <nl> private StringBuilder readHeader ( ByteBuf buffer ) { <nl> - StringBuilder sb = BUILDERS . get ( ) ; <nl> + StringBuilder sb = builder ( ) ; <nl> int headerSize = this . headerSize ; <nl> <nl> loop : <nl> private static int getChunkSize ( String hex ) { <nl> return Integer . parseInt ( hex , 16 ) ; <nl> } <nl> <nl> - private static StringBuilder readLine ( ByteBuf buffer , int maxLineLength ) { <nl> - StringBuilder sb = BUILDERS . get ( ) ; <nl> + private StringBuilder readLine ( ByteBuf buffer , int maxLineLength ) { <nl> + StringBuilder sb = builder ( ) ; <nl> int lineLength = 0 ; <nl> while ( true ) { <nl> byte nextByte = buffer . readByte ( ) ; <nl> private static int findEndOfString ( CharSequence sb ) { <nl> } <nl> return result ; <nl> } <nl> + <nl> + private StringBuilder builder ( ) { <nl> + if ( sb = = null ) { <nl> + / / Obtain the StringBuilder from the ThreadLocal and store it for later usage . <nl> + / / This minimize the ThreadLocal . get ( ) operations a lot and so eliminate some overhead <nl> + sb = BUILDERS . get ( ) ; <nl> + } <nl> + sb . setLength ( 0 ) ; <nl> + return sb ; <nl> + } <nl> } <nl>\n", "msg": "[ ] Limit the usage of ThreadLocal . get ( ) for performance reasons\n"}
{"diff_id": 8793, "repo": "oracle/graal\n", "sha": "ec6a8229302bdcff28295c1390dabeba741652a7\n", "time": "2020-01-30T12:24:36Z\n", "diff": "mmm a / src / com . oracle . truffle . espresso . jdwp / src / com / oracle / truffle / espresso / jdwp / impl / JDWP . java <nl> ppp b / src / com . oracle . truffle . espresso . jdwp / src / com / oracle / truffle / espresso / jdwp / impl / JDWP . java <nl> static CommandResult createReply ( Packet packet , JDWPContext context ) { <nl> if ( classLoader = = null ) { <nl> return new CommandResult ( reply ) ; <nl> } <nl> - <nl> - / / TODO ( Gregersen ) - we will need all classes for which this classloader was the <nl> - / / initiating loader <nl> - / / tracked by / browse / GR - 19820 <nl> KlassRef [ ] klasses = context . getInitiatedClasses ( classLoader ) ; <nl> <nl> reply . writeInt ( klasses . length ) ; <nl>\n", "msg": "Remove TODO for an issue that turned out to be a non - issue\n"}
{"diff_id": 8796, "repo": "bazelbuild/bazel\n", "sha": "32853238c25c60a7c0bb09378f2951af6301276b\n", "time": "2016-09-12T08:55:04Z\n", "diff": "new file mode 100644 <nl> index 000000000000 . . b9a653a125d8 <nl> mmm / dev / null <nl> ppp b / src / main / java / com / google / devtools / build / lib / remote / ContentDigests . java <nl> <nl> + / / Copyright 2016 The Bazel Authors . All rights reserved . <nl> + / / <nl> + / / Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> + / / you may not use this file except in compliance with the License . <nl> + / / You may obtain a copy of the License at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + / / <nl> + / / Unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the License is distributed on an \" AS IS \" BASIS , <nl> + / / WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + / / See the License for the specific language governing permissions and <nl> + / / limitations under the License . <nl> + <nl> + package com . google . devtools . build . lib . remote ; <nl> + <nl> + import com . google . common . hash . HashCode ; <nl> + import com . google . common . hash . Hashing ; <nl> + import com . google . devtools . build . lib . concurrent . ThreadSafety . ThreadSafe ; <nl> + import com . google . devtools . build . lib . remote . RemoteProtocol . Action ; <nl> + import com . google . devtools . build . lib . remote . RemoteProtocol . ContentDigest ; <nl> + import com . google . devtools . build . lib . vfs . Path ; <nl> + import com . google . protobuf . ByteString ; <nl> + import com . google . protobuf . Message ; <nl> + import java . io . IOException ; <nl> + <nl> + / * * Helper methods relating to computing ContentDigest messages for remote execution . * / <nl> + @ ThreadSafe <nl> + public final class ContentDigests { <nl> + private ContentDigests ( ) { } <nl> + <nl> + public static ContentDigest computeDigest ( byte [ ] blob ) { <nl> + return buildDigest ( Hashing . sha1 ( ) . hashBytes ( blob ) . asBytes ( ) , blob . length ) ; <nl> + } <nl> + <nl> + / / TODO ( olaola ) : cache these in ActionInputFileCache ! <nl> + public static ContentDigest computeDigest ( Path file ) throws IOException { <nl> + return buildDigest ( file . getSHA1Digest ( ) , file . getFileSize ( ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Computes a digest of the given proto message . Currently , we simply rely on message output as <nl> + * bytes , but this implementation relies on the stability of the proto encoding , in particular <nl> + * between different platforms and languages . <nl> + * TODO ( olaola ) : upgrade to a better implementation ! <nl> + * / <nl> + public static ContentDigest computeDigest ( Message message ) { <nl> + return computeDigest ( message . toByteArray ( ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * A special type of ContentDigest that is used only as a remote action cache key . <nl> + * This is a separate type in order to prevent accidentally using other ContentDigests <nl> + * as action keys . <nl> + * / <nl> + public static final class ActionKey { <nl> + private final ContentDigest digest ; <nl> + <nl> + public ContentDigest getDigest ( ) { <nl> + return digest ; <nl> + } <nl> + <nl> + private ActionKey ( ContentDigest digest ) { <nl> + this . digest = digest ; <nl> + } <nl> + } <nl> + <nl> + public static ActionKey computeActionKey ( Action action ) { <nl> + return new ActionKey ( computeDigest ( action ) ) ; <nl> + } <nl> + <nl> + public static ContentDigest buildDigest ( byte [ ] digest , long size ) { <nl> + ContentDigest . Builder b = ContentDigest . newBuilder ( ) ; <nl> + b . setDigest ( ByteString . copyFrom ( digest ) ) . setSizeBytes ( size ) ; <nl> + return b . build ( ) ; <nl> + } <nl> + <nl> + public static String toHexString ( ContentDigest digest ) { <nl> + return HashCode . fromBytes ( digest . getDigest ( ) . toByteArray ( ) ) . toString ( ) ; <nl> + } <nl> + <nl> + public static String toString ( ContentDigest digest ) { <nl> + return \" < digest : \" + toHexString ( digest ) + \" , size : \" + digest . getSizeBytes ( ) + \" bytes > \" ; <nl> + } <nl> + } <nl>\n", "msg": "Adding utility functions to compute ContentDigests for various types ; in\n"}
{"diff_id": 8833, "repo": "google/guava\n", "sha": "5b587abdfa0e513db8a11b7265ce8689d1edf277\n", "time": "2016-01-28T12:40:48Z\n", "diff": "mmm a / guava - testlib / src / com / google / common / collect / testing / features / FeatureUtil . java <nl> ppp b / guava - testlib / src / com / google / common / collect / testing / features / FeatureUtil . java <nl> <nl> import java . lang . annotation . Annotation ; <nl> import java . lang . reflect . AnnotatedElement ; <nl> import java . lang . reflect . Method ; <nl> + import java . util . ArrayDeque ; <nl> import java . util . ArrayList ; <nl> + import java . util . Collections ; <nl> import java . util . HashMap ; <nl> import java . util . LinkedHashSet ; <nl> import java . util . List ; <nl> import java . util . Locale ; <nl> import java . util . Map ; <nl> + import java . util . Queue ; <nl> import java . util . Set ; <nl> <nl> / * * <nl> <nl> * A cache of annotated objects ( typically a Class or Method ) to its <nl> * set of annotations . <nl> * / <nl> - private static Map < AnnotatedElement , Annotation [ ] > annotationCache = <nl> - new HashMap < AnnotatedElement , Annotation [ ] > ( ) ; <nl> + private static Map < AnnotatedElement , List < Annotation > > annotationCache = <nl> + new HashMap < AnnotatedElement , List < Annotation > > ( ) ; <nl> <nl> private static final Map < Class < ? > , TesterRequirements > <nl> classTesterRequirementsCache = <nl> new HashMap < Class < ? > , TesterRequirements > ( ) ; <nl> + <nl> + private static final Map < Method , TesterRequirements > <nl> + methodTesterRequirementsCache = new HashMap < Method , TesterRequirements > ( ) ; <nl> <nl> / * * <nl> * Given a set of features , add to it all the features directly or indirectly <nl> <nl> * @ return the same set of features , expanded with all implied features <nl> * / <nl> public static Set < Feature < ? > > addImpliedFeatures ( Set < Feature < ? > > features ) { <nl> - / / The base case of the recursion is an empty set of features , which will <nl> - / / occur when the previous set contained only simple features . <nl> - if ( ! features . isEmpty ( ) ) { <nl> - features . addAll ( impliedFeatures ( features ) ) ; <nl> + Queue < Feature < ? > > queue = new ArrayDeque < Feature < ? > > ( features ) ; <nl> + while ( ! queue . isEmpty ( ) ) { <nl> + Feature < ? > feature = queue . remove ( ) ; <nl> + for ( Feature < ? > implied : feature . getImpliedFeatures ( ) ) { <nl> + if ( features . add ( implied ) ) { <nl> + queue . add ( implied ) ; <nl> + } <nl> + } <nl> } <nl> return features ; <nl> } <nl> <nl> * @ return the implied set of features <nl> * / <nl> public static Set < Feature < ? > > impliedFeatures ( Set < Feature < ? > > features ) { <nl> - Set < Feature < ? > > implied = new LinkedHashSet < Feature < ? > > ( ) ; <nl> - for ( Feature < ? > feature : features ) { <nl> - implied . addAll ( feature . getImpliedFeatures ( ) ) ; <nl> + Set < Feature < ? > > impliedSet = new LinkedHashSet < Feature < ? > > ( ) ; <nl> + Queue < Feature < ? > > queue = new ArrayDeque < Feature < ? > > ( features ) ; <nl> + while ( ! queue . isEmpty ( ) ) { <nl> + Feature < ? > feature = queue . remove ( ) ; <nl> + for ( Feature < ? > implied : feature . getImpliedFeatures ( ) ) { <nl> + if ( ! features . contains ( implied ) & & impliedSet . add ( implied ) ) { <nl> + queue . add ( implied ) ; <nl> + } <nl> + } <nl> } <nl> - addImpliedFeatures ( implied ) ; <nl> - return implied ; <nl> + return impliedSet ; <nl> } <nl> <nl> / * * <nl> public static TesterRequirements getTesterRequirements ( Class < ? > testerClass ) <nl> * / <nl> public static TesterRequirements getTesterRequirements ( Method testerMethod ) <nl> throws ConflictingRequirementsException { <nl> - return buildTesterRequirements ( testerMethod ) ; <nl> + synchronized ( methodTesterRequirementsCache ) { <nl> + TesterRequirements requirements = methodTesterRequirementsCache . get ( testerMethod ) ; <nl> + if ( requirements = = null ) { <nl> + requirements = buildTesterRequirements ( testerMethod ) ; <nl> + methodTesterRequirementsCache . put ( testerMethod , requirements ) ; <nl> + } <nl> + return requirements ; <nl> + } <nl> } <nl> <nl> / * * <nl> public static TesterRequirements buildDeclaredTesterRequirements ( <nl> * / <nl> public static Iterable < Annotation > getTesterAnnotations ( <nl> AnnotatedElement classOrMethod ) { <nl> - List < Annotation > result = new ArrayList < Annotation > ( ) ; <nl> - <nl> - Annotation [ ] annotations ; <nl> synchronized ( annotationCache ) { <nl> - annotations = annotationCache . get ( classOrMethod ) ; <nl> + List < Annotation > annotations = annotationCache . get ( classOrMethod ) ; <nl> if ( annotations = = null ) { <nl> - annotations = classOrMethod . getDeclaredAnnotations ( ) ; <nl> + annotations = new ArrayList < Annotation > ( ) ; <nl> + for ( Annotation a : classOrMethod . getDeclaredAnnotations ( ) ) { <nl> + if ( a . annotationType ( ) . isAnnotationPresent ( TesterAnnotation . class ) ) { <nl> + annotations . add ( a ) ; <nl> + } <nl> + } <nl> + annotations = Collections . unmodifiableList ( annotations ) ; <nl> annotationCache . put ( classOrMethod , annotations ) ; <nl> } <nl> + return annotations ; <nl> } <nl> - <nl> - for ( Annotation a : annotations ) { <nl> - Class < ? extends Annotation > annotationClass = a . annotationType ( ) ; <nl> - if ( annotationClass . isAnnotationPresent ( TesterAnnotation . class ) ) { <nl> - result . add ( a ) ; <nl> - } <nl> - } <nl> - return result ; <nl> } <nl> <nl> / * * <nl> private static TesterRequirements buildTesterRequirements ( <nl> addImpliedFeatures ( Helpers . < Feature < ? > > copyToSet ( presentFeatures ) ) ; <nl> Set < Feature < ? > > allAbsentFeatures = <nl> addImpliedFeatures ( Helpers . < Feature < ? > > copyToSet ( absentFeatures ) ) ; <nl> - Set < Feature < ? > > conflictingFeatures = <nl> - intersection ( allPresentFeatures , allAbsentFeatures ) ; <nl> - if ( ! conflictingFeatures . isEmpty ( ) ) { <nl> - throw new ConflictingRequirementsException ( \" Annotation explicitly or \" <nl> - + \" implicitly requires one or more features to be both present \" <nl> - + \" and absent . \" , <nl> - conflictingFeatures , testerAnnotation ) ; <nl> + if ( ! Collections . disjoint ( allPresentFeatures , allAbsentFeatures ) ) { <nl> + throw new ConflictingRequirementsException ( <nl> + \" Annotation explicitly or \" <nl> + + \" implicitly requires one or more features to be both present \" <nl> + + \" and absent . \" , <nl> + intersection ( allPresentFeatures , allAbsentFeatures ) , <nl> + testerAnnotation ) ; <nl> } <nl> return new TesterRequirements ( allPresentFeatures , allAbsentFeatures ) ; <nl> } <nl> private static void checkConflict ( <nl> String earlierRequirement , Set < Feature < ? > > earlierFeatures , <nl> String newRequirement , Set < Feature < ? > > newFeatures , <nl> Object source ) throws ConflictingRequirementsException { <nl> - Set < Feature < ? > > conflictingFeatures ; <nl> - conflictingFeatures = intersection ( newFeatures , earlierFeatures ) ; <nl> - if ( ! conflictingFeatures . isEmpty ( ) ) { <nl> + if ( ! Collections . disjoint ( newFeatures , earlierFeatures ) ) { <nl> throw new ConflictingRequirementsException ( String . format ( Locale . ROOT , <nl> \" Annotation requires to be % s features that earlier \" <nl> + \" annotations required to be % s . \" , <nl> newRequirement , earlierRequirement ) , <nl> - conflictingFeatures , source ) ; <nl> + intersection ( newFeatures , earlierFeatures ) , source ) ; <nl> } <nl> } <nl> <nl> private static void checkConflict ( <nl> * Construct a new { @ link java . util . Set } that is the intersection <nl> * of the given sets . <nl> * / <nl> - / / Calls generic varargs method . <nl> - @ SuppressWarnings ( \" unchecked \" ) <nl> public static < T > Set < T > intersection ( <nl> Set < ? extends T > set1 , Set < ? extends T > set2 ) { <nl> - return intersection ( new Set [ ] { set1 , set2 } ) ; <nl> - } <nl> - <nl> - / * * <nl> - * Construct a new { @ link java . util . Set } that is the intersection <nl> - * of all the given sets . <nl> - * @ param sets the sets to intersect <nl> - * @ return the intersection of the sets <nl> - * @ throws java . lang . IllegalArgumentException if there are no sets to <nl> - * intersect <nl> - * / <nl> - public static < T > Set < T > intersection ( Set < ? extends T > . . . sets ) { <nl> - if ( sets . length = = 0 ) { <nl> - throw new IllegalArgumentException ( <nl> - \" Can ' t intersect no sets ; would have to return the universe . \" ) ; <nl> - } <nl> - Set < T > results = Helpers . copyToSet ( sets [ 0 ] ) ; <nl> - for ( int i = 1 ; i < sets . length ; i + + ) { <nl> - Set < ? extends T > set = sets [ i ] ; <nl> - results . retainAll ( set ) ; <nl> - } <nl> - return results ; <nl> + Set < T > result = Helpers . < T > copyToSet ( set1 ) ; <nl> + result . retainAll ( set2 ) ; <nl> + return result ; <nl> } <nl> } <nl>\n", "msg": "Some minor improvements to FeatureUtil in the hope of speeding up c . g . c . collect tests .\n"}
{"diff_id": 8922, "repo": "oracle/graal\n", "sha": "b10f39546532bd8a942d22f7c9e7b3ae0e0a50e6\n", "time": "2013-08-14T12:27:40Z\n", "diff": "mmm a / graal / com . oracle . graal . phases . common / src / com / oracle / graal / phases / common / ConditionalEliminationPhase . java <nl> ppp b / graal / com . oracle . graal . phases . common / src / com / oracle / graal / phases / common / ConditionalEliminationPhase . java <nl> protected void node ( FixedNode node ) { <nl> ResolvedJavaType type = state . getNodeType ( object ) ; <nl> if ( isNull | | ( type ! = null & & checkCast . type ( ) . isAssignableFrom ( type ) ) ) { <nl> boolean nonNull = state . isNonNull ( object ) ; <nl> - ValueAnchorNode anchor = graph . add ( new ValueAnchorNode ( ) ) ; <nl> + GuardingNode replacementAnchor = null ; <nl> + if ( nonNull ) { <nl> + / / Search for valid instanceof anchor . <nl> + for ( InstanceOfNode instanceOfNode : object . usages ( ) . filter ( InstanceOfNode . class ) ) { <nl> + if ( instanceOfNode . type ( ) = = checkCast . type ( ) & & state . trueConditions . containsKey ( instanceOfNode ) ) { <nl> + ValueNode v = state . trueConditions . get ( instanceOfNode ) ; <nl> + if ( v instanceof GuardingNode ) { <nl> + replacementAnchor = ( GuardingNode ) v ; <nl> + } <nl> + } <nl> + } <nl> + } <nl> + ValueAnchorNode anchor = null ; <nl> + if ( replacementAnchor = = null ) { <nl> + anchor = graph . add ( new ValueAnchorNode ( ) ) ; <nl> + replacementAnchor = anchor ; <nl> + } <nl> PiNode piNode ; <nl> if ( isNull ) { <nl> ConstantNode nullObject = ConstantNode . forObject ( null , metaAccessProvider , graph ) ; <nl> - piNode = graph . unique ( new PiNode ( nullObject , StampFactory . forConstant ( nullObject . value , metaAccessProvider ) , anchor ) ) ; <nl> + piNode = graph . unique ( new PiNode ( nullObject , StampFactory . forConstant ( nullObject . value , metaAccessProvider ) , replacementAnchor ) ) ; <nl> } else { <nl> - piNode = graph . unique ( new PiNode ( object , StampFactory . declared ( type , nonNull ) , anchor ) ) ; <nl> + piNode = graph . unique ( new PiNode ( object , StampFactory . declared ( type , nonNull ) , replacementAnchor ) ) ; <nl> } <nl> checkCast . replaceAtUsages ( piNode ) ; <nl> - graph . replaceFixedWithFixed ( checkCast , anchor ) ; <nl> + if ( anchor ! = null ) { <nl> + graph . replaceFixedWithFixed ( checkCast , anchor ) ; <nl> + } else { <nl> + graph . removeFixed ( checkCast ) ; <nl> + } <nl> metricCheckCastRemoved . increment ( ) ; <nl> } <nl> } else if ( node instanceof IfNode ) { <nl>\n", "msg": "Search for correct replacement anchor for eliminated checkcasts in ConditionalEliminationPhase .\n"}
{"diff_id": 8964, "repo": "SeleniumHQ/selenium\n", "sha": "71c3fe8147f74551d0f83161ecc590882669c1e6\n", "time": "2017-03-06T12:06:34Z\n", "diff": "mmm a / java / server / test / org / openqa / grid / common / SeleniumProtocolTest . java <nl> ppp b / java / server / test / org / openqa / grid / common / SeleniumProtocolTest . java <nl> <nl> + / / Licensed to the Software Freedom Conservancy ( SFC ) under one <nl> + / / or more contributor license agreements . See the NOTICE file <nl> + / / distributed with this work for additional information <nl> + / / regarding copyright ownership . The SFC licenses this file <nl> + / / to you under the Apache License , Version 2 . 0 ( the <nl> + / / \" License \" ) ; you may not use this file except in compliance <nl> + / / with the License . You may obtain a copy of the License at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + / / <nl> + / / Unless required by applicable law or agreed to in writing , <nl> + / / software distributed under the License is distributed on an <nl> + / / \" AS IS \" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY <nl> + / / KIND , either express or implied . See the License for the <nl> + / / specific language governing permissions and limitations <nl> + / / under the License . <nl> + <nl> package org . openqa . grid . common ; <nl> <nl> import static org . junit . Assert . assertEquals ; <nl>\n", "msg": "Update copyright header . No logical change .\n"}
{"diff_id": 8985, "repo": "netty/netty\n", "sha": "a25101dd0bb040d340b999dcec48953314202182\n", "time": "2016-11-21T19:11:43Z\n", "diff": "mmm a / transport / src / main / java / io / netty / channel / local / LocalChannel . java <nl> ppp b / transport / src / main / java / io / netty / channel / local / LocalChannel . java <nl> public void run ( ) { <nl> } <nl> <nl> private void releaseInboundBuffers ( ) { <nl> - if ( readInProgress ) { <nl> - return ; <nl> - } <nl> + assert eventLoop ( ) = = null | | eventLoop ( ) . inEventLoop ( ) ; <nl> + readInProgress = false ; <nl> Queue < Object > inboundBuffer = this . inboundBuffer ; <nl> Object msg ; <nl> while ( ( msg = inboundBuffer . poll ( ) ) ! = null ) { <nl>\n", "msg": "Now that LocalChannel # releaseInboundBuffers is only called from the EventLoop ( eb4d317b9d64f3945a209804fec4c3fe695f4f9f ) it should clear readInProgress and drain / release the queue . Otherwise if a read event is pending ( doBeginRead ) was called we may later call channelRead or channelReadComplete after we have closed the channel .\n"}
{"diff_id": 9194, "repo": "apache/shardingsphere\n", "sha": "fac29f5abfbf046a276e71cc8c98ae1a0ee879df\n", "time": "2020-03-23T15:19:36Z\n", "diff": "mmm a / sharding - core / sharding - core - common / src / main / java / org / apache / shardingsphere / core / metadata / ShardingMetaDataLoader . java <nl> ppp b / sharding - core / sharding - core - common / src / main / java / org / apache / shardingsphere / core / metadata / ShardingMetaDataLoader . java <nl> <nl> import java . util . Map . Entry ; <nl> import java . util . Optional ; <nl> import java . util . stream . Collectors ; <nl> + import java . util . concurrent . ExecutionException ; <nl> + import java . util . concurrent . ExecutorService ; <nl> + import java . util . concurrent . Executors ; <nl> + import java . util . concurrent . Future ; <nl> + import java . util . concurrent . TimeUnit ; <nl> + import java . util . concurrent . TimeoutException ; <nl> <nl> / * * <nl> * Sharding meta data loader . <nl> <nl> public final class ShardingMetaDataLoader { <nl> <nl> private static final String LINE_SEPARATOR = System . getProperty ( \" line . separator \" ) ; <nl> - <nl> + <nl> + private static final int CORES = Runtime . getRuntime ( ) . availableProcessors ( ) ; <nl> + <nl> + private static final int FUTURE_GET_TIME_OUT_SEC = 5 ; <nl> + <nl> private final Map < String , DataSource > dataSourceMap ; <nl> <nl> private final ShardingRule shardingRule ; <nl> public TableMetaData load ( final String logicTableName , final DatabaseType databa <nl> } <nl> Map < String , List < DataNode > > dataNodeGroups = tableRule . getDataNodeGroups ( ) ; <nl> Map < String , TableMetaData > actualTableMetaDataMap = new HashMap < > ( dataNodeGroups . size ( ) , 1 ) ; <nl> - / / TODO use multiple threads to load meta data for different data sources <nl> + Map < String , Future < TableMetaData > > tableFutureMap = new HashMap < > ( dataNodeGroups . size ( ) , 1 ) ; <nl> + ExecutorService executorService = Executors . newFixedThreadPool ( Math . min ( CORES * 2 , dataNodeGroups . size ( ) ) ) ; <nl> for ( Entry < String , List < DataNode > > entry : dataNodeGroups . entrySet ( ) ) { <nl> for ( DataNode each : entry . getValue ( ) ) { <nl> - actualTableMetaDataMap . put ( each . getTableName ( ) , TableMetaDataLoader . load ( dataSourceMap . get ( each . getDataSourceName ( ) ) , each . getTableName ( ) , databaseType . getName ( ) ) ) ; <nl> + Future < TableMetaData > futures = executorService . submit ( ( ) - > load ( each , databaseType ) ) ; <nl> + tableFutureMap . put ( each . getTableName ( ) , futures ) ; <nl> } <nl> } <nl> + tableFutureMap . forEach ( ( key , value ) - > { <nl> + try { <nl> + TableMetaData tableMetaData = value . get ( FUTURE_GET_TIME_OUT_SEC , TimeUnit . SECONDS ) ; <nl> + actualTableMetaDataMap . put ( key , tableMetaData ) ; <nl> + } catch ( InterruptedException | ExecutionException | TimeoutException e ) { <nl> + throw new IllegalStateException ( String . format ( \" Error while fetching tableMetaData with key = % s and Value = % s \" , key , value ) , e ) ; <nl> + } <nl> + } ) ; <nl> + executorService . shutdownNow ( ) ; <nl> checkUniformed ( logicTableName , actualTableMetaDataMap ) ; <nl> return actualTableMetaDataMap . values ( ) . iterator ( ) . next ( ) ; <nl> } <nl> + <nl> + private TableMetaData load ( final DataNode dataNode , final DatabaseType databaseType ) { <nl> + try { <nl> + return TableMetaDataLoader . load ( dataSourceMap . get ( dataNode . getDataSourceName ( ) ) , dataNode . getTableName ( ) , databaseType . getName ( ) ) ; <nl> + } catch ( SQLException e ) { <nl> + throw new IllegalStateException ( String . format ( \" SQLException for DataNode = % s and databaseType = % s \" , dataNode , databaseType . getName ( ) ) , e ) ; <nl> + } <nl> + } <nl> <nl> / * * <nl> * Load schema Meta data . <nl>\n", "msg": "Load ShardingMetaDataLoader metadata for different data sources concu  ( )\n"}
{"diff_id": 9274, "repo": "SeleniumHQ/selenium\n", "sha": "eb0055848f218de979975e99a1bb1f863efbf3c5\n", "time": "2009-05-11T19:02:40Z\n", "diff": "mmm a / selenium / src / java / org / openqa / selenium / WebDriverBackedSelenium . java <nl> ppp b / selenium / src / java / org / openqa / selenium / WebDriverBackedSelenium . java <nl> private void stopTimeoutThreadIfExists ( ) { <nl> timeoutThread = null ; <nl> } <nl> } <nl> - <nl> + <nl> + public WebDriver getUnderlyingWebDriver ( ) { <nl> + return driver ; <nl> + } <nl> + <nl> / * * <nl> * Creates a new timeout thread . If exists a previous existing timeout will <nl> * be stopped . <nl> private Object executeScript ( String script , Object . . . args ) { <nl> } <nl> <nl> public void captureEntirePageScreenshot ( String s ) { <nl> - throw new UnsupportedOperationException ( ) ; <nl> + throw new UnsupportedOperationException ( \" captureEntirePageScreenshot \" ) ; <nl> } <nl> <nl> public void addScript ( String arg0 , String arg1 ) { <nl>\n", "msg": "SimonStewart : Adding an obviously missing method for the Selenium emulation : it ' s now possible to get the underlying driver instance back .\n"}
{"diff_id": 9389, "repo": "apache/flink\n", "sha": "60a066abb5509b97915618d4d1a2729acced6e94\n", "time": "2019-11-06T20:42:22Z\n", "diff": "mmm a / flink - runtime / src / test / java / org / apache / flink / runtime / state / heap / CopyOnWriteStateMapTest . java <nl> ppp b / flink - runtime / src / test / java / org / apache / flink / runtime / state / heap / CopyOnWriteStateMapTest . java <nl> <nl> import org . apache . flink . runtime . state . internal . InternalKvState . StateIncrementalVisitor ; <nl> import org . apache . flink . util . TestLogger ; <nl> <nl> + import org . hamcrest . Matchers ; <nl> import org . junit . Assert ; <nl> import org . junit . Test ; <nl> - import org . mockito . Matchers ; <nl> - import org . mockito . Mockito ; <nl> <nl> import java . util . ArrayList ; <nl> import java . util . Arrays ; <nl> public void testCopyOnWriteContracts ( ) { <nl> @ Test <nl> public void testSnapshotRelease ( ) { <nl> final CopyOnWriteStateMap < Integer , Integer , Integer > stateMap = <nl> - Mockito . spy ( new CopyOnWriteStateMap < > ( IntSerializer . INSTANCE ) ) ; <nl> + new CopyOnWriteStateMap < > ( IntSerializer . INSTANCE ) ; <nl> <nl> for ( int i = 0 ; i < 10 ; i + + ) { <nl> stateMap . put ( i , i , i ) ; <nl> public void testSnapshotRelease ( ) { <nl> <nl> CopyOnWriteStateMapSnapshot < Integer , Integer , Integer > snapshot = stateMap . stateSnapshot ( ) ; <nl> Assert . assertFalse ( snapshot . isReleased ( ) ) ; <nl> + Assert . assertThat ( stateMap . getSnapshotVersions ( ) , Matchers . contains ( snapshot . getSnapshotVersion ( ) ) ) ; <nl> <nl> snapshot . release ( ) ; <nl> Assert . assertTrue ( snapshot . isReleased ( ) ) ; <nl> - Mockito . verify ( stateMap , Mockito . times ( 1 ) ) . releaseSnapshot ( Matchers . same ( snapshot ) ) ; <nl> + Assert . assertThat ( stateMap . getSnapshotVersions ( ) , Matchers . empty ( ) ) ; <nl> <nl> / / verify that snapshot will release itself only once <nl> snapshot . release ( ) ; <nl> - Mockito . verify ( stateMap , Mockito . times ( 1 ) ) . releaseSnapshot ( Matchers . same ( snapshot ) ) ; <nl> + Assert . assertThat ( stateMap . getSnapshotVersions ( ) , Matchers . empty ( ) ) ; <nl> } <nl> <nl> @ SuppressWarnings ( \" unchecked \" ) <nl>\n", "msg": "[ hotfix ] [ tests ] Replace mockito - based verification with property verification .\n"}
{"diff_id": 9480, "repo": "jenkinsci/jenkins\n", "sha": "d0f84c2e5314eb1f6448f0aa325e75adbfba020c\n", "time": "2013-11-15T21:32:27Z\n", "diff": "mmm a / core / src / main / java / hudson / Util . java <nl> ppp b / core / src / main / java / hudson / Util . java <nl> <nl> import java . text . NumberFormat ; <nl> import java . text . ParseException ; <nl> import java . util . * ; <nl> + import java . util . concurrent . TimeUnit ; <nl> import java . util . concurrent . atomic . AtomicBoolean ; <nl> import java . util . logging . Level ; <nl> import java . util . logging . Logger ; <nl> private static boolean createSymlinkJava7 ( File baseDir , String targetPath , Strin <nl> Object target = Class . forName ( \" java . nio . file . Paths \" ) . getMethod ( \" get \" , String . class , String [ ] . class ) . invoke ( null , targetPath , new String [ 0 ] ) ; <nl> Class < ? > filesC = Class . forName ( \" java . nio . file . Files \" ) ; <nl> Class < ? > pathC = Class . forName ( \" java . nio . file . Path \" ) ; <nl> - filesC . getMethod ( \" deleteIfExists \" , pathC ) . invoke ( null , path ) ; <nl> + Class < ? > fileAlreadyExistsExceptionC = Class . forName ( \" java . nio . file . FileAlreadyExistsException \" ) ; <nl> + <nl> Object noAttrs = Array . newInstance ( Class . forName ( \" java . nio . file . attribute . FileAttribute \" ) , 0 ) ; <nl> - filesC . getMethod ( \" createSymbolicLink \" , pathC , pathC , noAttrs . getClass ( ) ) . invoke ( null , path , target , noAttrs ) ; <nl> + final int maxNumberOfTries = 4 ; <nl> + final int timeInMillis = 100 ; <nl> + for ( int tryNumber = 1 ; tryNumber < = maxNumberOfTries ; tryNumber + + ) { <nl> + filesC . getMethod ( \" deleteIfExists \" , pathC ) . invoke ( null , path ) ; <nl> + try { <nl> + filesC . getMethod ( \" createSymbolicLink \" , pathC , pathC , noAttrs . getClass ( ) ) . invoke ( null , path , target , noAttrs ) ; <nl> + break ; <nl> + } <nl> + catch ( Exception x ) { <nl> + if ( fileAlreadyExistsExceptionC . isInstance ( x ) ) { <nl> + if ( tryNumber < maxNumberOfTries ) { <nl> + TimeUnit . MILLISECONDS . sleep ( timeInMillis ) ; / / trying to defeat likely ongoing race condition <nl> + continue ; <nl> + } <nl> + LOGGER . warning ( \" symlink FileAlreadyExistsException thrown \" + maxNumberOfTries + \" times = > cannot createSymbolicLink \" ) ; <nl> + } <nl> + throw x ; <nl> + } <nl> + } <nl> return true ; <nl> } catch ( NoSuchMethodException x ) { <nl> return false ; / / fine , Java 6 <nl>\n", "msg": "[ FIXED JENKINS - 20610 ] symlink FileAlreadyExistsException\n"}
{"diff_id": 9513, "repo": "bazelbuild/bazel\n", "sha": "e77b9d93ec64245fc5d343eccbe14b4da40e701c\n", "time": "2018-05-23T15:46:34Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / syntax / Runtime . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / syntax / Runtime . java <nl> public static void setupModuleGlobals ( Environment env , Class < ? > moduleClass ) { <nl> throw new AssertionError ( e ) ; <nl> } <nl> } <nl> - <nl> - / * * <nl> - * Registers global fields with SkylarkSignature into the specified Environment . Alias for <nl> - * { @ link # setupModuleGlobals } . <nl> - * <nl> - * @ deprecated Use { @ link # setupModuleGlobals } instead . <nl> - * / <nl> - @ Deprecated <nl> - / / TODO ( bazel - team ) : Remove after all callers updated . <nl> - public static void registerModuleGlobals ( Environment env , Class < ? > moduleClass ) { <nl> - setupModuleGlobals ( env , moduleClass ) ; <nl> - } <nl> } <nl>\n", "msg": "Remove deprecated method that no longer has any usages .\n"}
{"diff_id": 9522, "repo": "SeleniumHQ/selenium\n", "sha": "dbf998b0851817b6ebf9a466c6d39b4ce1b782ea\n", "time": "2013-05-04T23:19:54Z\n", "diff": "mmm a / java / client / test / org / openqa / selenium / SvgDocumentTest . java <nl> ppp b / java / client / test / org / openqa / selenium / SvgDocumentTest . java <nl> <nl> <nl> package org . openqa . selenium ; <nl> <nl> - import org . junit . Before ; <nl> import org . junit . Test ; <nl> - import org . openqa . selenium . internal . FindsByCssSelector ; <nl> import org . openqa . selenium . testing . Ignore ; <nl> import org . openqa . selenium . testing . JUnit4TestBase ; <nl> <nl> import static org . junit . Assert . assertEquals ; <nl> import static org . junit . Assume . assumeFalse ; <nl> - import static org . junit . Assume . assumeTrue ; <nl> import static org . openqa . selenium . testing . Ignore . Driver . HTMLUNIT ; <nl> - import static org . openqa . selenium . testing . Ignore . Driver . IE ; <nl> import static org . openqa . selenium . testing . Ignore . Driver . OPERA ; <nl> import static org . openqa . selenium . testing . Ignore . Driver . OPERA_MOBILE ; <nl> + import static org . openqa . selenium . testing . Ignore . Driver . SAFARI ; <nl> import static org . openqa . selenium . testing . TestUtilities . isOldIe ; <nl> <nl> - @ Ignore ( value = { HTMLUNIT , OPERA , OPERA_MOBILE } , <nl> - reason = \" HtmlUnit : SVG interaction is only implemented in rendered browsers \" ) <nl> + @ Ignore ( value = { HTMLUNIT , OPERA , OPERA_MOBILE , SAFARI } , <nl> + reason = \" HtmlUnit : SVG interaction is only implemented in rendered browsers ; \" <nl> + + \" Safari : SafariDriver cannot manipulate SVG documents \" ) <nl> public class SvgDocumentTest extends JUnit4TestBase { <nl> <nl> @ Test <nl>\n", "msg": "Skip svg document tests for Safari ; the SafariDriver cannot manipulate manipulate UI elements in a svg document .\n"}
{"diff_id": 9528, "repo": "dbeaver/dbeaver\n", "sha": "de31e2aefbea7ce8c606dc75b077f350a506965b\n", "time": "2020-10-29T16:55:20Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . ui . editors . sql / src / org / jkiss / dbeaver / ui / editors / sql / commands / OpenLinkInWindowHandler . java <nl> ppp b / plugins / org . jkiss . dbeaver . ui . editors . sql / src / org / jkiss / dbeaver / ui / editors / sql / commands / OpenLinkInWindowHandler . java <nl> <nl> import org . eclipse . ui . handlers . HandlerUtil ; <nl> import org . eclipse . ui . menus . UIElement ; <nl> import org . jkiss . dbeaver . runtime . DBWorkbench ; <nl> + import org . jkiss . dbeaver . ui . UIUtils ; <nl> import org . jkiss . dbeaver . ui . editors . sql . SQLEditor ; <nl> import org . jkiss . dbeaver . ui . editors . sql . internal . SQLEditorMessages ; <nl> import org . jkiss . dbeaver . utils . RuntimeUtils ; <nl> <nl> public class OpenLinkInWindowHandler extends AbstractHandler implements IElementUpdater { <nl> <nl> private static final String TITLE = \" Search selection in web \" ; <nl> - private static final String SEARCH_WEB_ADDRESS_PREFIX = \" http : / / www . google . com / search ? q = \" ; <nl> + private static final String SEARCH_WEB_ADDRESS_PREFIX = \" https : / / www . google . com / search ? q = \" ; <nl> <nl> @ Override <nl> public Object execute ( ExecutionEvent event ) throws ExecutionException { <nl> public Object execute ( ExecutionEvent event ) throws ExecutionException { <nl> } <nl> <nl> TextSelection textSelection = ( TextSelection ) selection ; <nl> - / / TODO : how to handle the spaces , handle url generation <nl> - String googleLink = SEARCH_WEB_ADDRESS_PREFIX + textSelection . getText ( ) . replaceAll ( \" \" , \" % 20 \" ) ; <nl> - / / It should not even be possible to use DBeaver on mobile <nl> + String googleLink = SEARCH_WEB_ADDRESS_PREFIX + textSelection . getText ( ) . replaceAll ( \" \" , \" % 20 \" ) . trim ( ) ; <nl> if ( Desktop . isDesktopSupported ( ) & & Desktop . getDesktop ( ) . isSupported ( Desktop . Action . BROWSE ) ) { <nl> - try { <nl> - Desktop . getDesktop ( ) . browse ( new URI ( googleLink ) ) ; <nl> - } catch ( IOException | URISyntaxException e ) { <nl> - DBWorkbench . getPlatformUI ( ) . showError ( TITLE , \" Exception when searching . \" , e ) ; <nl> - } <nl> + UIUtils . launchProgram ( googleLink ) ; <nl> } else { <nl> DBWorkbench . getPlatformUI ( ) . showError ( TITLE , \" Desktop is not supported . \" ) ; <nl> } <nl>\n", "msg": "trim text , use uiutils , use https for google link\n"}
{"diff_id": 9587, "repo": "apache/flink\n", "sha": "13bb32ef891428fe9e0e14b6ecc525f15c52c40a\n", "time": "2018-02-01T12:43:42Z\n", "diff": "mmm a / flink - runtime / src / main / java / org / apache / flink / runtime / checkpoint / CompletedCheckpoint . java <nl> ppp b / flink - runtime / src / main / java / org / apache / flink / runtime / checkpoint / CompletedCheckpoint . java <nl> void setDiscardCallback ( @ Nullable CompletedCheckpointStats . DiscardCallback disca <nl> public String toString ( ) { <nl> return String . format ( \" Checkpoint % d @ % d for % s \" , checkpointID , timestamp , job ) ; <nl> } <nl> - <nl> - @ Override <nl> - public boolean equals ( Object o ) { <nl> - if ( this = = o ) { <nl> - return true ; <nl> - } <nl> - if ( o = = null | | getClass ( ) ! = o . getClass ( ) ) { <nl> - return false ; <nl> - } <nl> - <nl> - CompletedCheckpoint that = ( CompletedCheckpoint ) o ; <nl> - <nl> - return checkpointID = = that . checkpointID & & job . equals ( that . job ) ; <nl> - } <nl> - <nl> - @ Override <nl> - public int hashCode ( ) { <nl> - int result = job . hashCode ( ) ; <nl> - result = 31 * result + ( int ) ( checkpointID ^ ( checkpointID > > > 32 ) ) ; <nl> - return result ; <nl> - } <nl> } <nl>\n", "msg": "[ hotfix ] [ checkpoints ] Drop ill - defined hashCode ( ) and equals ( ) from CompletedCheckpoint .\n"}
{"diff_id": 9921, "repo": "LMAX-Exchange/disruptor\n", "sha": "75d1f7cc692d3791ceca6da39e300eb41f4663e7\n", "time": "2019-03-11T16:09:14Z\n", "diff": "mmm a / src / main / java / com / lmax / disruptor / BatchEventProcessor . java <nl> ppp b / src / main / java / com / lmax / disruptor / BatchEventProcessor . java <nl> private void processEvents ( ) <nl> try <nl> { <nl> final long availableSequence = sequenceBarrier . waitFor ( nextSequence ) ; <nl> - if ( batchStartAware ! = null ) <nl> + if ( batchStartAware ! = null & & availableSequence > = nextSequence ) <nl> { <nl> batchStartAware . onBatchStart ( availableSequence - nextSequence + 1 ) ; <nl> } <nl>\n", "msg": "avoid signalling empty batch to BatchStartAware handler\n"}
{"diff_id": 9960, "repo": "oracle/graal\n", "sha": "e7675df22b52bd6a6986b4f860853b81f90b9909\n", "time": "2018-01-10T10:25:32Z\n", "diff": "mmm a / compiler / src / org . graalvm . compiler . hotspot / src / org / graalvm / compiler / hotspot / replacements / HotSpotReplacementsUtil . java <nl> ppp b / compiler / src / org . graalvm . compiler . hotspot / src / org / graalvm / compiler / hotspot / replacements / HotSpotReplacementsUtil . java <nl> public static Word arrayStart ( int [ ] a ) { <nl> return WordFactory . unsigned ( ComputeObjectAddressNode . get ( a , getArrayBaseOffset ( JavaKind . Int ) ) ) ; <nl> } <nl> <nl> + / * * <nl> + * Idiom for making { @ link GraalHotSpotVMConfig } a constant . <nl> + * / <nl> @ Fold <nl> - public static int objectAlignment ( @ InjectedParameter GraalHotSpotVMConfig config ) { <nl> - return config . objectAlignment ; <nl> + public static GraalHotSpotVMConfig getConfig ( @ InjectedParameter GraalHotSpotVMConfig config ) { <nl> + return config ; <nl> + } <nl> + <nl> + / * * <nl> + * Calls { @ link # arrayAllocationSize ( int , int , int , GraalHotSpotVMConfig ) } using an injected VM <nl> + * configuration object . <nl> + * / <nl> + public static int arrayAllocationSize ( int length , int headerSize , int log2ElementSize ) { <nl> + return arrayAllocationSize ( length , headerSize , log2ElementSize , getConfig ( INJECTED_VMCONFIG ) ) ; <nl> } <nl> <nl> / * * <nl> public static int objectAlignment ( @ InjectedParameter GraalHotSpotVMConfig config <nl> * @ param length the number of elements in the array <nl> * @ param headerSize the size of the array header <nl> * @ param log2ElementSize log2 of the size of an element in the array <nl> + * @ param config the VM configuration providing the <nl> + * { @ linkplain GraalHotSpotVMConfig # objectAlignment object alignment requirement } <nl> * @ return the size of the memory chunk <nl> * / <nl> - public static int arrayAllocationSize ( int length , int headerSize , int log2ElementSize ) { <nl> - int alignment = objectAlignment ( INJECTED_VMCONFIG ) ; <nl> + public static int arrayAllocationSize ( int length , int headerSize , int log2ElementSize , GraalHotSpotVMConfig config ) { <nl> + int alignment = config . objectAlignment ; <nl> int size = ( length < < log2ElementSize ) + headerSize + ( alignment - 1 ) ; <nl> int mask = ~ ( alignment - 1 ) ; <nl> return size & mask ; <nl>\n", "msg": "expose array allocation size computation for use wth a non - injected VM config object\n"}
{"diff_id": 10067, "repo": "SeleniumHQ/selenium\n", "sha": "3e7f0d73c7ffda0dc59266f19f7caeda1243397e\n", "time": "2006-11-06T20:22:10Z\n", "diff": "mmm a / server - coreless / src / main / java / org / openqa / selenium / server / browserlaunchers / BrowserLauncherFactory . java <nl> ppp b / server - coreless / src / main / java / org / openqa / selenium / server / browserlaunchers / BrowserLauncherFactory . java <nl> private RuntimeException browserNotSupported ( String browser ) { <nl> } <nl> <nl> private BrowserLauncher createBrowserLauncher ( Class c , String browserStartCommand , String sessionId , SeleneseQueue queue ) { <nl> + try { <nl> try { <nl> BrowserLauncher browserLauncher ; <nl> if ( null = = browserStartCommand ) { <nl> - Constructor ctor = c . getConstructor ( new Class [ ] { int . class , String . class } ) ; <nl> - Object [ ] args = new Object [ ] { new Integer ( server . getPort ( ) ) , sessionId } ; <nl> + Constructor ctor = c . getConstructor ( new Class [ ] { int . class , <nl> + String . class } ) ; <nl> + Object [ ] args = new Object [ ] { new Integer ( server . getPort ( ) ) , <nl> + sessionId } ; <nl> browserLauncher = ( BrowserLauncher ) ctor . newInstance ( args ) ; <nl> } else { <nl> - Constructor ctor = c . getConstructor ( new Class [ ] { int . class , String . class , String . class } ) ; <nl> - Object [ ] args = new Object [ ] { new Integer ( SeleniumServer . getPortDriversShouldContact ( ) ) , sessionId , browserStartCommand } ; <nl> + Constructor ctor = c . getConstructor ( new Class [ ] { int . class , <nl> + String . class , String . class } ) ; <nl> + Object [ ] args = new Object [ ] { <nl> + new Integer ( SeleniumServer <nl> + . getPortDriversShouldContact ( ) ) , sessionId , <nl> + browserStartCommand } ; <nl> browserLauncher = ( BrowserLauncher ) ctor . newInstance ( args ) ; <nl> } <nl> <nl> private BrowserLauncher createBrowserLauncher ( Class c , String browserStartComman <nl> } <nl> <nl> return browserLauncher ; <nl> - } catch ( InvocationTargetException e ) { <nl> - throw new RuntimeException ( \" failed to contruct launcher for \" + browserStartCommand , e . getTargetException ( ) ) ; <nl> - } catch ( Exception e ) { <nl> - throw new RuntimeException ( e ) ; <nl> + } catch ( InvocationTargetException e ) { <nl> + throw e . getTargetException ( ) ; <nl> } <nl> + } catch ( RuntimeException e ) { <nl> + throw e ; <nl> + } catch ( Throwable e ) { <nl> + throw new RuntimeException ( e ) ; <nl> + } <nl> } <nl> } <nl>\n", "msg": "Rethrow InvocationTargetException , because Ant will conceal nested exceptions\n"}
{"diff_id": 10072, "repo": "google/ExoPlayer\n", "sha": "fcd9ec6c23a556cea61ae1c7145471d4e18ed0f7\n", "time": "2014-10-09T20:55:10Z\n", "diff": "mmm a / library / src / main / java / com / google / android / exoplayer / MediaCodecAudioTrackRenderer . java <nl> ppp b / library / src / main / java / com / google / android / exoplayer / MediaCodecAudioTrackRenderer . java <nl> private long durationUsToFrames ( long durationUs ) { <nl> <nl> @ Override <nl> protected void onDisabled ( ) { <nl> - super . onDisabled ( ) ; <nl> - releaseAudioTrack ( ) ; <nl> audioSessionId = 0 ; <nl> + try { <nl> + releaseAudioTrack ( ) ; <nl> + } finally { <nl> + super . onDisabled ( ) ; <nl> + } <nl> } <nl> <nl> @ Override <nl>\n", "msg": "Tweak audio renderer to match dev / dev - hls .\n"}
{"diff_id": 10133, "repo": "redisson/redisson\n", "sha": "c3cdb4f5a8d1988c577c113fd7230c5d4d4c18ff\n", "time": "2018-05-31T12:55:44Z\n", "diff": "mmm a / redisson / src / main / java / org / redisson / RedissonExecutorService . java <nl> ppp b / redisson / src / main / java / org / redisson / RedissonExecutorService . java <nl> <nl> * / <nl> public class RedissonExecutorService implements RScheduledExecutorService { <nl> <nl> - private static final Logger log = LoggerFactory . getLogger ( RedissonExecutorService . class ) ; <nl> + private static final Logger LOGGER = LoggerFactory . getLogger ( RedissonExecutorService . class ) ; <nl> <nl> private static final RemoteInvocationOptions RESULT_OPTIONS = RemoteInvocationOptions . defaults ( ) . noAck ( ) . expectResultWithin ( 1 , TimeUnit . HOURS ) ; <nl> <nl> public void registerWorkers ( final int workers , ExecutorService executor ) { <nl> + \" redis . call ( ' zrem ' , KEYS [ 2 ] , unpack ( expiredTaskIds ) ) ; \" <nl> + \" if retryInterval ~ = false then \" <nl> + \" local startTime = tonumber ( ARGV [ 1 ] ) + tonumber ( retryInterval ) ; \" <nl> + <nl> + \" for i = 1 , # expiredTaskIds , 1 do \" <nl> + \" local name = expiredTaskIds [ i ] ; \" <nl> + \" local scheduledName = expiredTaskIds [ i ] ; \" <nl> public void registerWorkers ( final int workers , ExecutorService executor ) { <nl> + \" if v [ 1 ] = = expiredTaskIds [ i ] then \" <nl> + \" redis . call ( ' publish ' , KEYS [ 3 ] , startTime ) ; \" <nl> + \" end ; \" <nl> - + \" redis . call ( ' rpush ' , KEYS [ 1 ] , name ) ; \" <nl> + <nl> + + \" if redis . call ( ' linsert ' , KEYS [ 1 ] , ' before ' , name , name ) < 1 then \" <nl> + + \" redis . call ( ' rpush ' , KEYS [ 1 ] , name ) ; \" <nl> + + \" else \" <nl> + + \" redis . call ( ' lrem ' , KEYS [ 1 ] , - 1 , name ) ; \" <nl> + + \" end ; \" <nl> + \" end ; \" <nl> + \" else \" <nl> + \" redis . call ( ' rpush ' , KEYS [ 1 ] , unpack ( expiredTaskIds ) ) ; \" <nl> public void registerWorkers ( final int workers , ExecutorService executor ) { <nl> + \" end \" <nl> + \" return nil ; \" , <nl> Arrays . < Object > asList ( requestQueueName , schedulerQueueName , schedulerChannelName , tasksRetryIntervalName ) , <nl> - System . currentTimeMillis ( ) , 100 ) ; <nl> + System . currentTimeMillis ( ) , 50 ) ; <nl> } <nl> } ; <nl> queueTransferService . schedule ( getName ( ) , task ) ; <nl> public void onMessage ( String channel , String id ) { <nl> } <nl> } ) ; <nl> } <nl> - <nl> - private long repeatInterval = 5000 ; <nl> <nl> @ Override <nl> public void execute ( Runnable task ) { <nl>\n", "msg": "ExecutorService task failover implemented . ,\n"}
{"diff_id": 10147, "repo": "SeleniumHQ/selenium\n", "sha": "b92a9a24c1de1709ceb06b6f1476e4a11e6682e1\n", "time": "2012-07-09T15:58:09Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / firefox / FirefoxDriver . java <nl> ppp b / java / client / src / org / openqa / selenium / firefox / FirefoxDriver . java <nl> private static FirefoxProfile extractProfile ( Capabilities capabilities ) { <nl> } <nl> <nl> profile = getProfile ( profile ) ; <nl> + <nl> + if ( capabilities = = null ) { <nl> + return profile ; <nl> + } <nl> <nl> if ( capabilities . getCapability ( SUPPORTS_WEB_STORAGE ) ! = null ) { <nl> Boolean supportsWebStorage = ( Boolean ) capabilities . getCapability ( SUPPORTS_WEB_STORAGE ) ; <nl>\n", "msg": "EranMes on behalf of EmmaSoderberg : Adding null - check to extraction of profile in the Firefox driver\n"}
{"diff_id": 10293, "repo": "google/ExoPlayer\n", "sha": "ee05b60a19ef9bb1e43d9e7d337a41552f3f9f78\n", "time": "2017-12-12T21:25:35Z\n", "diff": "mmm a / library / dash / src / main / java / com / google / android / exoplayer2 / source / dash / DashMediaSource . java <nl> ppp b / library / dash / src / main / java / com / google / android / exoplayer2 / source / dash / DashMediaSource . java <nl> public Long parse ( Uri uri , InputStream inputStream ) throws IOException { <nl> private static final class Iso8601Parser implements ParsingLoadable . Parser < Long > { <nl> <nl> private static final String ISO_8601_FORMAT = \" yyyy - MM - dd ' T ' HH : mm : ss ' Z ' \" ; <nl> - private static final String ISO_8601_FORMAT_2 = \" yyyy - MM - dd ' T ' HH : mm : ssZ \" ; <nl> - private static final String ISO_8601_FORMAT_3 = \" yyyy - MM - dd ' T ' HH : mm : ssZ \" ; <nl> - private static final String ISO_8601_FORMAT_2_REGEX_PATTERN = \" . * [ + \\ \\ - ] \\ \\ d { 2 } : \\ \\ d { 2 } $ \" ; <nl> - private static final String ISO_8601_FORMAT_3_REGEX_PATTERN = \" . * [ + \\ \\ - ] \\ \\ d { 4 } $ \" ; <nl> + private static final String ISO_8601_WITH_OFFSET_FORMAT = \" yyyy - MM - dd ' T ' HH : mm : ssZ \" ; <nl> + private static final String ISO_8601_WITH_OFFSET_FORMAT_REGEX_PATTERN = \" . * [ + \\ \\ - ] \\ \\ d { 2 } : \\ \\ d { 2 } $ \" ; <nl> + private static final String ISO_8601_WITH_OFFSET_FORMAT_REGEX_PATTERN_2 = \" . * [ + \\ \\ - ] \\ \\ d { 4 } $ \" ; <nl> <nl> @ Override <nl> public Long parse ( Uri uri , InputStream inputStream ) throws IOException { <nl> public Long parse ( Uri uri , InputStream inputStream ) throws IOException { <nl> if ( firstLine ! = null ) { <nl> / / determine format pattern <nl> String formatPattern ; <nl> - if ( firstLine . matches ( ISO_8601_FORMAT_2_REGEX_PATTERN ) ) { <nl> - formatPattern = ISO_8601_FORMAT_2 ; <nl> - } else if ( firstLine . matches ( ISO_8601_FORMAT_3_REGEX_PATTERN ) ) { <nl> - formatPattern = ISO_8601_FORMAT_3 ; <nl> + if ( firstLine . matches ( ISO_8601_WITH_OFFSET_FORMAT_REGEX_PATTERN ) ) { <nl> + formatPattern = ISO_8601_WITH_OFFSET_FORMAT ; <nl> + } else if ( firstLine . matches ( ISO_8601_WITH_OFFSET_FORMAT_REGEX_PATTERN_2 ) ) { <nl> + formatPattern = ISO_8601_WITH_OFFSET_FORMAT ; <nl> } else { <nl> formatPattern = ISO_8601_FORMAT ; <nl> } <nl> public Long parse ( Uri uri , InputStream inputStream ) throws IOException { <nl> throw new ParserException ( \" Unable to parse ISO 8601 . Input value is null \" ) ; <nl> } <nl> } <nl> - } <nl> <nl> + } <nl> + <nl> } <nl>\n", "msg": "Iso8601Parser improved to be able to parse timestamp offsets from UTC\n"}
{"diff_id": 10305, "repo": "libgdx/libgdx\n", "sha": "b67b4d0047812b080cab6bcff3f341acb7ef0d45\n", "time": "2010-06-11T13:23:08Z\n", "diff": "mmm a / gdx - backend - android / src / com / badlogic / gdx / backends / android / AndroidFont . java <nl> ppp b / gdx - backend - android / src / com / badlogic / gdx / backends / android / AndroidFont . java <nl> public int getLineHeight ( ) { <nl> / * * <nl> * { @ inheritDoc } <nl> * / <nl> - @ Override <nl> + Rect tmpRect = new Rect ( ) ; <nl> + @ Override <nl> public int getStringWidth ( String text ) <nl> - { <nl> - Rect rect = new Rect ( ) ; <nl> - paint . getTextBounds ( text , 0 , text . length ( ) , rect ) ; <nl> - return rect . width ( ) ; <nl> + { <nl> + paint . getTextBounds ( text , 0 , text . length ( ) , tmpRect ) ; <nl> + return tmpRect . width ( ) ; <nl> } <nl> <nl> - Rect tmpRect = new Rect ( ) ; <nl> / * * <nl> * { @ inheritDoc } <nl> * / <nl>\n", "msg": "[ fixed ] removed temporary object allocation from getStringWidth .\n"}
{"diff_id": 10342, "repo": "bazelbuild/bazel\n", "sha": "6aa1da904d60dc466085a0e1fe16fe2b50190a66\n", "time": "2018-11-30T14:37:29Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / CcLinkParams . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / CcLinkParams . java <nl> public Builder addLinkOpts ( NestedSet < LinkOptions > linkOpts ) { <nl> return this ; <nl> } <nl> <nl> - / * * Adds a collection of linkstamps . * / <nl> - public Builder addLinkstamps ( <nl> - NestedSet < Artifact > linkstamps , NestedSet < Artifact > declaredIncludeSrcs ) { <nl> - for ( Artifact linkstamp : linkstamps ) { <nl> - linkstampsBuilder . add ( new Linkstamp ( linkstamp , declaredIncludeSrcs ) ) ; <nl> - } <nl> - return this ; <nl> - } <nl> - <nl> public Builder addLinkstamps ( NestedSet < Linkstamp > linkstamps ) { <nl> for ( Linkstamp linkstamp : linkstamps ) { <nl> linkstampsBuilder . add ( linkstamp ) ; <nl>\n", "msg": "Deletes unused CcLinkParams . Builder . addLinkstamps method .\n"}
{"diff_id": 10355, "repo": "ReactiveX/RxAndroid\n", "sha": "ecbaa4dbe54a55d69d6af65de1cbed00eb3dd720\n", "time": "2013-11-27T12:04:29Z\n", "diff": "mmm a / src / main / java / rx / android / observables / AndroidObservable . java <nl> ppp b / src / main / java / rx / android / observables / AndroidObservable . java <nl> <nl> * / <nl> package rx . android . observables ; <nl> <nl> + import static org . mockito . Mockito . verify ; <nl> + <nl> + import org . junit . Before ; <nl> + import org . junit . Test ; <nl> + import org . junit . runner . RunWith ; <nl> + import org . mockito . Mock ; <nl> + import org . mockito . MockitoAnnotations ; <nl> + import org . robolectric . Robolectric ; <nl> + import org . robolectric . RobolectricTestRunner ; <nl> + import org . robolectric . annotation . Config ; <nl> import rx . Observable ; <nl> + import rx . Observer ; <nl> import rx . operators . OperationObserveFromAndroidComponent ; <nl> <nl> import android . app . Activity ; <nl> import android . app . Fragment ; <nl> + import android . os . Build ; <nl> + import android . support . v4 . app . FragmentActivity ; <nl> + <nl> <nl> public final class AndroidObservable { <nl> <nl> + private static final boolean USES_SUPPORT_FRAGMENTS ; <nl> + <nl> + static { <nl> + boolean supportFragmentsAvailable = false ; <nl> + try { <nl> + Class . forName ( \" android . support . v4 . app . Fragment \" ) ; <nl> + supportFragmentsAvailable = true ; <nl> + } catch ( ClassNotFoundException e ) { <nl> + } <nl> + USES_SUPPORT_FRAGMENTS = supportFragmentsAvailable ; <nl> + } <nl> + <nl> private AndroidObservable ( ) { } <nl> <nl> + / * * <nl> + * Transforms a source observable to be attached to the given Activity , in such a way that notifications will always <nl> + * arrive on the main UI thread . Currently , this is equivalent to calling < code > observeOn ( AndroidSchedulers . mainThread ( ) ) < / code > , <nl> + * but this behavior may change in the future , so it is encouraged to use this wrapper instead . <nl> + * < p / > <nl> + * You must unsubscribe from the returned observable in < code > onDestroy < / code > to not leak the given Activity . <nl> + * < p / > <nl> + * Ex . : <nl> + * < pre > <nl> + * / / in any Activity <nl> + * mSubscription = fromActivity ( this , Observable . just ( \" value \" ) ) . subscribe ( . . . ) ; <nl> + * / / in onDestroy <nl> + * mSubscription . unsubscribe ( ) ; <nl> + * < / pre > <nl> + * <nl> + * @ param activity the activity in which the source observable will be observed <nl> + * @ param sourceObservable the observable sequence to observe from the given Activity <nl> + * @ param < T > <nl> + * @ return a new observable sequence that will emit notifications on the main UI thread <nl> + * / <nl> public static < T > Observable < T > fromActivity ( Activity activity , Observable < T > sourceObservable ) { <nl> return OperationObserveFromAndroidComponent . observeFromAndroidComponent ( sourceObservable , activity ) ; <nl> } <nl> <nl> - public static < T > Observable < T > fromFragment ( Fragment fragment , Observable < T > sourceObservable ) { <nl> - return OperationObserveFromAndroidComponent . observeFromAndroidComponent ( sourceObservable , fragment ) ; <nl> + / * * <nl> + * Transforms a source observable to be attached to the given fragment , in such a way that notifications will always <nl> + * arrive on the main UI thread . Moreover , it will be guaranteed that no notifications will be delivered to the <nl> + * fragment while it ' s in detached state ( i . e . its host Activity was destroyed . ) In other words , during calls <nl> + * to onNext , you may assume that fragment . getActivity ( ) will never return null . <nl> + * < p / > <nl> + * This method accepts both native fragments and support library fragments in its first parameter . It will throw <nl> + * for unsupported types . <nl> + * < p / > <nl> + * You must unsubscribe from the returned observable in < code > onDestroy < / code > to not leak the given fragment . <nl> + * < p / > <nl> + * Ex . : <nl> + * < pre > <nl> + * / / in any Fragment <nl> + * mSubscription = fromFragment ( this , Observable . just ( \" value \" ) ) . subscribe ( . . . ) ; <nl> + * / / in onDestroy <nl> + * mSubscription . unsubscribe ( ) ; <nl> + * < / pre > <nl> + * <nl> + * @ param fragment the fragment in which the source observable will be observed <nl> + * @ param sourceObservable the observable sequence to observe from the given fragment <nl> + * @ param < T > <nl> + * @ return a new observable sequence that will emit notifications on the main UI thread <nl> + * / <nl> + public static < T > Observable < T > fromFragment ( Object fragment , Observable < T > sourceObservable ) { <nl> + if ( USES_SUPPORT_FRAGMENTS & & fragment instanceof android . support . v4 . app . Fragment ) { <nl> + return OperationObserveFromAndroidComponent . observeFromAndroidComponent ( sourceObservable , ( android . support . v4 . app . Fragment ) fragment ) ; <nl> + } else if ( Build . VERSION . SDK_INT > = Build . VERSION_CODES . HONEYCOMB & & fragment instanceof Fragment ) { <nl> + return OperationObserveFromAndroidComponent . observeFromAndroidComponent ( sourceObservable , ( Fragment ) fragment ) ; <nl> + } else { <nl> + throw new IllegalArgumentException ( \" Target fragment is neither a native nor support library Fragment \" ) ; <nl> + } <nl> } <nl> <nl> - public static < T > Observable < T > fromFragment ( android . support . v4 . app . Fragment fragment , Observable < T > sourceObservable ) { <nl> - return OperationObserveFromAndroidComponent . observeFromAndroidComponent ( sourceObservable , fragment ) ; <nl> + @ RunWith ( RobolectricTestRunner . class ) <nl> + @ Config ( manifest = Config . NONE ) <nl> + public static final class AndroidObservableTest { <nl> + <nl> + / / support library fragments <nl> + private FragmentActivity fragmentActivity ; <nl> + private android . support . v4 . app . Fragment supportFragment ; <nl> + <nl> + / / native fragments <nl> + private Activity activity ; <nl> + private Fragment fragment ; <nl> + <nl> + @ Mock <nl> + private Observer < String > observer ; <nl> + <nl> + @ Before <nl> + public void setup ( ) { <nl> + MockitoAnnotations . initMocks ( this ) ; <nl> + supportFragment = new android . support . v4 . app . Fragment ( ) ; <nl> + fragmentActivity = Robolectric . buildActivity ( FragmentActivity . class ) . create ( ) . get ( ) ; <nl> + fragmentActivity . getSupportFragmentManager ( ) . beginTransaction ( ) . add ( supportFragment , null ) . commit ( ) ; <nl> + <nl> + fragment = new Fragment ( ) ; <nl> + activity = Robolectric . buildActivity ( Activity . class ) . create ( ) . get ( ) ; <nl> + activity . getFragmentManager ( ) . beginTransaction ( ) . add ( fragment , null ) . commit ( ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void itSupportsFragmentsFromTheSupportV4Library ( ) { <nl> + fromFragment ( supportFragment , Observable . just ( \" success \" ) ) . subscribe ( observer ) ; <nl> + verify ( observer ) . onNext ( \" success \" ) ; <nl> + verify ( observer ) . onCompleted ( ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void itSupportsNativeFragments ( ) { <nl> + fromFragment ( fragment , Observable . just ( \" success \" ) ) . subscribe ( observer ) ; <nl> + verify ( observer ) . onNext ( \" success \" ) ; <nl> + verify ( observer ) . onCompleted ( ) ; <nl> + } <nl> + <nl> + @ Test ( expected = IllegalArgumentException . class ) <nl> + public void itThrowsIfObjectPassedIsNotAFragment ( ) { <nl> + fromFragment ( \" not a fragment \" , Observable . never ( ) ) ; <nl> + } <nl> } <nl> <nl> } <nl>\n", "msg": "Use Object as argument type for fromFragment helper\n"}
{"diff_id": 10373, "repo": "google/gson\n", "sha": "1c09e24220471828234fe4e772c00a5668887d87\n", "time": "2011-11-23T09:26:44Z\n", "diff": "mmm a / gson / src / main / java / com / google / gson / GsonBuilder . java <nl> ppp b / gson / src / main / java / com / google / gson / GsonBuilder . java <nl> <nl> * <nl> * @ author Inderjeet Singh <nl> * @ author Joel Leitch <nl> + * @ author Jesse Wilson <nl> * / <nl> public final class GsonBuilder { <nl> private Excluder excluder = Excluder . DEFAULT ; <nl> <nl> public GsonBuilder ( ) { <nl> } <nl> <nl> - / / TODO : nice documentation <nl> - public GsonBuilder registerTypeAdapterFactory ( TypeAdapter . Factory factory ) { <nl> - factories . add ( factory ) ; <nl> - return this ; <nl> - } <nl> - <nl> / * * <nl> * Configures Gson to enable versioning support . <nl> * <nl> public GsonBuilder registerTypeAdapter ( Type type , Object typeAdapter ) { <nl> factories . add ( TreeTypeAdapter . newFactory ( typeToken , typeAdapter ) ) ; <nl> } <nl> if ( typeAdapter instanceof TypeAdapter < ? > ) { <nl> - typeAdapter ( TypeToken . get ( type ) , ( TypeAdapter ) typeAdapter ) ; <nl> + factories . add ( TypeAdapters . newFactory ( TypeToken . get ( type ) , ( TypeAdapter ) typeAdapter ) ) ; <nl> } <nl> return this ; <nl> } <nl> <nl> - / / TODO : inline this method ? <nl> - private < T > GsonBuilder typeAdapter ( TypeToken < T > type , TypeAdapter < T > typeAdapter ) { <nl> - factories . add ( TypeAdapters . newFactory ( type , typeAdapter ) ) ; <nl> + / * * <nl> + * Register a factory for type adapters . Registering a factory is useful when the type <nl> + * adapter needs to be configured based on the type of the field being processed . Gson <nl> + * is designed to handle a large number of factories , so you should consider registering <nl> + * them to be at par with registering an individual type adapter . <nl> + * / <nl> + public GsonBuilder registerTypeAdapterFactory ( TypeAdapter . Factory factory ) { <nl> + factories . add ( factory ) ; <nl> return this ; <nl> } <nl> <nl> public GsonBuilder registerTypeHierarchyAdapter ( Class < ? > baseType , Object typeAd <nl> TreeTypeAdapter . newTypeHierarchyFactory ( baseType , typeAdapter ) ) ; <nl> } <nl> if ( typeAdapter instanceof TypeAdapter < ? > ) { <nl> - typeHierarchyAdapter ( baseType , ( TypeAdapter ) typeAdapter ) ; <nl> + factories . add ( TypeAdapters . newTypeHierarchyFactory ( baseType , ( TypeAdapter ) typeAdapter ) ) ; <nl> } <nl> return this ; <nl> } <nl> <nl> - / / TODO : inline this method ? <nl> - private < T > GsonBuilder typeHierarchyAdapter ( Class < T > type , TypeAdapter < T > typeAdapter ) { <nl> - factories . add ( TypeAdapters . newTypeHierarchyFactory ( type , typeAdapter ) ) ; <nl> - return this ; <nl> - } <nl> - <nl> / * * <nl> * Section 2 . 4 of < a href = \" http : / / www . ietf . org / rfc / rfc4627 . txt \" > JSON specification < / a > disallows <nl> * special double values ( NaN , Infinity , - Infinity ) . However , <nl>\n", "msg": "inlined typeAdapter and typeHierarchyAdapter methods . Added some documentation for registerTypeHierarchyAdapterFactory .\n"}
{"diff_id": 10421, "repo": "netty/netty\n", "sha": "f0181a35ef09bab51467c0eed9d249e91013c27e\n", "time": "2015-01-23T06:11:16Z\n", "diff": "mmm a / codec - http / src / main / java / io / netty / handler / codec / http / ClientCookieDecoder . java <nl> ppp b / codec - http / src / main / java / io / netty / handler / codec / http / ClientCookieDecoder . java <nl> public static Cookie decode ( String header ) { <nl> int newNameStart = i ; <nl> int newNameEnd = i ; <nl> String value , rawValue ; <nl> - boolean first = true ; <nl> <nl> if ( i = = headerLen ) { <nl> value = rawValue = null ; <nl> public static Cookie decode ( String header ) { <nl> / / NAME ; ( no value till ' ; ' ) <nl> newNameEnd = i ; <nl> value = rawValue = null ; <nl> - first = false ; <nl> break keyValLoop ; <nl> } else if ( curChar = = ' = ' ) { <nl> / / NAME = VALUE <nl> public static Cookie decode ( String header ) { <nl> if ( i = = headerLen ) { <nl> / / NAME = ( empty value , i . e . nothing after ' = ' ) <nl> value = rawValue = \" \" ; <nl> - first = false ; <nl> break keyValLoop ; <nl> } <nl> <nl> public static Cookie decode ( String header ) { <nl> value = newValueBuf . toString ( ) ; <nl> / / only need to compute raw value for cookie <nl> / / value which is in first position <nl> - rawValue = first ? header . substring ( rawValueStart , rawValueEnd ) : null ; <nl> - first = false ; <nl> + rawValue = header . substring ( rawValueStart , rawValueEnd ) ; <nl> break keyValLoop ; <nl> } <nl> if ( hadBackslash ) { <nl> public static Cookie decode ( String header ) { <nl> / / only need to compute raw value for <nl> / / cookie value which is in first <nl> / / position <nl> - rawValue = first ? header . substring ( rawValueStart , rawValueEnd ) : null ; <nl> - first = false ; <nl> + rawValue = header . substring ( rawValueStart , rawValueEnd ) ; <nl> break keyValLoop ; <nl> } <nl> newValueBuf . append ( c ) ; <nl> public static Cookie decode ( String header ) { <nl> if ( i = = headerLen ) { <nl> / / NAME ( no value till the end of string ) <nl> newNameEnd = i ; <nl> - first = false ; <nl> value = rawValue = null ; <nl> break ; <nl> } <nl>\n", "msg": "Drop first flag that ' s no longer used\n"}
{"diff_id": 10480, "repo": "spring-projects/spring-boot\n", "sha": "3e7af3ddb8a534e542fb25f5a9a682320d3efca5\n", "time": "2014-01-30T07:00:20Z\n", "diff": "mmm a / spring - boot - tools / spring - boot - loader / src / main / java / org / springframework / boot / loader / jar / JarFile . java <nl> ppp b / spring - boot - tools / spring - boot - loader / src / main / java / org / springframework / boot / loader / jar / JarFile . java <nl> public synchronized JarFile getNestedJarFile ( final ZipEntry ze , <nl> * / <nl> public synchronized JarFile getNestedJarFile ( final JarEntryData sourceEntry , <nl> JarEntryFilter . . . filters ) throws IOException { <nl> - if ( sourceEntry . isDirectory ( ) ) { <nl> - return getNestedJarFileFromDirectoryEntry ( sourceEntry , filters ) ; <nl> + try { <nl> + if ( sourceEntry . isDirectory ( ) ) { <nl> + return getNestedJarFileFromDirectoryEntry ( sourceEntry , filters ) ; <nl> + } <nl> + return getNestedJarFileFromFileEntry ( sourceEntry , filters ) ; <nl> + } <nl> + catch ( IOException ex ) { <nl> + throw new IOException ( \" Unable to open nested jar file ' \" <nl> + + sourceEntry . getName ( ) + \" ' \" , ex ) ; <nl> } <nl> - return getNestedJarFileFromFileEntry ( sourceEntry , filters ) ; <nl> } <nl> <nl> private JarFile getNestedJarFileFromDirectoryEntry ( JarEntryData sourceEntry , <nl>\n", "msg": "Improve exception messages on nested jar failure\n"}
{"diff_id": 10515, "repo": "SeleniumHQ/selenium\n", "sha": "f08134855ba104e827653358c19fd10177803a69\n", "time": "2018-01-19T21:31:09Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / firefox / FirefoxBinary . java <nl> ppp b / java / client / src / org / openqa / selenium / firefox / FirefoxBinary . java <nl> public void startProfile ( FirefoxProfile profile , File profileDir , String . . . comm <nl> startFirefoxProcess ( command ) ; <nl> } <nl> <nl> - protected void startFirefoxProcess ( CommandLine command ) throws IOException { <nl> + protected void startFirefoxProcess ( CommandLine command ) { <nl> process = command ; <nl> command . executeAsync ( ) ; <nl> } <nl> protected String extractAndCheck ( File profileDir , String noFocusSoName , <nl> / * * <nl> * Waits for the process to execute , returning the command output taken from the profile ' s <nl> * execution . <nl> - * <nl> - * @ throws InterruptedException if we are interrupted while waiting for the process to launch <nl> - * @ throws IOException if there is a problem with reading the input stream of the launching <nl> - * process <nl> * / <nl> - public void waitFor ( ) throws InterruptedException , IOException { <nl> + public void waitFor ( ) { <nl> process . waitFor ( ) ; <nl> } <nl> <nl> public void waitFor ( ) throws InterruptedException , IOException { <nl> * execution . <nl> * <nl> * @ param timeout the maximum time to wait in milliseconds <nl> - * @ throws InterruptedException if we are interrupted while waiting for the process to launch <nl> - * @ throws IOException if there is a problem with reading the input stream of the launching <nl> - * process <nl> * / <nl> <nl> - public void waitFor ( long timeout ) throws InterruptedException , IOException { <nl> + public void waitFor ( long timeout ) { <nl> process . waitFor ( timeout ) ; <nl> } <nl> <nl> public void waitFor ( long timeout ) throws InterruptedException , IOException { <nl> * Gets all console output of the binary . Output retrieval is non - destructive and non - blocking . <nl> * <nl> * @ return the console output of the executed binary . <nl> - * @ throws IOException IO exception reading from the output stream of the firefox process <nl> * / <nl> - public String getConsoleOutput ( ) throws IOException { <nl> + public String getConsoleOutput ( ) { <nl> if ( process = = null ) { <nl> return null ; <nl> } <nl>\n", "msg": "Deleting declaration of exceptions that can never be thrown ( they are wrapped to WebDriverException )\n"}
{"diff_id": 10643, "repo": "material-components/material-components-android\n", "sha": "5c83026c176e291157c2cf3ca4cfc9cb76f12820\n", "time": "2020-10-22T23:21:43Z\n", "diff": "mmm a / lib / java / com / google / android / material / floatingactionbutton / ExtendedFloatingActionButton . java <nl> ppp b / lib / java / com / google / android / material / floatingactionbutton / ExtendedFloatingActionButton . java <nl> <nl> <nl> private boolean isExtended = true ; <nl> private boolean isTransforming = false ; <nl> + private boolean animateShowBeforeLayout = false ; <nl> <nl> @ NonNull protected ColorStateList originalTextCsl ; <nl> <nl> public final boolean isExtended ( ) { <nl> return isExtended ; <nl> } <nl> <nl> + / * * <nl> + * Sets whether to enable animation for a call to show { @ link # show } even if the view has not been <nl> + * laid out yet . <nl> + * <nl> + * < p > This may be set to { @ code true } if the button is initially hidden but should animate when <nl> + * later shown . The default is { @ code false } . <nl> + * / <nl> + public void setAnimateShowBeforeLayout ( boolean animateShowBeforeLayout ) { <nl> + this . animateShowBeforeLayout = animateShowBeforeLayout ; <nl> + } <nl> + <nl> @ Override <nl> public void setPaddingRelative ( int start , int top , int end , int bottom ) { <nl> super . setPaddingRelative ( start , top , end , bottom ) ; <nl> public void hide ( @ NonNull OnChangedCallback callback ) { <nl> / * * <nl> * Shows the button . <nl> * <nl> - * < p > This method will animate the button show if the view has already been laid out . <nl> + * < p > This method will animate the button show if the view has already been laid out , or if { @ link <nl> + * # setAnimateShowBeforeLayout } is { @ code true } . <nl> * / <nl> public void show ( ) { <nl> performMotion ( showStrategy , null ) ; <nl> public void show ( ) { <nl> / * * <nl> * Shows the button . <nl> * <nl> - * < p > This method will animate the button show if the view has already been laid out . <nl> + * < p > This method will animate the button show if the view has already been laid out , or if { @ link <nl> + * # setAnimateShowBeforeLayout } is { @ code true } . <nl> * <nl> * @ param callback the callback to notify when this view is shown <nl> * / <nl> private boolean isOrWillBeHidden ( ) { <nl> } <nl> <nl> private boolean shouldAnimateVisibilityChange ( ) { <nl> - return ViewCompat . isLaidOut ( this ) & & ! isInEditMode ( ) ; <nl> + return ( ViewCompat . isLaidOut ( this ) | | ( ! isOrWillBeShown ( ) & & animateShowBeforeLayout ) ) <nl> + & & ! isInEditMode ( ) ; <nl> } <nl> <nl> / * * <nl>\n", "msg": "[ ExtendedFloatingActionButton ] Add support for initial show animation .\n"}
{"diff_id": 10900, "repo": "oracle/graal\n", "sha": "c245cba3293cc3bc6aace3f25ddba9aa8694c072\n", "time": "2017-08-21T19:17:06Z\n", "diff": "mmm a / truffle / src / com . oracle . truffle . api . vm / src / com / oracle / truffle / api / vm / PolyglotContextImpl . java <nl> ppp b / truffle / src / com . oracle . truffle . api . vm / src / com / oracle / truffle / api / vm / PolyglotContextImpl . java <nl> synchronized boolean isActive ( ) { <nl> PolyglotThreadInfo getFirstActiveOtherThread ( boolean includePolyglotThread ) { <nl> assert Thread . holdsLock ( this ) ; <nl> / / send enters and leaves into a lock by setting the lastThread to null . <nl> + this . lastThread = PolyglotThreadInfo . NULL ; <nl> for ( PolyglotThreadInfo otherInfo : threads . values ( ) ) { <nl> if ( ! includePolyglotThread & & otherInfo . isPolyglotThread ( ) ) { <nl> continue ; <nl>\n", "msg": "Reduce probability of races by sending all threads to a lock in getFirstActiveOtherThread .\n"}
{"diff_id": 10926, "repo": "alibaba/fastjson\n", "sha": "3dabad16d9421bf0bf0a631b0e199cf23b38ae63\n", "time": "2020-01-25T12:02:44Z\n", "diff": "mmm a / src / main / java / com / alibaba / fastjson / parser / JSONScanner . java <nl> ppp b / src / main / java / com / alibaba / fastjson / parser / JSONScanner . java <nl> protected void setTimeZone ( char timeZoneFlag , char t0 , char t1 , char t3 , char t4 <nl> } <nl> <nl> if ( calendar . getTimeZone ( ) . getRawOffset ( ) ! = timeZoneOffset ) { <nl> - calendar . setTimeZone ( new SimpleTimeZone ( timeZoneOffset , \" \" + timeZoneOffset ) ) ; <nl> + calendar . setTimeZone ( new SimpleTimeZone ( timeZoneOffset , Integer . toString ( timeZoneOffset ) ) ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "SimpleTimeZone ID : use Integer . toString instead of String concat\n"}
{"diff_id": 11189, "repo": "oracle/graal\n", "sha": "1f895168456d9d15df72954db3713b4f43f1819c\n", "time": "2017-11-01T05:28:17Z\n", "diff": "mmm a / truffle / src / com . oracle . truffle . tools . profiler . test / src / com / oracle / truffle / tools / profiler / test / CPUSamplerTest . java <nl> ppp b / truffle / src / com . oracle . truffle . tools . profiler . test / src / com / oracle / truffle / tools / profiler / test / CPUSamplerTest . java <nl> <nl> <nl> private CPUSampler sampler ; <nl> <nl> + final int executionCount = 1000 ; <nl> + <nl> @ Before <nl> public void setupSampler ( ) { <nl> for ( PolyglotRuntime . Instrument instrument : engine . getRuntime ( ) . getInstruments ( ) . values ( ) ) { <nl> public void testCorrectRootStructure ( ) { <nl> <nl> sampler . setFilter ( NO_INTERNAL_ROOT_TAG_FILTER ) ; <nl> sampler . setCollecting ( true ) ; <nl> - for ( int i = 0 ; i < 10_000 ; i + + ) { <nl> + for ( int i = 0 ; i < executionCount ; i + + ) { <nl> execute ( defaultSourceForSampling ) ; <nl> } <nl> <nl> public void testCorrectRootStructureRecursive ( ) { <nl> <nl> sampler . setFilter ( NO_INTERNAL_ROOT_TAG_FILTER ) ; <nl> sampler . setCollecting ( true ) ; <nl> - for ( int i = 0 ; i < 10_000 ; i + + ) { <nl> + for ( int i = 0 ; i < executionCount ; i + + ) { <nl> execute ( defaultRecursiveSourceForSampling ) ; <nl> } <nl> <nl> public void testCorrectRootStructureRecursive ( ) { <nl> public void testCorrectCallStructure ( ) { <nl> sampler . setFilter ( NO_INTERNAL_CALL_TAG_FILTER ) ; <nl> sampler . setCollecting ( true ) ; <nl> - for ( int i = 0 ; i < 10_000 ; i + + ) { <nl> + for ( int i = 0 ; i < executionCount ; i + + ) { <nl> execute ( defaultSourceForSampling ) ; <nl> } <nl> Collection < CallTreeNode < CPUSampler . HitCounts > > children = sampler . getRootNodes ( ) ; <nl> public void testCorrectCallStructure ( ) { <nl> public void testCorrectCallStructureRecursive ( ) { <nl> sampler . setFilter ( NO_INTERNAL_CALL_TAG_FILTER ) ; <nl> sampler . setCollecting ( true ) ; <nl> - for ( int i = 0 ; i < 10_000 ; i + + ) { <nl> + <nl> + for ( int i = 0 ; i < executionCount ; i + + ) { <nl> execute ( defaultRecursiveSourceForSampling ) ; <nl> } <nl> Collection < CallTreeNode < CPUSampler . HitCounts > > children = sampler . getRootNodes ( ) ; <nl> public void testShadowStackOverflows ( ) { <nl> sampler . setFilter ( NO_INTERNAL_ROOT_TAG_FILTER ) ; <nl> sampler . setStackLimit ( 2 ) ; <nl> sampler . setCollecting ( true ) ; <nl> - for ( int i = 0 ; i < 10_000 ; i + + ) { <nl> + for ( int i = 0 ; i < executionCount ; i + + ) { <nl> execute ( defaultSourceForSampling ) ; <nl> } <nl> Assert . assertTrue ( sampler . hasStackOverflowed ( ) ) ; <nl>\n", "msg": "Reducing number of iterations to speedup tests .\n"}
{"diff_id": 11310, "repo": "apache/flink\n", "sha": "382bf304f042b762dc4b456da7605174de67d741\n", "time": "2014-04-30T14:50:46Z\n", "diff": "mmm a / stratosphere - java / src / main / java / eu / stratosphere / api / java / DataSet . java <nl> ppp b / stratosphere - java / src / main / java / eu / stratosphere / api / java / DataSet . java <nl> public ExecutionEnvironment getExecutionEnvironment ( ) { <nl> * Writes a DataSet as a text file to the specified location . < br / > <nl> * For each element of the DataSet the result of { @ link Object # toString ( ) } is written . <nl> * <nl> - * @ param filePath The path pointing to the location the text file is written to . <nl> + * @ param filePath The path pointing to the location the text file is written to . <nl> + * @ return The DataSink that writes the DataSet . <nl> * <nl> * @ see TextOutputFormat <nl> * / <nl> - public void writeAsText ( String filePath ) { <nl> - output ( new TextOutputFormat < T > ( new Path ( filePath ) ) ) ; <nl> + public DataSink < T > writeAsText ( String filePath ) { <nl> + return output ( new TextOutputFormat < T > ( new Path ( filePath ) ) ) ; <nl> } <nl> <nl> / * * <nl> public void writeAsText ( String filePath ) { <nl> * Tuples are are separated by the default line delimiter { @ link CsvOutputFormat . DEFAULT_LINE_DELIMITER } . <nl> * <nl> * @ param filePath The path pointing to the location the CSV file is written to . <nl> + * @ return The DataSink that writes the DataSet . <nl> * <nl> * @ see Tuple <nl> * @ see CsvOutputFormat <nl> * / <nl> - public void writeAsCsv ( String filePath ) { <nl> - writeAsCsv ( filePath , CsvOutputFormat . DEFAULT_LINE_DELIMITER , CsvOutputFormat . DEFAULT_FIELD_DELIMITER ) ; <nl> + public DataSink < T > writeAsCsv ( String filePath ) { <nl> + return writeAsCsv ( filePath , CsvOutputFormat . DEFAULT_LINE_DELIMITER , CsvOutputFormat . DEFAULT_FIELD_DELIMITER ) ; <nl> } <nl> <nl> / * * <nl> public void writeAsCsv ( String filePath ) { <nl> * @ see Tuple <nl> * @ see CsvOutputFormat <nl> * / <nl> - public void writeAsCsv ( String filePath , String rowDelimiter , String fieldDelimiter ) { <nl> + public DataSink < T > writeAsCsv ( String filePath , String rowDelimiter , String fieldDelimiter ) { <nl> Validate . isTrue ( this . type . isTupleType ( ) , \" The writeAsCsv ( ) method can only be used on data sets of tuples . \" ) ; <nl> - internalWriteAsCsv ( new Path ( filePath ) , rowDelimiter , fieldDelimiter ) ; <nl> + return internalWriteAsCsv ( new Path ( filePath ) , rowDelimiter , fieldDelimiter ) ; <nl> } <nl> <nl> @ SuppressWarnings ( \" unchecked \" ) <nl> - private < X extends Tuple > void internalWriteAsCsv ( Path filePath , String rowDelimiter , String fieldDelimiter ) { <nl> - output ( ( OutputFormat < T > ) new CsvOutputFormat < X > ( filePath , rowDelimiter , fieldDelimiter ) ) ; <nl> + private < X extends Tuple > DataSink < T > internalWriteAsCsv ( Path filePath , String rowDelimiter , String fieldDelimiter ) { <nl> + return output ( ( OutputFormat < T > ) new CsvOutputFormat < X > ( filePath , rowDelimiter , fieldDelimiter ) ) ; <nl> } <nl> <nl> / * * <nl> * Writes a DataSet to the standard output stream ( stdout ) . < br / > <nl> - * For each element of the DataSet the result of { @ link Object # toString ( ) } is written . <nl> + * For each element of the DataSet the result of { @ link Object # toString ( ) } is written . <nl> + * <nl> + * @ return The DataSink that writes the DataSet . <nl> * / <nl> - public void print ( ) { <nl> - output ( new PrintingOutputFormat < T > ( false ) ) ; <nl> + public DataSink < T > print ( ) { <nl> + return output ( new PrintingOutputFormat < T > ( false ) ) ; <nl> } <nl> <nl> / * * <nl> * Writes a DataSet to the standard error stream ( stderr ) . < br / > <nl> * For each element of the DataSet the result of { @ link Object # toString ( ) } is written . <nl> + * <nl> + * @ return The DataSink that writes the DataSet . <nl> * / <nl> - public void printToErr ( ) { <nl> - output ( new PrintingOutputFormat < T > ( true ) ) ; <nl> + public DataSink < T > printToErr ( ) { <nl> + return output ( new PrintingOutputFormat < T > ( true ) ) ; <nl> } <nl> <nl> / * * <nl> public void printToErr ( ) { <nl> * <nl> * @ param outputFormat The FileOutputFormat to write the DataSet . <nl> * @ param filePath The path to the location where the DataSet is written . <nl> + * @ return The DataSink that writes the DataSet . <nl> * <nl> * @ see FileOutputFormat <nl> * / <nl> - public void write ( FileOutputFormat < T > outputFormat , String filePath ) { <nl> + public DataSink < T > write ( FileOutputFormat < T > outputFormat , String filePath ) { <nl> Validate . notNull ( filePath , \" File path must not be null . \" ) ; <nl> Validate . notNull ( outputFormat , \" Output format must not be null . \" ) ; <nl> <nl> outputFormat . setOutputFilePath ( new Path ( filePath ) ) ; <nl> - output ( outputFormat ) ; <nl> + return output ( outputFormat ) ; <nl> } <nl> <nl> / * * <nl> public void write ( FileOutputFormat < T > outputFormat , String filePath ) { <nl> * @ param outputFormat The FileOutputFormat to write the DataSet . <nl> * @ param filePath The path to the location where the DataSet is written . <nl> * @ param writeMode The mode of writing , indicating whether to overwrite existing files . <nl> + * @ return The DataSink that writes the DataSet . <nl> * <nl> * @ see FileOutputFormat <nl> * / <nl> - public void write ( FileOutputFormat < T > outputFormat , String filePath , WriteMode writeMode ) { <nl> + public DataSink < T > write ( FileOutputFormat < T > outputFormat , String filePath , WriteMode writeMode ) { <nl> Validate . notNull ( filePath , \" File path must not be null . \" ) ; <nl> Validate . notNull ( writeMode , \" Write mode must not be null . \" ) ; <nl> Validate . notNull ( outputFormat , \" Output format must not be null . \" ) ; <nl> <nl> outputFormat . setOutputFilePath ( new Path ( filePath ) ) ; <nl> outputFormat . setWriteMode ( writeMode ) ; <nl> - output ( outputFormat ) ; <nl> + return output ( outputFormat ) ; <nl> } <nl> <nl> / * * <nl>\n", "msg": "All sink methods in DataSet return the DataSink object to allow setting parameters .\n"}
{"diff_id": 11548, "repo": "netty/netty\n", "sha": "195d7476d505f26bd34e53e1b391db51b7169773\n", "time": "2016-07-07T04:41:43Z\n", "diff": "mmm a / transport / src / main / java / io / netty / channel / AbstractChannel . java <nl> ppp b / transport / src / main / java / io / netty / channel / AbstractChannel . java <nl> public SocketAddress localAddress ( ) { <nl> return localAddress ; <nl> } <nl> <nl> + / * * <nl> + * @ deprecated no use - case for this . <nl> + * / <nl> + @ Deprecated <nl> protected void invalidateLocalAddress ( ) { <nl> localAddress = null ; <nl> } <nl> public SocketAddress remoteAddress ( ) { <nl> } <nl> <nl> / * * <nl> - * Reset the stored remoteAddress <nl> + * @ deprecated no use - case for this . <nl> * / <nl> + @ Deprecated <nl> protected void invalidateRemoteAddress ( ) { <nl> remoteAddress = null ; <nl> } <nl>\n", "msg": "Deprecate methods in AbstractChannel that have no real usage .\n"}
{"diff_id": 11621, "repo": "SeleniumHQ/selenium\n", "sha": "762c0e91aab60c29d7f92845dd52efc817e41df1\n", "time": "2017-08-08T10:11:57Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / remote / internal / JsonToWebElementConverter . java <nl> ppp b / java / client / src / org / openqa / selenium / remote / internal / JsonToWebElementConverter . java <nl> public Object apply ( Object result ) { <nl> if ( result instanceof Map < ? , ? > ) { <nl> Map < ? , ? > resultAsMap = ( Map < ? , ? > ) result ; <nl> String elementKey = getElementKey ( resultAsMap ) ; <nl> - if ( null ! = elementKey ) { <nl> + if ( null ! = elementKey ) { <nl> RemoteWebElement element = newRemoteWebElement ( ) ; <nl> element . setId ( String . valueOf ( resultAsMap . get ( elementKey ) ) ) ; <nl> return element ; <nl> private RemoteWebElement setOwner ( RemoteWebElement element ) { <nl> } <nl> return element ; <nl> } <nl> - private static String getElementKey ( Map < ? , ? > resultAsMap ) { <nl> + private String getElementKey ( Map < ? , ? > resultAsMap ) { <nl> for ( Dialect d : Dialect . values ( ) ) { <nl> String elementKeyForDialect = d . getEncodedElementKey ( ) ; <nl> if ( resultAsMap . containsKey ( elementKeyForDialect ) ) { <nl>\n", "msg": "No logical changes - removing unused ` static ` and adding whitespace\n"}
{"diff_id": 11742, "repo": "oracle/graal\n", "sha": "a7badb96373ceadeec7ce0487e07fc07c40049bb\n", "time": "2019-05-14T11:39:59Z\n", "diff": "mmm a / wasm / src / com . oracle . truffle . wasm . parser / src / com / oracle / truffle / wasm / parser / binary / BinaryStreamReader . java <nl> ppp b / wasm / src / com . oracle . truffle . wasm . parser / src / com / oracle / truffle / wasm / parser / binary / BinaryStreamReader . java <nl> public int readSignedInt32 ( ) { <nl> shift + = 7 ; <nl> } while ( ( b & 0x80 ) ! = 0 ) ; <nl> <nl> - if ( ( shift < 32 ) & & ( b & 0x40 ) = = 0 ) { <nl> + if ( ( shift < 32 ) & & ( b & 0x40 ) ! = 0 ) { <nl> result | = ( ~ 0 < < shift ) ; <nl> } <nl> return result ; <nl> public int readUnsignedInt32 ( ) { <nl> return result ; <nl> } <nl> <nl> - public float readF32 ( ) { <nl> - int rawBits = read4 ( ) ; <nl> - return Float . intBitsToFloat ( rawBits ) ; <nl> + public int readFloat32 ( ) { <nl> + return read4 ( ) ; <nl> } <nl> <nl> - public double readF64 ( ) { <nl> - long rawBits = read8 ( ) ; <nl> - return Double . longBitsToDouble ( rawBits ) ; <nl> + public long readFloat64 ( ) { <nl> + return read8 ( ) ; <nl> } <nl> <nl> public byte read1 ( ) { <nl>\n", "msg": "parser : fix sign extension in readSignedInt32\n"}
{"diff_id": 11747, "repo": "material-components/material-components-android\n", "sha": "64d2ddce2c303ced0ba528a0f3a7e1d22f56a58e\n", "time": "2018-01-03T19:36:22Z\n", "diff": "mmm a / lib / src / android / support / design / widget / TabLayout . java <nl> ppp b / lib / src / android / support / design / widget / TabLayout . java <nl> public TabView ( Context context ) { <nl> <nl> private void updateBackgroundDrawable ( Context context ) { <nl> if ( mTabBackgroundResId ! = 0 ) { <nl> - this . mBaseBackgroundDrawable = AppCompatResources . getDrawable ( context , mTabBackgroundResId ) ; <nl> + mBaseBackgroundDrawable = AppCompatResources . getDrawable ( context , mTabBackgroundResId ) ; <nl> + if ( mBaseBackgroundDrawable ! = null & & mBaseBackgroundDrawable . isStateful ( ) ) { <nl> + mBaseBackgroundDrawable . setState ( getDrawableState ( ) ) ; <nl> + } <nl> } else { <nl> - this . mBaseBackgroundDrawable = null ; <nl> + mBaseBackgroundDrawable = null ; <nl> } <nl> <nl> Drawable background ; <nl> private void updateBackgroundDrawable ( Context context ) { <nl> background = contentDrawable ; <nl> } <nl> ViewCompat . setBackground ( this , background ) ; <nl> + TabLayout . this . invalidate ( ) ; <nl> } <nl> <nl> / * * <nl> private void drawBackground ( Canvas canvas ) { <nl> } <nl> } <nl> <nl> + @ Override <nl> + protected void drawableStateChanged ( ) { <nl> + super . drawableStateChanged ( ) ; <nl> + boolean changed = false ; <nl> + int [ ] state = getDrawableState ( ) ; <nl> + if ( mBaseBackgroundDrawable ! = null & & mBaseBackgroundDrawable . isStateful ( ) ) { <nl> + changed | = mBaseBackgroundDrawable . setState ( state ) ; <nl> + } <nl> + <nl> + if ( changed ) { <nl> + invalidate ( ) ; <nl> + TabLayout . this . invalidate ( ) ; / / Invalidate TabLayout , which draws mBaseBackgroundDrawable <nl> + } <nl> + } <nl> + <nl> @ Override <nl> public boolean performClick ( ) { <nl> final boolean handled = super . performClick ( ) ; <nl>\n", "msg": "Properly draw tab background state in TabLayout\n"}
{"diff_id": 11868, "repo": "bazelbuild/bazel\n", "sha": "4fe1047e13c7565c419b98ac060e44e63da1a48d\n", "time": "2016-12-01T10:15:23Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / CppCompileActionBuilder . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / CppCompileActionBuilder . java <nl> public CppCompileAction build ( ) { <nl> / / something that uses A ( a header of it ) , we mark A and all of its transitive deps as inputs . <nl> / / We still don ' t need to rebuild A , as none of its inputs have changed , but we do rebuild B <nl> / / now and then the two modules are out of sync . <nl> - / / We also have to disable this for fake C + + compile actions as those currently do a build first <nl> - / / before discovering inputs and thus would not declare their inputs properly . <nl> boolean shouldPruneModules = <nl> shouldScanIncludes <nl> & & useHeaderModules <nl> - & & ! fake <nl> & & ! getActionName ( ) . equals ( CppCompileAction . CPP_MODULE_COMPILE ) ; <nl> if ( useHeaderModules & & ! shouldPruneModules ) { <nl> realMandatoryInputsBuilder . addTransitive ( context . getTransitiveModules ( usePic ) ) ; <nl>\n", "msg": "Re - enable modules pruning for fake compile actions . I think our initial\n"}
{"diff_id": 11884, "repo": "google/ExoPlayer\n", "sha": "e922f834010a8e8fafceca98a2c918ca75b1a1ca\n", "time": "2019-10-30T08:51:57Z\n", "diff": "mmm a / library / ui / src / main / java / com / google / android / exoplayer2 / ui / SubtitlePainter . java <nl> ppp b / library / ui / src / main / java / com / google / android / exoplayer2 / ui / SubtitlePainter . java <nl> private void setupTextLayout ( ) { <nl> int textRight ; <nl> if ( cuePosition ! = Cue . DIMEN_UNSET ) { <nl> int anchorPosition = Math . round ( parentWidth * cuePosition ) + parentLeft ; <nl> - textLeft = cuePositionAnchor = = Cue . ANCHOR_TYPE_END ? anchorPosition - textWidth <nl> - : cuePositionAnchor = = Cue . ANCHOR_TYPE_MIDDLE ? ( anchorPosition * 2 - textWidth ) / 2 <nl> - : anchorPosition ; <nl> + switch ( cuePositionAnchor ) { <nl> + case Cue . ANCHOR_TYPE_END : <nl> + textLeft = anchorPosition - textWidth ; <nl> + break ; <nl> + case Cue . ANCHOR_TYPE_MIDDLE : <nl> + textLeft = ( anchorPosition * 2 - textWidth ) / 2 ; <nl> + break ; <nl> + case Cue . ANCHOR_TYPE_START : <nl> + case Cue . TYPE_UNSET : <nl> + default : <nl> + textLeft = anchorPosition ; <nl> + } <nl> + <nl> textLeft = Math . max ( textLeft , parentLeft ) ; <nl> textRight = Math . min ( textLeft + textWidth , parentRight ) ; <nl> } else { <nl>\n", "msg": "Change nested ternary to switch in SubtitlePainter\n"}
{"diff_id": 11993, "repo": "elastic/elasticsearch\n", "sha": "d750fa1a2f6c5bdd25ba486ce6a3a589cefb3d2e\n", "time": "2011-12-29T09:43:55Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / index / analysis / IcuAnalysisBinderProcessor . java <nl> ppp b / src / main / java / org / elasticsearch / index / analysis / IcuAnalysisBinderProcessor . java <nl> <nl> <nl> @ Override <nl> public void processTokenizers ( TokenizersBindings tokenizersBindings ) { <nl> - tokenizersBindings . processTokenizer ( \" icuTokenizer \" , IcuTokenizerFactory . class ) ; <nl> tokenizersBindings . processTokenizer ( \" icu_tokenizer \" , IcuTokenizerFactory . class ) ; <nl> } <nl> <nl> @ Override <nl> public void processTokenFilters ( TokenFiltersBindings tokenFiltersBindings ) { <nl> - tokenFiltersBindings . processTokenFilter ( \" icuNormalizer \" , IcuNormalizerTokenFilterFactory . class ) ; <nl> tokenFiltersBindings . processTokenFilter ( \" icu_normalizer \" , IcuNormalizerTokenFilterFactory . class ) ; <nl> - <nl> - tokenFiltersBindings . processTokenFilter ( \" icuFolding \" , IcuFoldingTokenFilterFactory . class ) ; <nl> tokenFiltersBindings . processTokenFilter ( \" icu_folding \" , IcuFoldingTokenFilterFactory . class ) ; <nl> - <nl> - tokenFiltersBindings . processTokenFilter ( \" icuCollation \" , IcuCollationTokenFilterFactory . class ) ; <nl> tokenFiltersBindings . processTokenFilter ( \" icu_collation \" , IcuCollationTokenFilterFactory . class ) ; <nl> - <nl> - tokenFiltersBindings . processTokenFilter ( \" icuTransform \" , IcuTransformTokenFilterFactory . class ) ; <nl> tokenFiltersBindings . processTokenFilter ( \" icu_transform \" , IcuTransformTokenFilterFactory . class ) ; <nl> } <nl> } <nl>\n", "msg": "no need to have both camel case and underscore casing , we handle camelcase from underscore automatically .\n"}
{"diff_id": 12149, "repo": "netty/netty\n", "sha": "33a4a9f8e17e736f82c0a7d8fb0f303b3468db51\n", "time": "2008-09-06T09:04:11Z\n", "diff": "mmm a / src / main / java / org / jboss / netty / bootstrap / ClientBootstrap . java <nl> ppp b / src / main / java / org / jboss / netty / bootstrap / ClientBootstrap . java <nl> public ChannelFuture connect ( final SocketAddress remoteAddress , final SocketAddr <nl> } <nl> } while ( future = = null ) ; <nl> <nl> + pipeline . remove ( \" connector \" ) ; <nl> + <nl> return future ; <nl> } <nl> <nl>\n", "msg": "It ' s more correct to remove the connector handler in ClientBootstrap\n"}
{"diff_id": 12183, "repo": "bazelbuild/bazel\n", "sha": "8b5e2118719058d3784469d2312431dc44106dea\n", "time": "2016-12-02T19:09:12Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / skyframe / SkyframeExecutor . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / SkyframeExecutor . java <nl> protected PerBuildSyscallCache newPerBuildSyscallCache ( int concurrencyLevel ) { <nl> * expensive , and is on the critical path of null builds . <nl> * / <nl> protected final PerBuildSyscallCache getPerBuildSyscallCache ( int concurrencyLevel ) { <nl> - if ( lastConcurrencyLevel = = concurrencyLevel ) { <nl> + if ( perBuildSyscallCache ! = null & & lastConcurrencyLevel = = concurrencyLevel ) { <nl> perBuildSyscallCache . clear ( ) ; <nl> return perBuildSyscallCache ; <nl> } <nl> public abstract void invalidateFilesUnderPathForTesting ( EventHandler eventHandle <nl> for ( AspectValueKey aspectKey : aspectKeys ) { <nl> keys . add ( aspectKey . getSkyKey ( ) ) ; <nl> } <nl> - return buildDriver . evaluate ( keys , keepGoing , numThreads , eventHandler ) ; <nl> + EvaluationResult < ActionLookupValue > result = <nl> + buildDriver . evaluate ( keys , keepGoing , numThreads , eventHandler ) ; <nl> + / / Get rid of any memory retained by the cache - - all loading is done . <nl> + perBuildSyscallCache = null ; <nl> + return result ; <nl> } <nl> <nl> / * * <nl>\n", "msg": "Null out perBuildSyscallCache after analysis is finished to save memory during execution .\n"}
{"diff_id": 12259, "repo": "oracle/graal\n", "sha": "6474ec2a94a0d7d31b737f30674e2a48aee06565\n", "time": "2013-10-03T16:09:21Z\n", "diff": "mmm a / graal / com . oracle . truffle . api . dsl . test / src / com / oracle / truffle / api / dsl / test / ImplicitCastTest . java <nl> ppp b / graal / com . oracle . truffle . api . dsl . test / src / com / oracle / truffle / api / dsl / test / ImplicitCastTest . java <nl> public boolean op2 ( boolean v0 , boolean v1 ) { <nl> public void testImplicitCast2 ( ) { <nl> ImplicitCast2Node node = ImplicitCast2NodeFactory . create ( null , null ) ; <nl> TestRootNode < ImplicitCast2Node > root = new TestRootNode < > ( node ) ; <nl> - Assert . assertEquals ( \" 2 \" , root . getNode ( ) . executeEvaluated ( null , \" 2 \" ) ) ; <nl> - Assert . assertEquals ( true , root . getNode ( ) . executeEvaluated ( null , 1 ) ) ; <nl> - Assert . assertEquals ( \" 1 \" , root . getNode ( ) . executeEvaluated ( null , \" 1 \" ) ) ; <nl> - Assert . assertEquals ( true , root . getNode ( ) . executeEvaluated ( null , 1 ) ) ; <nl> - Assert . assertEquals ( true , root . getNode ( ) . executeEvaluated ( null , true ) ) ; <nl> + Assert . assertEquals ( \" 42 \" , root . getNode ( ) . executeEvaluated ( null , \" 4 \" , \" 2 \" ) ) ; <nl> + Assert . assertEquals ( true , root . getNode ( ) . executeEvaluated ( null , 1 , 1 ) ) ; <nl> + Assert . assertEquals ( \" 42 \" , root . getNode ( ) . executeEvaluated ( null , \" 4 \" , \" 2 \" ) ) ; <nl> + Assert . assertEquals ( true , root . getNode ( ) . executeEvaluated ( null , 1 , 1 ) ) ; <nl> + Assert . assertEquals ( true , root . getNode ( ) . executeEvaluated ( null , true , true ) ) ; <nl> } <nl> <nl> } <nl>\n", "msg": "Truffle - DSL : fixed minor issue in implicit cast tests .\n"}
{"diff_id": 12616, "repo": "oracle/graal\n", "sha": "cea65ebc8158e692855f71bd0561b177b97aa5b8\n", "time": "2013-07-26T17:49:00Z\n", "diff": "mmm a / graal / com . oracle . graal . replacements / src / com / oracle / graal / replacements / nodes / MacroNode . java <nl> ppp b / graal / com . oracle . graal . replacements / src / com / oracle / graal / replacements / nodes / MacroNode . java <nl> public JavaType getReturnType ( ) { <nl> return returnType ; <nl> } <nl> <nl> + / * * <nl> + * Gets a snippet to be used for lowering this macro node . <nl> + * / <nl> @ SuppressWarnings ( \" unused \" ) <nl> protected StructuredGraph getSnippetGraph ( LoweringTool tool ) { <nl> return null ; <nl> } <nl> <nl> + / * * <nl> + * Gets a normal method substitution to be used for lowering this macro node . This is only <nl> + * called if { @ link # getSnippetGraph ( LoweringTool ) } return nulls . <nl> + * / <nl> + protected StructuredGraph getSubstitutionGraph ( LoweringTool tool ) { <nl> + return tool . getReplacements ( ) . getMethodSubstitution ( getTargetMethod ( ) ) ; <nl> + } <nl> + <nl> @ Override <nl> public void lower ( LoweringTool tool , LoweringType loweringType ) { <nl> - StructuredGraph snippetGraph = getSnippetGraph ( tool ) ; <nl> + StructuredGraph replacementGraph = getSnippetGraph ( tool ) ; <nl> + if ( replacementGraph = = null ) { <nl> + replacementGraph = getSubstitutionGraph ( tool ) ; <nl> + } <nl> <nl> InvokeNode invoke = replaceWithInvoke ( ) ; <nl> assert invoke . verify ( ) ; <nl> <nl> - if ( snippetGraph ! = null ) { <nl> - InliningUtil . inline ( invoke , snippetGraph , false ) ; <nl> + if ( replacementGraph ! = null ) { <nl> + InliningUtil . inline ( invoke , replacementGraph , false ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "made it possible for a MacroNode to be lowered via a standard method substitution\n"}
{"diff_id": 12630, "repo": "libgdx/libgdx\n", "sha": "3e6807ea304801bb3ff7028ec64980c455239d86\n", "time": "2014-01-19T20:28:42Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / graphics / glutils / FrameBuffer . java <nl> ppp b / gdx / src / com / badlogic / gdx / graphics / glutils / FrameBuffer . java <nl> public void dispose ( ) { <nl> / * * Makes the frame buffer current so everything gets drawn to it . * / <nl> public void begin ( ) { <nl> Gdx . graphics . getGL20 ( ) . glBindFramebuffer ( GL20 . GL_FRAMEBUFFER , framebufferHandle ) ; <nl> + setFrameBufferViewport ( ) ; <nl> + } <nl> + <nl> + / * * Sets viewport to the dimensions of framebuffer . Called by { @ link # begin ( ) } . * / <nl> + protected void setFrameBufferViewport ( ) { <nl> Gdx . graphics . getGL20 ( ) . glViewport ( 0 , 0 , colorTexture . getWidth ( ) , colorTexture . getHeight ( ) ) ; <nl> } <nl> <nl> / * * Unbinds the framebuffer , all drawing will be performed to the normal framebuffer from here on . * / <nl> public void end ( ) { <nl> Gdx . graphics . getGL20 ( ) . glBindFramebuffer ( GL20 . GL_FRAMEBUFFER , defaultFramebufferHandle ) ; <nl> + setDefaultFrameBufferViewport ( ) ; <nl> + } <nl> + <nl> + / * * Sets viewport to the dimensions of default framebuffer ( window ) . Called by { @ link # end ( ) } . * / <nl> + protected void setDefaultFrameBufferViewport ( ) { <nl> Gdx . graphics . getGL20 ( ) . glViewport ( 0 , 0 , Gdx . graphics . getWidth ( ) , Gdx . graphics . getHeight ( ) ) ; <nl> } <nl> <nl>\n", "msg": "Added finer control over viewport setting on begin / end\n"}
{"diff_id": 12655, "repo": "elastic/elasticsearch\n", "sha": "1bdd84bcb2f12254be374c0a80911dd272632ceb\n", "time": "2015-05-21T12:44:13Z\n", "diff": "new file mode 100644 <nl> index 0000000000000 . . 0fbe3e36e4445 <nl> mmm / dev / null <nl> ppp b / src / test / java / org / elasticsearch / watcher / WatcherF . java <nl> <nl> + / * <nl> + * Copyright Elasticsearch B . V . and / or licensed to Elasticsearch B . V . under one <nl> + * or more contributor license agreements . Licensed under the Elastic License ; <nl> + * you may not use this file except in compliance with the Elastic License . <nl> + * / <nl> + package org . elasticsearch . watcher ; <nl> + <nl> + import org . elasticsearch . bootstrap . ElasticsearchF ; <nl> + import org . elasticsearch . license . plugin . LicensePlugin ; <nl> + <nl> + / * * <nl> + * Main class to easily run Watcher from a IDE . <nl> + * It sets all the options to run the Watcher plugin and access it from Sense , but doesn ' t run with Shield . <nl> + * <nl> + * During startup an error will be printed that the config directory can ' t be found , to fix this : <nl> + * 1 ) Add a config directly to the top level project directory <nl> + * 2 ) or set ` - Des . path . conf = ` to a location where there is a config directory on your machine . <nl> + * / <nl> + public class WatcherF { <nl> + <nl> + public static void main ( String [ ] args ) { <nl> + System . setProperty ( \" es . http . cors . enabled \" , \" true \" ) ; <nl> + System . setProperty ( \" es . script . disable_dynamic \" , \" false \" ) ; <nl> + System . setProperty ( \" es . shield . enabled \" , \" false \" ) ; <nl> + System . setProperty ( \" es . plugins . load_classpath_plugins \" , \" false \" ) ; <nl> + System . setProperty ( \" es . plugin . types \" , WatcherPlugin . class . getName ( ) + \" , \" + LicensePlugin . class . getName ( ) ) ; <nl> + System . setProperty ( \" es . cluster . name \" , WatcherF . class . getSimpleName ( ) ) ; <nl> + <nl> + ElasticsearchF . main ( args ) ; <nl> + } <nl> + <nl> + } <nl>\n", "msg": "test : Add a simple runner that allows to run Watcher from the IDE and work out of the box with Sense .\n"}
{"diff_id": 12904, "repo": "SeleniumHQ/selenium\n", "sha": "45590752873682decab04d0aa227e0d34ecd4b35\n", "time": "2012-06-14T16:27:36Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / firefox / FirefoxDriver . java <nl> ppp b / java / client / src / org / openqa / selenium / firefox / FirefoxDriver . java <nl> <nl> import org . openqa . selenium . logging . LocalLogs ; <nl> import org . openqa . selenium . logging . NeedsLocalLogs ; <nl> import org . openqa . selenium . logging . LoggingPreferences ; <nl> - import org . openqa . selenium . logging . Logs ; <nl> import org . openqa . selenium . remote . Command ; <nl> import org . openqa . selenium . remote . CommandExecutor ; <nl> import org . openqa . selenium . remote . DesiredCapabilities ; <nl>\n", "msg": "SimonStewart : Clean up imports . No logical changes here either .\n"}
{"diff_id": 12961, "repo": "spring-projects/spring-boot\n", "sha": "d1d953819ac9f0c0ece5160b96899030cabda46c\n", "time": "2020-09-12T01:11:47Z\n", "diff": "mmm a / spring - boot - project / spring - boot - autoconfigure / src / main / java / org / springframework / boot / autoconfigure / web / servlet / error / ErrorMvcAutoConfiguration . java <nl> ppp b / spring - boot - project / spring - boot - autoconfigure / src / main / java / org / springframework / boot / autoconfigure / web / servlet / error / ErrorMvcAutoConfiguration . java <nl> public void render ( Map < String , ? > model , HttpServletRequest request , HttpServlet <nl> } <nl> response . setContentType ( TEXT_HTML_UTF8 . toString ( ) ) ; <nl> StringBuilder builder = new StringBuilder ( ) ; <nl> - Date timestamp = ( Date ) model . get ( \" timestamp \" ) ; <nl> + Object timestamp = model . get ( \" timestamp \" ) ; <nl> Object message = model . get ( \" message \" ) ; <nl> Object trace = model . get ( \" trace \" ) ; <nl> if ( response . getContentType ( ) = = null ) { <nl>\n", "msg": "Allow other \" timestamp \" types in MVC error model\n"}
{"diff_id": 12965, "repo": "bumptech/glide\n", "sha": "d2b2742c35ec572b3b683ef6baa9eefcc9326acc\n", "time": "2018-12-19T23:49:00Z\n", "diff": "mmm a / library / src / main / java / com / bumptech / glide / load / engine / Engine . java <nl> ppp b / library / src / main / java / com / bumptech / glide / load / engine / Engine . java <nl> public void shutdown ( ) { <nl> * <nl> * < p > Non - final for mocking . <nl> * / <nl> - public static class LoadStatus { <nl> + public class LoadStatus { <nl> private final EngineJob < ? > engineJob ; <nl> private final ResourceCallback cb ; <nl> <nl> public void shutdown ( ) { <nl> } <nl> <nl> public void cancel ( ) { <nl> - engineJob . removeCallback ( cb ) ; <nl> + / / Acquire the Engine lock so that a new request can ' t get access to a particular EngineJob <nl> + / / just after the EngineJob has been cancelled . Without this lock , we ' d allow new requests <nl> + / / to find the cancelling EngineJob in our Jobs data structure . With this lock , the EngineJob <nl> + / / is both cancelled and removed from Jobs atomically . <nl> + synchronized ( Engine . this ) { <nl> + engineJob . removeCallback ( cb ) ; <nl> + } <nl> } <nl> } <nl> <nl>\n", "msg": "Ensure that EngineJobs are cancelled and removed from Engine ' s Job set atomically .\n"}
{"diff_id": 13031, "repo": "elastic/elasticsearch\n", "sha": "4c7bd71bdf296524105f9b45dc11f0334301ad27\n", "time": "2018-04-10T12:36:13Z\n", "diff": "mmm a / plugin / ml / src / main / java / org / elasticsearch / xpack / ml / job / process / autodetect / AutodetectProcessManager . java <nl> ppp b / plugin / ml / src / main / java / org / elasticsearch / xpack / ml / job / process / autodetect / AutodetectProcessManager . java <nl> public void killProcess ( JobTask jobTask , boolean awaitCompletion , String reason ) <nl> . kill ( ) ; <nl> } else { <nl> / / If the process is missing but the task exists this is most likely <nl> - / / because the job went into the failed state then the node restarted <nl> - / / causing the task to be recreated but the failed process wasn ' t . <nl> - / / We still need to remove the task from the TaskManager ( which <nl> - / / is what the kill would do ) <nl> + / / due to 2 reasons . The first is because the job went into the failed <nl> + / / state then the node restarted causing the task to be recreated <nl> + / / but the failed process wasn ' t . The second is that the job went into <nl> + / / the failed state and the user tries to remove it force - deleting it . <nl> + / / Force - delete issues a kill but the process will not be present <nl> + / / as it is cleaned up already . In both cases , we still need to remove <nl> + / / the task from the TaskManager ( which is what the kill would do ) <nl> logger . trace ( \" [ { } ] Marking job task as completed \" , jobTask . getJobId ( ) ) ; <nl> jobTask . markAsCompleted ( ) ; <nl> } <nl>\n", "msg": "[ ML ] Improve comment on why task is marked completed on kill process\n"}
{"diff_id": 13082, "repo": "oracle/graal\n", "sha": "d89a6710d6ac4af3c6caeea7052fd10766e0a5f1\n", "time": "2015-04-07T00:55:05Z\n", "diff": "mmm a / graal / com . oracle . graal . phases . common / src / com / oracle / graal / phases / common / DominatorConditionalEliminationPhase . java <nl> ppp b / graal / com . oracle . graal . phases . common / src / com / oracle / graal / phases / common / DominatorConditionalEliminationPhase . java <nl> private void processGuard ( GuardNode node , List < Runnable > undoOperations ) { <nl> node . replaceAndDelete ( guard ) ; <nl> } else { <nl> DeoptimizeNode deopt = node . graph ( ) . add ( new DeoptimizeNode ( node . action ( ) , node . reason ( ) ) ) ; <nl> - Block block = nodeToBlock . apply ( node ) ; <nl> - AbstractBeginNode beginNode = block . getBeginNode ( ) ; <nl> + AbstractBeginNode beginNode = ( AbstractBeginNode ) node . getAnchor ( ) ; <nl> FixedNode next = beginNode . next ( ) ; <nl> beginNode . setNext ( deopt ) ; <nl> GraphUtil . killCFG ( next ) ; <nl>\n", "msg": "conditional elimination : use begin node from guard anchor instead of node to block map\n"}
{"diff_id": 13111, "repo": "spring-projects/spring-framework\n", "sha": "801c8ed8ac7640ef733db0274d7352693ea73757\n", "time": "2020-09-15T07:41:14Z\n", "diff": "mmm a / spring - web / src / main / java / org / springframework / http / converter / json / KotlinSerializationJsonHttpMessageConverter . java <nl> ppp b / spring - web / src / main / java / org / springframework / http / converter / json / KotlinSerializationJsonHttpMessageConverter . java <nl> <nl> import kotlinx . serialization . SerializersKt ; <nl> import kotlinx . serialization . json . Json ; <nl> <nl> + import org . springframework . core . GenericTypeResolver ; <nl> import org . springframework . http . HttpInputMessage ; <nl> import org . springframework . http . HttpOutputMessage ; <nl> import org . springframework . http . MediaType ; <nl> <nl> * <nl> * @ author Andreas Ahlenstorf <nl> * @ author Sebastien Deleuze <nl> + * @ author Juergen Hoeller <nl> * @ since 5 . 3 <nl> * / <nl> public class KotlinSerializationJsonHttpMessageConverter extends AbstractGenericHttpMessageConverter < Object > { <nl> <nl> <nl> private final Json json ; <nl> <nl> + <nl> / * * <nl> * Construct a new { @ code KotlinSerializationJsonHttpMessageConverter } with the default configuration . <nl> * / <nl> public KotlinSerializationJsonHttpMessageConverter ( Json json ) { <nl> this . json = json ; <nl> } <nl> <nl> + <nl> @ Override <nl> protected boolean supports ( Class < ? > clazz ) { <nl> try { <nl> - resolve ( clazz ) ; <nl> + serializer ( clazz ) ; <nl> return true ; <nl> } <nl> catch ( Exception ex ) { <nl> protected boolean supports ( Class < ? > clazz ) { <nl> } <nl> <nl> @ Override <nl> - protected Object readInternal ( Class < ? > clazz , HttpInputMessage inputMessage ) throws IOException , HttpMessageNotReadableException { <nl> - return this . read ( clazz , null , inputMessage ) ; <nl> + public final Object read ( Type type , @ Nullable Class < ? > contextClass , HttpInputMessage inputMessage ) <nl> + throws IOException , HttpMessageNotReadableException { <nl> + <nl> + return decode ( serializer ( GenericTypeResolver . resolveType ( type , contextClass ) ) , inputMessage ) ; <nl> } <nl> <nl> @ Override <nl> - public Object read ( Type type , @ Nullable Class < ? > contextClass , HttpInputMessage inputMessage ) throws IOException , HttpMessageNotReadableException { <nl> + protected final Object readInternal ( Class < ? > clazz , HttpInputMessage inputMessage ) <nl> + throws IOException , HttpMessageNotReadableException { <nl> + <nl> + return decode ( serializer ( clazz ) , inputMessage ) ; <nl> + } <nl> + <nl> + private Object decode ( KSerializer < Object > serializer , HttpInputMessage inputMessage ) <nl> + throws IOException , HttpMessageNotReadableException { <nl> + <nl> MediaType contentType = inputMessage . getHeaders ( ) . getContentType ( ) ; <nl> String jsonText = StreamUtils . copyToString ( inputMessage . getBody ( ) , getCharsetToUse ( contentType ) ) ; <nl> try { <nl> / / TODO Use stream based API when available <nl> - return this . json . decodeFromString ( resolve ( type ) , jsonText ) ; <nl> + return this . json . decodeFromString ( serializer , jsonText ) ; <nl> } <nl> catch ( SerializationException ex ) { <nl> throw new HttpMessageNotReadableException ( \" Could not read JSON : \" + ex . getMessage ( ) , ex , inputMessage ) ; <nl> public Object read ( Type type , @ Nullable Class < ? > contextClass , HttpInputMessage <nl> } <nl> <nl> @ Override <nl> - protected void writeInternal ( Object o , HttpOutputMessage outputMessage ) throws HttpMessageNotWritableException { <nl> - try { <nl> - this . writeInternal ( o , o . getClass ( ) , outputMessage ) ; <nl> - } <nl> - catch ( IOException ex ) { <nl> - throw new HttpMessageNotWritableException ( \" Could not write JSON : \" + ex . getMessage ( ) , ex ) ; <nl> - } <nl> + protected final void writeInternal ( Object object , @ Nullable Type type , HttpOutputMessage outputMessage ) <nl> + throws IOException , HttpMessageNotWritableException { <nl> + <nl> + encode ( object , serializer ( type ! = null ? type : object . getClass ( ) ) , outputMessage ) ; <nl> } <nl> <nl> - @ Override <nl> - protected void writeInternal ( Object o , @ Nullable Type type , HttpOutputMessage outputMessage ) throws IOException , HttpMessageNotWritableException { <nl> + private void encode ( Object object , KSerializer < Object > serializer , HttpOutputMessage outputMessage ) <nl> + throws IOException , HttpMessageNotWritableException { <nl> + <nl> try { <nl> - String json = this . json . encodeToString ( resolve ( type ) , o ) ; <nl> + String json = this . json . encodeToString ( serializer , object ) ; <nl> MediaType contentType = outputMessage . getHeaders ( ) . getContentType ( ) ; <nl> outputMessage . getBody ( ) . write ( json . getBytes ( getCharsetToUse ( contentType ) ) ) ; <nl> outputMessage . getBody ( ) . flush ( ) ; <nl> private Charset getCharsetToUse ( @ Nullable MediaType contentType ) { <nl> } <nl> <nl> / * * <nl> - * Tries to find a serializer that can marshall or unmarshall instances of the given type using <nl> - * kotlinx . serialization . If no serializer can be found , an exception is thrown . <nl> - * < p > <nl> - * Resolved serializers are cached and cached results are returned on successive calls . <nl> - * <nl> - * @ param type to find a serializer for . <nl> - * @ return resolved serializer for the given type . <nl> - * @ throws RuntimeException if no serializer supporting the given type can be found . <nl> + * Tries to find a serializer that can marshall or unmarshall instances of the given type <nl> + * using kotlinx . serialization . If no serializer can be found , an exception is thrown . <nl> + * < p > Resolved serializers are cached and cached results are returned on successive calls . <nl> + * @ param type the type to find a serializer for <nl> + * @ return a resolved serializer for the given type <nl> + * @ throws RuntimeException if no serializer supporting the given type can be found <nl> * / <nl> - private KSerializer < Object > resolve ( Type type ) { <nl> + private KSerializer < Object > serializer ( Type type ) { <nl> KSerializer < Object > serializer = serializerCache . get ( type ) ; <nl> if ( serializer = = null ) { <nl> serializer = SerializersKt . serializer ( type ) ; <nl> private Charset getCharsetToUse ( @ Nullable MediaType contentType ) { <nl> } <nl> return serializer ; <nl> } <nl> + <nl> } <nl>\n", "msg": "Revise type resolution for alignment with AbstractJsonHttpMessageConverter\n"}
{"diff_id": 13219, "repo": "oracle/graal\n", "sha": "379e11c0d8f987e0ab47dc7d0bd0d52769e03845\n", "time": "2020-04-27T13:20:00Z\n", "diff": "mmm a / truffle / src / com . oracle . truffle . api / src / com / oracle / truffle / api / nodes / RootNode . java <nl> ppp b / truffle / src / com . oracle . truffle . api / src / com / oracle / truffle / api / nodes / RootNode . java <nl> public static RootNode createConstantNode ( Object constant ) { <nl> return new Constant ( constant ) ; <nl> } <nl> <nl> - final Lock getLazyLock ( ) { <nl> + final ReentrantLock getLazyLock ( ) { <nl> ReentrantLock l = this . lock ; <nl> if ( l = = null ) { <nl> l = initializeLock ( ) ; <nl>\n", "msg": "More precise return type for getLazyLock ( ) .\n"}
{"diff_id": 13551, "repo": "oracle/graal\n", "sha": "e6ae52886ce578dc46bd09d5735c1ef85fb9ad13\n", "time": "2012-05-11T13:17:53Z\n", "diff": "mmm a / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / extended / ReadHubNode . java <nl> ppp b / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / extended / ReadHubNode . java <nl> <nl> import com . oracle . graal . nodes . * ; <nl> import com . oracle . graal . nodes . spi . * ; <nl> import com . oracle . graal . nodes . type . * ; <nl> + import com . oracle . max . cri . ri . * ; <nl> + import com . oracle . max . cri . ri . RiType . * ; <nl> <nl> / / TODO ( chaeubl ) this should be a FloatingNode but Lowering is not possible in that case <nl> - public final class ReadHubNode extends FixedWithNextNode implements Lowerable { <nl> + public final class ReadHubNode extends FixedWithNextNode implements Lowerable , Canonicalizable { <nl> @ Input private ValueNode object ; <nl> <nl> public ValueNode object ( ) { <nl> public ReadHubNode ( ValueNode object ) { <nl> public void lower ( CiLoweringTool tool ) { <nl> tool . getRuntime ( ) . lower ( this , tool ) ; <nl> } <nl> + <nl> + @ Override <nl> + public ValueNode canonical ( CanonicalizerTool tool ) { <nl> + RiResolvedType exactType = object . exactType ( ) ; <nl> + <nl> + if ( exactType = = null & & tool . assumptions ( ) ! = null & & object . declaredType ( ) ! = null ) { <nl> + exactType = object . declaredType ( ) . uniqueConcreteSubtype ( ) ; <nl> + if ( exactType ! = null ) { <nl> + tool . assumptions ( ) . recordConcreteSubtype ( object . declaredType ( ) , exactType ) ; <nl> + } <nl> + } <nl> + if ( exactType ! = null ) { <nl> + return ConstantNode . forCiConstant ( exactType . getEncoding ( Representation . ObjectHub ) , tool . runtime ( ) , graph ( ) ) ; <nl> + } <nl> + return this ; <nl> + } <nl> } <nl>\n", "msg": "use exactType and assumptions to canonicalize ReadHubNode\n"}
{"diff_id": 13593, "repo": "netty/netty\n", "sha": "656d7ca054b8c479235a470617a0e1bd0f60ed0c\n", "time": "2013-04-24T02:28:42Z\n", "diff": "mmm a / common / src / main / java / io / netty / util / NetUtil . java <nl> ppp b / common / src / main / java / io / netty / util / NetUtil . java <nl> <nl> * / <nl> package io . netty . util ; <nl> <nl> + import io . netty . util . internal . PlatformDependent ; <nl> import io . netty . util . internal . logging . InternalLogger ; <nl> import io . netty . util . internal . logging . InternalLoggerFactory ; <nl> <nl> import java . io . BufferedReader ; <nl> import java . io . FileReader ; <nl> - import java . io . IOException ; <nl> import java . net . InetAddress ; <nl> - import java . net . InetSocketAddress ; <nl> import java . net . NetworkInterface ; <nl> - import java . net . ServerSocket ; <nl> - import java . net . Socket ; <nl> import java . net . SocketException ; <nl> import java . util . ArrayList ; <nl> import java . util . Enumeration ; <nl> <nl> private static final InternalLogger logger = InternalLoggerFactory . getInstance ( NetUtil . class ) ; <nl> <nl> static { <nl> - / / Start the process of discovering localhost <nl> - InetAddress localhost ; <nl> + / / Find the first loopback interface available . <nl> + NetworkInterface loopbackIface = null ; <nl> try { <nl> - localhost = InetAddress . getLocalHost ( ) ; <nl> - validateHost ( localhost ) ; <nl> - } catch ( IOException e0 ) { <nl> - / / The default local host names did not work . Try hard - coded IPv4 address . <nl> - try { <nl> - localhost = InetAddress . getByAddress ( new byte [ ] { 127 , 0 , 0 , 1 } ) ; <nl> - validateHost ( localhost ) ; <nl> - } catch ( IOException e1 ) { <nl> - / / The hard - coded IPv4 address did not work . Try hard coded IPv6 address . <nl> - try { <nl> - localhost = InetAddress . getByAddress ( new byte [ ] { 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 } ) ; <nl> - validateHost ( localhost ) ; <nl> - } catch ( IOException e2 ) { <nl> - / / Log all exceptions we caught so far for easier diagnosis . <nl> - logger . warn ( \" Failed to resolve localhost with InetAddress . getLocalHost ( ) : \" , e0 ) ; <nl> - logger . warn ( \" Failed to resolve localhost with InetAddress . getByAddress ( 127 . 0 . 0 . 1 ) : \" , e1 ) ; <nl> - logger . warn ( \" Failed to resolve localhost with InetAddress . getByAddress ( : : 1 ) \" , e2 ) ; <nl> - throw new Error ( \" failed to resolve localhost ; incorrect network configuration ? \" ) ; <nl> + for ( Enumeration < NetworkInterface > ifaces = NetworkInterface . getNetworkInterfaces ( ) ; <nl> + ifaces . hasMoreElements ( ) ; ) { <nl> + <nl> + NetworkInterface iface = ifaces . nextElement ( ) ; <nl> + if ( iface . isLoopback ( ) ) { <nl> + / / Found <nl> + loopbackIface = iface ; <nl> + break ; <nl> } <nl> } <nl> + if ( loopbackIface = = null ) { <nl> + logger . warn ( \" Failed to find the loopback interface \" ) ; <nl> + } <nl> + } catch ( SocketException e ) { <nl> + logger . warn ( \" Failed to find the loopback interface \" , e ) ; <nl> } <nl> <nl> - LOCALHOST = localhost ; <nl> - <nl> - / / Prepare to get the local NetworkInterface <nl> - NetworkInterface loopbackInterface ; <nl> - <nl> - try { <nl> - / / Automatically get the loopback interface <nl> - loopbackInterface = NetworkInterface . getByInetAddress ( LOCALHOST ) ; <nl> - } catch ( SocketException e ) { <nl> - / / No ? Alright . There is a backup ! <nl> - loopbackInterface = null ; <nl> + LOOPBACK_IF = loopbackIface ; <nl> + <nl> + / / Find the localhost address <nl> + InetAddress localhost = null ; <nl> + if ( LOOPBACK_IF ! = null ) { <nl> + logger . debug ( \" Loopback interface : { } \" , LOOPBACK_IF . getDisplayName ( ) ) ; <nl> + for ( Enumeration < InetAddress > addrs = LOOPBACK_IF . getInetAddresses ( ) ; <nl> + addrs . hasMoreElements ( ) ; ) { <nl> + InetAddress a = addrs . nextElement ( ) ; <nl> + if ( localhost = = null ) { <nl> + logger . debug ( \" Loopback address : { } ( primary ) \" , a ) ; <nl> + localhost = a ; <nl> + } else { <nl> + logger . debug ( \" Loopback address : { } \" , a ) ; <nl> + } <nl> + } <nl> } <nl> <nl> - / / Check to see if a network interface was not found <nl> - if ( loopbackInterface = = null ) { <nl> + if ( localhost = = null ) { <nl> + InetAddress localhost6 = null ; <nl> try { <nl> - / / Start iterating over all network interfaces <nl> - for ( Enumeration < NetworkInterface > interfaces = NetworkInterface . getNetworkInterfaces ( ) ; <nl> - interfaces . hasMoreElements ( ) ; ) { <nl> - / / Get the \" next \" interface <nl> - NetworkInterface networkInterface = interfaces . nextElement ( ) ; <nl> - <nl> - / / Check to see if the interface is a loopback interface <nl> - if ( networkInterface . isLoopback ( ) ) { <nl> - / / Phew ! The loopback interface was found . <nl> - loopbackInterface = networkInterface ; <nl> - / / No need to keep iterating <nl> - break ; <nl> + localhost6 = InetAddress . getByAddress ( new byte [ ] { 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 } ) ; <nl> + } catch ( Exception e ) { <nl> + / / We should not get here as long as the length of the address is correct . <nl> + PlatformDependent . throwException ( e ) ; <nl> + } <nl> + <nl> + try { <nl> + if ( NetworkInterface . getByInetAddress ( localhost6 ) ! = null ) { <nl> + logger . debug ( \" Using hard - coded IPv6 localhost address : { } \" , localhost6 ) ; <nl> + localhost = localhost6 ; <nl> + } <nl> + } catch ( Exception e ) { <nl> + / / Ignore <nl> + } finally { <nl> + if ( localhost = = null ) { <nl> + InetAddress localhost4 = null ; <nl> + try { <nl> + localhost4 = InetAddress . getByAddress ( new byte [ ] { 127 , 0 , 0 , 1 } ) ; <nl> + } catch ( Exception e ) { <nl> + / / We should not get here as long as the length of the address is correct . <nl> + PlatformDependent . throwException ( e ) ; <nl> } <nl> + <nl> + logger . debug ( \" Using hard - coded IPv4 localhost address : { } \" , localhost4 ) ; <nl> + localhost = localhost4 ; <nl> } <nl> - } catch ( SocketException e ) { <nl> - / / Nope . Can ' t do anything else , sorry ! <nl> - logger . warn ( \" Failed to enumerate network interfaces \" , e ) ; <nl> } <nl> } <nl> <nl> - / / Set the loopback interface constant <nl> - LOOPBACK_IF = loopbackInterface ; <nl> + LOCALHOST = localhost ; <nl> <nl> int somaxconn = 3072 ; <nl> BufferedReader in = null ; <nl> try { <nl> in = new BufferedReader ( new FileReader ( \" / proc / sys / net / core / somaxconn \" ) ) ; <nl> somaxconn = Integer . parseInt ( in . readLine ( ) ) ; <nl> + logger . debug ( \" / proc / sys / net / core / somaxconn : { } \" , somaxconn ) ; <nl> } catch ( Exception e ) { <nl> / / Failed to get SOMAXCONN <nl> } finally { <nl> <nl> SOMAXCONN = somaxconn ; <nl> } <nl> <nl> - private static void validateHost ( InetAddress host ) throws IOException { <nl> - ServerSocket ss = null ; <nl> - Socket s1 = null ; <nl> - Socket s2 = null ; <nl> - try { <nl> - ss = new ServerSocket ( ) ; <nl> - ss . setReuseAddress ( false ) ; <nl> - ss . bind ( new InetSocketAddress ( host , 0 ) ) ; <nl> - s1 = new Socket ( host , ss . getLocalPort ( ) ) ; <nl> - s2 = ss . accept ( ) ; <nl> - } finally { <nl> - if ( s2 ! = null ) { <nl> - try { <nl> - s2 . close ( ) ; <nl> - } catch ( IOException e ) { <nl> - / / Ignore <nl> - } <nl> - } <nl> - if ( s1 ! = null ) { <nl> - try { <nl> - s1 . close ( ) ; <nl> - } catch ( IOException e ) { <nl> - / / Ignore <nl> - } <nl> - } <nl> - if ( ss ! = null ) { <nl> - try { <nl> - ss . close ( ) ; <nl> - } catch ( IOException e ) { <nl> - / / Ignore <nl> - } <nl> - } <nl> - } <nl> - } <nl> - <nl> / * * <nl> * Creates an byte [ ] based on an ipAddressString . No error handling is <nl> * performed here . <nl> * / <nl> - public static byte [ ] createByteArrayFromIpAddressString ( <nl> - String ipAddressString ) { <nl> + public static byte [ ] createByteArrayFromIpAddressString ( String ipAddressString ) { <nl> <nl> if ( isValidIpV4Address ( ipAddressString ) ) { <nl> - StringTokenizer tokenizer = new StringTokenizer ( ipAddressString , <nl> - \" . \" ) ; <nl> + StringTokenizer tokenizer = new StringTokenizer ( ipAddressString , \" . \" ) ; <nl> String token ; <nl> int tempInt ; <nl> byte [ ] byteAddress = new byte [ 4 ] ; <nl>\n", "msg": "Improve localhost / local interface detection mechanism in NetUtil\n"}
{"diff_id": 13668, "repo": "bazelbuild/bazel\n", "sha": "4037908524325293a44be0d1b1a0060f706243ba\n", "time": "2019-02-01T22:16:53Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / buildtool / ExecutionTool . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / buildtool / ExecutionTool . java <nl> <nl> import com . google . common . base . Predicate ; <nl> import com . google . common . base . Stopwatch ; <nl> import com . google . common . base . Suppliers ; <nl> + import com . google . common . base . Throwables ; <nl> import com . google . common . collect . ImmutableList ; <nl> import com . google . common . collect . ImmutableMap ; <nl> import com . google . common . collect . ImmutableSet ; <nl> void executeBuild ( <nl> . printErrLn ( <nl> env . getRuntime ( ) . getProductName ( ) + \" : Entering directory ` \" + getExecRoot ( ) + \" / ' \" ) ; <nl> } <nl> + <nl> + Throwable catastrophe = null ; <nl> boolean buildCompleted = false ; <nl> try { <nl> for ( ActionContextProvider actionContextProvider : actionContextProviders ) { <nl> void executeBuild ( <nl> } <nl> <nl> Profiler . instance ( ) . markPhase ( ProfilePhase . EXECUTE ) ; <nl> - <nl> builder . buildArtifacts ( <nl> env . getReporter ( ) , <nl> analysisResult . getTopLevelArtifactsToOwnerLabels ( ) . getArtifacts ( ) , <nl> void executeBuild ( <nl> } catch ( BuildFailedException | TestExecException e ) { <nl> buildCompleted = true ; <nl> throw e ; <nl> + } catch ( Error | RuntimeException e ) { <nl> + catastrophe = e ; <nl> } finally { <nl> + / / These may flush logs , which may help if there is a catastrophic failure . <nl> + for ( ActionContextProvider actionContextProvider : actionContextProviders ) { <nl> + actionContextProvider . executionPhaseEnding ( ) ; <nl> + } <nl> + <nl> + / / Handlers process these events and others ( e . g . CommandCompleteEvent ) , even in the event of <nl> + / / a catastrophic failure . Posting these is consistent with other behavior . <nl> + env . getEventBus ( ) <nl> + . post ( <nl> + new ExecutionFinishedEvent ( <nl> + ImmutableMap . of ( ) , <nl> + 0L , <nl> + skyframeExecutor . getOutputDirtyFilesAndClear ( ) , <nl> + skyframeExecutor . getModifiedFilesDuringPreviousBuildAndClear ( ) ) ) ; <nl> + <nl> + env . getEventBus ( ) <nl> + . post ( new ExecutionPhaseCompleteEvent ( timer . stop ( ) . elapsed ( TimeUnit . MILLISECONDS ) ) ) ; <nl> + <nl> + if ( catastrophe ! = null ) { <nl> + Throwables . throwIfUnchecked ( catastrophe ) ; <nl> + } <nl> + / / NOTE : No finalization activities below will run in the event of a catastrophic error ! <nl> + <nl> env . recordLastExecutionTime ( ) ; <nl> + <nl> if ( request . isRunningInEmacs ( ) ) { <nl> request <nl> . getOutErr ( ) <nl> void executeBuild ( <nl> getReporter ( ) . handle ( Event . progress ( \" Building complete . \" ) ) ; <nl> } <nl> <nl> - env . getEventBus ( ) . post ( new ExecutionFinishedEvent ( ImmutableMap . < String , Long > of ( ) , 0L , <nl> - skyframeExecutor . getOutputDirtyFilesAndClear ( ) , <nl> - skyframeExecutor . getModifiedFilesDuringPreviousBuildAndClear ( ) ) ) ; <nl> - <nl> executor . executionPhaseEnding ( ) ; <nl> - for ( ActionContextProvider actionContextProvider : actionContextProviders ) { <nl> - actionContextProvider . executionPhaseEnding ( ) ; <nl> - } <nl> <nl> if ( buildCompleted ) { <nl> saveActionCache ( actionCache ) ; <nl> } <nl> <nl> - env . getEventBus ( ) <nl> - . post ( new ExecutionPhaseCompleteEvent ( timer . stop ( ) . elapsed ( TimeUnit . MILLISECONDS ) ) ) ; <nl> - <nl> try ( SilentCloseable c = Profiler . instance ( ) . profile ( \" Show results \" ) ) { <nl> buildResult . setSuccessfulTargets ( <nl> determineSuccessfulTargets ( configuredTargets , builtTargets ) ) ; <nl> buildResult . setSuccessfulAspects ( determineSuccessfulAspects ( aspects , builtAspects ) ) ; <nl> buildResult . setSkippedTargets ( analysisResult . getTargetsToSkip ( ) ) ; <nl> BuildResultPrinter buildResultPrinter = new BuildResultPrinter ( env ) ; <nl> - buildResultPrinter . showBuildResult ( request , buildResult , configuredTargets , <nl> - analysisResult . getTargetsToSkip ( ) , analysisResult . getAspects ( ) ) ; <nl> + buildResultPrinter . showBuildResult ( <nl> + request , <nl> + buildResult , <nl> + configuredTargets , <nl> + analysisResult . getTargetsToSkip ( ) , <nl> + analysisResult . getAspects ( ) ) ; <nl> } <nl> <nl> try ( SilentCloseable c = Profiler . instance ( ) . profile ( \" Show artifacts \" ) ) { <nl>\n", "msg": "Skip non - essential cleanup after catastrophic failures in ExecutionTool\n"}
{"diff_id": 13730, "repo": "elastic/elasticsearch\n", "sha": "b0b7c917c37cf7a2b2b5de63aa38ea612dba757f\n", "time": "2014-11-16T19:54:49Z\n", "diff": "mmm a / src / test / java / org / elasticsearch / test / store / MockFSDirectoryService . java <nl> ppp b / src / test / java / org / elasticsearch / test / store / MockFSDirectoryService . java <nl> public void afterIndexShardClosed ( ShardId sid , @ Nullable IndexShard indexShard ) <nl> <nl> @ Override <nl> public Directory [ ] build ( ) throws IOException { <nl> - return helper . wrapAllInplace ( delegateService . build ( ) ) ; <nl> + return delegateService . build ( ) ; <nl> } <nl> <nl> @ Override <nl>\n", "msg": "Prevent double wrapping directories in MockDirectoryWrapper\n"}
{"diff_id": 13784, "repo": "google/guava\n", "sha": "5401a778bfddd5ff34a3902d6c756479149602e4\n", "time": "2013-03-27T20:20:01Z\n", "diff": "mmm a / guava / src / com / google / common / reflect / TypeResolver . java <nl> ppp b / guava / src / com / google / common / reflect / TypeResolver . java <nl> private static void populateTypeMappings ( <nl> public Type resolveType ( Type type ) { <nl> checkNotNull ( type ) ; <nl> if ( type instanceof TypeVariable ) { <nl> - return resolveTypeVariable ( ( TypeVariable < ? > ) type ) ; <nl> + return typeTable . resolve ( ( TypeVariable < ? > ) type ) ; <nl> } else if ( type instanceof ParameterizedType ) { <nl> return resolveParameterizedType ( ( ParameterizedType ) type ) ; <nl> } else if ( type instanceof GenericArrayType ) { <nl> private Type resolveGenericArrayType ( GenericArrayType type ) { <nl> return Types . newArrayType ( componentType ) ; <nl> } <nl> <nl> - private Type resolveTypeVariable ( final TypeVariable < ? > var ) { <nl> - TypeResolver guarded = new TypeResolver ( new TypeTable ( typeTable ) { <nl> - @ Override public Type resolveTypeVariable ( <nl> - TypeVariable < ? > intermediateVar , TypeResolver guardedResolver ) { <nl> - if ( intermediateVar . getGenericDeclaration ( ) . equals ( var . getGenericDeclaration ( ) ) ) { <nl> - return intermediateVar ; <nl> - } <nl> - return typeTable . resolveTypeVariable ( intermediateVar , guardedResolver ) ; <nl> - } <nl> - } ) ; <nl> - return typeTable . resolveTypeVariable ( var , guarded ) ; <nl> - } <nl> - <nl> private ParameterizedType resolveParameterizedType ( ParameterizedType type ) { <nl> Type owner = type . getOwnerType ( ) ; <nl> Type resolvedOwner = ( owner = = null ) ? null : resolveType ( owner ) ; <nl> private ParameterizedType resolveParameterizedType ( ParameterizedType type ) { <nl> } <nl> } <nl> <nl> + / * * A TypeTable maintains mapping from { @ link TypeVariable } to types . * / <nl> private static class TypeTable { <nl> private final ImmutableMap < TypeVariable < ? > , Type > map ; <nl> - <nl> - TypeTable ( ImmutableMap < TypeVariable < ? > , Type > map ) { <nl> - this . map = map ; <nl> - } <nl> <nl> TypeTable ( ) { <nl> this . map = ImmutableMap . of ( ) ; <nl> } <nl> - <nl> - TypeTable ( TypeTable copy ) { <nl> - this . map = copy . map ; <nl> + <nl> + private TypeTable ( ImmutableMap < TypeVariable < ? > , Type > map ) { <nl> + this . map = map ; <nl> } <nl> <nl> / * * Returns a new { @ code TypeResolver } with { @ code variable } mapping to { @ code type } . * / <nl> final TypeTable where ( Map < ? extends TypeVariable < ? > , ? extends Type > mappings ) { <nl> return new TypeTable ( builder . build ( ) ) ; <nl> } <nl> <nl> + final Type resolve ( final TypeVariable < ? > var ) { <nl> + final TypeTable unguarded = this ; <nl> + TypeTable guarded = new TypeTable ( ) { <nl> + @ Override public Type resolveInternal ( <nl> + TypeVariable < ? > intermediateVar , TypeTable forDependent ) { <nl> + if ( intermediateVar . getGenericDeclaration ( ) . equals ( var . getGenericDeclaration ( ) ) ) { <nl> + return intermediateVar ; <nl> + } <nl> + return unguarded . resolveInternal ( intermediateVar , forDependent ) ; <nl> + } <nl> + } ; <nl> + return resolveInternal ( var , guarded ) ; <nl> + } <nl> + <nl> / * * <nl> * Resolves { @ code var } using the encapsulated type mapping . If it maps to yet another <nl> - * non - reified type , { @ code guardedResolver } is used to do further resolution , which doesn ' t <nl> - * try to resolve any type variable on generic declarations that are already being resolved . <nl> + * non - reified type or has bounds , { @ code forDependants } is used to do further resolution , which <nl> + * doesn ' t try to resolve any type variable on generic declarations that are already being <nl> + * resolved . <nl> + * <nl> + * < p > Should only be called and overridden by { @ link # resolve ( TypeVariable ) } . <nl> * / <nl> - Type resolveTypeVariable ( TypeVariable < ? > var , TypeResolver guardedResolver ) { <nl> - checkNotNull ( guardedResolver ) ; <nl> - Type type = map . get ( var ) ; <nl> - if ( type = = null ) { <nl> - Type [ ] bounds = var . getBounds ( ) ; <nl> - if ( bounds . length = = 0 ) { <nl> - return var ; <nl> - } <nl> - return Types . newTypeVariable ( <nl> - var . getGenericDeclaration ( ) , <nl> - var . getName ( ) , <nl> - guardedResolver . resolveTypes ( bounds ) ) ; <nl> + Type resolveInternal ( TypeVariable < ? > var , TypeTable forDependants ) { <nl> + Type type = map . get ( var ) ; <nl> + if ( type = = null ) { <nl> + Type [ ] bounds = var . getBounds ( ) ; <nl> + if ( bounds . length = = 0 ) { <nl> + return var ; <nl> } <nl> - / / in case the type is yet another type variable . <nl> - return guardedResolver . resolveType ( type ) ; <nl> + return Types . newTypeVariable ( <nl> + var . getGenericDeclaration ( ) , <nl> + var . getName ( ) , <nl> + new TypeResolver ( forDependants ) . resolveTypes ( bounds ) ) ; <nl> + } <nl> + / / in case the type is yet another type variable . <nl> + return new TypeResolver ( forDependants ) . resolveType ( type ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "Some more refactoring of TypeResolver . TypeTable . I was in a hurry . The TypeTable code wasn ' t in a form I ' d LGTM .\n"}
{"diff_id": 13802, "repo": "spring-projects/spring-framework\n", "sha": "a3942c5c1bb914ddbeca9b3ef50a1cb2e984872e\n", "time": "2009-03-12T21:30:42Z\n", "diff": "mmm a / org . springframework . jdbc / src / main / java / org / springframework / jdbc / object / GenericSqlQuery . java <nl> ppp b / org . springframework . jdbc / src / main / java / org / springframework / jdbc / object / GenericSqlQuery . java <nl> <nl> <nl> package org . springframework . jdbc . object ; <nl> <nl> - import java . sql . ResultSet ; <nl> - import java . sql . SQLException ; <nl> import java . util . Map ; <nl> <nl> import org . springframework . jdbc . core . RowMapper ; <nl> import org . springframework . util . Assert ; <nl> - import org . springframework . dao . InvalidDataAccessApiUsageException ; <nl> + import org . springframework . dao . InvalidDataAccessResourceUsageException ; <nl> <nl> public class GenericSqlQuery extends SqlQuery { <nl> <nl> protected RowMapper newRowMapper ( Object [ ] parameters , Map context ) { <nl> return ( RowMapper ) rowMapperClass . newInstance ( ) ; <nl> } <nl> catch ( InstantiationException e ) { <nl> - throw new InvalidDataAccessApiUsageException ( \" Unable to instantiate RowMapper \" , e ) ; <nl> + throw new InvalidDataAccessResourceUsageException ( \" Unable to instantiate RowMapper \" , e ) ; <nl> } <nl> catch ( IllegalAccessException e ) { <nl> - throw new InvalidDataAccessApiUsageException ( \" Unable to instantiate RowMapper \" , e ) ; <nl> + throw new InvalidDataAccessResourceUsageException ( \" Unable to instantiate RowMapper \" , e ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "changed exception class thrown for problems configuring GenericSqlQuery class ( SPR - 3986 )\n"}
{"diff_id": 13839, "repo": "netty/netty\n", "sha": "f0a96e7417002b0c786ce837a8711bee5e1e0895\n", "time": "2009-05-21T12:04:28Z\n", "diff": "mmm a / src / main / java / org / jboss / netty / handler / logging / LoggingHandler . java <nl> ppp b / src / main / java / org / jboss / netty / handler / logging / LoggingHandler . java <nl> public void handleDownstream ( ChannelHandlerContext ctx , ChannelEvent e ) <nl> } <nl> <nl> protected void log ( ChannelEvent e ) { <nl> - String msg = e . toString ( ) ; <nl> if ( logger . isDebugEnabled ( ) ) { <nl> + String msg = e . toString ( ) ; <nl> + <nl> / / Append hex dump if necessary . <nl> if ( hexDump & & e instanceof MessageEvent ) { <nl> MessageEvent me = ( MessageEvent ) e ; <nl>\n", "msg": "Tiny optimization - no need to create a string when there ' s nothing to log\n"}
{"diff_id": 13862, "repo": "elastic/elasticsearch\n", "sha": "4e206cd02d3e8622f34f44736798ea8ae3680ea6\n", "time": "2015-06-01T14:38:48Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / indices / flush / SyncedFlushService . java <nl> ppp b / src / main / java / org / elasticsearch / indices / flush / SyncedFlushService . java <nl> public void handleResponse ( PreSyncedFlushResponse response ) { <nl> <nl> @ Override <nl> public void handleException ( TransportException exp ) { <nl> - logger . trace ( \" { } error while performing pre synced flush on [ { } ] , skipping \" , shardId , exp , shard ) ; <nl> + logger . trace ( \" { } error while performing pre synced flush on [ { } ] , skipping \" , exp , shardId , shard ) ; <nl> if ( countDown . countDown ( ) ) { <nl> listener . onResponse ( commitIds ) ; <nl> } <nl>\n", "msg": "fix log message . exception first , parameters later\n"}
{"diff_id": 13904, "repo": "bazelbuild/bazel\n", "sha": "c35e572314b0dd1939f8314272799f1ca3bb9cd6\n", "time": "2017-07-24T19:04:39Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / packages / ClassObjectConstructor . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / packages / ClassObjectConstructor . java <nl> <nl> + \" Note : Some providers , defined internally , do not allow instance creation \" <nl> + \" < / li > \" <nl> + \" < li > It is a < i > key < / i > to access a provider instance on a \" <nl> - + \" < a href = \\ \" lib / Target . html \\ \" > Target < / a > \" <nl> + + \" < a href = \\ \" Target . html \\ \" > Target < / a > \" <nl> + \" < pre class = \\ \" language - python \\ \" > DataInfo = provider ( ) \\ n \" <nl> + \" def _rule_impl ( ctx ) \\ n \" <nl> + \" . . . ctx . attr . dep [ DataInfo ] < / pre > \" <nl>\n", "msg": "Fixed relative link in documentation to Provider\n"}
{"diff_id": 13910, "repo": "oracle/graal\n", "sha": "9c2f35ee5f45f9deb56b5e5810ba1e45d5dd7562\n", "time": "2015-04-15T01:14:27Z\n", "diff": "mmm a / graal / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / generator / NodeGenFactory . java <nl> ppp b / graal / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / generator / NodeGenFactory . java <nl> private CodeTree createFastPath ( CodeTreeBuilder parent , SpecializationData speci <nl> var = currentLocals . createValue ( execution , targetType ) . nextName ( ) ; <nl> builder . tree ( createAssignExecuteChild ( builder , execution , executableType , var , shortCircuit , currentLocals ) ) ; <nl> currentLocals . setValue ( execution , var ) ; <nl> - <nl> } <nl> } <nl> <nl> public CodeTree createBody ( SpecializationData s , LocalContext values ) { <nl> } ; <nl> builder . tree ( createGuardAndCast ( group , returnType , currentLocals , executionFactory ) ) ; <nl> if ( hasFallthrough ( group , returnType , originalValues , true , null ) | | group . getSpecialization ( ) . isFallback ( ) ) { <nl> - builder . tree ( createCallNext ( builder , executableType , executableType , originalValues ) ) ; <nl> + builder . tree ( createCallNext ( builder , executableType , node . getGenericExecutableType ( executableType ) , originalValues ) ) ; <nl> } <nl> } <nl> return builder . build ( ) ; <nl>\n", "msg": "Truffle - DSL : fixed wrong executable delegate .\n"}
{"diff_id": 13998, "repo": "bazelbuild/bazel\n", "sha": "83e31f6a9e81ddd2ae6843b57ee4e63a80127dcc\n", "time": "2019-02-06T21:48:24Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / skyframe / SkyFunctions . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / SkyFunctions . java <nl> <nl> SkyFunctionName . createHermetic ( \" PACKAGE_ERROR_MESSAGE \" ) ; <nl> public static final SkyFunctionName TARGET_MARKER = <nl> SkyFunctionName . createHermetic ( \" TARGET_MARKER \" ) ; <nl> - / / Non - hermetic because accesses package locator <nl> + / / Semi - hermetic because accesses package locator <nl> public static final SkyFunctionName TARGET_PATTERN = <nl> - SkyFunctionName . createNonHermetic ( \" TARGET_PATTERN \" ) ; <nl> + SkyFunctionName . createSemiHermetic ( \" TARGET_PATTERN \" ) ; <nl> static final SkyFunctionName TARGET_PATTERN_ERROR = <nl> SkyFunctionName . createHermetic ( \" TARGET_PATTERN_ERROR \" ) ; <nl> public static final SkyFunctionName PREPARE_DEPS_OF_PATTERNS = <nl>\n", "msg": "Make TARGET_PATTERN semi - hermetic . It ' s depended on by RegisteredToolchainsFunction , so it affects a lot .\n"}
{"diff_id": 14244, "repo": "google/guava\n", "sha": "3ba3d53f4d16117e74d1aed5786887dd8dab4ce6\n", "time": "2014-05-13T01:26:39Z\n", "diff": "mmm a / guava / src / com / google / common / base / Objects . java <nl> ppp b / guava / src / com / google / common / base / Objects . java <nl> private Objects ( ) { } <nl> * <nl> * < p > < b > Note for Java 7 and later : < / b > This method should be treated as <nl> * deprecated ; use { @ link java . util . Objects # equals } instead . <nl> - * <nl> * / <nl> @ CheckReturnValue <nl> public static boolean equal ( @ Nullable Object a , @ Nullable Object b ) { <nl> public static boolean equal ( @ Nullable Object a , @ Nullable Object b ) { <nl> * <nl> * < p > < b > Note for Java 7 and later : < / b > This method should be treated as <nl> * deprecated ; use { @ link java . util . Objects # hash } instead . <nl> - * <nl> * / <nl> public static int hashCode ( @ Nullable Object . . . objects ) { <nl> return Arrays . hashCode ( objects ) ; <nl>\n", "msg": "Revert base . Objects - > j . u . Objects deprecations until we do the bulk of the migrations ourselves ( blocked : see bug ) .\n"}
{"diff_id": 14439, "repo": "bazelbuild/bazel\n", "sha": "39361913aca9b91f600f2a314f0f4d47336faae2\n", "time": "2018-09-21T16:41:09Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / runtime / BlazeCommandDispatcher . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / runtime / BlazeCommandDispatcher . java <nl> private BlazeCommandResult execExclusively ( <nl> } <nl> return result ; <nl> } catch ( Throwable e ) { <nl> + outErr . printErr ( <nl> + \" Internal error thrown during build . Printing stack trace : \" <nl> + + Throwables . getStackTraceAsString ( e ) ) ; <nl> e . printStackTrace ( ) ; <nl> BugReport . printBug ( outErr , e ) ; <nl> BugReport . sendBugReport ( e , args , env . getCrashData ( ) ) ; <nl>\n", "msg": "Log Throwables that happened during the build to the outErr of the BlazeCommandDispatcher . This way they can be logged in the BEP .\n"}
{"diff_id": 14443, "repo": "libgdx/libgdx\n", "sha": "f8b33290dfa7f705fc5ce7d882c46dc07729d851\n", "time": "2014-12-17T15:34:31Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / utils / Json . java <nl> ppp b / gdx / src / com / badlogic / gdx / utils / Json . java <nl> public void readField ( Object object , String fieldName , String jsonName , Class e <nl> FieldMetadata metadata = fields . get ( fieldName ) ; <nl> if ( metadata = = null ) throw new SerializationException ( \" Field not found : \" + fieldName + \" ( \" + type . getName ( ) + \" ) \" ) ; <nl> Field field = metadata . field ; <nl> + if ( elementType = = null ) elementType = metadata . elementType ; <nl> + readField ( object , field , jsonName , elementType , jsonMap ) ; <nl> + } <nl> + <nl> + / * * @ param object May be null if the field is static . <nl> + * @ param elementType May be null if the type is unknown . * / <nl> + public void readField ( Object object , Field field , String jsonName , Class elementType , JsonValue jsonMap ) { <nl> JsonValue jsonValue = jsonMap . get ( jsonName ) ; <nl> if ( jsonValue = = null ) return ; <nl> - if ( elementType = = null ) elementType = metadata . elementType ; <nl> try { <nl> field . set ( object , readValue ( field . getType ( ) , elementType , jsonValue ) ) ; <nl> } catch ( ReflectionException ex ) { <nl> - throw new SerializationException ( \" Error accessing field : \" + field . getName ( ) + \" ( \" + type . getName ( ) + \" ) \" , ex ) ; <nl> + throw new SerializationException ( \" Error accessing field : \" + field . getName ( ) + \" ( \" <nl> + + field . getDeclaringClass ( ) . getName ( ) + \" ) \" , ex ) ; <nl> } catch ( SerializationException ex ) { <nl> - ex . addTrace ( field . getName ( ) + \" ( \" + type . getName ( ) + \" ) \" ) ; <nl> + ex . addTrace ( field . getName ( ) + \" ( \" + field . getDeclaringClass ( ) . getName ( ) + \" ) \" ) ; <nl> throw ex ; <nl> } catch ( RuntimeException runtimeEx ) { <nl> SerializationException ex = new SerializationException ( runtimeEx ) ; <nl> - ex . addTrace ( field . getName ( ) + \" ( \" + type . getName ( ) + \" ) \" ) ; <nl> + ex . addTrace ( field . getName ( ) + \" ( \" + field . getDeclaringClass ( ) . getName ( ) + \" ) \" ) ; <nl> throw ex ; <nl> } <nl> } <nl>\n", "msg": "Added readField method that can be used for a static field .\n"}
{"diff_id": 14445, "repo": "signalapp/Signal-Android\n", "sha": "a079e479ecd296b94e312213aba87ab47f33e826\n", "time": "2019-12-04T20:25:26Z\n", "diff": "mmm a / src / org / thoughtcrime / securesms / util / CommunicationActions . java <nl> ppp b / src / org / thoughtcrime / securesms / util / CommunicationActions . java <nl> <nl> import androidx . annotation . Nullable ; <nl> import androidx . appcompat . app . AlertDialog ; <nl> import androidx . core . app . TaskStackBuilder ; <nl> + <nl> + import android . os . Bundle ; <nl> + import android . os . Handler ; <nl> + import android . os . Looper ; <nl> + import android . os . ResultReceiver ; <nl> import android . text . TextUtils ; <nl> import android . widget . Toast ; <nl> <nl> <nl> import org . thoughtcrime . securesms . permissions . Permissions ; <nl> import org . thoughtcrime . securesms . recipients . Recipient ; <nl> import org . thoughtcrime . securesms . service . WebRtcCallService ; <nl> + import org . thoughtcrime . securesms . util . concurrent . SimpleTask ; <nl> <nl> public class CommunicationActions { <nl> <nl> public static void startVoiceCall ( @ NonNull Activity activity , @ NonNull Recipient <nl> return ; <nl> } <nl> <nl> - new AlertDialog . Builder ( activity ) <nl> - . setMessage ( R . string . CommunicationActions_start_voice_call ) <nl> - . setPositiveButton ( R . string . CommunicationActions_call , ( d , w ) - > startCallInternal ( activity , recipient , false ) ) <nl> - . setNegativeButton ( R . string . CommunicationActions_cancel , ( d , w ) - > d . dismiss ( ) ) <nl> - . setCancelable ( true ) <nl> - . show ( ) ; <nl> + WebRtcCallService . isCallActive ( activity , new ResultReceiver ( new Handler ( Looper . getMainLooper ( ) ) ) { <nl> + @ Override <nl> + protected void onReceiveResult ( int resultCode , Bundle resultData ) { <nl> + if ( resultCode = = 1 ) { <nl> + startCallInternal ( activity , recipient , false ) ; <nl> + } else { <nl> + new AlertDialog . Builder ( activity ) <nl> + . setMessage ( R . string . CommunicationActions_start_voice_call ) <nl> + . setPositiveButton ( R . string . CommunicationActions_call , ( d , w ) - > startCallInternal ( activity , recipient , false ) ) <nl> + . setNegativeButton ( R . string . CommunicationActions_cancel , ( d , w ) - > d . dismiss ( ) ) <nl> + . setCancelable ( true ) <nl> + . show ( ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> } <nl> <nl> public static void startVideoCall ( @ NonNull Activity activity , @ NonNull Recipient recipient ) { <nl> public static void startVideoCall ( @ NonNull Activity activity , @ NonNull Recipient <nl> return ; <nl> } <nl> <nl> - new AlertDialog . Builder ( activity ) <nl> - . setMessage ( R . string . CommunicationActions_start_video_call ) <nl> - . setPositiveButton ( R . string . CommunicationActions_call , ( d , w ) - > startCallInternal ( activity , recipient , true ) ) <nl> - . setNegativeButton ( R . string . CommunicationActions_cancel , ( d , w ) - > d . dismiss ( ) ) <nl> - . setCancelable ( true ) <nl> - . show ( ) ; <nl> + WebRtcCallService . isCallActive ( activity , new ResultReceiver ( new Handler ( Looper . getMainLooper ( ) ) ) { <nl> + @ Override <nl> + protected void onReceiveResult ( int resultCode , Bundle resultData ) { <nl> + if ( resultCode = = 1 ) { <nl> + startCallInternal ( activity , recipient , false ) ; <nl> + } else { <nl> + new AlertDialog . Builder ( activity ) <nl> + . setMessage ( R . string . CommunicationActions_start_video_call ) <nl> + . setPositiveButton ( R . string . CommunicationActions_call , ( d , w ) - > startCallInternal ( activity , recipient , true ) ) <nl> + . setNegativeButton ( R . string . CommunicationActions_cancel , ( d , w ) - > d . dismiss ( ) ) <nl> + . setCancelable ( true ) <nl> + . show ( ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> } <nl> <nl> public static void startConversation ( @ NonNull Context context , @ NonNull Recipient recipient , @ Nullable String text ) { <nl>\n", "msg": "Skip call dialog if signal call is already active .\n"}
{"diff_id": 14458, "repo": "elastic/elasticsearch\n", "sha": "07044e02b99a8453b099ca690337e19a771f232f\n", "time": "2015-12-15T14:25:17Z\n", "diff": "mmm a / core / src / main / java / org / elasticsearch / index / IndexService . java <nl> ppp b / core / src / main / java / org / elasticsearch / index / IndexService . java <nl> <nl> private final AtomicBoolean deleted = new AtomicBoolean ( false ) ; <nl> private final IndexSettings indexSettings ; <nl> <nl> - @ Inject <nl> public IndexService ( IndexSettings indexSettings , NodeEnvironment nodeEnv , <nl> SimilarityService similarityService , <nl> ShardStoreDeleter shardStoreDeleter , <nl>\n", "msg": "IndexService : remove unneed inject annotation from\n"}
{"diff_id": 14552, "repo": "elastic/elasticsearch\n", "sha": "48392b79d8433f65bb7c40bc66cb85c415b6520c\n", "time": "2020-02-16T10:16:54Z\n", "diff": "mmm a / x - pack / plugin / transform / qa / single - node - tests / src / test / java / org / elasticsearch / xpack / transform / integration / TransformRobustnessIT . java <nl> ppp b / x - pack / plugin / transform / qa / single - node - tests / src / test / java / org / elasticsearch / xpack / transform / integration / TransformRobustnessIT . java <nl> public void testTaskRemovalAfterInternalIndexGotDeleted ( ) throws Exception { <nl> <nl> / / the task is gone <nl> assertEquals ( 0 , getNumberOfTransformTasks ( ) ) ; <nl> + <nl> + / / delete the transform because the task might have written a state doc , cleanup fails if the index isn ' t empty <nl> + deleteTransform ( transformId ) ; <nl> } <nl> <nl> @ SuppressWarnings ( \" unchecked \" ) <nl>\n", "msg": "delete the transform to delete any docs which might have been written by the ( )\n"}
{"diff_id": 14563, "repo": "SeleniumHQ/selenium\n", "sha": "6854c791523fb7c3fe93bd3338d10dff61bb39c8\n", "time": "2009-12-29T15:32:47Z\n", "diff": "mmm a / selenium / src / java / org / openqa / selenium / WebDriverCommandProcessor . java <nl> ppp b / selenium / src / java / org / openqa / selenium / WebDriverCommandProcessor . java <nl> public Object call ( ) throws Exception { <nl> } ) ; <nl> } <nl> <nl> + public boolean isMethodAvailable ( String methodName ) { <nl> + return seleneseMethods . containsKey ( methodName ) ; <nl> + } <nl> + <nl> + public void addMethod ( String methodName , SeleneseCommand command ) { <nl> + seleneseMethods . put ( methodName , command ) ; <nl> + } <nl> + <nl> public Map < String , SeleneseCommand > getMethodMap ( ) { <nl> return seleneseMethods ; <nl> } <nl>\n", "msg": "PatrickLightbody Removing leaky access in favor of Simon ' s suggested changes , documented here http : / / code . google . com / p / selenium / source / detail ? r = 7953\n"}
{"diff_id": 14791, "repo": "dbeaver/dbeaver\n", "sha": "4699e430b00c677ad25dd4c1eee787bb2e955c6b\n", "time": "2019-08-07T14:06:33Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . ui . editors . base / src / org / jkiss / dbeaver / ui / editors / object / struct / EditForeignKeyPage . java <nl> ppp b / plugins / org . jkiss . dbeaver . ui . editors . base / src / org / jkiss / dbeaver / ui / editors / object / struct / EditForeignKeyPage . java <nl> private void handleRefTableSelect ( ) { <nl> final Collection < ? extends DBSTableIndex > indexes = ( ( DBSTable ) refTable ) . getIndexes ( monitor ) ; <nl> if ( ! CommonUtils . isEmpty ( indexes ) ) { <nl> for ( DBSTableIndex constraint : indexes ) { <nl> - if ( constraint . isUnique ( ) ) { <nl> + if ( constraint . isUnique ( ) & & isConstraintIndex ( monitor , curConstraints , constraint ) ) { <nl> curConstraints . add ( constraint ) ; <nl> } <nl> } <nl> private void handleRefTableSelect ( ) { <nl> } ) ; <nl> } <nl> for ( DBSEntityConstraint constraint : curConstraints ) { <nl> - uniqueKeyCombo . add ( constraint . getName ( ) ) ; <nl> + uniqueKeyCombo . add ( constraint . getName ( ) + \" ( \" + constraint . getConstraintType ( ) . getLocalizedName ( ) + \" ) \" ) ; <nl> } <nl> if ( uniqueKeyCombo . getItemCount ( ) = = 0 ) { <nl> if ( curRefTable = = null ) { <nl> private void handleRefTableSelect ( ) { <nl> updatePageState ( ) ; <nl> } <nl> <nl> + private boolean isConstraintIndex ( DBRProgressMonitor monitor , List < DBSEntityConstraint > constraints , DBSTableIndex index ) throws DBException { <nl> + List < ? extends DBSTableIndexColumn > iAttrs = index . getAttributeReferences ( monitor ) ; <nl> + <nl> + for ( DBSEntityConstraint constraint : constraints ) { <nl> + if ( constraint instanceof DBSEntityReferrer ) { <nl> + List < ? extends DBSEntityAttributeRef > cAttrs = ( ( DBSEntityReferrer ) constraint ) . getAttributeReferences ( monitor ) ; <nl> + if ( CommonUtils . equalObjects ( iAttrs , cAttrs ) ) { <nl> + return true ; <nl> + } <nl> + } <nl> + } <nl> + return false ; <nl> + } <nl> + <nl> private void handleUniqueKeySelect ( ) <nl> { <nl> fkColumns . clear ( ) ; <nl>\n", "msg": "FK create dialog fix ( remove unique key dups , shwo unique key type )\n"}
{"diff_id": 15040, "repo": "oracle/graal\n", "sha": "5e3484640004676ef53219fabe043bbaa4f30382\n", "time": "2019-11-08T10:31:38Z\n", "diff": "mmm a / compiler / src / org . graalvm . compiler . hotspot . test / src / org / graalvm / compiler / hotspot / test / CheckGraalIntrinsics . java <nl> ppp b / compiler / src / org . graalvm . compiler . hotspot . test / src / org / graalvm / compiler / hotspot / test / CheckGraalIntrinsics . java <nl> public static ResolvedJavaMethod resolveIntrinsic ( MetaAccessProvider metaAccess , <nl> private static Collection < String > add ( Collection < String > c , String . . . elements ) { <nl> String [ ] sorted = elements . clone ( ) ; <nl> Arrays . sort ( sorted ) ; <nl> - for ( int i = 0 ; i < elements . length ; i + + ) { <nl> - if ( ! elements [ i ] . equals ( sorted [ i ] ) ) { <nl> - / / Let ' s keep the list sorted for easier visual inspection <nl> - fail ( \" Element % d is out of order , \\ \" % s \\ \" \" , i , elements [ i ] ) ; <nl> + if ( ! Arrays . equals ( elements , sorted ) ) { <nl> + int width = 2 + Arrays . asList ( elements ) . stream ( ) . map ( String : : length ) . reduce ( 0 , Integer : : max ) ; <nl> + Formatter fmt = new Formatter ( ) ; <nl> + fmt . format ( \" % - \" + width + \" s | sorted % n \" , \" original \" ) ; <nl> + fmt . format ( \" % s % n \" , new String ( new char [ width * 2 + 2 ] ) . replace ( ' \\ 0 ' , ' = ' ) ) ; <nl> + for ( int i = 0 ; i < elements . length ; i + + ) { <nl> + fmt . format ( \" % - \" + width + \" s | % s % n \" , elements [ i ] , sorted [ i ] ) ; <nl> } <nl> + fail ( \" Elements not sorted alphabetically : % n % s \" , fmt ) ; <nl> } <nl> c . addAll ( Arrays . asList ( elements ) ) ; <nl> return c ; <nl> public CheckGraalIntrinsics ( ) { <nl> / / AES intrinsics <nl> if ( ! config . useAESIntrinsics ) { <nl> add ( ignore , <nl> - \" com / sun / crypto / provider / AESCrypt . \" + aesEncryptName + \" ( [ BI [ BI ) V \" , <nl> \" com / sun / crypto / provider / AESCrypt . \" + aesDecryptName + \" ( [ BI [ BI ) V \" , <nl> + \" com / sun / crypto / provider / AESCrypt . \" + aesEncryptName + \" ( [ BI [ BI ) V \" , <nl> \" com / sun / crypto / provider / CipherBlockChaining . \" + cbcDecryptName + \" ( [ BII [ BI ) I \" , <nl> \" com / sun / crypto / provider / CipherBlockChaining . \" + cbcEncryptName + \" ( [ BII [ BI ) I \" ) ; <nl> } <nl>\n", "msg": "fixed ordering of ignored crypto intrinsics\n"}
{"diff_id": 15062, "repo": "EnterpriseQualityCoding/FizzBuzzEnterpriseEdition\n", "sha": "779b3b49b1819e4da470f1008dbfc6fa67d55313\n", "time": "2014-03-04T23:02:15Z\n", "diff": "new file mode 100644 <nl> index 0000000 . . 81904bc <nl> mmm / dev / null <nl> ppp b / src / main / java / com / seriouscompany / business / java / fizzbuzz / packagenamingpackage / interfaces / strategies / FizzBuzzOutputStrategy . java <nl> <nl> + package com . seriouscompany . business . java . fizzbuzz . packagenamingpackage . interfaces . strategies ; <nl> + <nl> + public interface FizzBuzzOutputStrategy { <nl> + <nl> + public void output ( String output ) ; <nl> + <nl> + } <nl>\n", "msg": "Adding a much needed output strategy to get away from that old , crusty , System . out construct\n"}
{"diff_id": 15077, "repo": "jenkinsci/jenkins\n", "sha": "109474d5263a4542129f0bc82e81f8dfdd8df5b9\n", "time": "2015-11-27T10:44:01Z\n", "diff": "mmm a / core / src / main / java / hudson / cli / DeleteNodeCommand . java <nl> ppp b / core / src / main / java / hudson / cli / DeleteNodeCommand . java <nl> <nl> <nl> import hudson . Extension ; <nl> import hudson . model . Node ; <nl> + import org . acegisecurity . AccessDeniedException ; <nl> import jenkins . model . Jenkins ; <nl> import org . kohsuke . args4j . Argument ; <nl> <nl> - import java . nio . file . AccessDeniedException ; <nl> import java . util . HashSet ; <nl> import java . util . List ; <nl> import java . util . logging . Logger ; <nl>\n", "msg": "CLI delete - node : correction of handling an exception occurred during execution when not enough rights are on\n"}
{"diff_id": 15153, "repo": "dbeaver/dbeaver\n", "sha": "c7b86c6b83388a4b85952542812e8870e1680ecb\n", "time": "2018-09-08T12:46:48Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . data . transfer / src / org / jkiss / dbeaver / tools / transfer / stream / page / StreamProducerPageSettings . java <nl> ppp b / plugins / org . jkiss . dbeaver . data . transfer / src / org / jkiss / dbeaver / tools / transfer / stream / page / StreamProducerPageSettings . java <nl> <nl> package org . jkiss . dbeaver . tools . transfer . stream . page ; <nl> <nl> import org . eclipse . swt . SWT ; <nl> + import org . eclipse . swt . custom . SashForm ; <nl> import org . eclipse . swt . events . SelectionAdapter ; <nl> import org . eclipse . swt . events . SelectionEvent ; <nl> import org . eclipse . swt . layout . GridData ; <nl> public void createControl ( Composite parent ) { <nl> <nl> initializeDialogUnits ( parent ) ; <nl> <nl> - Composite composite = new Composite ( parent , SWT . NULL ) ; <nl> - composite . setLayout ( new GridLayout ( ) ) ; <nl> - composite . setLayoutData ( new GridData ( GridData . FILL_BOTH ) ) ; <nl> + SashForm settingsDivider = new SashForm ( parent , SWT . VERTICAL ) ; <nl> + settingsDivider . setLayoutData ( new GridData ( GridData . FILL_BOTH ) ) ; <nl> <nl> { <nl> - Group inputFilesGroup = new Group ( composite , SWT . NONE ) ; <nl> + Group inputFilesGroup = new Group ( settingsDivider , SWT . NONE ) ; <nl> inputFilesGroup . setText ( DTMessages . data_transfer_wizard_settings_group_input_files ) ; <nl> inputFilesGroup . setLayoutData ( new GridData ( GridData . FILL_BOTH ) ) ; <nl> inputFilesGroup . setLayout ( new GridLayout ( 1 , false ) ) ; <nl> public void widgetDefaultSelected ( SelectionEvent e ) { <nl> } <nl> <nl> { <nl> - Group exporterSettings = new Group ( composite , SWT . NONE ) ; <nl> + Group exporterSettings = new Group ( settingsDivider , SWT . NONE ) ; <nl> exporterSettings . setText ( DTMessages . data_transfer_wizard_settings_group_importer ) ; <nl> exporterSettings . setLayoutData ( new GridData ( GridData . FILL_BOTH ) ) ; <nl> exporterSettings . setLayout ( new GridLayout ( 1 , false ) ) ; <nl> <nl> propsEditor = new PropertyTreeViewer ( exporterSettings , SWT . BORDER ) ; <nl> } <nl> + settingsDivider . setWeights ( new int [ ] { 300 , 700 } ) ; <nl> <nl> - setControl ( composite ) ; <nl> + setControl ( settingsDivider ) ; <nl> } <nl> <nl> private boolean chooseSourceFile ( DataTransferPipe pipe ) { <nl>\n", "msg": "Stream producer settings page fix ( use sash )\n"}
{"diff_id": 15471, "repo": "jenkinsci/jenkins\n", "sha": "4153308074aab9d40c1162a3fbacc8edc9df049f\n", "time": "2008-08-20T00:32:20Z\n", "diff": "mmm a / core / src / main / java / hudson / model / UpdateCenter . java <nl> ppp b / core / src / main / java / hudson / model / UpdateCenter . java <nl> public Thread newThread ( Runnable r ) { <nl> * Returns true if it ' s time for us to check for new version . <nl> * / <nl> public boolean isDue ( ) { <nl> + if ( neverUpdate ) return false ; <nl> if ( dataTimestamp = = - 1 ) <nl> dataTimestamp = getDataFile ( ) . file . lastModified ( ) ; <nl> long now = System . currentTimeMillis ( ) ; <nl> public PageDecoratorImpl ( ) { <nl> private static final long DAY = DAYS . toMillis ( 1 ) ; <nl> <nl> private static final Logger LOGGER = Logger . getLogger ( UpdateCenter . class . getName ( ) ) ; <nl> + <nl> + public static boolean neverUpdate = Boolean . getBoolean ( UpdateCenter . class . getName ( ) + \" . never \" ) ; <nl> } <nl>\n", "msg": "added a hook to skip update center updates . This is primarily added for testing .\n"}
{"diff_id": 15505, "repo": "jenkinsci/jenkins\n", "sha": "cfa4533e7920a8446923d00effc40c98ae0d6c2b\n", "time": "2013-04-29T06:01:57Z\n", "diff": "new file mode 100644 <nl> index 00000000000 . . ab7cd790508 <nl> mmm / dev / null <nl> ppp b / core / src / main / java / jenkins / security / SecurityContextExecutorService . java <nl> <nl> + package jenkins . security ; <nl> + <nl> + import java . util . Collection ; <nl> + import java . util . List ; <nl> + import java . util . concurrent . Callable ; <nl> + import java . util . concurrent . ExecutionException ; <nl> + import java . util . concurrent . ExecutorService ; <nl> + import java . util . concurrent . Future ; <nl> + import java . util . concurrent . TimeUnit ; <nl> + import java . util . concurrent . TimeoutException ; <nl> + <nl> + import org . acegisecurity . context . SecurityContext ; <nl> + import org . acegisecurity . context . SecurityContextHolder ; <nl> + <nl> + public class SecurityContextExecutorService implements ExecutorService { <nl> + private final ExecutorService service ; <nl> + private final SecurityContext initialContext = SecurityContextHolder . getContext ( ) ; <nl> + <nl> + public SecurityContextExecutorService ( ExecutorService service ) { <nl> + this . service = service ; <nl> + } <nl> + public static SecurityContextExecutorService wrapExecutorWithSecurityContext ( ExecutorService service ) { <nl> + return new SecurityContextExecutorService ( service ) ; <nl> + } <nl> + public void execute ( Runnable arg0 ) { <nl> + SecurityContext executorContext = SecurityContextHolder . getContext ( ) ; <nl> + SecurityContextHolder . setContext ( initialContext ) ; <nl> + try { <nl> + service . execute ( arg0 ) ; <nl> + } finally { <nl> + SecurityContextHolder . setContext ( executorContext ) ; <nl> + } <nl> + } <nl> + public boolean awaitTermination ( long timeout , TimeUnit unit ) <nl> + throws InterruptedException { <nl> + return service . awaitTermination ( timeout , unit ) ; <nl> + } <nl> + public < T > List < Future < T > > invokeAll ( Collection < ? extends Callable < T > > tasks ) <nl> + throws InterruptedException { <nl> + SecurityContext executorContext = SecurityContextHolder . getContext ( ) ; <nl> + SecurityContextHolder . setContext ( initialContext ) ; <nl> + try { <nl> + return service . invokeAll ( tasks ) ; <nl> + } finally { <nl> + SecurityContextHolder . setContext ( executorContext ) ; <nl> + } <nl> + } <nl> + public < T > List < Future < T > > invokeAll ( <nl> + Collection < ? extends Callable < T > > tasks , long timeout , TimeUnit unit ) <nl> + throws InterruptedException { <nl> + SecurityContext executorContext = SecurityContextHolder . getContext ( ) ; <nl> + SecurityContextHolder . setContext ( initialContext ) ; <nl> + try { <nl> + return service . invokeAll ( tasks , timeout , unit ) ; <nl> + } finally { <nl> + SecurityContextHolder . setContext ( executorContext ) ; <nl> + } <nl> + } <nl> + public < T > T invokeAny ( Collection < ? extends Callable < T > > tasks ) <nl> + throws InterruptedException , ExecutionException { <nl> + SecurityContext executorContext = SecurityContextHolder . getContext ( ) ; <nl> + SecurityContextHolder . setContext ( initialContext ) ; <nl> + try { <nl> + return service . invokeAny ( tasks ) ; <nl> + } finally { <nl> + SecurityContextHolder . setContext ( executorContext ) ; <nl> + } <nl> + } <nl> + public < T > T invokeAny ( Collection < ? extends Callable < T > > tasks , <nl> + long timeout , TimeUnit unit ) throws InterruptedException , <nl> + ExecutionException , TimeoutException { <nl> + SecurityContext executorContext = SecurityContextHolder . getContext ( ) ; <nl> + SecurityContextHolder . setContext ( initialContext ) ; <nl> + try { <nl> + return service . invokeAny ( tasks , timeout , unit ) ; <nl> + } finally { <nl> + SecurityContextHolder . setContext ( executorContext ) ; <nl> + } <nl> + } <nl> + public boolean isShutdown ( ) { <nl> + return service . isShutdown ( ) ; <nl> + } <nl> + public boolean isTerminated ( ) { <nl> + return service . isTerminated ( ) ; <nl> + } <nl> + public void shutdown ( ) { <nl> + service . shutdown ( ) ; <nl> + } <nl> + public List < Runnable > shutdownNow ( ) { <nl> + return service . shutdownNow ( ) ; <nl> + } <nl> + public < T > Future < T > submit ( Callable < T > task ) { <nl> + SecurityContext executorContext = SecurityContextHolder . getContext ( ) ; <nl> + SecurityContextHolder . setContext ( initialContext ) ; <nl> + try { <nl> + return service . submit ( task ) ; <nl> + } finally { <nl> + SecurityContextHolder . setContext ( executorContext ) ; <nl> + } <nl> + } <nl> + public Future < ? > submit ( Runnable task ) { <nl> + SecurityContext executorContext = SecurityContextHolder . getContext ( ) ; <nl> + SecurityContextHolder . setContext ( initialContext ) ; <nl> + try { <nl> + return service . submit ( task ) ; <nl> + } finally { <nl> + SecurityContextHolder . setContext ( executorContext ) ; <nl> + } <nl> + } <nl> + public < T > Future < T > submit ( Runnable task , T result ) { <nl> + SecurityContext executorContext = SecurityContextHolder . getContext ( ) ; <nl> + SecurityContextHolder . setContext ( initialContext ) ; <nl> + try { <nl> + return service . submit ( task , result ) ; <nl> + } finally { <nl> + SecurityContextHolder . setContext ( executorContext ) ; <nl> + } <nl> + } <nl> + <nl> + } <nl>\n", "msg": "[ JENKINS - 17510 ] Adding SecurityContextExecutorService - a wrapper to provide security context to each executor\n"}
{"diff_id": 15536, "repo": "SeleniumHQ/selenium\n", "sha": "9162e5c12499a10d436deea6b86c53b0a64e46fd\n", "time": "2011-12-03T04:24:55Z\n", "diff": "mmm a / java / server / src / org / openqa / grid / internal / RemoteProxy . java <nl> ppp b / java / server / src / org / openqa / grid / internal / RemoteProxy . java <nl> <nl> import java . io . IOException ; <nl> import java . io . InputStreamReader ; <nl> import java . lang . reflect . Constructor ; <nl> + import java . lang . reflect . InvocationTargetException ; <nl> import java . net . MalformedURLException ; <nl> import java . net . URL ; <nl> import java . security . InvalidParameterException ; <nl> public RemoteProxy ( RegistrationRequest request , Registry registry ) { <nl> } <nl> <nl> private SeleniumProtocol getProtocol ( DesiredCapabilities capability ) { <nl> - String type = ( String ) capability . getCapability ( SELENIUM_PROTOCOL ) ; <nl> + / / Older grid nodes will return a value from the SeleniumProtocol enum , newer nodes will return a String . <nl> + / / Ultimately we can treat both as Strings or enum values , so stick with Object as a variant type . <nl> + Object type = capability . getCapability ( SELENIUM_PROTOCOL ) ; <nl> <nl> SeleniumProtocol protocol ; <nl> if ( type = = null ) { <nl> protocol = SeleniumProtocol . WebDriver ; <nl> } else { <nl> try { <nl> - protocol = SeleniumProtocol . valueOf ( type ) ; <nl> + protocol = SeleniumProtocol . valueOf ( type . toString ( ) ) ; <nl> } catch ( IllegalArgumentException e ) { <nl> throw new GridException ( type <nl> - + \" isn ' t a valid protocol type for grid . See SeleniumProtocol enim . \" , e ) ; <nl> + + \" isn ' t a valid protocol type for grid . See SeleniumProtocol enum . \" , e ) ; <nl> } <nl> } <nl> return protocol ; <nl> protected boolean isBusy ( ) { <nl> ( ( RemoteProxy ) proxy ) . setupTimeoutListener ( ) ; <nl> return ( T ) proxy ; <nl> } else { <nl> - throw new InvalidParameterException ( \" Error : \" + proxy . getClass ( ) + \" isn ' t a remote proxy \" ) ; <nl> + throw new InvalidParameterException ( \" Error : \" + proxy . getClass ( ) + \" isn ' t a remote proxy \" ) ; <nl> } <nl> + } catch ( InvocationTargetException e ) { <nl> + e . getTargetException ( ) . printStackTrace ( ) ; <nl> + throw new InvalidParameterException ( \" Error : \" + e . getTargetException ( ) . getMessage ( ) ) ; <nl> } catch ( Exception e ) { <nl> e . printStackTrace ( ) ; <nl> - throw new InvalidParameterException ( \" Error : \" + e . getMessage ( ) ) ; <nl> + throw new InvalidParameterException ( \" Error : \" + e . getMessage ( ) ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "KevinMenard : Fixed an issue with older RC nodes registering with a newer hub .\n"}
{"diff_id": 15564, "repo": "libgdx/libgdx\n", "sha": "1932b837af9458ce4aaf54a420ab96b2d2f38371\n", "time": "2013-06-20T19:01:22Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / graphics / g3d / shaders / CompositeShader . java <nl> ppp b / gdx / src / com / badlogic / gdx / graphics / g3d / shaders / CompositeShader . java <nl> private void init ( Renderable renderable ) { <nl> } <nl> } <nl> <nl> + @ Override <nl> + public void init ( ) { <nl> + } <nl> + <nl> @ Override <nl> public int compareTo ( Shader other ) { <nl> return 0 ; <nl>\n", "msg": "CompositeShader , add unimplemented method to fix warning\n"}
{"diff_id": 15673, "repo": "jenkinsci/jenkins\n", "sha": "54f4733cd009d98d912b20c0f546db5e24bc3d66\n", "time": "2018-10-24T18:35:15Z\n", "diff": "mmm a / core / src / main / java / hudson / slaves / SlaveComputer . java <nl> ppp b / core / src / main / java / hudson / slaves / SlaveComputer . java <nl> protected void kill ( ) { <nl> <nl> public RetentionStrategy getRetentionStrategy ( ) { <nl> Slave n = getNode ( ) ; <nl> - return n = = null ? RetentionStrategy . INSTANCE : n . getRetentionStrategy ( ) ; <nl> + return n = = null ? RetentionStrategy . NOOP : n . getRetentionStrategy ( ) ; <nl> } <nl> <nl> / * * <nl>\n", "msg": "SlaveComputer . getRetentionStrategy was using Always when there was no node , leading to launches of unused agent JVMs .\n"}
{"diff_id": 15696, "repo": "iluwatar/java-design-patterns\n", "sha": "6ed842e58bab97bc7eebe47575838a0b1f0910d7\n", "time": "2016-09-22T18:34:46Z\n", "diff": "mmm a / caching / src / main / java / com / iluwatar / caching / AppManager . java <nl> ppp b / caching / src / main / java / com / iluwatar / caching / AppManager . java <nl> public static void initDb ( boolean useMongoDb ) { <nl> public static void initCachingPolicy ( CachingPolicy policy ) { <nl> cachingPolicy = policy ; <nl> if ( cachingPolicy = = CachingPolicy . BEHIND ) { <nl> - Runtime . getRuntime ( ) . addShutdownHook ( new Thread ( new Runnable ( ) { <nl> - @ Override <nl> - public void run ( ) { <nl> - CacheStore . flushCache ( ) ; <nl> - } <nl> - } ) ) ; <nl> + Runtime . getRuntime ( ) . addShutdownHook ( new Thread ( CacheStore : : flushCache ) ) ; <nl> } <nl> CacheStore . clearCache ( ) ; <nl> } <nl>\n", "msg": "Caching pattern : Refactor shutdown hook to use method reference\n"}
{"diff_id": 15798, "repo": "bazelbuild/bazel\n", "sha": "cbd8789f46258d3d900bc69ed6cd36c1c46c51bb\n", "time": "2016-05-17T16:17:49Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / rules / python / PyCommon . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / python / PyCommon . java <nl> public Artifact createPycFile ( <nl> SpawnAction . Builder builder = new SpawnAction . Builder ( ) <nl> . setResources ( PY_COMPILE_RESOURCE_SET ) <nl> . setExecutable ( pythonBinary ) <nl> - . setProgressMessage ( \" Compiling Python \" ) <nl> + . setProgressMessage ( \" Compiling Python \" + source . prettyPrint ( ) ) <nl> . addInputArgument ( <nl> ruleContext . getPrerequisiteArtifact ( pythonPrecompileAttribute , Mode . HOST ) ) <nl> . setMnemonic ( \" PyCompile \" ) ; <nl>\n", "msg": "Improve progress message of the actions triggered by - - precompile_python .\n"}
{"diff_id": 16040, "repo": "apache/flink\n", "sha": "0ffe9dcba7d3ff92ae152c3599b413a37ea0f47e\n", "time": "2015-11-01T19:57:40Z\n", "diff": "mmm a / flink - quickstart / flink - tez - quickstart / src / main / resources / archetype - resources / src / main / java / Driver . java <nl> ppp b / flink - quickstart / flink - tez - quickstart / src / main / resources / archetype - resources / src / main / java / Driver . java <nl> <nl> - # set ( $ hash = ' # ' ) <nl> - <nl> package $ { package } ; <nl> <nl> / * <nl> <nl> <nl> public class Driver { <nl> <nl> - private static final DecimalFormat formatter = new DecimalFormat ( \" $ { hash } $ { hash } $ { hash } . $ { hash } $ { hash } % \" ) ; <nl> + private static final DecimalFormat formatter = new DecimalFormat ( \" # # # . # # % \" ) ; <nl> <nl> public static void main ( String [ ] args ) { <nl> int exitCode = - 1 ; <nl>\n", "msg": "[ tez ] remove unused hash variable\n"}
{"diff_id": 16088, "repo": "elastic/elasticsearch\n", "sha": "72ad72248034b2368c8931bb08bc060c73d6e701\n", "time": "2011-10-15T13:35:14Z\n", "diff": "mmm a / modules / elasticsearch / src / main / java / org / elasticsearch / common / lucene / docset / DocSets . java <nl> ppp b / modules / elasticsearch / src / main / java / org / elasticsearch / common / lucene / docset / DocSets . java <nl> public static void and ( FixedBitSet into , DocIdSet other ) throws IOException { <nl> } <nl> } else { <nl> if ( other = = null ) { <nl> - into . clear ( 0 , into . length ( ) + 1 ) ; <nl> + into . clear ( 0 , into . length ( ) ) ; <nl> } else { <nl> / / copied from OpenBitSetDISI # inPlaceAnd <nl> DocIdSetIterator disi = other . iterator ( ) ; <nl> if ( disi = = null ) { <nl> - into . clear ( 0 , into . length ( ) + 1 ) ; <nl> + into . clear ( 0 , into . length ( ) ) ; <nl> } else { <nl> int bitSetDoc = into . nextSetBit ( 0 ) ; <nl> int disiDoc ; <nl> public static void and ( FixedBitSet into , DocIdSet other ) throws IOException { <nl> bitSetDoc = into . nextSetBit ( disiDoc + 1 ) ; <nl> } <nl> if ( bitSetDoc ! = - 1 ) { <nl> - into . clear ( bitSetDoc , into . length ( ) + 1 ) ; <nl> + into . clear ( bitSetDoc , into . length ( ) ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Array out - of - bounds exception with bool filter , closes .\n"}
{"diff_id": 16189, "repo": "netty/netty\n", "sha": "a8830aee4252864370167c8ed72e1ef79ef3824d\n", "time": "2013-05-17T19:19:59Z\n", "diff": "similarity index 98 % <nl> rename from transport / src / main / java / io / netty / channel / group / ImmediateEventExecutor . java <nl> rename to common / src / main / java / io / netty / util / concurrent / ImmediateEventExecutor . java <nl> mmm a / transport / src / main / java / io / netty / channel / group / ImmediateEventExecutor . java <nl> ppp b / common / src / main / java / io / netty / util / concurrent / ImmediateEventExecutor . java <nl> <nl> * License for the specific language governing permissions and limitations <nl> * under the License . <nl> * / <nl> - package io . netty . channel . group ; <nl> + package io . netty . util . concurrent ; <nl> <nl> import io . netty . util . concurrent . AbstractEventExecutor ; <nl> import io . netty . util . concurrent . DefaultPromise ; <nl>\n", "msg": "[ ] Move ImmediateEventExecutor to common and let it access via a static public field\n"}
{"diff_id": 16278, "repo": "SeleniumHQ/selenium\n", "sha": "18dfc4c3d4f40fd1ea39f1fb09d93fec9f3895b8\n", "time": "2020-01-16T11:04:42Z\n", "diff": "new file mode 100644 <nl> index 00000000000 . . 4f48c727dd4 <nl> mmm / dev / null <nl> ppp b / java / server / src / org / openqa / selenium / grid / commands / MessageBusCommand . java <nl> <nl> + / / Licensed to the Software Freedom Conservancy ( SFC ) under one <nl> + / / or more contributor license agreements . See the NOTICE file <nl> + / / distributed with this work for additional information <nl> + / / regarding copyright ownership . The SFC licenses this file <nl> + / / to you under the Apache License , Version 2 . 0 ( the <nl> + / / \" License \" ) ; you may not use this file except in compliance <nl> + / / with the License . You may obtain a copy of the License at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + / / <nl> + / / Unless required by applicable law or agreed to in writing , <nl> + / / software distributed under the License is distributed on an <nl> + / / \" AS IS \" BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY <nl> + / / KIND , either express or implied . See the License for the <nl> + / / specific language governing permissions and limitations <nl> + / / under the License . <nl> + <nl> + package org . openqa . selenium . grid . commands ; <nl> + <nl> + import com . beust . jcommander . JCommander ; <nl> + import com . beust . jcommander . ParameterException ; <nl> + import com . google . auto . service . AutoService ; <nl> + import com . google . common . collect . ImmutableMap ; <nl> + import com . google . common . net . MediaType ; <nl> + import org . openqa . selenium . BuildInfo ; <nl> + import org . openqa . selenium . cli . CliCommand ; <nl> + import org . openqa . selenium . events . EventBus ; <nl> + import org . openqa . selenium . grid . config . AnnotatedConfig ; <nl> + import org . openqa . selenium . grid . config . CompoundConfig ; <nl> + import org . openqa . selenium . grid . config . ConcatenatingConfig ; <nl> + import org . openqa . selenium . grid . config . Config ; <nl> + import org . openqa . selenium . grid . config . EnvConfig ; <nl> + import org . openqa . selenium . grid . config . MapConfig ; <nl> + import org . openqa . selenium . grid . log . LoggingOptions ; <nl> + import org . openqa . selenium . grid . server . BaseServerFlags ; <nl> + import org . openqa . selenium . grid . server . BaseServerOptions ; <nl> + import org . openqa . selenium . grid . server . EventBusFlags ; <nl> + import org . openqa . selenium . grid . server . EventBusOptions ; <nl> + import org . openqa . selenium . grid . server . HelpFlags ; <nl> + import org . openqa . selenium . grid . server . Server ; <nl> + import org . openqa . selenium . netty . server . NettyServer ; <nl> + import org . openqa . selenium . remote . http . Contents ; <nl> + import org . openqa . selenium . remote . http . HttpResponse ; <nl> + import org . openqa . selenium . remote . http . Route ; <nl> + <nl> + import java . util . logging . Logger ; <nl> + <nl> + @ AutoService ( CliCommand . class ) <nl> + public class MessageBusCommand implements CliCommand { <nl> + private static final Logger LOG = Logger . getLogger ( MessageBusCommand . class . getName ( ) ) ; <nl> + <nl> + @ Override <nl> + public String getName ( ) { <nl> + return \" message - bus \" ; <nl> + } <nl> + <nl> + @ Override <nl> + public String getDescription ( ) { <nl> + return \" Standalone instance of the message bus . \" ; <nl> + } <nl> + <nl> + @ Override <nl> + public boolean isShown ( ) { <nl> + return false ; <nl> + } <nl> + <nl> + @ Override <nl> + public Executable configure ( String . . . args ) { <nl> + HelpFlags help = new HelpFlags ( ) ; <nl> + BaseServerFlags baseFlags = new BaseServerFlags ( 5557 ) ; <nl> + EventBusFlags eventBusFlags = new EventBusFlags ( ) ; <nl> + <nl> + JCommander commander = JCommander . newBuilder ( ) <nl> + . programName ( \" standalone \" ) <nl> + . addObject ( baseFlags ) <nl> + . addObject ( eventBusFlags ) <nl> + . addObject ( help ) <nl> + . build ( ) ; <nl> + <nl> + return ( ) - > { <nl> + try { <nl> + commander . parse ( args ) ; <nl> + } catch ( ParameterException e ) { <nl> + System . err . println ( e . getMessage ( ) ) ; <nl> + commander . usage ( ) ; <nl> + return ; <nl> + } <nl> + <nl> + if ( help . displayHelp ( commander , System . out ) ) { <nl> + return ; <nl> + } <nl> + <nl> + Config config = new CompoundConfig ( <nl> + new EnvConfig ( ) , <nl> + new ConcatenatingConfig ( \" message - bus \" , ' . ' , System . getProperties ( ) ) , <nl> + new AnnotatedConfig ( help ) , <nl> + new AnnotatedConfig ( eventBusFlags ) , <nl> + new AnnotatedConfig ( baseFlags ) , <nl> + new MapConfig ( ImmutableMap . of ( <nl> + \" events \" , ImmutableMap . of ( <nl> + \" bind \" , true , <nl> + \" publish \" , \" tcp : / / * : 4442 \" , <nl> + \" subscribe \" , \" tcp : / / * : 4443 \" ) ) ) ) ; <nl> + <nl> + LoggingOptions loggingOptions = new LoggingOptions ( config ) ; <nl> + loggingOptions . configureLogging ( ) ; <nl> + <nl> + EventBusOptions events = new EventBusOptions ( config ) ; <nl> + / / We need this reference to stop the bus being garbage collected . Which would be less than ideal . <nl> + EventBus bus = events . getEventBus ( ) ; <nl> + <nl> + BaseServerOptions serverOptions = new BaseServerOptions ( config ) ; <nl> + <nl> + Server < ? > server = new NettyServer ( <nl> + serverOptions , <nl> + Route . get ( \" / status \" ) . to ( ( ) - > req - > <nl> + new HttpResponse ( ) <nl> + . addHeader ( \" Content - Type \" , MediaType . JSON_UTF_8 . toString ( ) ) <nl> + . setContent ( Contents . asJson ( ImmutableMap . of ( \" ready \" , true , \" message \" , \" Event bus running \" ) ) ) ) ) ; <nl> + server . start ( ) ; <nl> + <nl> + BuildInfo info = new BuildInfo ( ) ; <nl> + LOG . info ( String . format ( \" Started Selenium message bus % s ( revision % s ) \" , info . getReleaseLabel ( ) , info . getBuildRevision ( ) ) ) ; <nl> + <nl> + / / If we exit , the bus goes out of scope , and it ' s closed <nl> + Thread . currentThread ( ) . join ( ) ; <nl> + <nl> + LOG . info ( \" Shutting down : \" + bus ) ; <nl> + } ; <nl> + } <nl> + } <nl>\n", "msg": "[ grid ] Add a command to run the message bus as a standalone component\n"}
{"diff_id": 16399, "repo": "jenkinsci/jenkins\n", "sha": "9492baf125f10576b2bf0369835739cad146b092\n", "time": "2014-05-28T22:30:26Z\n", "diff": "mmm a / core / src / main / java / hudson / scm / SCM . java <nl> ppp b / core / src / main / java / hudson / scm / SCM . java <nl> protected final String nullify ( String s ) { <nl> <nl> return r ; <nl> } <nl> + <nl> + @ Deprecated <nl> + public static List < SCMDescriptor < ? > > _for ( final AbstractProject project ) { <nl> + return _for ( ( Job ) project ) ; <nl> + } <nl> } <nl>\n", "msg": "Need to retain original signature of _for ( AbstractProject ) for binary compatibility .\n"}
{"diff_id": 16447, "repo": "oracle/graal\n", "sha": "fafcfac30a4956cb54b7a27f724d17e4459853c8\n", "time": "2015-01-20T22:16:14Z\n", "diff": "mmm a / graal / com . oracle . graal . compiler . common / src / com / oracle / graal / compiler / common / type / ArithmeticOpTable . java <nl> ppp b / graal / com . oracle . graal . compiler . common / src / com / oracle / graal / compiler / common / type / ArithmeticOpTable . java <nl> private ArithmeticOpTable ( UnaryOp < Neg > neg , BinaryOp < Add > add , BinaryOp < Sub > sub <nl> this . floatConvert = new FloatConvertOp [ FloatConvert . values ( ) . length ] ; <nl> floatConvert . forEach ( op - > this . floatConvert [ op . getFloatConvert ( ) . ordinal ( ) ] = op ) ; <nl> <nl> - this . hash = Objects . hash ( neg , add , sub , mul , div , rem , not , and , or , xor , shl , shr , ushr , abs , sqrt , zeroExtend , signExtend , narrow , floatConvert ) ; <nl> + this . hash = Objects . hash ( neg , add , sub , mul , div , rem , not , and , or , xor , shl , shr , ushr , abs , sqrt , zeroExtend , signExtend , narrow ) ; <nl> } <nl> <nl> @ Override <nl>\n", "msg": "made some hash codes stable across VM executions to support replay compilation\n"}
{"diff_id": 16581, "repo": "bazelbuild/bazel\n", "sha": "1707cba6adb993e8b0f8520c563e7a66597c45a4\n", "time": "2018-08-01T17:25:33Z\n", "diff": "mmm a / src / tools / android / java / com / google / devtools / build / android / aapt2 / ProtoApk . java <nl> ppp b / src / tools / android / java / com / google / devtools / build / android / aapt2 / ProtoApk . java <nl> <nl> import com . android . aapt . Resources . ConfigValue ; <nl> import com . android . aapt . Resources . Entry ; <nl> import com . android . aapt . Resources . FileReference ; <nl> - import com . android . aapt . Resources . FileReference . Type ; <nl> import com . android . aapt . Resources . Item ; <nl> import com . android . aapt . Resources . Package ; <nl> import com . android . aapt . Resources . Plural ; <nl> import com . android . aapt . Resources . Reference ; <nl> import com . android . aapt . Resources . ResourceTable ; <nl> import com . android . aapt . Resources . Style ; <nl> + import com . android . aapt . Resources . Type ; <nl> import com . android . aapt . Resources . Value ; <nl> import com . android . aapt . Resources . XmlAttribute ; <nl> import com . android . aapt . Resources . XmlElement ; <nl> <nl> import com . google . common . base . Preconditions ; <nl> import com . google . common . collect . ImmutableList ; <nl> import com . google . common . collect . ImmutableMap ; <nl> + import java . io . Closeable ; <nl> import java . io . IOException ; <nl> import java . io . InputStream ; <nl> + import java . io . OutputStream ; <nl> import java . io . UnsupportedEncodingException ; <nl> import java . net . URI ; <nl> import java . nio . ByteBuffer ; <nl> import java . nio . ByteOrder ; <nl> import java . nio . file . FileSystem ; <nl> import java . nio . file . FileSystems ; <nl> + import java . nio . file . FileVisitResult ; <nl> import java . nio . file . Files ; <nl> import java . nio . file . Path ; <nl> + import java . nio . file . SimpleFileVisitor ; <nl> + import java . nio . file . StandardOpenOption ; <nl> + import java . nio . file . attribute . BasicFileAttributes ; <nl> import java . util . ArrayList ; <nl> import java . util . List ; <nl> + import java . util . function . BiPredicate ; <nl> <nl> - / * * Provides an interface to an apk in proto format . * / <nl> - public class ProtoApk { <nl> + / * * <nl> + * Provides an interface to an apk in proto format . Since the apk is backed by a zip , it is <nl> + * important to close the ProtoApk when done . <nl> + * / <nl> + public class ProtoApk implements Closeable { <nl> <nl> private static final String RESOURCE_TABLE = \" resources . pb \" ; <nl> private static final String MANIFEST = \" AndroidManifest . xml \" ; <nl> + private static final String RES_DIRECTORY = \" res \" ; <nl> + private final URI uri ; <nl> private final FileSystem apkFileSystem ; <nl> <nl> - private ProtoApk ( FileSystem apkFileSystem ) { <nl> + private ProtoApk ( URI uri , FileSystem apkFileSystem ) { <nl> + this . uri = uri ; <nl> this . apkFileSystem = apkFileSystem ; <nl> } <nl> <nl> / * * Reads a ProtoApk from a path and verifies that it is in the expected format . * / <nl> public static ProtoApk readFrom ( Path apkPath ) throws IOException { <nl> - final FileSystem apkFileSystem = <nl> - FileSystems . newFileSystem ( URI . create ( \" jar : \" + apkPath . toUri ( ) ) , ImmutableMap . of ( ) ) ; <nl> + final URI uri = URI . create ( \" jar : \" + apkPath . toUri ( ) ) ; <nl> + return readFrom ( uri ) ; <nl> + } <nl> <nl> + private static ProtoApk readFrom ( URI uri ) throws IOException { <nl> + final FileSystem apkFileSystem = FileSystems . newFileSystem ( uri , ImmutableMap . of ( ) ) ; <nl> Preconditions . checkArgument ( Files . exists ( apkFileSystem . getPath ( RESOURCE_TABLE ) ) ) ; <nl> Preconditions . checkArgument ( Files . exists ( apkFileSystem . getPath ( MANIFEST ) ) ) ; <nl> - return new ProtoApk ( apkFileSystem ) ; <nl> + return new ProtoApk ( URI . create ( uri . getSchemeSpecificPart ( ) ) , apkFileSystem ) ; <nl> } <nl> <nl> - / * * Visits all resource declarations and references using the { @ link ResourceVisitor } . * / <nl> - public < T extends ResourceVisitor < T > > T visitResources ( T sink ) throws IOException { <nl> + / * * <nl> + * Creates a copy of the current apk . <nl> + * <nl> + * @ param destination Path to the new apk destination . <nl> + * @ param resourceFilter A filter for determining whether a given resource will be included in the <nl> + * copy . <nl> + * @ return The new ProtoApk . <nl> + * @ throws IOException when there are issues reading the apk . <nl> + * / <nl> + public ProtoApk copy ( Path destination , BiPredicate < ResourceType , String > resourceFilter ) <nl> + throws IOException { <nl> + <nl> + final URI dstZipUri = URI . create ( \" jar : \" + destination . toUri ( ) ) ; <nl> + try ( FileSystem dstZip = <nl> + FileSystems . newFileSystem ( dstZipUri , ImmutableMap . of ( \" create \" , \" true \" ) ) ) { <nl> + <nl> + final ResourceTable . Builder dstTableBuilder = ResourceTable . newBuilder ( ) ; <nl> + final ResourceTable resourceTable = <nl> + ResourceTable . parseFrom ( Files . newInputStream ( apkFileSystem . getPath ( RESOURCE_TABLE ) ) ) ; <nl> + dstTableBuilder . setSourcePool ( resourceTable . getSourcePool ( ) ) ; <nl> + for ( Package pkg : resourceTable . getPackageList ( ) ) { <nl> + Package dstPkg = copyPackage ( resourceFilter , dstZip , pkg ) ; <nl> + if ( ! dstPkg . getTypeList ( ) . isEmpty ( ) ) { <nl> + dstTableBuilder . addPackage ( dstPkg ) ; <nl> + } <nl> + } <nl> + try ( OutputStream output = <nl> + Files . newOutputStream ( dstZip . getPath ( RESOURCE_TABLE ) , StandardOpenOption . CREATE_NEW ) ) { <nl> + dstTableBuilder . build ( ) . writeTo ( output ) ; <nl> + } <nl> + <nl> + Files . walkFileTree ( apkFileSystem . getPath ( \" / \" ) , new CopyingFileVisitor ( dstZip ) ) ; <nl> + } <nl> + <nl> + return readFrom ( dstZipUri ) ; <nl> + } <nl> + <nl> + private Package copyPackage ( <nl> + BiPredicate < ResourceType , String > resourceFilter , FileSystem dstZip , Package pkg ) <nl> + throws IOException { <nl> + Package . Builder dstPkgBuilder = Package . newBuilder ( pkg ) ; <nl> + dstPkgBuilder . clearType ( ) ; <nl> + for ( Resources . Type type : pkg . getTypeList ( ) ) { <nl> + copyResourceType ( resourceFilter , dstZip , dstPkgBuilder , type ) ; <nl> + } <nl> + return dstPkgBuilder . build ( ) ; <nl> + } <nl> + <nl> + private void copyResourceType ( <nl> + BiPredicate < ResourceType , String > resourceFilter , <nl> + FileSystem dstZip , <nl> + Package . Builder dstPkgBuilder , <nl> + Resources . Type type ) <nl> + throws IOException { <nl> + Type . Builder dstTypeBuilder = Resources . Type . newBuilder ( type ) ; <nl> + dstTypeBuilder . clearEntry ( ) ; <nl> + <nl> + ResourceType resourceType = ResourceType . getEnum ( type . getName ( ) ) ; <nl> + for ( Entry entry : type . getEntryList ( ) ) { <nl> + if ( resourceFilter . test ( resourceType , entry . getName ( ) ) ) { <nl> + copyEntry ( dstZip , dstTypeBuilder , entry ) ; <nl> + } <nl> + } <nl> + final Resources . Type dstType = dstTypeBuilder . build ( ) ; <nl> + if ( ! dstType . getEntryList ( ) . isEmpty ( ) ) { <nl> + dstPkgBuilder . addType ( dstType ) ; <nl> + } <nl> + } <nl> + <nl> + private void copyEntry ( FileSystem dstZip , Type . Builder dstTypeBuilder , Entry entry ) <nl> + throws IOException { <nl> + dstTypeBuilder . addEntry ( Entry . newBuilder ( entry ) ) ; <nl> + for ( ConfigValue configValue : entry . getConfigValueList ( ) ) { <nl> + if ( configValue . hasValue ( ) <nl> + & & configValue . getValue ( ) . hasItem ( ) <nl> + & & configValue . getValue ( ) . getItem ( ) . hasFile ( ) ) { <nl> + final String path = configValue . getValue ( ) . getItem ( ) . getFile ( ) . getPath ( ) ; <nl> + final Path resourcePath = dstZip . getPath ( path ) ; <nl> + Files . createDirectories ( resourcePath . getParent ( ) ) ; <nl> + Files . copy ( apkFileSystem . getPath ( path ) , resourcePath ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + public < T extends ResourceVisitor > T visitResources ( T visitor ) throws IOException { <nl> <nl> / / visit manifest <nl> - visitXmlResource ( apkFileSystem . getPath ( MANIFEST ) , sink . enteringManifest ( ) ) ; <nl> + visitXmlResource ( apkFileSystem . getPath ( MANIFEST ) , visitor . enteringManifest ( ) ) ; <nl> <nl> / / visit resource table and associated files . <nl> final ResourceTable resourceTable = <nl> public static ProtoApk readFrom ( Path apkPath ) throws IOException { <nl> : ImmutableList . of ( ) ; <nl> <nl> for ( Package pkg : resourceTable . getPackageList ( ) ) { <nl> - ResourcePackageVisitor pkgVisitor = sink . enteringPackage ( pkg . getPackageId ( ) . getId ( ) ) ; <nl> + ResourcePackageVisitor pkgVisitor = visitor . enteringPackage ( pkg . getPackageId ( ) . getId ( ) ) ; <nl> for ( Resources . Type type : pkg . getTypeList ( ) ) { <nl> ResourceTypeVisitor typeVisitor = <nl> pkgVisitor . enteringResourceType ( <nl> public static ProtoApk readFrom ( Path apkPath ) throws IOException { <nl> } <nl> } <nl> } <nl> - return sink ; <nl> + return visitor ; <nl> } <nl> <nl> - / / TODO ( corysmith ) : Centralize duplicated code with AndroidCompiledDataDeserializer . <nl> + / * * Return the underlying uri for this apk . * / <nl> + public URI asApk ( ) { <nl> + return uri . normalize ( ) ; <nl> + } <nl> + <nl> + / / TODO ( 72324748 ) : Centralize duplicated code with AndroidCompiledDataDeserializer . <nl> private static List < String > decodeSourcePool ( byte [ ] bytes ) throws UnsupportedEncodingException { <nl> ByteBuffer byteBuffer = ByteBuffer . wrap ( bytes ) . order ( ByteOrder . LITTLE_ENDIAN ) ; <nl> <nl> private void visitItem ( ResourceValueVisitor entryVisitor , Item item ) { <nl> <nl> private void visitFile ( ResourceValueVisitor entryVisitor , FileReference file ) { <nl> final Path path = apkFileSystem . getPath ( file . getPath ( ) ) ; <nl> - if ( file . getType ( ) = = Type . PROTO_XML ) { <nl> + if ( file . getType ( ) = = FileReference . Type . PROTO_XML ) { <nl> visitXmlResource ( path , entryVisitor . entering ( path ) ) ; <nl> - } else if ( file . getType ( ) ! = Type . PNG ) { <nl> + } else if ( file . getType ( ) ! = FileReference . Type . PNG ) { <nl> entryVisitor . acceptOpaqueFileType ( path ) ; <nl> } <nl> } <nl> private void visitReference ( ReferenceVisitor visitor , Reference ref ) { <nl> } <nl> } <nl> <nl> + @ Override <nl> + public void close ( ) throws IOException { <nl> + apkFileSystem . close ( ) ; <nl> + } <nl> + <nl> / * * Provides an entry point to recording declared and referenced resources in the apk . * / <nl> public interface ResourceVisitor < T extends ResourceVisitor < T > > { <nl> / * * Called when entering the manifest . * / <nl> default void acceptEmptyReference ( ) { <nl> / / pass <nl> } <nl> } <nl> + <nl> + private static class CopyingFileVisitor extends SimpleFileVisitor < Path > { <nl> + <nl> + private final FileSystem dstZip ; <nl> + <nl> + CopyingFileVisitor ( FileSystem dstZip ) { <nl> + this . dstZip = dstZip ; <nl> + } <nl> + <nl> + @ Override <nl> + public FileVisitResult preVisitDirectory ( Path dir , BasicFileAttributes attrs ) { <nl> + / / Skip the resources , they are copied above . <nl> + if ( dir . endsWith ( RES_DIRECTORY ) ) { <nl> + return FileVisitResult . SKIP_SUBTREE ; <nl> + } <nl> + return FileVisitResult . CONTINUE ; <nl> + } <nl> + <nl> + @ Override <nl> + @ SuppressWarnings ( \" JavaOptionalSuggestions \" ) <nl> + / / Not using Files . copy ( Path , Path ) , as it has been shown to corrupt on certain OSs when copying <nl> + / / between filesystems . <nl> + public FileVisitResult visitFile ( Path file , BasicFileAttributes attrs ) throws IOException { <nl> + if ( ! RESOURCE_TABLE . equals ( file . getFileName ( ) . toString ( ) ) & & ! Files . isDirectory ( file ) ) { <nl> + Path dest = dstZip . getPath ( file . toString ( ) ) ; <nl> + Files . createDirectories ( dest . getParent ( ) ) ; <nl> + try ( InputStream in = Files . newInputStream ( file ) ) { <nl> + Files . copy ( in , dest ) ; <nl> + } <nl> + } <nl> + return FileVisitResult . CONTINUE ; <nl> + } <nl> + } <nl> } <nl>\n", "msg": "Add the ability to do a filtered copy of a ProtoApk\n"}
{"diff_id": 16589, "repo": "oracle/graal\n", "sha": "42d251fbc414eca2b4ac4ac873a78e931fb66cb7\n", "time": "2014-06-24T21:22:39Z\n", "diff": "mmm a / graal / com . oracle . graal . compiler . test / src / com / oracle / graal / compiler / test / GraalCompilerTest . java <nl> ppp b / graal / com . oracle . graal . compiler . test / src / com / oracle / graal / compiler / test / GraalCompilerTest . java <nl> protected static String getCanonicalGraphString ( StructuredGraph graph , boolean e <nl> } <nl> result . append ( \" \\ n \" ) ; <nl> for ( Node node : schedule . getBlockToNodesMap ( ) . get ( block ) ) { <nl> - if ( node . recordsUsages ( ) ) { <nl> + if ( node . isAlive ( ) & & node . recordsUsages ( ) ) { <nl> if ( ! excludeVirtual | | ! ( node instanceof VirtualObjectNode | | node instanceof ProxyNode ) ) { <nl> int id ; <nl> if ( canonicalId . get ( node ) ! = null ) { <nl>\n", "msg": "handle dead - code eliminated nodes in GraalCOmpilerTest . getCanonicalGraphString\n"}
{"diff_id": 16610, "repo": "spring-projects/spring-boot\n", "sha": "03fce55cdb1477fdd7992fb1f1da255db1134293\n", "time": "2017-11-27T10:44:53Z\n", "diff": "mmm a / spring - boot - project / spring - boot - test / src / test / java / org / springframework / boot / test / util / TestPropertyValuesTests . java <nl> ppp b / spring - boot - project / spring - boot - test / src / test / java / org / springframework / boot / test / util / TestPropertyValuesTests . java <nl> public void applyToSystemPropertySource ( ) throws Exception { <nl> Type . SYSTEM_ENVIRONMENT ) ; <nl> assertThat ( this . environment . getProperty ( \" foo . bar \" ) ) . isEqualTo ( \" BAZ \" ) ; <nl> assertThat ( this . environment . getPropertySources ( ) . contains ( <nl> - \" test - \" + StandardEnvironment . SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME ) ) . isTrue ( ) ; <nl> + \" test - \" + StandardEnvironment . SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME ) ) <nl> + . isTrue ( ) ; <nl> } <nl> <nl> @ Test <nl>\n", "msg": "Polish \" Remove a redundant dash in TestPropertyValues . Type \"\n"}
{"diff_id": 16621, "repo": "oracle/graal\n", "sha": "440e2232d368d7ab71f22e3fa3c395f0c8373778\n", "time": "2017-12-18T13:46:44Z\n", "diff": "mmm a / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / metadata / debuginfo / SourceModel . java <nl> ppp b / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / metadata / debuginfo / SourceModel . java <nl> private static MDBaseNode getDebugInfo ( MetadataAttachmentHolder holder ) { <nl> <nl> private final LinkedList < Integer > removeFromBlock = new LinkedList < > ( ) ; <nl> private int blockInstIndex = 0 ; <nl> + private DbgValueInstruction lastDbgValue = null ; <nl> <nl> private SourceFunction currentFunction = null ; <nl> private InstructionBlock currentBlock = null ; <nl> public void visit ( GlobalVariable variable ) { <nl> @ Override <nl> public void visit ( InstructionBlock block ) { <nl> currentBlock = block ; <nl> + lastDbgValue = null ; <nl> for ( blockInstIndex = 0 ; blockInstIndex < block . getInstructionCount ( ) ; blockInstIndex + + ) { <nl> block . getInstruction ( blockInstIndex ) . accept ( this ) ; <nl> } <nl> public void visit ( InstructionBlock block ) { <nl> } <nl> removeFromBlock . clear ( ) ; <nl> } <nl> - currentBlock = null ; <nl> } <nl> <nl> @ Override <nl> private void handleDebugIntrinsic ( VoidCallInstruction call , int mdlocalArgIndex , <nl> index = l ; <nl> } <nl> final DbgValueInstruction dbgValue = new DbgValueInstruction ( value , variable , index , expression ) ; <nl> - variable . addValue ( dbgValue ) ; <nl> - currentBlock . set ( blockInstIndex , dbgValue ) ; <nl> + <nl> + if ( dbgValue . equals ( lastDbgValue ) ) { <nl> + / / at higher optimization levels llvm often duplicates the @ llvm . dbg . value <nl> + / / intrinsic call , we remove it again to avoid unnecessary runtime overhead <nl> + removeFromBlock . addFirst ( blockInstIndex ) ; <nl> + <nl> + } else { <nl> + variable . addValue ( dbgValue ) ; <nl> + currentBlock . set ( blockInstIndex , dbgValue ) ; <nl> + lastDbgValue = dbgValue ; <nl> + } <nl> } <nl> } <nl> } <nl>\n", "msg": "Prevent Duplicate Emission of Calls to @ llvm . dbg . value Intrinsic\n"}
{"diff_id": 16729, "repo": "oracle/graal\n", "sha": "3b73f0f8a20db9b9e6db931dc89e0f001145aaa3\n", "time": "2014-03-18T11:39:23Z\n", "diff": "mmm a / graal / com . oracle . graal . debug / src / com / oracle / graal / debug / Debug . java <nl> ppp b / graal / com . oracle . graal . debug / src / com / oracle / graal / debug / Debug . java <nl> public static Indent logAndIndent ( String msg , Object . . . args ) { <nl> * A disabled metric has virtually no overhead . <nl> * / <nl> public static DebugMetric metric ( String name ) { <nl> - if ( Boolean . getBoolean ( ENABLE_METRIC_PROPERTY_NAME_PREFIX + name ) ) { <nl> + if ( enabledMetrics ! = null & & enabledMetrics . contains ( name ) ) { <nl> return new MetricImpl ( name , false ) ; <nl> } else if ( ENABLED ) { <nl> return new MetricImpl ( name , true ) ; <nl> public long getCurrentValue ( ) { <nl> * / <nl> public static final String ENABLE_METRIC_PROPERTY_NAME_PREFIX = \" graal . debug . metric . \" ; <nl> <nl> + private static final Set < String > enabledMetrics ; <nl> + private static final Set < String > enabledTimers ; <nl> + static { <nl> + Set < String > metrics = new HashSet < > ( ) ; <nl> + Set < String > timers = new HashSet < > ( ) ; <nl> + for ( Map . Entry < Object , Object > e : System . getProperties ( ) . entrySet ( ) ) { <nl> + String name = e . getKey ( ) . toString ( ) ; <nl> + if ( name . startsWith ( ENABLE_METRIC_PROPERTY_NAME_PREFIX ) & & Boolean . parseBoolean ( e . getValue ( ) . toString ( ) ) ) { <nl> + metrics . add ( name . substring ( ENABLE_METRIC_PROPERTY_NAME_PREFIX . length ( ) ) ) ; <nl> + } <nl> + if ( name . startsWith ( ENABLE_TIMER_PROPERTY_NAME_PREFIX ) & & Boolean . parseBoolean ( e . getValue ( ) . toString ( ) ) ) { <nl> + timers . add ( name . substring ( ENABLE_TIMER_PROPERTY_NAME_PREFIX . length ( ) ) ) ; <nl> + } <nl> + } <nl> + enabledMetrics = metrics . isEmpty ( ) ? null : metrics ; <nl> + enabledTimers = timers . isEmpty ( ) ? null : timers ; <nl> + } <nl> + <nl> / * * <nl> * Creates a { @ linkplain DebugTimer timer } that is enabled iff debugging is <nl> * { @ linkplain # isEnabled ( ) enabled } or the system property whose name is formed by adding to <nl> public long getCurrentValue ( ) { <nl> * A disabled timer has virtually no overhead . <nl> * / <nl> public static DebugTimer timer ( String name ) { <nl> - if ( Boolean . getBoolean ( ENABLE_TIMER_PROPERTY_NAME_PREFIX + name ) ) { <nl> + if ( enabledTimers ! = null & & enabledTimers . contains ( name ) ) { <nl> return new TimerImpl ( name , false ) ; <nl> } else if ( ENABLED ) { <nl> return new TimerImpl ( name , true ) ; <nl>\n", "msg": "reduced overhead of Debug . metric ( ) and Debug . timer ( ) when no metrics or timers are enabled\n"}
{"diff_id": 16906, "repo": "oracle/graal\n", "sha": "083aa76e3c40d56844201487a288ec3aadd8d7ff\n", "time": "2018-10-03T17:25:00Z\n", "diff": "mmm a / compiler / src / org . graalvm . compiler . truffle . compiler / src / org / graalvm / compiler / truffle / compiler / substitutions / TruffleGraphBuilderPlugins . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . compiler / src / org / graalvm / compiler / truffle / compiler / substitutions / TruffleGraphBuilderPlugins . java <nl> <nl> package org . graalvm . compiler . truffle . compiler . substitutions ; <nl> <nl> import static java . lang . Character . toUpperCase ; <nl> + import static org . graalvm . compiler . debug . DebugOptions . DumpOnError ; <nl> import static org . graalvm . compiler . truffle . common . TruffleCompilerOptions . TruffleUseFrameWithoutBoxing ; <nl> import static org . graalvm . compiler . truffle . common . TruffleCompilerRuntime . getRuntime ; <nl> <nl> <nl> import org . graalvm . compiler . core . common . type . StampPair ; <nl> import org . graalvm . compiler . core . common . type . TypeReference ; <nl> import org . graalvm . compiler . debug . DebugContext ; <nl> + import org . graalvm . compiler . debug . GraalError ; <nl> import org . graalvm . compiler . graph . Node ; <nl> import org . graalvm . compiler . nodes . CallTargetNode ; <nl> import org . graalvm . compiler . nodes . CallTargetNode . InvokeKind ; <nl> public boolean apply ( GraphBuilderContext b , ResolvedJavaMethod targetMethod , Rec <nl> } else if ( canDelayIntrinsification ) { <nl> return false ; <nl> } else { <nl> - throw b . bailout ( \" unsafeCast arguments could not reduce to a constant : \" + clazz + \" , \" + nonNull + \" , \" + isExactType ) ; <nl> + String message = \" unsafeCast arguments could not reduce to a constant : \" + clazz + \" , \" + nonNull + \" , \" + isExactType ; <nl> + if ( DumpOnError . getValue ( b . getOptions ( ) ) ) { <nl> + / / Produce a graph dump to diagnose GR - 8831 <nl> + throw new GraalError ( message ) ; <nl> + } <nl> + throw b . bailout ( message ) ; <nl> } <nl> } <nl> } ) ; <nl>\n", "msg": "throw a GraalError to force a graph dump\n"}
{"diff_id": 17162, "repo": "netty/netty\n", "sha": "c8fb2a84c58d6350d7dac6bd246bd140d0e46a40\n", "time": "2015-08-27T07:50:09Z\n", "diff": "mmm a / transport / src / main / java / io / netty / channel / group / DefaultChannelGroup . java <nl> ppp b / transport / src / main / java / io / netty / channel / group / DefaultChannelGroup . java <nl> public void operationComplete ( ChannelFuture future ) throws Exception { <nl> remove ( future . channel ( ) ) ; <nl> } <nl> } ; <nl> + private final boolean stayClosed ; <nl> + private volatile boolean closed ; <nl> <nl> / * * <nl> * Creates a new group with a generated name and the provided { @ link EventExecutor } to notify the <nl> * { @ link ChannelGroupFuture } s . <nl> * / <nl> public DefaultChannelGroup ( EventExecutor executor ) { <nl> - this ( \" group - 0x \" + Integer . toHexString ( nextId . incrementAndGet ( ) ) , executor ) ; <nl> + this ( executor , false ) ; <nl> } <nl> <nl> / * * <nl> public DefaultChannelGroup ( EventExecutor executor ) { <nl> * duplicate check is done against group names . <nl> * / <nl> public DefaultChannelGroup ( String name , EventExecutor executor ) { <nl> + this ( name , executor , false ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Creates a new group with a generated name and the provided { @ link EventExecutor } to notify the <nl> + * { @ link ChannelGroupFuture } s . { @ code stayClosed } defines whether or not , this group can be closed <nl> + * more than once . Adding channels to a closed group will immediately close them , too . This makes it <nl> + * easy , to shutdown server and child channels at once . <nl> + * / <nl> + public DefaultChannelGroup ( EventExecutor executor , boolean stayClosed ) { <nl> + this ( \" group - 0x \" + Integer . toHexString ( nextId . incrementAndGet ( ) ) , executor , stayClosed ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Creates a new group with the specified { @ code name } and { @ link EventExecutor } to notify the <nl> + * { @ link ChannelGroupFuture } s . { @ code stayClosed } defines whether or not , this group can be closed <nl> + * more than once . Adding channels to a closed group will immediately close them , too . This makes it <nl> + * easy , to shutdown server and child channels at once . Please note that different groups can have <nl> + * the same name , which means no duplicate check is done against group names . <nl> + * / <nl> + public DefaultChannelGroup ( String name , EventExecutor executor , boolean stayClosed ) { <nl> if ( name = = null ) { <nl> throw new NullPointerException ( \" name \" ) ; <nl> } <nl> this . name = name ; <nl> this . executor = executor ; <nl> + this . stayClosed = stayClosed ; <nl> } <nl> <nl> @ Override <nl> public boolean add ( Channel channel ) { <nl> if ( added ) { <nl> channel . closeFuture ( ) . addListener ( remover ) ; <nl> } <nl> + <nl> + if ( stayClosed & & closed ) { <nl> + <nl> + / / First add channel , than check if closed . <nl> + / / Seems inefficient at first , but this way a volatile <nl> + / / gives us enough synchronization to be thread - safe . <nl> + / / <nl> + / / If true : Close right away . <nl> + / / ( Might be closed a second time by ChannelGroup . close ( ) , but this is ok ) <nl> + / / <nl> + / / If false : Channel will definitely be closed by the ChannelGroup . <nl> + / / ( Because closed = true always happens - before ChannelGroup . close ( ) ) <nl> + / / <nl> + / / See https : / / github . com / netty / netty / issues / 4020 <nl> + channel . close ( ) ; <nl> + } <nl> + <nl> return added ; <nl> } <nl> <nl> public ChannelGroupFuture close ( ChannelMatcher matcher ) { <nl> Map < Channel , ChannelFuture > futures = <nl> new LinkedHashMap < Channel , ChannelFuture > ( size ( ) ) ; <nl> <nl> + if ( stayClosed ) { <nl> + / / It is important to set the closed to true , before closing channels . <nl> + / / Our invariants are : <nl> + / / closed = true happens - before ChannelGroup . close ( ) <nl> + / / ChannelGroup . add ( ) happens - before checking closed = = true <nl> + / / <nl> + / / See https : / / github . com / netty / netty / issues / 4020 <nl> + closed = true ; <nl> + } <nl> + <nl> for ( Channel c : serverChannels . values ( ) ) { <nl> if ( matcher . matches ( c ) ) { <nl> futures . put ( c , c . close ( ) ) ; <nl>\n", "msg": "Fix race condition of DefaultChannelGroup by introducing a closed flag .\n"}
{"diff_id": 17314, "repo": "elastic/elasticsearch\n", "sha": "59a9a0d3ef790c59006ab2f1d1ec8ebf0f7ac04a\n", "time": "2013-07-30T10:55:14Z\n", "diff": "mmm a / src / test / java / org / elasticsearch / test / integration / indices / settings / UpdateSettingsTests . java <nl> ppp b / src / test / java / org / elasticsearch / test / integration / indices / settings / UpdateSettingsTests . java <nl> <nl> import org . elasticsearch . cluster . metadata . IndexMetaData ; <nl> import org . elasticsearch . common . Priority ; <nl> import org . elasticsearch . common . settings . ImmutableSettings ; <nl> + import org . elasticsearch . index . engine . VersionConflictEngineException ; <nl> import org . elasticsearch . test . integration . AbstractSharedClusterTest ; <nl> import org . junit . Test ; <nl> <nl> - import static org . hamcrest . MatcherAssert . assertThat ; <nl> + import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertThrows ; <nl> import static org . hamcrest . Matchers . equalTo ; <nl> import static org . hamcrest . Matchers . nullValue ; <nl> <nl> public void testOpenCloseUpdateSettings ( ) throws Exception { <nl> assertThat ( indexMetaData . settings ( ) . get ( \" index . refresh_interval \" ) , equalTo ( \" 1s \" ) ) ; <nl> assertThat ( indexMetaData . settings ( ) . get ( \" index . cache . filter . type \" ) , equalTo ( \" none \" ) ) ; <nl> } <nl> + <nl> + @ Test <nl> + public void testRobinEngineGCDeletesSetting ( ) throws InterruptedException { <nl> + createIndex ( \" test \" ) ; <nl> + client ( ) . prepareIndex ( \" test \" , \" type \" , \" 1 \" ) . setSource ( \" f \" , 1 ) . get ( ) ; / / set version to 1 <nl> + client ( ) . prepareDelete ( \" test \" , \" type \" , \" 1 \" ) . get ( ) ; / / sets version to 2 <nl> + client ( ) . prepareIndex ( \" test \" , \" type \" , \" 1 \" ) . setSource ( \" f \" , 2 ) . setVersion ( 2 ) . get ( ) ; / / delete is still in cache this should work & set version to 3 <nl> + client ( ) . admin ( ) . indices ( ) . prepareUpdateSettings ( \" test \" ) <nl> + . setSettings ( ImmutableSettings . settingsBuilder ( ) <nl> + . put ( \" index . gc_deletes \" , 0 ) <nl> + ) . get ( ) ; <nl> + <nl> + client ( ) . prepareDelete ( \" test \" , \" type \" , \" 1 \" ) . get ( ) ; / / sets version to 4 <nl> + Thread . sleep ( 300 ) ; / / wait for cache time to change TODO : this needs to be solved better . To be discussed . <nl> + assertThrows ( client ( ) . prepareIndex ( \" test \" , \" type \" , \" 1 \" ) . setSource ( \" f \" , 3 ) . setVersion ( 4 ) , VersionConflictEngineException . class ) ; / / delete is should not be in cache <nl> + <nl> + } <nl> } <nl> \\ No newline at end of file <nl>\n", "msg": "Ported an 0 . 90 branch excplicit test for dynamic update of gc_delete setting for RobinEngine .\n"}
{"diff_id": 17410, "repo": "jenkinsci/jenkins\n", "sha": "ec3dbb093a42eb0b031104bc11ae010c22f30966\n", "time": "2007-12-18T06:01:15Z\n", "diff": "mmm a / core / src / main / java / hudson / security / Permission . java <nl> ppp b / core / src / main / java / hudson / security / Permission . java <nl> public String toString ( ) { <nl> * Generic delete access . <nl> * / <nl> public static final Permission DELETE = new Permission ( Permission . class , \" Generic Delete \" , WRITE ) ; <nl> + <nl> + / * * <nl> + * Generic configuration access . <nl> + * / <nl> + public static final Permission CONFIGURE = new Permission ( Permission . class , \" Generic Configure \" , WRITE ) ; <nl> } <nl>\n", "msg": "add configuration as it ' s a common pattern seen in multiple places .\n"}
{"diff_id": 17420, "repo": "oracle/graal\n", "sha": "846cdd4e5709e4ebd725f0166509df147e060da3\n", "time": "2014-02-07T11:37:34Z\n", "diff": "mmm a / graal / com . oracle . graal . compiler . test / src / com / oracle / graal / compiler / test / nfi / NativeFunctionInterfaceTest . java <nl> ppp b / graal / com . oracle . graal . compiler . test / src / com / oracle / graal / compiler / test / nfi / NativeFunctionInterfaceTest . java <nl> <nl> package com . oracle . graal . compiler . test . nfi ; <nl> <nl> import static com . oracle . graal . graph . UnsafeAccess . * ; <nl> + import static java . io . File . * ; <nl> + import static java . lang . System . * ; <nl> import static org . junit . Assert . * ; <nl> <nl> + import java . io . * ; <nl> import java . util . * ; <nl> <nl> import org . junit . * ; <nl> public void test6 ( ) { <nl> public void test7 ( ) { <nl> double result = 0 ; <nl> NativeFunctionHandle handle = ffi . getFunctionHandle ( \" pow \" , double . class , double . class , double . class ) ; <nl> - for ( int i = 0 ; i < 100000 ; i + + ) { <nl> + for ( int i = 0 ; i < 10 ; i + + ) { <nl> result = ( double ) handle . call ( 3D , 5 . 5D ) ; <nl> } <nl> assertEquals ( Math . pow ( 3D , 5 . 5D ) , result , 0 ) ; <nl> public void test8 ( ) { <nl> Assert . assertEquals ( expected . length ( ) , result ) ; <nl> } <nl> <nl> + private static double [ ] someDoubles = { 2454 . 346D , 98789 . 22D , Double . MAX_VALUE , Double . MIN_NORMAL , Double . NEGATIVE_INFINITY , Double . POSITIVE_INFINITY } ; <nl> + <nl> @ Test <nl> public void test9 ( ) { <nl> - double [ ] src = { 2454 . 346D , 98789 . 22D , Double . MAX_VALUE , Double . MIN_NORMAL , Double . NEGATIVE_INFINITY , Double . POSITIVE_INFINITY } ; <nl> + double [ ] src = someDoubles . clone ( ) ; <nl> double [ ] dst = new double [ src . length ] ; <nl> <nl> NativeFunctionHandle memcpy = ffi . getFunctionHandle ( \" memcpy \" , void . class , double [ ] . class , double [ ] . class , int . class ) ; <nl> public void test9 ( ) { <nl> <nl> assertArrayEquals ( src , dst , 0 . 0D ) ; <nl> } <nl> + <nl> + private static String getVMName ( ) { <nl> + String vmName = System . getProperty ( \" java . vm . name \" ) . toLowerCase ( ) ; <nl> + String vm = null ; <nl> + if ( vmName . contains ( \" server \" ) ) { <nl> + vm = \" server \" ; <nl> + } else if ( vmName . contains ( \" graal \" ) ) { <nl> + vm = \" graal \" ; <nl> + } else if ( vmName . contains ( \" client \" ) ) { <nl> + vm = \" client \" ; <nl> + } <nl> + <nl> + Assume . assumeTrue ( vm ! = null ) ; <nl> + return vm ; <nl> + } <nl> + <nl> + private static String getVMLibPath ( ) { <nl> + String vm = getVMName ( ) ; <nl> + <nl> + String path = String . format ( \" % s % c % s % c % s \" , getProperty ( \" sun . boot . library . path \" ) , separatorChar , vm , separatorChar , mapLibraryName ( \" jvm \" ) ) ; <nl> + / / Only continue if the library file exists <nl> + Assume . assumeTrue ( new File ( path ) . exists ( ) ) ; <nl> + return path ; <nl> + } <nl> + <nl> + @ Test <nl> + public void test10 ( ) { <nl> + NativeLibraryHandle vmLib = ffi . getLibraryHandle ( getVMLibPath ( ) ) ; <nl> + NativeFunctionHandle currentTimeMillis = ffi . getFunctionHandle ( vmLib , \" JVM_CurrentTimeMillis \" , long . class ) ; <nl> + long time1 = ( long ) currentTimeMillis . call ( ) ; <nl> + long time2 = System . currentTimeMillis ( ) ; <nl> + long delta = time2 - time1 ; <nl> + <nl> + / / The 2 calls to get the current time should not differ by more than <nl> + / / 100 milliseconds at the very most <nl> + assertTrue ( String . valueOf ( delta ) , delta > = 0 ) ; <nl> + assertTrue ( String . valueOf ( delta ) , delta < 100 ) ; <nl> + } <nl> + <nl> + private static String getJavaLibPath ( ) { <nl> + String path = String . format ( \" % s % c % s \" , getProperty ( \" sun . boot . library . path \" ) , separatorChar , mapLibraryName ( \" java \" ) ) ; <nl> + Assume . assumeTrue ( new File ( path ) . exists ( ) ) ; <nl> + return path ; <nl> + } <nl> + <nl> + private static void testD2L ( NativeFunctionHandle d2l ) { <nl> + for ( double d : someDoubles ) { <nl> + long expected = Double . doubleToRawLongBits ( d ) ; <nl> + long actual = ( long ) d2l . call ( 0L , 0L , d ) ; <nl> + assertEquals ( Double . toString ( d ) , expected , actual ) ; <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> + public void test11 ( ) { <nl> + NativeLibraryHandle javaLib = ffi . getLibraryHandle ( getJavaLibPath ( ) ) ; <nl> + NativeFunctionHandle d2l = ffi . getFunctionHandle ( javaLib , \" Java_java_lang_Double_doubleToRawLongBits \" , long . class , long . class , long . class , double . class ) ; <nl> + testD2L ( d2l ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void test12 ( ) { <nl> + NativeLibraryHandle [ ] libs = { ffi . getLibraryHandle ( getVMLibPath ( ) ) , ffi . getLibraryHandle ( getJavaLibPath ( ) ) } ; <nl> + NativeFunctionHandle d2l = ffi . getFunctionHandle ( libs , \" Java_java_lang_Double_doubleToRawLongBits \" , long . class , long . class , long . class , double . class ) ; <nl> + testD2L ( d2l ) ; <nl> + <nl> + NativeLibraryHandle [ ] libsReveresed = { libs [ 1 ] , libs [ 0 ] } ; <nl> + d2l = ffi . getFunctionHandle ( libsReveresed , \" Java_java_lang_Double_doubleToRawLongBits \" , long . class , long . class , long . class , double . class ) ; <nl> + testD2L ( d2l ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void test13 ( ) { <nl> + NativeLibraryHandle [ ] libs = { ffi . getLibraryHandle ( getVMLibPath ( ) ) , ffi . getLibraryHandle ( getJavaLibPath ( ) ) } ; <nl> + NativeFunctionPointer functionPointer = ffi . getFunctionPointer ( libs , \" Java_java_lang_Double_doubleToRawLongBits \" ) ; <nl> + NativeFunctionHandle d2l = ffi . getFunctionHandle ( functionPointer , long . class , long . class , long . class , double . class ) ; <nl> + testD2L ( d2l ) ; <nl> + <nl> + NativeLibraryHandle [ ] libsReveresed = { libs [ 1 ] , libs [ 0 ] } ; <nl> + functionPointer = ffi . getFunctionPointer ( libsReveresed , \" Java_java_lang_Double_doubleToRawLongBits \" ) ; <nl> + d2l = ffi . getFunctionHandle ( functionPointer , long . class , long . class , long . class , double . class ) ; <nl> + testD2L ( d2l ) ; <nl> + } <nl> } <nl>\n", "msg": "added complete test coverage for NativeFunctionInterface except for getNativeFunctionPointerFromRawValue\n"}
{"diff_id": 17470, "repo": "oracle/graal\n", "sha": "bef0014d93969a9ac5c2b6ba8c07a764b4a805dc\n", "time": "2016-03-14T09:02:57Z\n", "diff": "mmm a / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / alloc / trace / lsra / TraceLinearScanLifetimeAnalysisPhase . java <nl> ppp b / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / alloc / trace / lsra / TraceLinearScanLifetimeAnalysisPhase . java <nl> private Analyser ( TraceLinearScan linearScan , TraceBuilderResult < ? > traceBuilderR <nl> <nl> private void analyze ( ) { <nl> countInstructions ( ) ; <nl> - allocator . printLir ( \" Before register allocation \" , true ) ; <nl> buildIntervals ( ) ; <nl> + allocator . printLir ( \" Before register allocation \" , true ) ; <nl> } <nl> <nl> private boolean sameTrace ( AbstractBlockBase < ? > a , AbstractBlockBase < ? > b ) { <nl>\n", "msg": "TraceRA : fix block printing for trace interval dumps .\n"}
{"diff_id": 17476, "repo": "jenkinsci/jenkins\n", "sha": "40f17ead8cb0b2bdb21a51e709b19b4e56d82a11\n", "time": "2009-05-02T19:40:20Z\n", "diff": "mmm a / core / src / main / java / hudson / model / Cause . java <nl> ppp b / core / src / main / java / hudson / model / Cause . java <nl> public String getShortDescription ( ) { <nl> private transient Cause upstreamCause ; <nl> private List < Cause > upstreamCauses = new ArrayList < Cause > ( ) ; <nl> <nl> + / / for backward bytecode compatibility <nl> + public UpstreamCause ( AbstractBuild < ? , ? > up ) { <nl> + this ( ( Run < ? , ? > ) up ) ; <nl> + } <nl> + <nl> public UpstreamCause ( Run < ? , ? > up ) { <nl> upstreamBuild = up . getNumber ( ) ; <nl> upstreamProject = up . getParent ( ) . getName ( ) ; <nl>\n", "msg": "readd the AbstractBuild constructor for UpstreamCause to maintain\n"}
{"diff_id": 17487, "repo": "libgdx/libgdx\n", "sha": "c6c48fba575148a040165b01d51ec76be17a9878\n", "time": "2011-06-26T14:00:37Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / math / Rectangle . java <nl> ppp b / gdx / src / com / badlogic / gdx / math / Rectangle . java <nl> public void set ( float x , float y , float width , float height ) { <nl> } <nl> <nl> / * * <nl> - * @ param x0 point x coordinate <nl> - * @ param y0 point y coordinate <nl> + * @ param x point x coordinate <nl> + * @ param y point y coordinate <nl> * @ return whether the point is contained in the rectangle <nl> * / <nl> public boolean contains ( float x , float y ) { <nl>\n", "msg": "[ fixed ] warning in Rectangle documentation .\n"}
{"diff_id": 17635, "repo": "jenkinsci/jenkins\n", "sha": "25075826b5d26bb8be11789a89b28fd9d11d1c2e\n", "time": "2014-08-27T15:16:52Z\n", "diff": "mmm a / core / src / main / java / jenkins / model / lazy / AbstractLazyLoadRunMap . java <nl> ppp b / core / src / main / java / jenkins / model / lazy / AbstractLazyLoadRunMap . java <nl> private Index ( Index rhs ) { <nl> * / <nl> private File dir ; <nl> <nl> + @ Restricted ( NoExternalUse . class ) / / subclassing other than by RunMap does not guarantee compatibility <nl> protected AbstractLazyLoadRunMap ( File dir ) { <nl> initBaseDir ( dir ) ; <nl> } <nl>\n", "msg": "Making various changes to ALLRM incompatible to subclasses , so be explicit that this is distinct from RunMap only for purposes of clarity and testing .\n"}
{"diff_id": 17687, "repo": "elastic/elasticsearch\n", "sha": "5328f145ef7776a1c260c0ba6eaee04665b229f8\n", "time": "2015-10-07T15:03:29Z\n", "diff": "mmm a / core / src / main / java / org / elasticsearch / common / cache / Cache . java <nl> ppp b / core / src / main / java / org / elasticsearch / common / cache / Cache . java <nl> void setRemovalListener ( RemovalListener < K , V > removalListener ) { <nl> * / <nl> protected long now ( ) { <nl> / / System . nanoTime takes non - negligible time , so we only use it if we need it <nl> + / / use System . nanoTime because we want relative time , not absolute time <nl> return entriesExpireAfterAccess | | entriesExpireAfterWrite ? System . nanoTime ( ) : 0 ; <nl> } <nl> <nl>\n", "msg": "Clarify use of System . nanoTime for measuring eviction times\n"}
{"diff_id": 17966, "repo": "netty/netty\n", "sha": "b6abefb5b803c82c0fd85409f614fc45d10eaba9\n", "time": "2012-05-19T15:08:45Z\n", "diff": "mmm a / codec - http / src / main / java / io / netty / handler / codec / http / websocketx / WebSocketClientHandshaker08 . java <nl> ppp b / codec - http / src / main / java / io / netty / handler / codec / http / websocketx / WebSocketClientHandshaker08 . java <nl> public void finishHandshake ( Channel channel , HttpResponse response ) { <nl> String subprotocol = response . getHeader ( Names . SEC_WEBSOCKET_PROTOCOL ) ; <nl> setActualSubprotocol ( subprotocol ) ; <nl> <nl> + setHandshakeComplete ( ) ; <nl> + <nl> channel . getPipeline ( ) . replace ( HttpResponseDecoder . class , \" ws - decoder \" , <nl> new WebSocket08FrameDecoder ( false , allowExtensions , this . getMaxFramePayloadLength ( ) ) ) ; <nl> <nl> - setHandshakeComplete ( ) ; <nl> } <nl> } <nl>\n", "msg": "Add a replace ( . . ) method to FrameDecoder and also to ReplayDecoder as it now extend FrameDecoder . This also fix\n"}
{"diff_id": 18046, "repo": "netty/netty\n", "sha": "476d2aea76847ccae6831d0f41a4d06d7a6e3b77\n", "time": "2017-03-19T15:08:07Z\n", "diff": "mmm a / codec / src / test / java / io / netty / handler / codec / xml / XmlFrameDecoderTest . java <nl> ppp b / codec / src / test / java / io / netty / handler / codec / xml / XmlFrameDecoderTest . java <nl> public void testDecodeWithMultipleMessages ( ) { <nl> testDecodeWithXml ( input , frame1 , frame2 , frame3 ) ; <nl> } <nl> <nl> + @ Test <nl> + public void testFraming ( ) { <nl> + testDecodeWithXml ( Arrays . asList ( \" < abc \" , \" > 123 < / a \" , \" bc > \" ) , \" < abc > 123 < / abc > \" ) ; <nl> + } <nl> + <nl> @ Test <nl> public void testDecodeWithSampleXml ( ) { <nl> for ( final String xmlSample : xmlSamples ) { <nl> public void testDecodeWithSampleXml ( ) { <nl> } <nl> } <nl> <nl> - private static void testDecodeWithXml ( String xml , Object . . . expected ) { <nl> + private static void testDecodeWithXml ( List < String > xmlFrames , Object . . . expected ) { <nl> EmbeddedChannel ch = new EmbeddedChannel ( new XmlFrameDecoder ( 1048576 ) ) ; <nl> Exception cause = null ; <nl> try { <nl> - ch . writeInbound ( Unpooled . copiedBuffer ( xml , CharsetUtil . UTF_8 ) ) ; <nl> + for ( String xmlFrame : xmlFrames ) { <nl> + ch . writeInbound ( Unpooled . copiedBuffer ( xmlFrame , CharsetUtil . UTF_8 ) ) ; <nl> + } <nl> } catch ( Exception e ) { <nl> cause = e ; <nl> } <nl> private static void testDecodeWithXml ( String xml , Object . . . expected ) { <nl> } <nl> } <nl> <nl> + private static void testDecodeWithXml ( String xml , Object . . . expected ) { <nl> + testDecodeWithXml ( Collections . singletonList ( xml ) , expected ) ; <nl> + } <nl> + <nl> private String sample ( String number ) throws IOException , URISyntaxException { <nl> String path = \" io / netty / handler / codec / xml / sample - \" + number + \" . xml \" ; <nl> URL url = getClass ( ) . getClassLoader ( ) . getResource ( path ) ; <nl>\n", "msg": "Adding method to assert XML decoder framing works\n"}
{"diff_id": 18078, "repo": "jenkinsci/jenkins\n", "sha": "c0c49727dfd69cf7a170014321dd82345381068d\n", "time": "2011-06-24T06:57:08Z\n", "diff": "mmm a / core / src / main / java / hudson / cli / GroovyCommand . java <nl> ppp b / core / src / main / java / hudson / cli / GroovyCommand . java <nl> protected int run ( ) throws Exception { <nl> private String loadScript ( ) throws CmdLineException , IOException , InterruptedException { <nl> if ( script = = null ) <nl> throw new CmdLineException ( null , \" No script is specified \" ) ; <nl> + if ( script . equals ( \" = \" ) ) <nl> + return IOUtils . toString ( stdin ) ; <nl> + <nl> return channel . call ( new Callable < String , IOException > ( ) { <nl> public String call ( ) throws IOException { <nl> - if ( script . equals ( \" = \" ) ) <nl> - return IOUtils . toString ( System . in ) ; <nl> - <nl> File f = new File ( script ) ; <nl> if ( f . exists ( ) ) <nl> return FileUtils . readFileToString ( f ) ; <nl>\n", "msg": "should read from stdin as the caller might be feeding it from elsewhere\n"}
{"diff_id": 18146, "repo": "spring-projects/spring-framework\n", "sha": "d2c0885e2979e9708d5d700f6a3e131bc9a770b1\n", "time": "2016-03-16T17:14:44Z\n", "diff": "mmm a / spring - context / src / main / java / org / springframework / jndi / JndiLocatorDelegate . java <nl> ppp b / spring - context / src / main / java / org / springframework / jndi / JndiLocatorDelegate . java <nl> <nl> / * <nl> - * Copyright 2002 - 2012 the original author or authors . <nl> + * Copyright 2002 - 2016 the original author or authors . <nl> * <nl> * Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> * you may not use this file except in compliance with the License . <nl> <nl> import javax . naming . InitialContext ; <nl> import javax . naming . NamingException ; <nl> <nl> + import org . springframework . core . SpringProperties ; <nl> + <nl> / * * <nl> * { @ link JndiLocatorSupport } subclass with public lookup methods , <nl> * for convenient use as a delegate . <nl> <nl> * / <nl> public class JndiLocatorDelegate extends JndiLocatorSupport { <nl> <nl> + / * * <nl> + * System property that instructs Spring to ignore a default JNDI environment , i . e . <nl> + * to always return { @ code false } from { @ link # isDefaultJndiEnvironmentAvailable ( ) } . <nl> + * < p > The default is \" false \" , allowing for regular default JNDI access e . g . in <nl> + * { @ link JndiPropertySource } . Switching this flag to { @ code true } is an optimization <nl> + * for scenarios where nothing is ever to be found for such JNDI fallback searches <nl> + * to begin with , avoiding the repeated JNDI lookup overhead . <nl> + * < p > Note that this flag just affects JNDI fallback searches , not explicitly configured <nl> + * JNDI lookups such as for a { @ code DataSource } or some other environment resource . <nl> + * The flag literally just affects code which attempts JNDI searches based on the <nl> + * { @ code JndiLocatorDelegate . isDefaultJndiEnvironmentAvailable ( ) } check : in particular , <nl> + * { @ code StandardServletEnvironment } and { @ code StandardPortletEnvironment } . <nl> + * @ since 4 . 3 <nl> + * @ see # isDefaultJndiEnvironmentAvailable ( ) <nl> + * @ see JndiPropertySource <nl> + * / <nl> + public static final String IGNORE_JNDI_PROPERTY_NAME = \" spring . jndi . ignore \" ; <nl> + <nl> + <nl> + private static final boolean shouldIgnoreDefaultJndiEnvironment = <nl> + SpringProperties . getFlag ( IGNORE_JNDI_PROPERTY_NAME ) ; <nl> + <nl> + <nl> @ Override <nl> public Object lookup ( String jndiName ) throws NamingException { <nl> return super . lookup ( jndiName ) ; <nl> public static JndiLocatorDelegate createDefaultResourceRefLocator ( ) { <nl> * { @ code false } if not <nl> * / <nl> public static boolean isDefaultJndiEnvironmentAvailable ( ) { <nl> + if ( shouldIgnoreDefaultJndiEnvironment ) { <nl> + return false ; <nl> + } <nl> try { <nl> new InitialContext ( ) . getEnvironment ( ) ; <nl> return true ; <nl>\n", "msg": "StandardServletEnvironment supports \" spring . jndi . ignore \" flag for efficient property lookups\n"}
{"diff_id": 18180, "repo": "bazelbuild/bazel\n", "sha": "245154d031aa4ba2a820b0b2bcd39baf428ce8c6\n", "time": "2019-03-01T18:08:54Z\n", "diff": "mmm a / src / test / java / com / google / devtools / build / skyframe / ParallelEvaluatorTest . java <nl> ppp b / src / test / java / com / google / devtools / build / skyframe / ParallelEvaluatorTest . java <nl> public String extractTag ( SkyKey skyKey ) { <nl> assertThat ( result . errorMap ( ) ) . doesNotContainKey ( rogueKey ) ; <nl> } <nl> <nl> + / / Explicit test that we tolerate a SkyFunction that declares different [ sequences of ] deps each <nl> + / / restart . Such behavior from a SkyFunction isn ' t desired , but Bazel - on - Skyframe does indeed do <nl> + / / this . <nl> + @ Test <nl> + public void declaresDifferentDepsAfterRestart ( ) throws Exception { <nl> + graph = new DeterministicHelper . DeterministicProcessableGraph ( new InMemoryGraphImpl ( ) ) ; <nl> + tester = new GraphTester ( ) ; <nl> + SkyKey grandChild1Key = GraphTester . toSkyKey ( \" grandChild1 \" ) ; <nl> + tester . getOrCreate ( grandChild1Key ) . setConstantValue ( new StringValue ( \" grandChild1 \" ) ) ; <nl> + SkyKey child1Key = GraphTester . toSkyKey ( \" child1 \" ) ; <nl> + tester <nl> + . getOrCreate ( child1Key ) <nl> + . addDependency ( grandChild1Key ) <nl> + . setConstantValue ( new StringValue ( \" child1 \" ) ) ; <nl> + SkyKey grandChild2Key = GraphTester . toSkyKey ( \" grandChild2 \" ) ; <nl> + tester . getOrCreate ( grandChild2Key ) . setConstantValue ( new StringValue ( \" grandChild2 \" ) ) ; <nl> + SkyKey child2Key = GraphTester . toSkyKey ( \" child2 \" ) ; <nl> + tester . getOrCreate ( child2Key ) . setConstantValue ( new StringValue ( \" child2 \" ) ) ; <nl> + SkyKey parentKey = GraphTester . toSkyKey ( \" parent \" ) ; <nl> + AtomicInteger numComputes = new AtomicInteger ( 0 ) ; <nl> + tester <nl> + . getOrCreate ( parentKey ) <nl> + . setBuilder ( <nl> + new SkyFunction ( ) { <nl> + @ Override <nl> + public SkyValue compute ( SkyKey skyKey , Environment env ) throws InterruptedException { <nl> + switch ( numComputes . incrementAndGet ( ) ) { <nl> + case 1 : <nl> + env . getValue ( child1Key ) ; <nl> + Preconditions . checkState ( env . valuesMissing ( ) ) ; <nl> + return null ; <nl> + case 2 : <nl> + env . getValue ( child2Key ) ; <nl> + Preconditions . checkState ( env . valuesMissing ( ) ) ; <nl> + return null ; <nl> + case 3 : <nl> + return new StringValue ( \" the third time ' s the charm ! \" ) ; <nl> + default : <nl> + throw new IllegalStateException ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ Override <nl> + public String extractTag ( SkyKey skyKey ) { <nl> + return null ; <nl> + } <nl> + } ) ; <nl> + EvaluationResult < StringValue > result = eval ( / * keepGoing = * / false , ImmutableList . of ( parentKey ) ) ; <nl> + assertThatEvaluationResult ( result ) . hasNoError ( ) ; <nl> + assertThatEvaluationResult ( result ) <nl> + . hasEntryThat ( parentKey ) <nl> + . isEqualTo ( new StringValue ( \" the third time ' s the charm ! \" ) ) ; <nl> + } <nl> + <nl> private void runUnhandledTransitiveErrors ( boolean keepGoing , <nl> final boolean explicitlyPropagateError ) throws Exception { <nl> graph = new DeterministicHelper . DeterministicProcessableGraph ( new InMemoryGraphImpl ( ) ) ; <nl>\n", "msg": "Add explicit unit test for the case where a SkyFunction doesn ' t request the same deps on each restart .\n"}
{"diff_id": 18205, "repo": "bazelbuild/bazel\n", "sha": "3eeb660ef4a7d175669995ba8139218b052b3b51\n", "time": "2017-04-30T21:11:49Z\n", "diff": "new file mode 100644 <nl> index 000000000000 . . 1ef476f87f4b <nl> mmm / dev / null <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / android / AndroidLocalTestBase . java <nl> <nl> + / / Copyright 2017 The Bazel Authors . All rights reserved . <nl> + / / <nl> + / / Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> + / / you may not use this file except in compliance with the License . <nl> + / / You may obtain a copy of the License at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + / / <nl> + / / Unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the License is distributed on an \" AS IS \" BASIS , <nl> + / / WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + / / See the License for the specific language governing permissions and <nl> + / / limitations under the License . package com . google . devtools . build . lib . rules . android ; <nl> + package com . google . devtools . build . lib . rules . android ; <nl> + <nl> + import static com . google . devtools . build . lib . packages . BuildType . LABEL_LIST ; <nl> + import static com . google . devtools . build . lib . rules . java . DeployArchiveBuilder . Compression . COMPRESSED ; <nl> + <nl> + import com . google . common . base . Joiner ; <nl> + import com . google . common . collect . ImmutableList ; <nl> + import com . google . common . collect . ImmutableMap ; <nl> + import com . google . common . collect . Iterables ; <nl> + import com . google . common . collect . Sets ; <nl> + import com . google . devtools . build . lib . actions . Artifact ; <nl> + import com . google . devtools . build . lib . analysis . ConfiguredTarget ; <nl> + import com . google . devtools . build . lib . analysis . FileProvider ; <nl> + import com . google . devtools . build . lib . analysis . RuleConfiguredTarget . Mode ; <nl> + import com . google . devtools . build . lib . analysis . RuleConfiguredTargetBuilder ; <nl> + import com . google . devtools . build . lib . analysis . RuleContext ; <nl> + import com . google . devtools . build . lib . analysis . Runfiles ; <nl> + import com . google . devtools . build . lib . analysis . RunfilesProvider ; <nl> + import com . google . devtools . build . lib . analysis . RunfilesSupport ; <nl> + import com . google . devtools . build . lib . analysis . TransitiveInfoCollection ; <nl> + import com . google . devtools . build . lib . collect . nestedset . NestedSet ; <nl> + import com . google . devtools . build . lib . collect . nestedset . NestedSetBuilder ; <nl> + import com . google . devtools . build . lib . rules . RuleConfiguredTargetFactory ; <nl> + import com . google . devtools . build . lib . rules . android . AndroidLibraryAarProvider . Aar ; <nl> + import com . google . devtools . build . lib . rules . java . ClasspathConfiguredFragment ; <nl> + import com . google . devtools . build . lib . rules . java . DeployArchiveBuilder ; <nl> + import com . google . devtools . build . lib . rules . java . JavaCommon ; <nl> + import com . google . devtools . build . lib . rules . java . JavaCompilationArgsProvider ; <nl> + import com . google . devtools . build . lib . rules . java . JavaCompilationArtifacts ; <nl> + import com . google . devtools . build . lib . rules . java . JavaCompilationHelper ; <nl> + import com . google . devtools . build . lib . rules . java . JavaHelper ; <nl> + import com . google . devtools . build . lib . rules . java . JavaPrimaryClassProvider ; <nl> + import com . google . devtools . build . lib . rules . java . JavaRuleOutputJarsProvider ; <nl> + import com . google . devtools . build . lib . rules . java . JavaRunfilesProvider ; <nl> + import com . google . devtools . build . lib . rules . java . JavaRuntimeClasspathProvider ; <nl> + import com . google . devtools . build . lib . rules . java . JavaSemantics ; <nl> + import com . google . devtools . build . lib . rules . java . JavaSkylarkApiProvider ; <nl> + import com . google . devtools . build . lib . rules . java . JavaSourceInfoProvider ; <nl> + import com . google . devtools . build . lib . rules . java . JavaSourceJarsProvider ; <nl> + import com . google . devtools . build . lib . rules . java . JavaTargetAttributes ; <nl> + import com . google . devtools . build . lib . rules . java . SingleJarActionBuilder ; <nl> + import com . google . devtools . build . lib . rules . java . proto . GeneratedExtensionRegistryProvider ; <nl> + import com . google . devtools . build . lib . syntax . Type ; <nl> + import com . google . devtools . build . lib . util . Preconditions ; <nl> + import com . google . devtools . build . lib . vfs . PathFragment ; <nl> + import java . util . ArrayList ; <nl> + import java . util . LinkedHashSet ; <nl> + import java . util . List ; <nl> + import java . util . Set ; <nl> + <nl> + / * * <nl> + * An base implementation for the \" android_local_test \" rule . <nl> + * / <nl> + public abstract class AndroidLocalTestBase implements RuleConfiguredTargetFactory { <nl> + <nl> + @ Override <nl> + public ConfiguredTarget create ( RuleContext ruleContext ) <nl> + throws InterruptedException , RuleErrorException { <nl> + <nl> + ruleContext . checkSrcsSamePackage ( true ) ; <nl> + <nl> + JavaSemantics javaSemantics = createJavaSemantics ( ) ; <nl> + <nl> + final JavaCommon javaCommon = new JavaCommon ( ruleContext , javaSemantics ) ; <nl> + / / Use the regular Java javacopts . Enforcing android - compatible Java <nl> + / / ( - source 7 - target 7 and no TWR ) is unnecessary for robolectric tests <nl> + / / since they run on a JVM , not an android device . <nl> + JavaTargetAttributes . Builder attributesBuilder = javaCommon . initCommon ( ) ; <nl> + <nl> + String testClass = <nl> + getAndCheckTestClass ( ruleContext , ImmutableList . copyOf ( attributesBuilder . getSourceFiles ( ) ) ) ; <nl> + getAndCheckTestSupport ( ruleContext ) ; <nl> + javaSemantics . checkForProtoLibraryAndJavaProtoLibraryOnSameProto ( ruleContext , javaCommon ) ; <nl> + if ( ruleContext . hasErrors ( ) ) { <nl> + return null ; <nl> + } <nl> + <nl> + Artifact srcJar = ruleContext . getImplicitOutputArtifact ( JavaSemantics . JAVA_BINARY_SOURCE_JAR ) ; <nl> + JavaSourceJarsProvider . Builder javaSourceJarsProviderBuilder = <nl> + JavaSourceJarsProvider . builder ( ) <nl> + . addSourceJar ( srcJar ) <nl> + . addAllTransitiveSourceJars ( javaCommon . collectTransitiveSourceJars ( srcJar ) ) ; <nl> + <nl> + Artifact classJar = ruleContext . getImplicitOutputArtifact ( JavaSemantics . JAVA_BINARY_CLASS_JAR ) ; <nl> + JavaRuleOutputJarsProvider . Builder javaRuleOutputJarsProviderBuilder = <nl> + JavaRuleOutputJarsProvider . builder ( ) <nl> + . addOutputJar ( <nl> + classJar , <nl> + classJar , <nl> + srcJar = = null ? ImmutableList . < Artifact > of ( ) : ImmutableList . of ( srcJar ) ) ; <nl> + <nl> + JavaCompilationArtifacts . Builder javaArtifactsBuilder = new JavaCompilationArtifacts . Builder ( ) ; <nl> + JavaCompilationHelper helper = <nl> + getJavaCompilationHelperWithDependencies ( ruleContext , javaSemantics , javaCommon , <nl> + attributesBuilder ) ; <nl> + Artifact instrumentationMetadata = <nl> + helper . createInstrumentationMetadata ( classJar , javaArtifactsBuilder ) ; <nl> + Artifact executable = ruleContext . createOutputArtifact ( ) ; / / the artifact for the rule itself <nl> + NestedSetBuilder < Artifact > filesToBuildBuilder = <nl> + NestedSetBuilder . < Artifact > stableOrder ( ) . add ( classJar ) . add ( executable ) ; <nl> + <nl> + GeneratedExtensionRegistryProvider generatedExtensionRegistryProvider = <nl> + javaSemantics . createGeneratedExtensionRegistry ( <nl> + ruleContext , <nl> + javaCommon , <nl> + filesToBuildBuilder , <nl> + javaArtifactsBuilder , <nl> + javaRuleOutputJarsProviderBuilder , <nl> + javaSourceJarsProviderBuilder ) ; <nl> + <nl> + String mainClass = <nl> + getMainClass ( <nl> + ruleContext , <nl> + javaSemantics , <nl> + helper , <nl> + executable , <nl> + instrumentationMetadata , <nl> + javaArtifactsBuilder , <nl> + attributesBuilder ) ; <nl> + <nl> + / / JavaCompilationHelper . getAttributes ( ) builds the JavaTargetAttributes , after which the <nl> + / / JavaTargetAttributes becomes immutable . This is an extra safety check to avoid inconsistent <nl> + / / states ( i . e . building the JavaTargetAttributes then modifying it again ) . <nl> + addRuntimeJarsToArtifactsBuilder ( javaArtifactsBuilder , helper . getAttributes ( ) , classJar ) ; <nl> + <nl> + / / The gensrc jar is created only if the target uses annotation processing . Otherwise , <nl> + / / it is null , and the source jar action will not depend on the compile action . <nl> + Artifact manifestProtoOutput = helper . createManifestProtoOutput ( classJar ) ; <nl> + <nl> + Artifact genClassJar = null ; <nl> + Artifact genSourceJar = null ; <nl> + if ( helper . usesAnnotationProcessing ( ) ) { <nl> + genClassJar = helper . createGenJar ( classJar ) ; <nl> + genSourceJar = helper . createGensrcJar ( classJar ) ; <nl> + helper . createGenJarAction ( classJar , manifestProtoOutput , genClassJar ) ; <nl> + } <nl> + Artifact outputDepsProtoArtifact = <nl> + helper . createOutputDepsProtoArtifact ( classJar , javaArtifactsBuilder ) ; <nl> + javaRuleOutputJarsProviderBuilder . setJdeps ( outputDepsProtoArtifact ) ; <nl> + helper . createCompileAction ( <nl> + classJar , <nl> + manifestProtoOutput , <nl> + genSourceJar , <nl> + outputDepsProtoArtifact , <nl> + instrumentationMetadata ) ; <nl> + helper . createSourceJarAction ( srcJar , genSourceJar ) ; <nl> + <nl> + setUpJavaCommon ( javaCommon , helper , javaArtifactsBuilder . build ( ) ) ; <nl> + <nl> + Artifact launcher = JavaHelper . launcherArtifactForTarget ( javaSemantics , ruleContext ) ; <nl> + <nl> + javaSemantics . createStubAction ( <nl> + ruleContext , <nl> + javaCommon , <nl> + getJvmFlags ( ruleContext , testClass ) , <nl> + executable , <nl> + mainClass , <nl> + JavaCommon . getJavaBinSubstitution ( ruleContext , launcher ) ) ; <nl> + <nl> + Artifact deployJar = <nl> + ruleContext . getImplicitOutputArtifact ( JavaSemantics . JAVA_BINARY_DEPLOY_JAR ) ; <nl> + <nl> + NestedSet < Artifact > filesToBuild = filesToBuildBuilder . build ( ) ; <nl> + <nl> + Iterable < AndroidLibraryAarProvider > androidAarProviders = <nl> + Sets . newLinkedHashSet ( <nl> + Iterables . concat ( <nl> + ruleContext . getPrerequisites ( <nl> + \" runtime_deps \" , Mode . TARGET , AndroidLibraryAarProvider . class ) , <nl> + ruleContext . getPrerequisites ( <nl> + \" deps \" , Mode . TARGET , AndroidLibraryAarProvider . class ) ) ) ; <nl> + <nl> + Runfiles defaultRunfiles = <nl> + collectDefaultRunfiles ( ruleContext , javaCommon , filesToBuild , androidAarProviders ) ; <nl> + <nl> + ImmutableList < String > cmdLineArgs = <nl> + ImmutableList . of ( <nl> + \" - - android_libraries = \" + getTransitiveLibrariesArg ( androidAarProviders ) , <nl> + \" - - strict_libraries = \" + getStrictLibrariesArg ( androidAarProviders ) ) ; <nl> + <nl> + RunfilesSupport runfilesSupport = <nl> + RunfilesSupport . withExecutable ( ruleContext , defaultRunfiles , executable , cmdLineArgs ) ; <nl> + <nl> + / / Create the deploy jar and make it dependent on the runfiles middleman if an executable is <nl> + / / created . Do not add the deploy jar to files to build , so we will only build it when it gets <nl> + / / requested . <nl> + new DeployArchiveBuilder ( javaSemantics , ruleContext ) <nl> + . setOutputJar ( deployJar ) <nl> + . setJavaStartClass ( mainClass ) <nl> + . setDeployManifestLines ( ImmutableList . < String > of ( ) ) <nl> + . setAttributes ( helper . getAttributes ( ) ) <nl> + . addRuntimeJars ( javaCommon . getJavaCompilationArtifacts ( ) . getRuntimeJars ( ) ) <nl> + . setIncludeBuildData ( true ) <nl> + . setRunfilesMiddleman ( runfilesSupport . getRunfilesMiddleman ( ) ) <nl> + . setCompression ( COMPRESSED ) <nl> + . setLauncher ( launcher ) <nl> + . build ( ) ; <nl> + <nl> + JavaSourceJarsProvider sourceJarsProvider = javaSourceJarsProviderBuilder . build ( ) ; <nl> + NestedSet < Artifact > transitiveSourceJars = sourceJarsProvider . getTransitiveSourceJars ( ) ; <nl> + <nl> + / / TODO ( bazel - team ) : if ( getOptions ( ) . sourceJars ) then make this a dummy prerequisite for the <nl> + / / DeployArchiveAction ? Needs a few changes there as we can ' t pass inputs <nl> + SingleJarActionBuilder . createSourceJarAction ( <nl> + ruleContext , <nl> + ImmutableMap . < PathFragment , Artifact > of ( ) , <nl> + transitiveSourceJars . toCollection ( ) , <nl> + ruleContext . getImplicitOutputArtifact ( JavaSemantics . JAVA_BINARY_DEPLOY_SOURCE_JAR ) ) ; <nl> + <nl> + RuleConfiguredTargetBuilder builder = new RuleConfiguredTargetBuilder ( ruleContext ) ; <nl> + <nl> + if ( generatedExtensionRegistryProvider ! = null ) { <nl> + builder . addProvider ( <nl> + GeneratedExtensionRegistryProvider . class , <nl> + generatedExtensionRegistryProvider ) ; <nl> + } <nl> + <nl> + addExtraProviders ( builder , javaCommon , classJar , srcJar , genClassJar , genSourceJar ) ; <nl> + <nl> + JavaRuleOutputJarsProvider ruleOutputJarsProvider = javaRuleOutputJarsProviderBuilder . build ( ) ; <nl> + JavaSkylarkApiProvider . Builder skylarkApiProvider = <nl> + JavaSkylarkApiProvider . builder ( ) <nl> + . setRuleOutputJarsProvider ( ruleOutputJarsProvider ) <nl> + . setSourceJarsProvider ( sourceJarsProvider ) ; <nl> + <nl> + javaCommon . addTransitiveInfoProviders ( builder , skylarkApiProvider , filesToBuild , classJar ) ; <nl> + javaCommon . addGenJarsProvider ( builder , skylarkApiProvider , genClassJar , genSourceJar ) ; <nl> + <nl> + / / No need to use the flag map here - just confirming that dynamic configurations are in use . <nl> + / / TODO ( mstaib ) : remove when static configurations are removed . <nl> + AndroidFeatureFlagSetProvider . getAndValidateFlagMapFromRuleContext ( ruleContext ) ; <nl> + <nl> + return builder <nl> + . setFilesToBuild ( filesToBuild ) <nl> + . addSkylarkTransitiveInfo ( JavaSkylarkApiProvider . NAME , skylarkApiProvider . build ( ) ) <nl> + . addProvider ( ruleOutputJarsProvider ) <nl> + . addProvider ( <nl> + RunfilesProvider . class , <nl> + RunfilesProvider . withData ( <nl> + defaultRunfiles , <nl> + new Runfiles . Builder ( ruleContext . getWorkspaceName ( ) ) <nl> + . merge ( runfilesSupport ) <nl> + . build ( ) ) ) <nl> + . setRunfilesSupport ( runfilesSupport , executable ) <nl> + . addProvider ( <nl> + JavaRuntimeClasspathProvider . class , <nl> + new JavaRuntimeClasspathProvider ( javaCommon . getRuntimeClasspath ( ) ) ) <nl> + . addProvider ( JavaSourceJarsProvider . class , sourceJarsProvider ) <nl> + . addProvider ( JavaPrimaryClassProvider . class , new JavaPrimaryClassProvider ( testClass ) ) <nl> + . addProvider ( <nl> + JavaSourceInfoProvider . class , <nl> + JavaSourceInfoProvider . fromJavaTargetAttributes ( helper . getAttributes ( ) , javaSemantics ) ) <nl> + . addOutputGroup ( JavaSemantics . SOURCE_JARS_OUTPUT_GROUP , transitiveSourceJars ) <nl> + . build ( ) ; <nl> + } <nl> + <nl> + protected abstract JavaSemantics createJavaSemantics ( ) ; <nl> + <nl> + protected abstract void addExtraProviders ( <nl> + RuleConfiguredTargetBuilder builder , <nl> + JavaCommon javaCommon , <nl> + Artifact classJar , <nl> + Artifact srcJar , <nl> + Artifact genClassJar , <nl> + Artifact genSourceJar ) ; <nl> + <nl> + protected abstract ImmutableList < String > getJvmFlags ( RuleContext ruleContext , String testClass ) ; <nl> + <nl> + protected abstract String getMainClass ( <nl> + RuleContext ruleContext , <nl> + JavaSemantics javaSemantics , <nl> + JavaCompilationHelper helper , <nl> + Artifact executable , <nl> + Artifact instrumentationMetadata , <nl> + JavaCompilationArtifacts . Builder javaArtifactsBuilder , <nl> + JavaTargetAttributes . Builder attributesBuilder ) <nl> + throws InterruptedException ; <nl> + <nl> + protected abstract JavaCompilationHelper getJavaCompilationHelperWithDependencies ( <nl> + RuleContext ruleContext , JavaSemantics javaSemantics , JavaCommon javaCommon , <nl> + JavaTargetAttributes . Builder javaTargetAttributesBuilder ) ; <nl> + <nl> + protected abstract void getJavaContracts ( <nl> + RuleContext ruleContext , List < TransitiveInfoCollection > depsForRunfiles ) ; <nl> + <nl> + protected static TransitiveInfoCollection getAndCheckTestSupport ( RuleContext ruleContext ) { <nl> + / / Add the unit test support to the list of dependencies . <nl> + TransitiveInfoCollection testSupport = null ; <nl> + TransitiveInfoCollection t = <nl> + Iterables . getOnlyElement ( ruleContext . getPrerequisites ( \" $ testsupport \" , Mode . TARGET ) ) ; <nl> + if ( t . getProvider ( JavaCompilationArgsProvider . class ) ! = null ) { <nl> + testSupport = t ; <nl> + } else { <nl> + ruleContext . attributeError ( <nl> + \" $ testsupport \" , \" this prerequisite is not a java_library rule , or contains errors \" ) ; <nl> + } <nl> + return testSupport ; <nl> + } <nl> + <nl> + private static void setUpJavaCommon ( <nl> + JavaCommon common , <nl> + JavaCompilationHelper helper , <nl> + JavaCompilationArtifacts javaCompilationArtifacts ) { <nl> + common . setJavaCompilationArtifacts ( javaCompilationArtifacts ) ; <nl> + common . setClassPathFragment ( <nl> + new ClasspathConfiguredFragment ( <nl> + common . getJavaCompilationArtifacts ( ) , <nl> + helper . getAttributes ( ) , <nl> + false , <nl> + helper . getBootclasspathOrDefault ( ) ) ) ; <nl> + } <nl> + <nl> + private static void addRuntimeJarsToArtifactsBuilder ( <nl> + JavaCompilationArtifacts . Builder javaArtifactsBuilder , <nl> + JavaTargetAttributes attributes , <nl> + Artifact classJar ) { <nl> + if ( attributes . hasSources ( ) | | attributes . hasResources ( ) ) { <nl> + / / We only want to add a jar to the classpath of a dependent rule if it has content . <nl> + javaArtifactsBuilder . addRuntimeJar ( classJar ) ; <nl> + } <nl> + } <nl> + <nl> + private Runfiles collectDefaultRunfiles ( <nl> + RuleContext ruleContext , <nl> + JavaCommon javaCommon , <nl> + NestedSet < Artifact > filesToBuild , <nl> + Iterable < AndroidLibraryAarProvider > androidLibraryAarProviders ) { <nl> + Runfiles . Builder builder = new Runfiles . Builder ( ruleContext . getWorkspaceName ( ) ) ; <nl> + builder . addTransitiveArtifacts ( filesToBuild ) ; <nl> + builder . addArtifacts ( javaCommon . getJavaCompilationArtifacts ( ) . getRuntimeJars ( ) ) ; <nl> + <nl> + builder . addRunfiles ( ruleContext , RunfilesProvider . DEFAULT_RUNFILES ) ; <nl> + builder . add ( ruleContext , JavaRunfilesProvider . TO_RUNFILES ) ; <nl> + <nl> + List < TransitiveInfoCollection > depsForRunfiles = new ArrayList < > ( ) ; <nl> + <nl> + if ( ruleContext . isAttrDefined ( \" $ robolectric \" , LABEL_LIST ) ) { <nl> + depsForRunfiles . addAll ( ruleContext . getPrerequisites ( \" $ robolectric \" , Mode . TARGET ) ) ; <nl> + } <nl> + depsForRunfiles . addAll ( ruleContext . getPrerequisites ( \" runtime_deps \" , Mode . TARGET ) ) ; <nl> + <nl> + getJavaContracts ( ruleContext , depsForRunfiles ) ; <nl> + <nl> + depsForRunfiles . add ( getAndCheckTestSupport ( ruleContext ) ) ; <nl> + <nl> + builder . addTargets ( depsForRunfiles , JavaRunfilesProvider . TO_RUNFILES ) ; <nl> + builder . addTargets ( depsForRunfiles , RunfilesProvider . DEFAULT_RUNFILES ) ; <nl> + <nl> + for ( AndroidLibraryAarProvider aarProvider : androidLibraryAarProviders ) { <nl> + if ( aarProvider . getAar ( ) ! = null ) { <nl> + builder . addArtifact ( aarProvider . getAar ( ) . getAar ( ) ) ; <nl> + builder . addArtifact ( aarProvider . getAar ( ) . getManifest ( ) ) ; <nl> + } <nl> + for ( Aar aar : aarProvider . getTransitiveAars ( ) ) { <nl> + builder . addArtifact ( aar . getAar ( ) ) ; <nl> + builder . addArtifact ( aar . getManifest ( ) ) ; <nl> + } <nl> + } <nl> + <nl> + if ( ruleContext . getConfiguration ( ) . isCodeCoverageEnabled ( ) ) { <nl> + Artifact instrumentedJar = javaCommon . getJavaCompilationArtifacts ( ) . getInstrumentedJar ( ) ; <nl> + if ( instrumentedJar ! = null ) { <nl> + builder . addArtifact ( instrumentedJar ) ; <nl> + } <nl> + } <nl> + <nl> + builder . addArtifacts ( javaCommon . getRuntimeClasspath ( ) ) ; <nl> + <nl> + / / Add the JDK files if it comes from P4 ( see java_stub_template . txt ) . <nl> + TransitiveInfoCollection javabaseTarget = ruleContext . getPrerequisite ( \" : jvm \" , Mode . TARGET ) ; <nl> + <nl> + if ( javabaseTarget ! = null ) { <nl> + builder . addTransitiveArtifacts ( <nl> + javabaseTarget . getProvider ( FileProvider . class ) . getFilesToBuild ( ) ) ; <nl> + } <nl> + return builder . build ( ) ; <nl> + } <nl> + <nl> + private static String getAndCheckTestClass ( <nl> + RuleContext ruleContext , ImmutableList < Artifact > sourceFiles ) { <nl> + String testClass = <nl> + ruleContext . getRule ( ) . isAttrDefined ( \" test_class \" , Type . STRING ) <nl> + ? ruleContext . attributes ( ) . get ( \" test_class \" , Type . STRING ) <nl> + : \" \" ; <nl> + <nl> + if ( testClass . isEmpty ( ) ) { <nl> + testClass = JavaCommon . determinePrimaryClass ( ruleContext , sourceFiles ) ; <nl> + if ( testClass = = null ) { <nl> + ruleContext . ruleError ( <nl> + \" cannot determine junit . framework . Test class \" <nl> + + \" ( Found no source file ' \" <nl> + + ruleContext . getTarget ( ) . getName ( ) <nl> + + \" . java ' and package name doesn ' t include ' java ' or ' javatests ' . \" <nl> + + \" You might want to rename the rule or add a ' test_class ' \" <nl> + + \" attribute . ) \" ) ; <nl> + } <nl> + } <nl> + return testClass ; <nl> + } <nl> + <nl> + protected static String getTransitiveLibrariesArg ( <nl> + Iterable < AndroidLibraryAarProvider > aarProviders ) { <nl> + Set < String > args = new LinkedHashSet < > ( ) ; <nl> + <nl> + for ( AndroidLibraryAarProvider aarProvider : aarProviders ) { <nl> + for ( Aar aar : aarProvider . getTransitiveAars ( ) ) { <nl> + Preconditions . checkNotNull ( aar . getAar ( ) ) ; <nl> + Preconditions . checkNotNull ( aar . getManifest ( ) ) ; <nl> + args . add ( <nl> + aar . getManifest ( ) . getRootRelativePathString ( ) <nl> + + \" : \" <nl> + + aar . getAar ( ) . getRootRelativePathString ( ) ) ; <nl> + } <nl> + } <nl> + return Joiner . on ( \" , \" ) . join ( args ) ; <nl> + } <nl> + <nl> + protected static String getStrictLibrariesArg ( Iterable < AndroidLibraryAarProvider > aarProviders ) { <nl> + Set < String > args = new LinkedHashSet < > ( ) ; <nl> + <nl> + for ( AndroidLibraryAarProvider aarProvider : aarProviders ) { <nl> + Aar aar = aarProvider . getAar ( ) ; <nl> + if ( aar ! = null ) { <nl> + Preconditions . checkNotNull ( aar . getAar ( ) ) ; <nl> + Preconditions . checkNotNull ( aar . getManifest ( ) ) ; <nl> + args . add ( <nl> + aar . getManifest ( ) . getRootRelativePathString ( ) <nl> + + \" : \" <nl> + + aar . getAar ( ) . getRootRelativePathString ( ) ) ; <nl> + } <nl> + } <nl> + return Joiner . on ( \" , \" ) . join ( args ) ; <nl> + } <nl> + } <nl>\n", "msg": "Introduce a base class for AndroidLocalTest , AndroidLocalTestBase . This is a first step for future Bazel android_local_test rule support .\n"}
{"diff_id": 18431, "repo": "elastic/elasticsearch\n", "sha": "877f2ffcd7785e417c41d0df4b5bd4e3e6d3e350\n", "time": "2012-07-10T22:02:18Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / gateway / local / LocalGateway . java <nl> ppp b / src / main / java / org / elasticsearch / gateway / local / LocalGateway . java <nl> public void reset ( ) throws Exception { <nl> <nl> @ Override <nl> public void clusterChanged ( final ClusterChangedEvent event ) { <nl> - / / nothing to do until we actually recover from the gateway or any other block indicates we need to disable persistency <nl> - if ( event . state ( ) . blocks ( ) . disableStatePersistence ( ) ) { <nl> - return ; <nl> - } <nl> / / order is important , first metaState , and then shardsState <nl> / / so dangling indices will be recorded <nl> metaState . clusterChanged ( event ) ; <nl>\n", "msg": "propagate cluster event to shard and meta states in local gateway even when state persistence is disabled , so they can act on it if needed\n"}
{"diff_id": 18459, "repo": "oracle/graal\n", "sha": "a5c33cc22440d3de1bbf00919f77e8f5bd6da43f\n", "time": "2019-08-08T16:05:23Z\n", "diff": "mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / Target_java_lang_Class . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / Target_java_lang_Class . java <nl> public static void registerNatives ( ) { <nl> return StaticObject . NULL ; <nl> } <nl> <nl> + @ Substitution ( hasReceiver = true ) <nl> + public static @ Host ( byte [ ] . class ) StaticObject getRawTypeAnnotations ( @ Host ( Class . class ) StaticObject self ) { <nl> + Klass klass = self . getMirrorKlass ( ) ; <nl> + if ( klass instanceof ObjectKlass ) { <nl> + Attribute annotations = ( ( ObjectKlass ) klass ) . getAttribute ( Name . RuntimeVisibleTypeAnnotations ) ; <nl> + if ( annotations ! = null ) { <nl> + return StaticObject . wrap ( annotations . getData ( ) ) ; <nl> + } <nl> + } <nl> + return StaticObject . NULL ; <nl> + } <nl> + <nl> @ TruffleBoundary <nl> @ Substitution ( hasReceiver = true ) <nl> public static @ Host ( sun . reflect . ConstantPool . class ) StaticObject getConstantPool ( @ Host ( Class . class ) StaticObject self ) { <nl>\n", "msg": "Add substitution for Class . getRawTypeAnnotations .\n"}
{"diff_id": 18487, "repo": "spring-projects/spring-framework\n", "sha": "5d0700b9360399802bf929a0b7b845cb6bb73813\n", "time": "2018-04-03T10:21:03Z\n", "diff": "mmm a / spring - core / src / main / java / org / springframework / core / annotation / AnnotationUtils . java <nl> ppp b / spring - core / src / main / java / org / springframework / core / annotation / AnnotationUtils . java <nl> <nl> private static final Map < Class < ? > , Set < Method > > annotatedBaseTypeCache = <nl> new ConcurrentReferenceHashMap < > ( 256 ) ; <nl> <nl> + @ Deprecated / / just here for older tool versions trying to reflectively clear the cache <nl> + private static final Map < Class < ? > , ? > annotatedInterfaceCache = annotatedBaseTypeCache ; <nl> + <nl> private static final Map < Class < ? extends Annotation > , Boolean > synthesizableCache = <nl> new ConcurrentReferenceHashMap < > ( 256 ) ; <nl> <nl>\n", "msg": "AnnotationUtils . annotatedInterfaceCache available as deprecated field\n"}
{"diff_id": 18838, "repo": "bumptech/glide\n", "sha": "22c5c8fe925673a4ae2de128cd30ad7911fa2f53\n", "time": "2015-10-30T16:25:13Z\n", "diff": "mmm a / library / src / main / java / com / bumptech / glide / request / SingleRequest . java <nl> ppp b / library / src / main / java / com / bumptech / glide / request / SingleRequest . java <nl> public void begin ( ) { <nl> width = overrideWidth ; <nl> height = overrideHeight ; <nl> } <nl> - onLoadFailed ( new GlideException ( \" Received null model \" ) ) ; <nl> + / / Only log at more verbose log levels if the user has set a fallback drawable , because <nl> + / / fallback Drawables indicate the user expects null models occasionally . <nl> + int logLevel = getFallbackDrawable ( ) = = null ? Log . WARN : Log . DEBUG ; <nl> + onLoadFailed ( new GlideException ( \" Received null model \" ) , logLevel ) ; <nl> return ; <nl> } <nl> <nl> private void onResourceReady ( Resource < R > resource , R result , DataSource dataSour <nl> * / <nl> @ Override <nl> public void onLoadFailed ( GlideException e ) { <nl> + onLoadFailed ( e , Log . WARN ) ; <nl> + } <nl> + <nl> + private void onLoadFailed ( GlideException e , int maxLogLevel ) { <nl> stateVerifier . throwIfRecycled ( ) ; <nl> int logLevel = glideContext . getLogLevel ( ) ; <nl> - if ( logLevel < = Log . WARN ) { <nl> + if ( logLevel < = maxLogLevel ) { <nl> Log . w ( GLIDE_TAG , \" Load failed for \" + model + \" with size [ \" + width + \" x \" + height + \" ] \" , e ) ; <nl> if ( logLevel < = Log . INFO ) { <nl> e . logRootCauses ( GLIDE_TAG ) ; <nl>\n", "msg": "Decrease log verbosity when loading null models with fallback Drawables set .\n"}
{"diff_id": 18994, "repo": "libgdx/libgdx\n", "sha": "36bb6e9562e2a18b69e437fdaa374a862e26f87e\n", "time": "2013-06-13T09:20:31Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / scenes / scene2d / ui / TextField . java <nl> ppp b / gdx / src / com / badlogic / gdx / scenes / scene2d / ui / TextField . java <nl> <nl> import com . badlogic . gdx . utils . Array ; <nl> import com . badlogic . gdx . utils . Clipboard ; <nl> import com . badlogic . gdx . utils . FloatArray ; <nl> - import com . badlogic . gdx . utils . SharedLibraryLoader ; <nl> import com . badlogic . gdx . utils . TimeUtils ; <nl> import com . badlogic . gdx . utils . Timer ; <nl> import com . badlogic . gdx . utils . Timer . Task ; <nl> <nl> static private final Vector2 tmp2 = new Vector2 ( ) ; <nl> static private final Vector2 tmp3 = new Vector2 ( ) ; <nl> <nl> + static boolean isMac = System . getProperty ( \" os . name \" ) . contains ( \" Mac \" ) ; <nl> + <nl> TextFieldStyle style ; <nl> String text , messageText ; <nl> private CharSequence displayText ; <nl> public boolean keyDown ( InputEvent event , int keycode ) { <nl> if ( stage ! = null & & stage . getKeyboardFocus ( ) = = TextField . this ) { <nl> boolean repeat = false ; <nl> boolean ctrl ; <nl> - if ( SharedLibraryLoader . isMac ) <nl> + if ( isMac ) <nl> ctrl = Gdx . input . isKeyPressed ( Keys . SYM ) ; <nl> else <nl> ctrl = Gdx . input . isKeyPressed ( Keys . CONTROL_LEFT ) | | Gdx . input . isKeyPressed ( Keys . CONTROL_RIGHT ) ; <nl>\n", "msg": "Removed use of SharedLibraryLoader for silly GWT .\n"}
{"diff_id": 19035, "repo": "SeleniumHQ/selenium\n", "sha": "f1cd2ea900131feb8b3a8f26b98bb51d5fb05d57\n", "time": "2009-01-03T07:20:52Z\n", "diff": "mmm a / server - coreless / src / main / java / org / openqa / selenium / server / browserlaunchers / FirefoxChromeLauncher . java <nl> ppp b / server - coreless / src / main / java / org / openqa / selenium / server / browserlaunchers / FirefoxChromeLauncher . java <nl> private void copyRunnerHtmlFiles ( ) { <nl> htmlDir . mkdirs ( ) ; <nl> <nl> LauncherUtils . extractHTAFile ( htmlDir , getPort ( ) , \" / core / TestRunner . html \" , \" TestRunner . html \" ) ; <nl> + LauncherUtils . extractHTAFile ( htmlDir , getPort ( ) , \" / core / TestPrompt . html \" , \" TestPrompt . html \" ) ; <nl> LauncherUtils . extractHTAFile ( htmlDir , getPort ( ) , \" / core / RemoteRunner . html \" , \" RemoteRunner . html \" ) ; <nl> <nl> } <nl> public String convert ( String httpUrl ) throws MalformedURLException { <nl> <nl> @ Override / / need to specify an absolute resultsUrl <nl> public void launchHTMLSuite ( String suiteUrl , String browserURL , boolean multiWindow , String defaultLogLevel ) { <nl> + / / If navigating to TestPrompt , use the baked - in version instead . <nl> + if ( suiteUrl ! = null & & suiteUrl . startsWith ( \" TestPrompt . html ? \" ) ) { <nl> + suiteUrl = suiteUrl . replaceFirst ( \" ^ TestPrompt \\ \\ . html \\ \\ ? \" , \" chrome : / / src / content / TestPrompt . html ? \" ) ; <nl> + } <nl> launch ( LauncherUtils . getDefaultHTMLSuiteUrl ( browserURL , suiteUrl , multiWindow , getPort ( ) , defaultLogLevel ) , null ) ; <nl> } <nl> <nl>\n", "msg": "Support extracting TestPrompt . html so we can run firefox chrome tests manually individually using launchOnly\n"}
{"diff_id": 19083, "repo": "jenkinsci/jenkins\n", "sha": "8f7d16a53382f3794b36439ce494395b0de3c35a\n", "time": "2012-10-15T16:24:37Z\n", "diff": "mmm a / core / src / main / java / jenkins / model / Jenkins . java <nl> ppp b / core / src / main / java / jenkins / model / Jenkins . java <nl> public Computer createComputer ( ) { <nl> <nl> private synchronized TaskBuilder loadTasks ( ) throws IOException { <nl> File projectsDir = new File ( root , \" jobs \" ) ; <nl> - if ( ! projectsDir . isDirectory ( ) & & ! projectsDir . mkdirs ( ) ) { <nl> + if ( ! projectsDir . getCanonicalFile ( ) . isDirectory ( ) & & ! projectsDir . mkdirs ( ) ) { <nl> if ( projectsDir . exists ( ) ) <nl> throw new IOException ( projectsDir + \" is not a directory \" ) ; <nl> throw new IOException ( \" Unable to create \" + projectsDir + \" \\ nPermission issue ? Please create this directory manually . \" ) ; <nl>\n", "msg": "[ FIXED JENKINS - 12458 ] support symlink for jobs subdirectory\n"}
{"diff_id": 19093, "repo": "SeleniumHQ/selenium\n", "sha": "117b9d61c9a0398f2e059439737f864918673c38\n", "time": "2020-09-04T18:00:10Z\n", "diff": "mmm a / java / server / src / org / openqa / selenium / grid / commands / Hub . java <nl> ppp b / java / server / src / org / openqa / selenium / grid / commands / Hub . java <nl> <nl> import static java . net . HttpURLConnection . HTTP_OK ; <nl> import static org . openqa . selenium . grid . config . StandardGridRoles . EVENT_BUS_ROLE ; <nl> import static org . openqa . selenium . grid . config . StandardGridRoles . HTTPD_ROLE ; <nl> + import static org . openqa . selenium . grid . config . StandardGridRoles . ROUTER_ROLE ; <nl> import static org . openqa . selenium . remote . http . Route . combine ; <nl> <nl> @ AutoService ( CliCommand . class ) <nl> public String getDescription ( ) { <nl> <nl> @ Override <nl> public Set < Role > getConfigurableRoles ( ) { <nl> - return ImmutableSet . of ( EVENT_BUS_ROLE , HTTPD_ROLE ) ; <nl> + return ImmutableSet . of ( EVENT_BUS_ROLE , HTTPD_ROLE , ROUTER_ROLE ) ; <nl> } <nl> <nl> @ Override <nl>\n", "msg": "[ grid ] Adding router role to Hub , this enables the flags on the CLI\n"}
{"diff_id": 19192, "repo": "google/guava\n", "sha": "316bf60b25eb3bb5b65dd7d25b698c9f9ef5cc5c\n", "time": "2014-02-13T19:33:21Z\n", "diff": "mmm a / guava / src / com / google / common / net / HttpHeaders . java <nl> ppp b / guava / src / com / google / common / net / HttpHeaders . java <nl> private HttpHeaders ( ) { } <nl> public static final String EXPECT = \" Expect \" ; <nl> / * * The HTTP { @ code From } header field name . * / <nl> public static final String FROM = \" From \" ; <nl> + / * * <nl> + * The HTTP { @ code Follow - Only - When - Prerender - Shown } < / a > header field name . <nl> + * <nl> + * @ since 17 . 0 <nl> + * / <nl> + @ Beta <nl> + public static final String FOLLOW_ONLY_WHEN_PRERENDER_SHOWN = \" Follow - Only - When - Prerender - Shown \" ; <nl> / * * The HTTP { @ code Host } header field name . * / <nl> public static final String HOST = \" Host \" ; <nl> / * * The HTTP { @ code If - Match } header field name . * / <nl>\n", "msg": "Add Follow - OnlyWhenPrerender - Shown http header constant .\n"}
{"diff_id": 19280, "repo": "elastic/elasticsearch\n", "sha": "06ff97f63d1da2b28643d5e4990fc42a54f7585d\n", "time": "2016-08-31T12:23:51Z\n", "diff": "mmm a / elasticsearch / x - pack / security / src / main / java / org / elasticsearch / xpack / security / transport / netty4 / SecurityNetty4Transport . java <nl> ppp b / elasticsearch / x - pack / security / src / main / java / org / elasticsearch / xpack / security / transport / netty4 / SecurityNetty4Transport . java <nl> <nl> import io . netty . channel . ChannelOutboundHandlerAdapter ; <nl> import io . netty . channel . ChannelPromise ; <nl> import io . netty . handler . ssl . SslHandler ; <nl> - import io . netty . util . concurrent . Future ; <nl> - import org . elasticsearch . ElasticsearchException ; <nl> import org . elasticsearch . common . SuppressForbidden ; <nl> - import org . elasticsearch . common . collect . Tuple ; <nl> import org . elasticsearch . common . inject . Inject ; <nl> import org . elasticsearch . common . inject . internal . Nullable ; <nl> import org . elasticsearch . common . io . stream . NamedWriteableRegistry ; <nl> <nl> <nl> import java . net . InetSocketAddress ; <nl> import java . net . SocketAddress ; <nl> - import java . util . ArrayList ; <nl> - import java . util . List ; <nl> - import java . util . concurrent . TimeUnit ; <nl> <nl> import static org . elasticsearch . xpack . security . Security . setting ; <nl> import static org . elasticsearch . xpack . security . Security . settingPrefix ; <nl> protected ChannelHandler getClientChannelInitializer ( ) { <nl> return new SecurityClientChannelInitializer ( ) ; <nl> } <nl> <nl> - / * * <nl> - * This method ensures that all channels have their SSL handshakes completed . This is necessary to prevent the application from <nl> - * writing data while the handshake is in progress which could cause the handshake to fail . <nl> - * / <nl> - @ Override <nl> - protected void onAfterChannelsConnected ( NodeChannels nodeChannels ) { <nl> - List < Tuple < Future < Channel > , Channel > > handshakes = new ArrayList < > ( ) ; <nl> - for ( Channel channel : nodeChannels . allChannels ) { <nl> - SslHandler handler = channel . pipeline ( ) . get ( SslHandler . class ) ; <nl> - if ( handler ! = null ) { <nl> - handshakes . add ( Tuple . tuple ( handler . handshakeFuture ( ) , channel ) ) ; <nl> - } <nl> - } <nl> - <nl> - for ( Tuple < Future < Channel > , Channel > handshake : handshakes ) { <nl> - handshake . v1 ( ) . awaitUninterruptibly ( 30L , TimeUnit . SECONDS ) ; <nl> - if ( ! handshake . v1 ( ) . isSuccess ( ) ) { <nl> - throw new ElasticsearchException ( \" handshake failed for channel [ { } ] \" , handshake . v2 ( ) ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> class SecurityServerChannelInitializer extends ServerChannelInitializer { <nl> <nl> private final boolean sslEnabled ; <nl>\n", "msg": "security : remove explicit handshake wait in netty4 transport\n"}
{"diff_id": 19437, "repo": "libgdx/libgdx\n", "sha": "2d3696c519a67e767f46be026bd216bcd78c25cd\n", "time": "2011-06-04T10:42:46Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / scenes / scene2d / actors / FastImage . java <nl> ppp b / gdx / src / com / badlogic / gdx / scenes / scene2d / actors / FastImage . java <nl> <nl> private float sScaleY ; <nl> private float sWidth ; <nl> private float sHeight ; <nl> - private Sprite sprite = new Sprite ( ) ; <nl> - boolean updated = false ; <nl> + private Sprite sprite = new Sprite ( ) ; <nl> <nl> public FastImage ( String name ) { <nl> super ( name ) ; <nl> public FastImage ( String name , TextureRegion region ) { <nl> } <nl> } <nl> <nl> - private void updateSprite ( ) { <nl> - if ( updated ) return ; <nl> + private void updateSprite ( ) { <nl> if ( sX ! = x | | sY ! = y ) { <nl> sprite . setPosition ( x , y ) ; <nl> sX = x ; <nl> private void updateSprite ( ) { <nl> sHeight = height ; <nl> } <nl> <nl> - sprite . setRegion ( region ) ; <nl> - updated = true ; <nl> + sprite . setRegion ( region ) ; <nl> } <nl> <nl> @ Override protected boolean touchDown ( float x , float y , int pointer ) { <nl>\n", "msg": "[ fixed ] updated check in FastImage . Bollocks .\n"}
{"diff_id": 19461, "repo": "elastic/elasticsearch\n", "sha": "76af8425f0200f30952433ea279f01cdf9538e76\n", "time": "2011-12-08T12:14:04Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / index / shard / service / InternalIndexShard . java <nl> ppp b / src / main / java / org / elasticsearch / index / shard / service / InternalIndexShard . java <nl> public long count ( float minScore , byte [ ] querySource , int querySourceOffset , int <nl> <nl> @ Override <nl> public void refresh ( Engine . Refresh refresh ) throws ElasticSearchException { <nl> - writeAllowed ( ) ; <nl> + verifyStarted ( ) ; <nl> if ( logger . isTraceEnabled ( ) ) { <nl> logger . trace ( \" refresh with { } \" , refresh ) ; <nl> } <nl> public MergeStats mergeStats ( ) { <nl> <nl> @ Override <nl> public void flush ( Engine . Flush flush ) throws ElasticSearchException { <nl> - writeAllowed ( ) ; <nl> + verifyStarted ( ) ; <nl> if ( logger . isTraceEnabled ( ) ) { <nl> logger . trace ( \" flush with { } \" , flush ) ; <nl> } <nl> public void flush ( Engine . Flush flush ) throws ElasticSearchException { <nl> <nl> @ Override <nl> public void optimize ( Engine . Optimize optimize ) throws ElasticSearchException { <nl> - writeAllowed ( ) ; <nl> + verifyStarted ( ) ; <nl> if ( logger . isTraceEnabled ( ) ) { <nl> logger . trace ( \" optimize with { } \" , optimize ) ; <nl> } <nl> public void optimize ( Engine . Optimize optimize ) throws ElasticSearchException { <nl> <nl> @ Override <nl> public void recover ( Engine . RecoveryHandler recoveryHandler ) throws EngineException { <nl> - writeAllowed ( ) ; <nl> + verifyStarted ( ) ; <nl> engine . recover ( recoveryHandler ) ; <nl> } <nl> <nl> public void writeAllowed ( ) throws IllegalIndexShardStateException { <nl> } <nl> } <nl> <nl> + public void verifyStarted ( ) throws IllegalIndexShardStateException { <nl> + IndexShardState state = this . state ; / / one time volatile read <nl> + if ( state ! = IndexShardState . STARTED ) { <nl> + throw new IndexShardNotStartedException ( shardId , state ) ; <nl> + } <nl> + } <nl> + <nl> private void startScheduledTasksIfNeeded ( ) { <nl> if ( refreshInterval . millis ( ) > 0 ) { <nl> refreshScheduledFuture = threadPool . schedule ( refreshInterval , ThreadPool . Names . SAME , new EngineRefresher ( ) ) ; <nl>\n", "msg": "separate writeAllowed check to actual operation compared to optimize / flush / refresh\n"}
{"diff_id": 19469, "repo": "oracle/graal\n", "sha": "8abdc28258ad9c942869a9336cfb224259e90a4e\n", "time": "2016-02-07T22:28:40Z\n", "diff": "mmm a / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / graphbuilderconf / InvocationPlugins . java <nl> ppp b / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / graphbuilderconf / InvocationPlugins . java <nl> public InvocationPlugins ( InvocationPlugins parent ) { <nl> this ( parent , parent . getMetaAccess ( ) ) ; <nl> } <nl> <nl> + public InvocationPlugins ( Map < ResolvedJavaMethod , InvocationPlugin > plugins , InvocationPlugins parent , MetaAccessProvider metaAccess ) { <nl> + this . metaAccess = metaAccess ; <nl> + this . parent = parent ; <nl> + <nl> + this . deferredRegistrations = null ; <nl> + <nl> + for ( Map . Entry < ResolvedJavaMethod , InvocationPlugin > entry : plugins . entrySet ( ) ) { <nl> + ResolvedJavaMethod method = entry . getKey ( ) ; <nl> + InvocationPlugin plugin = entry . getValue ( ) ; <nl> + <nl> + String internalName = method . getDeclaringClass ( ) . getName ( ) ; <nl> + ClassPlugins classPlugins = registrations . get ( internalName ) ; <nl> + if ( classPlugins = = null ) { <nl> + classPlugins = new ClassPlugins ( null ) ; <nl> + registrations . put ( internalName , classPlugins ) ; <nl> + classPlugins . entries = new HashMap < > ( ) ; <nl> + } <nl> + <nl> + classPlugins . entries . put ( method , plugin ) ; <nl> + } <nl> + } <nl> + <nl> public MetaAccessProvider getMetaAccess ( ) { <nl> return metaAccess ; <nl> } <nl>\n", "msg": "Add constructor to create InvocationPlugins from map of already resolved methods\n"}
{"diff_id": 19599, "repo": "elastic/elasticsearch\n", "sha": "aa1eedc06295d7bcba11bfcce146a37d14453470\n", "time": "2016-10-19T08:00:54Z\n", "diff": "mmm a / elasticsearch / src / test / java / org / elasticsearch / xpack / security / SecurityTribeIT . java <nl> ppp b / elasticsearch / src / test / java / org / elasticsearch / xpack / security / SecurityTribeIT . java <nl> <nl> import org . elasticsearch . action . admin . cluster . health . ClusterHealthResponse ; <nl> import org . elasticsearch . client . Client ; <nl> import org . elasticsearch . cluster . ClusterState ; <nl> + import org . elasticsearch . cluster . ClusterStateObserver ; <nl> + import org . elasticsearch . cluster . service . ClusterService ; <nl> import org . elasticsearch . common . UUIDs ; <nl> import org . elasticsearch . common . settings . Settings ; <nl> + import org . elasticsearch . common . unit . TimeValue ; <nl> + import org . elasticsearch . common . util . concurrent . ThreadContext ; <nl> import org . elasticsearch . env . NodeEnvironment ; <nl> import org . elasticsearch . index . IndexNotFoundException ; <nl> import org . elasticsearch . node . MockNode ; <nl> <nl> import org . elasticsearch . test . InternalTestCluster ; <nl> import org . elasticsearch . test . NativeRealmIntegTestCase ; <nl> import org . elasticsearch . test . SecuritySettingsSource ; <nl> - import org . elasticsearch . test . discovery . MockZenPing ; <nl> import org . elasticsearch . xpack . security . action . role . GetRolesResponse ; <nl> import org . elasticsearch . xpack . security . action . role . PutRoleResponse ; <nl> import org . elasticsearch . xpack . security . action . user . PutUserResponse ; <nl> <nl> import org . junit . BeforeClass ; <nl> <nl> import java . util . ArrayList ; <nl> - import java . util . Collection ; <nl> import java . util . Collections ; <nl> import java . util . HashMap ; <nl> import java . util . HashSet ; <nl> import java . util . List ; <nl> import java . util . Map ; <nl> import java . util . Set ; <nl> + import java . util . concurrent . CountDownLatch ; <nl> <nl> import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertAcked ; <nl> import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertNoTimeout ; <nl> protected boolean ignoreExternalCluster ( ) { <nl> return true ; <nl> } <nl> <nl> - private void setupTribeNode ( Settings settings ) throws NodeValidationException { <nl> + private void setupTribeNode ( Settings settings ) throws NodeValidationException , InterruptedException { <nl> SecuritySettingsSource cluster2SettingsSource = new SecuritySettingsSource ( 1 , useSSL , systemKey ( ) , createTempDir ( ) , Scope . TEST ) ; <nl> Map < String , String > asMap = new HashMap < > ( cluster2SettingsSource . nodeSettings ( 0 ) . getAsMap ( ) ) ; <nl> asMap . remove ( NodeEnvironment . MAX_LOCAL_STORAGE_NODES_SETTING . getKey ( ) ) ; <nl> private void setupTribeNode ( Settings settings ) throws NodeValidationException { <nl> classpathPlugins . addAll ( getMockPlugins ( ) ) ; <nl> tribeNode = new MockNode ( merged , classpathPlugins ) . start ( ) ; <nl> tribeClient = getClientWrapper ( ) . apply ( tribeNode . client ( ) ) ; <nl> + ClusterStateObserver observer = new ClusterStateObserver ( tribeNode . injector ( ) . getInstance ( ClusterService . class ) , <nl> + logger , new ThreadContext ( settings ) ) ; <nl> + CountDownLatch latch = new CountDownLatch ( 1 ) ; <nl> + final int cluster1Nodes = internalCluster ( ) . size ( ) ; <nl> + final int cluster2Nodes = cluster2 . size ( ) ; <nl> + logger . info ( \" waiting for [ { } ] nodes to be added to the tribe cluster state \" , cluster1Nodes + cluster2Nodes + 2 ) ; <nl> + observer . waitForNextChange ( new ClusterStateObserver . Listener ( ) { <nl> + @ Override <nl> + public void onNewClusterState ( ClusterState state ) { <nl> + latch . countDown ( ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public void onClusterServiceClose ( ) { <nl> + fail ( \" tribe cluster service closed \" ) ; <nl> + latch . countDown ( ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public void onTimeout ( TimeValue timeout ) { <nl> + fail ( \" timed out waiting for nodes to be added to tribe ' s cluster state \" ) ; <nl> + latch . countDown ( ) ; <nl> + } <nl> + } , new ClusterStateObserver . ValidationPredicate ( ) { <nl> + @ Override <nl> + protected boolean validate ( ClusterState newState ) { <nl> + return newState . nodes ( ) . getSize ( ) = = cluster1Nodes + cluster2Nodes + 3 ; <nl> + } <nl> + } ) ; <nl> + latch . await ( ) ; <nl> } <nl> <nl> public void testThatTribeCanAuthenticateElasticUser ( ) throws Exception { <nl>\n", "msg": "SecurityTribeIT - wait for tribe node to full process incoming cluster states\n"}
{"diff_id": 19622, "repo": "elastic/elasticsearch\n", "sha": "4debf44cd9786bf2b91bd6ed28ffee33b1f7835c\n", "time": "2013-08-09T19:39:47Z\n", "diff": "mmm a / src / test / java / org / elasticsearch / test / integration / indices / mapping / UpdateMappingTests . java <nl> ppp b / src / test / java / org / elasticsearch / test / integration / indices / mapping / UpdateMappingTests . java <nl> public void updateMappingNoChanges ( ) throws Exception { <nl> @ SuppressWarnings ( \" unchecked \" ) <nl> @ Test <nl> public void updateDefaultMappingSettings ( ) throws Exception { <nl> - client ( ) . admin ( ) . indices ( ) . prepareCreate ( \" test \" ) . addMapping ( MapperService . DEFAULT_MAPPING , <nl> + <nl> + / / TODO : bleskes : move back to combined index and mapping creation ( pending bug fix concerning concurrent not - acked mapping requests ) <nl> + createIndex ( \" test \" ) ; <nl> + client ( ) . admin ( ) . indices ( ) . preparePutMapping ( \" test \" ) . setType ( MapperService . DEFAULT_MAPPING ) . setSource ( <nl> JsonXContent . contentBuilder ( ) . startObject ( ) . startObject ( MapperService . DEFAULT_MAPPING ) <nl> . field ( \" date_detection \" , false ) <nl> . endObject ( ) . endObject ( ) <nl>\n", "msg": "Separated index creation from mapping creation pending bug fix concerning concurrent not - acked mapping requests\n"}
{"diff_id": 19684, "repo": "apache/flink\n", "sha": "74939e9846e397d5ae320334200ab968be8ad42b\n", "time": "2011-10-14T15:54:55Z\n", "diff": "mmm a / nephele / nephele - server / src / test / java / eu / stratosphere / nephele / checkpointing / FailingJobITCase . java <nl> ppp b / nephele / nephele - server / src / test / java / eu / stratosphere / nephele / checkpointing / FailingJobITCase . java <nl> <nl> private static final int RECORD_SIZE = 256 ; <nl> <nl> / * * <nl> - * Number of records after which the execution failure shall occur . <nl> + * Configuration key to access the number of records after which the execution failure shall occur . <nl> * / <nl> - private static final int FAILED_AFTER_RECORD = 95490 ; <nl> + private static final String FAILED_AFTER_RECORD_KEY = \" failure . after . record \" ; <nl> <nl> / * * <nl> * The degree of parallelism for the job . <nl> * / <nl> private static final int DEGREE_OF_PARALLELISM = 4 ; <nl> <nl> - / * * <nl> - * Index of the parallel subtask in which the failure shall occur . <nl> - * / <nl> - private static final int FAILURE_INDEX = 0 ; <nl> - <nl> - / * * <nl> - * The key to access the configuration flag for a task failure . <nl> - * / <nl> - private static final String FAILURE_KEY = \" failure \" ; <nl> - <nl> / * * <nl> * The key to access the index of the subtask which is supposed to fail . <nl> * / <nl> <nl> / * * <nl> * Global flag to indicate if a task has already failed once . <nl> * / <nl> - private static final AtomicBoolean FAILED_ONCE = new AtomicBoolean ( false ) ; <nl> - <nl> + private static final AtomicBoolean FAILED_ONCE = new AtomicBoolean ( false ) ; <nl> + <nl> / * * <nl> * This is an auxiliary class to run the job manager thread . <nl> * <nl> public void registerInputOutput ( ) { <nl> @ Override <nl> public void invoke ( ) throws Exception { <nl> <nl> + final int failAfterRecord = getRuntimeConfiguration ( ) . getInteger ( FAILED_AFTER_RECORD_KEY , - 1 ) ; <nl> + final boolean failing = ( getIndexInSubtaskGroup ( ) = = getRuntimeConfiguration ( ) . getInteger ( <nl> + FAILURE_INDEX_KEY , - 1 ) ) ; <nl> + <nl> final FailingJobRecord record = new FailingJobRecord ( ) ; <nl> for ( int i = 0 ; i < RECORDS_TO_GENERATE ; + + i ) { <nl> this . recordWriter . emit ( record ) ; <nl> + <nl> + if ( i = = failAfterRecord & & failing ) { <nl> + if ( FAILED_ONCE . compareAndSet ( false , true ) ) { <nl> + throw new RuntimeException ( \" Runtime exception in \" + getEnvironment ( ) . getTaskName ( ) + \" \" <nl> + + getIndexInSubtaskGroup ( ) ) ; <nl> + } <nl> + } <nl> } <nl> } <nl> } <nl> public void invoke ( ) throws Exception { <nl> <nl> final FailingJobRecord record = new FailingJobRecord ( ) ; <nl> <nl> + final int failAfterRecord = getRuntimeConfiguration ( ) . getInteger ( FAILED_AFTER_RECORD_KEY , - 1 ) ; <nl> + <nl> int count = 0 ; <nl> - boolean failing = ( getRuntimeConfiguration ( ) . getBoolean ( FAILURE_KEY , false ) & & ( getIndexInSubtaskGroup ( ) = = getRuntimeConfiguration ( ) <nl> - . getInteger ( FAILURE_INDEX_KEY , - 1 ) ) ) ; <nl> + final boolean failing = ( getIndexInSubtaskGroup ( ) = = getRuntimeConfiguration ( ) . getInteger ( <nl> + FAILURE_INDEX_KEY , - 1 ) ) ; <nl> while ( this . recordReader . next ( record ) ) { <nl> <nl> this . recordWriter . emit ( record ) ; <nl> - if ( count + + = = FAILED_AFTER_RECORD & & failing ) { <nl> - if ( FAILED_ONCE . compareAndSet ( false , true ) ) { <nl> + if ( count + + = = failAfterRecord & & failing ) { <nl> + if ( FAILED_ONCE . compareAndSet ( false , true ) ) { <nl> throw new RuntimeException ( \" Runtime exception in \" + getEnvironment ( ) . getTaskName ( ) + \" \" <nl> + getIndexInSubtaskGroup ( ) ) ; <nl> } <nl> public void invoke ( ) throws Exception { <nl> public void registerInputOutput ( ) { <nl> <nl> this . recordReader = new MutableRecordReader < FailingJobITCase . FailingJobRecord > ( this , <nl> - new BipartiteDistributionPattern ( ) ) ; <nl> + new BipartiteDistributionPattern ( ) ) ; <nl> } <nl> <nl> / * * <nl> public void registerInputOutput ( ) { <nl> @ Override <nl> public void invoke ( ) throws Exception { <nl> <nl> + final int failAfterRecord = getRuntimeConfiguration ( ) . getInteger ( FAILED_AFTER_RECORD_KEY , - 1 ) ; <nl> + <nl> + int count = 0 ; <nl> + final boolean failing = ( getIndexInSubtaskGroup ( ) = = getRuntimeConfiguration ( ) . getInteger ( <nl> + FAILURE_INDEX_KEY , - 1 ) ) ; <nl> + <nl> final FailingJobRecord record = new FailingJobRecord ( ) ; <nl> while ( this . recordReader . next ( record ) ) { <nl> - / / Simply consume the records <nl> + <nl> + if ( count + + = = failAfterRecord & & failing ) { <nl> + if ( FAILED_ONCE . compareAndSet ( false , true ) ) { <nl> + throw new RuntimeException ( \" Runtime exception in \" + getEnvironment ( ) . getTaskName ( ) + \" \" <nl> + + getIndexInSubtaskGroup ( ) ) ; <nl> + } <nl> + } <nl> } <nl> } <nl> <nl> public void testFailingInternalVertex ( ) { <nl> innerVertex2 . setTaskClass ( InnerTask . class ) ; <nl> innerVertex2 . setNumberOfSubtasks ( DEGREE_OF_PARALLELISM ) ; <nl> innerVertex2 . setNumberOfSubtasksPerInstance ( DEGREE_OF_PARALLELISM ) ; <nl> - innerVertex2 . getConfiguration ( ) . setBoolean ( FAILURE_KEY , true ) ; <nl> - innerVertex2 . getConfiguration ( ) . setInteger ( FAILURE_INDEX_KEY , FAILURE_INDEX ) ; <nl> + innerVertex2 . getConfiguration ( ) . setInteger ( FAILED_AFTER_RECORD_KEY , 95490 ) ; <nl> + innerVertex2 . getConfiguration ( ) . setInteger ( FAILURE_INDEX_KEY , 0 ) ; <nl> + <nl> + final JobTaskVertex innerVertex3 = new JobTaskVertex ( \" Inner vertex 3 \" , jobGraph ) ; <nl> + innerVertex3 . setTaskClass ( InnerTask . class ) ; <nl> + innerVertex3 . setNumberOfSubtasks ( DEGREE_OF_PARALLELISM ) ; <nl> + innerVertex3 . setNumberOfSubtasksPerInstance ( DEGREE_OF_PARALLELISM ) ; <nl> + <nl> + final JobGenericOutputVertex output = new JobGenericOutputVertex ( \" Output \" , jobGraph ) ; <nl> + output . setOutputClass ( OutputTask . class ) ; <nl> + output . setNumberOfSubtasks ( DEGREE_OF_PARALLELISM ) ; <nl> + output . setNumberOfSubtasksPerInstance ( DEGREE_OF_PARALLELISM ) ; <nl> + <nl> + / / Configure instance sharing <nl> + innerVertex1 . setVertexToShareInstancesWith ( input ) ; <nl> + innerVertex2 . setVertexToShareInstancesWith ( input ) ; <nl> + innerVertex3 . setVertexToShareInstancesWith ( input ) ; <nl> + output . setVertexToShareInstancesWith ( input ) ; <nl> + <nl> + try { <nl> + <nl> + input . connectTo ( innerVertex1 , ChannelType . INMEMORY , CompressionLevel . NO_COMPRESSION ) ; <nl> + innerVertex1 . connectTo ( innerVertex2 , ChannelType . INMEMORY , CompressionLevel . NO_COMPRESSION ) ; <nl> + innerVertex2 . connectTo ( innerVertex3 , ChannelType . INMEMORY , CompressionLevel . NO_COMPRESSION ) ; <nl> + innerVertex3 . connectTo ( output , ChannelType . INMEMORY , CompressionLevel . NO_COMPRESSION ) ; <nl> + <nl> + } catch ( JobGraphDefinitionException e ) { <nl> + fail ( StringUtils . stringifyException ( e ) ) ; <nl> + } <nl> + <nl> + / / Reset the FAILED_ONCE flag <nl> + FAILED_ONCE . set ( false ) ; <nl> + <nl> + / / Create job client and launch job <nl> + try { <nl> + JobClient jobClient = new JobClient ( jobGraph , configuration ) ; <nl> + jobClient . submitJobAndWait ( ) ; <nl> + } catch ( IOException ioe ) { <nl> + fail ( StringUtils . stringifyException ( ioe ) ) ; <nl> + } catch ( JobExecutionException e ) { <nl> + fail ( StringUtils . stringifyException ( e ) ) ; <nl> + } <nl> + } <nl> + <nl> + / * * <nl> + * This test checks Nephele ' s capabilities to recover from file channel checkpoints . <nl> + * / <nl> + @ Test <nl> + public void testRecoveryFromFileChannels ( ) { <nl> + <nl> + final JobGraph jobGraph = new JobGraph ( \" Job with file channels \" ) ; <nl> + <nl> + final JobGenericInputVertex input = new JobGenericInputVertex ( \" Input \" , jobGraph ) ; <nl> + input . setInputClass ( InputTask . class ) ; <nl> + input . setNumberOfSubtasks ( DEGREE_OF_PARALLELISM ) ; <nl> + input . setNumberOfSubtasksPerInstance ( DEGREE_OF_PARALLELISM ) ; <nl> + <nl> + final JobTaskVertex innerVertex1 = new JobTaskVertex ( \" Inner vertex 1 \" , jobGraph ) ; <nl> + innerVertex1 . setTaskClass ( InnerTask . class ) ; <nl> + innerVertex1 . setNumberOfSubtasks ( DEGREE_OF_PARALLELISM ) ; <nl> + innerVertex1 . setNumberOfSubtasksPerInstance ( DEGREE_OF_PARALLELISM ) ; <nl> + <nl> + final JobGenericOutputVertex output = new JobGenericOutputVertex ( \" Output \" , jobGraph ) ; <nl> + output . setOutputClass ( OutputTask . class ) ; <nl> + output . setNumberOfSubtasks ( DEGREE_OF_PARALLELISM ) ; <nl> + output . setNumberOfSubtasksPerInstance ( DEGREE_OF_PARALLELISM ) ; <nl> + output . getConfiguration ( ) . setInteger ( FAILED_AFTER_RECORD_KEY , 153201 ) ; <nl> + output . getConfiguration ( ) . setInteger ( FAILURE_INDEX_KEY , 1 ) ; <nl> + <nl> + / / Configure instance sharing <nl> + innerVertex1 . setVertexToShareInstancesWith ( input ) ; <nl> + output . setVertexToShareInstancesWith ( input ) ; <nl> + <nl> + try { <nl> + <nl> + input . connectTo ( innerVertex1 , ChannelType . INMEMORY , CompressionLevel . NO_COMPRESSION ) ; <nl> + innerVertex1 . connectTo ( output , ChannelType . FILE , CompressionLevel . NO_COMPRESSION ) ; <nl> + <nl> + } catch ( JobGraphDefinitionException e ) { <nl> + fail ( StringUtils . stringifyException ( e ) ) ; <nl> + } <nl> + <nl> + / / Reset the FAILED_ONCE flag <nl> + FAILED_ONCE . set ( false ) ; <nl> + <nl> + / / Create job client and launch job <nl> + try { <nl> + JobClient jobClient = new JobClient ( jobGraph , configuration ) ; <nl> + jobClient . submitJobAndWait ( ) ; <nl> + } catch ( IOException ioe ) { <nl> + fail ( StringUtils . stringifyException ( ioe ) ) ; <nl> + } catch ( JobExecutionException e ) { <nl> + fail ( StringUtils . stringifyException ( e ) ) ; <nl> + } <nl> + } <nl> + <nl> + / * * <nl> + * This test checks Nephele ' s fault tolerance capabilities by simulating a failing input vertex . <nl> + * / <nl> + @ Test <nl> + public void testFailingInputVertex ( ) { <nl> + <nl> + final JobGraph jobGraph = new JobGraph ( \" Job with failing inner vertex \" ) ; <nl> + <nl> + final JobGenericInputVertex input = new JobGenericInputVertex ( \" Input \" , jobGraph ) ; <nl> + input . setInputClass ( InputTask . class ) ; <nl> + input . setNumberOfSubtasks ( DEGREE_OF_PARALLELISM ) ; <nl> + input . setNumberOfSubtasksPerInstance ( DEGREE_OF_PARALLELISM ) ; <nl> + input . getConfiguration ( ) . setInteger ( FAILED_AFTER_RECORD_KEY , 804937 ) ; <nl> + input . getConfiguration ( ) . setInteger ( FAILURE_INDEX_KEY , 3 ) ; <nl> + <nl> + final JobTaskVertex innerVertex1 = new JobTaskVertex ( \" Inner vertex 1 \" , jobGraph ) ; <nl> + innerVertex1 . setTaskClass ( InnerTask . class ) ; <nl> + innerVertex1 . setNumberOfSubtasks ( DEGREE_OF_PARALLELISM ) ; <nl> + innerVertex1 . setNumberOfSubtasksPerInstance ( DEGREE_OF_PARALLELISM ) ; <nl> + <nl> + final JobTaskVertex innerVertex2 = new JobTaskVertex ( \" Inner vertex 2 \" , jobGraph ) ; <nl> + innerVertex2 . setTaskClass ( InnerTask . class ) ; <nl> + innerVertex2 . setNumberOfSubtasks ( DEGREE_OF_PARALLELISM ) ; <nl> + innerVertex2 . setNumberOfSubtasksPerInstance ( DEGREE_OF_PARALLELISM ) ; <nl> <nl> final JobTaskVertex innerVertex3 = new JobTaskVertex ( \" Inner vertex 3 \" , jobGraph ) ; <nl> innerVertex3 . setTaskClass ( InnerTask . class ) ; <nl> public void testFailingInternalVertex ( ) { <nl> <nl> / / Reset the FAILED_ONCE flag <nl> FAILED_ONCE . set ( false ) ; <nl> - <nl> + <nl> / / Create job client and launch job <nl> try { <nl> JobClient jobClient = new JobClient ( jobGraph , configuration ) ; <nl>\n", "msg": "Added two more integration tests for the fault tolerance features\n"}
{"diff_id": 19697, "repo": "SeleniumHQ/selenium\n", "sha": "3d3f8e600efccecb1f1479796357af52e40b6693\n", "time": "2020-11-27T07:37:50Z\n", "diff": "mmm a / java / server / test / org / openqa / selenium / grid / distributor / DistributorTest . java <nl> ppp b / java / server / test / org / openqa / selenium / grid / distributor / DistributorTest . java <nl> private void waitForAllNodesToHaveCapacity ( Distributor distributor , int nodeCoun <nl> . pollingEvery ( Duration . ofMillis ( 100 ) ) <nl> . until ( d - > { <nl> Set < NodeStatus > nodes = d . getStatus ( ) . getNodes ( ) ; <nl> - return nodes . size ( ) = = nodeCount & & nodes . stream ( ) . allMatch ( NodeStatus : : hasCapacity ) ; <nl> + return nodes . size ( ) = = nodeCount & & nodes . stream ( ) . allMatch ( <nl> + node - > node . getAvailability ( ) = = UP & & node . hasCapacity ( ) ) ; <nl> } ) ; <nl> } catch ( TimeoutException ex ) { <nl> Set < NodeStatus > nodes = distributor . getStatus ( ) . getNodes ( ) ; <nl>\n", "msg": "[ java ] Adding more waits to make DistributorTest stable\n"}
{"diff_id": 19764, "repo": "bazelbuild/bazel\n", "sha": "5d660595111ec2a14c87856e76b78422e267c628\n", "time": "2017-06-14T11:16:08Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / buildtool / BuildRequest . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / buildtool / BuildRequest . java <nl> public ProgressReportIntervalConverter ( ) { <nl> } <nl> } <nl> <nl> - @ VisibleForTesting public static final int MAX_JOBS = 2000 ; <nl> - private static final int JOBS_TOO_HIGH_WARNING = 1000 ; <nl> + @ VisibleForTesting public static final int MAX_JOBS = 3000 ; <nl> + private static final int JOBS_TOO_HIGH_WARNING = 1500 ; <nl> <nl> private final UUID id ; <nl> private final LoadingCache < Class < ? extends OptionsBase > , Optional < OptionsBase > > optionsCache ; <nl>\n", "msg": "Bump the blaze max jobs and warning threshold to keep up with the times .\n"}
{"diff_id": 19794, "repo": "netty/netty\n", "sha": "f4e128b8070a197ac3b770a203dcdc72af1088fc\n", "time": "2013-07-23T05:11:11Z\n", "diff": "mmm a / common / src / main / java / io / netty / util / ResourceLeakDetector . java <nl> ppp b / common / src / main / java / io / netty / util / ResourceLeakDetector . java <nl> <nl> <nl> public final class ResourceLeakDetector < T > { <nl> <nl> - private static volatile boolean disabled ; <nl> + private static boolean disabled ; <nl> <nl> private static final InternalLogger logger = InternalLoggerFactory . getInstance ( ResourceLeakDetector . class ) ; <nl> <nl>\n", "msg": "[ ] No need for volatile as it is not needed to be precise\n"}
{"diff_id": 20019, "repo": "greenrobot/EventBus\n", "sha": "80e38942e439bd872e5f5bd920d03a187fc8b752\n", "time": "2013-01-03T17:40:27Z\n", "diff": "mmm a / EventBus / src / de / greenrobot / event / util / ErrorDialogManager . java <nl> ppp b / EventBus / src / de / greenrobot / event / util / ErrorDialogManager . java <nl> <nl> - package de . greenrobot . event . util ; <nl> - <nl> - import android . annotation . TargetApi ; <nl> - import android . app . Activity ; <nl> - import android . app . Application ; <nl> - import android . os . Build ; <nl> - import android . os . Bundle ; <nl> - import android . support . v4 . app . DialogFragment ; <nl> - import android . support . v4 . app . Fragment ; <nl> - import android . support . v4 . app . FragmentActivity ; <nl> - import android . support . v4 . app . FragmentManager ; <nl> - import android . util . Log ; <nl> - import de . greenrobot . event . EventBus ; <nl> - <nl> - / * * <nl> - * Central class for app that want to use event based error dialogs . < br / > <nl> - * < br / > <nl> - * How to use : <nl> - * < ol > <nl> - * < li > Set the { @ link # factory } to configure dialogs for your app , typically in { @ link Application # onCreate ( ) } < / li > <nl> - * < li > Use one of { @ link # attachTo ( Activity ) } , { @ link # attachTo ( Activity , boolean ) } or <nl> - * { @ link # attachTo ( Activity , boolean , Bundle ) } in your Activity , typically in onCreate . < / li > <nl> - * < / ol > <nl> - * <nl> - * For more complex mappings , you can supply your own { @ link ErrorDialogFragmentFactory } . <nl> - * <nl> - * @ author Markus <nl> - * / <nl> - public class ErrorDialogManager { <nl> - <nl> - public static class SupportManagerFragment extends Fragment { <nl> - protected boolean finishAfterDialog ; <nl> - protected Bundle argumentsForErrorDialog ; <nl> - private EventBus eventBus ; <nl> - <nl> - @ Override <nl> - public void onResume ( ) { <nl> - super . onResume ( ) ; <nl> - eventBus = ErrorDialogManager . factory . config . getEventBus ( ) ; <nl> - eventBus . register ( this ) ; <nl> - } <nl> - <nl> - @ Override <nl> - public void onPause ( ) { <nl> - eventBus . unregister ( this ) ; <nl> - super . onPause ( ) ; <nl> - } <nl> - <nl> - public void onEventMainThread ( ThrowableFailureEvent event ) { <nl> - checkLogException ( event ) ; <nl> - / / Execute pending commits before finding to avoid multiple error fragments being shown <nl> - FragmentManager fm = getFragmentManager ( ) ; <nl> - fm . executePendingTransactions ( ) ; <nl> - <nl> - DialogFragment existingFragment = ( DialogFragment ) fm . findFragmentByTag ( TAG_ERROR_DIALOG ) ; <nl> - if ( existingFragment ! = null ) { <nl> - / / Just show the latest error <nl> - existingFragment . dismiss ( ) ; <nl> - } <nl> - <nl> - android . support . v4 . app . DialogFragment errorFragment = ( android . support . v4 . app . DialogFragment ) factory <nl> - . prepareErrorFragment ( event , finishAfterDialog , argumentsForErrorDialog ) ; <nl> - if ( errorFragment ! = null ) { <nl> - errorFragment . show ( fm , TAG_ERROR_DIALOG ) ; <nl> - } <nl> - } <nl> - <nl> - public static void attachTo ( Activity activity , boolean finishAfterDialog , Bundle argumentsForErrorDialog ) { <nl> - FragmentManager fm = ( ( FragmentActivity ) activity ) . getSupportFragmentManager ( ) ; <nl> - SupportManagerFragment fragment = ( SupportManagerFragment ) fm . findFragmentByTag ( TAG_ERROR_DIALOG_MANAGER ) ; <nl> - if ( fragment = = null ) { <nl> - fragment = new SupportManagerFragment ( ) ; <nl> - fm . beginTransaction ( ) . add ( fragment , TAG_ERROR_DIALOG_MANAGER ) . commit ( ) ; <nl> - } <nl> - fragment . finishAfterDialog = finishAfterDialog ; <nl> - fragment . argumentsForErrorDialog = argumentsForErrorDialog ; <nl> - } <nl> - } <nl> - <nl> - @ TargetApi ( Build . VERSION_CODES . HONEYCOMB ) <nl> - public static class HoneycombManagerFragment extends android . app . Fragment { <nl> - protected boolean finishAfterDialog ; <nl> - protected Bundle argumentsForErrorDialog ; <nl> - private EventBus eventBus ; <nl> - <nl> - @ Override <nl> - public void onResume ( ) { <nl> - super . onResume ( ) ; <nl> - eventBus = ErrorDialogManager . factory . config . getEventBus ( ) ; <nl> - eventBus . register ( this ) ; <nl> - } <nl> - <nl> - @ Override <nl> - public void onPause ( ) { <nl> - eventBus . unregister ( this ) ; <nl> - super . onPause ( ) ; <nl> - } <nl> - <nl> - public void onEventMainThread ( ThrowableFailureEvent event ) { <nl> - checkLogException ( event ) ; <nl> - <nl> - / / Execute pending commits before finding to avoid multiple error fragments being shown <nl> - android . app . FragmentManager fm = getFragmentManager ( ) ; <nl> - fm . executePendingTransactions ( ) ; <nl> - <nl> - android . app . DialogFragment existingFragment = ( android . app . DialogFragment ) fm <nl> - . findFragmentByTag ( TAG_ERROR_DIALOG ) ; <nl> - if ( existingFragment ! = null ) { <nl> - / / Just show the latest error <nl> - existingFragment . dismiss ( ) ; <nl> - } <nl> - <nl> - android . app . DialogFragment errorFragment = ( android . app . DialogFragment ) factory . prepareErrorFragment ( event , <nl> - finishAfterDialog , argumentsForErrorDialog ) ; <nl> - if ( errorFragment ! = null ) { <nl> - errorFragment . show ( fm , TAG_ERROR_DIALOG ) ; <nl> - } <nl> - } <nl> - <nl> - public static void attachTo ( Activity activity , boolean finishAfterDialog , Bundle argumentsForErrorDialog ) { <nl> - android . app . FragmentManager fm = activity . getFragmentManager ( ) ; <nl> - HoneycombManagerFragment fragment = ( HoneycombManagerFragment ) fm <nl> - . findFragmentByTag ( TAG_ERROR_DIALOG_MANAGER ) ; <nl> - if ( fragment = = null ) { <nl> - fragment = new HoneycombManagerFragment ( ) ; <nl> - fm . beginTransaction ( ) . add ( fragment , TAG_ERROR_DIALOG_MANAGER ) . commit ( ) ; <nl> - } <nl> - fragment . finishAfterDialog = finishAfterDialog ; <nl> - fragment . argumentsForErrorDialog = argumentsForErrorDialog ; <nl> - } <nl> - } <nl> - <nl> - / * * Must be set by the application . * / <nl> - public static ErrorDialogFragmentFactory < ? > factory ; <nl> - <nl> - protected static final String TAG_ERROR_DIALOG = \" de . greenrobot . eventbus . error_dialog \" ; <nl> - protected static final String TAG_ERROR_DIALOG_MANAGER = \" de . greenrobot . eventbus . error_dialog_manager \" ; <nl> - <nl> - public static final String KEY_TITLE = \" de . greenrobot . eventbus . errordialog . title \" ; <nl> - public static final String KEY_MESSAGE = \" de . greenrobot . eventbus . errordialog . message \" ; <nl> - public static final String KEY_FINISH_AFTER_DIALOG = \" de . greenrobot . eventbus . errordialog . finish_after_dialog \" ; <nl> - public static final String KEY_ICON_ID = \" de . greenrobot . eventbus . errordialog . icon_id \" ; <nl> - public static final String KEY_EVENT_TYPE_ON_CLOSE = \" de . greenrobot . eventbus . errordialog . event_type_on_close \" ; <nl> - <nl> - public static void attachTo ( Activity activity ) { <nl> - attachTo ( activity , false , null ) ; <nl> - } <nl> - <nl> - public static void attachTo ( Activity activity , boolean finishAfterDialog ) { <nl> - attachTo ( activity , finishAfterDialog , null ) ; <nl> - } <nl> - <nl> - public static void attachTo ( Activity activity , boolean finishAfterDialog , Bundle argumentsForErrorDialog ) { <nl> - if ( factory = = null ) { <nl> - throw new RuntimeException ( \" You must set the static factory field to configure error dialogs for your app . \" ) ; <nl> - } <nl> - if ( isSupportActivity ( activity ) ) { <nl> - SupportManagerFragment . attachTo ( activity , finishAfterDialog , argumentsForErrorDialog ) ; <nl> - } else { <nl> - HoneycombManagerFragment . attachTo ( activity , finishAfterDialog , argumentsForErrorDialog ) ; <nl> - } <nl> - } <nl> - <nl> - private static boolean isSupportActivity ( Activity activity ) { <nl> - boolean isSupport = false ; <nl> - for ( Class < ? > c = activity . getClass ( ) . getSuperclass ( ) ; ; c = c . getSuperclass ( ) ) { <nl> - if ( c = = null ) { <nl> - throw new RuntimeException ( \" Illegal activity type : \" + activity . getClass ( ) ) ; <nl> - } <nl> - String name = c . getName ( ) ; <nl> - if ( name . equals ( \" android . support . v4 . app . FragmentActivity \" ) ) { <nl> - isSupport = true ; <nl> - break ; <nl> - } else if ( name . startsWith ( \" com . actionbarsherlock . app \" ) <nl> - & & ( name . endsWith ( \" . SherlockActivity \" ) | | name . endsWith ( \" . SherlockListActivity \" ) | | name <nl> - . endsWith ( \" . SherlockPreferenceActivity \" ) ) ) { <nl> - throw new RuntimeException ( \" Please use SherlockFragmentActivity . Illegal activity : \" + name ) ; <nl> - } else if ( name . equals ( \" android . app . Activity \" ) ) { <nl> - if ( Build . VERSION . SDK_INT < Build . VERSION_CODES . HONEYCOMB ) { <nl> - throw new RuntimeException ( <nl> - \" Illegal activity without fragment support . Either use Android 3 . 0 + or android . support . v4 . app . FragmentActivity . \" ) ; <nl> - } <nl> - break ; <nl> - } <nl> - } <nl> - return isSupport ; <nl> - } <nl> - <nl> - protected static void checkLogException ( ThrowableFailureEvent event ) { <nl> - if ( factory . config . logExceptions ) { <nl> - String tag = factory . config . tagForLoggingExceptions ; <nl> - if ( tag = = null ) { <nl> - tag = EventBus . TAG ; <nl> - } <nl> - Log . i ( tag , \" Error dialog manager received exception \" , event . throwable ) ; <nl> - } <nl> - } <nl> - <nl> - } <nl> + package de . greenrobot . event . util ; <nl> + <nl> + import android . annotation . TargetApi ; <nl> + import android . app . Activity ; <nl> + import android . app . Application ; <nl> + import android . os . Build ; <nl> + import android . os . Bundle ; <nl> + import android . support . v4 . app . DialogFragment ; <nl> + import android . support . v4 . app . Fragment ; <nl> + import android . support . v4 . app . FragmentActivity ; <nl> + import android . support . v4 . app . FragmentManager ; <nl> + import android . util . Log ; <nl> + import de . greenrobot . event . EventBus ; <nl> + <nl> + / * * <nl> + * Central class for app that want to use event based error dialogs . < br / > <nl> + * < br / > <nl> + * How to use : <nl> + * < ol > <nl> + * < li > Set the { @ link # factory } to configure dialogs for your app , typically in { @ link Application # onCreate ( ) } < / li > <nl> + * < li > Use one of { @ link # attachTo ( Activity ) } , { @ link # attachTo ( Activity , boolean ) } or <nl> + * { @ link # attachTo ( Activity , boolean , Bundle ) } in your Activity , typically in onCreate . < / li > <nl> + * < / ol > <nl> + * <nl> + * For more complex mappings , you can supply your own { @ link ErrorDialogFragmentFactory } . <nl> + * <nl> + * @ author Markus <nl> + * / <nl> + public class ErrorDialogManager { <nl> + <nl> + public static class SupportManagerFragment extends Fragment { <nl> + protected boolean finishAfterDialog ; <nl> + protected Bundle argumentsForErrorDialog ; <nl> + private EventBus eventBus ; <nl> + private boolean skipRegisterOnNextResume ; <nl> + <nl> + @ Override <nl> + public void onCreate ( Bundle savedInstanceState ) { <nl> + super . onCreate ( savedInstanceState ) ; <nl> + eventBus = ErrorDialogManager . factory . config . getEventBus ( ) ; <nl> + eventBus . register ( this ) ; <nl> + skipRegisterOnNextResume = true ; <nl> + } <nl> + <nl> + @ Override <nl> + public void onResume ( ) { <nl> + super . onResume ( ) ; <nl> + if ( skipRegisterOnNextResume ) { <nl> + / / registered in onCreate , skip registration in this run <nl> + skipRegisterOnNextResume = false ; <nl> + } else { <nl> + eventBus = ErrorDialogManager . factory . config . getEventBus ( ) ; <nl> + eventBus . register ( this ) ; <nl> + } <nl> + } <nl> + <nl> + @ Override <nl> + public void onPause ( ) { <nl> + eventBus . unregister ( this ) ; <nl> + super . onPause ( ) ; <nl> + } <nl> + <nl> + public void onEventMainThread ( ThrowableFailureEvent event ) { <nl> + checkLogException ( event ) ; <nl> + / / Execute pending commits before finding to avoid multiple error fragments being shown <nl> + FragmentManager fm = getFragmentManager ( ) ; <nl> + fm . executePendingTransactions ( ) ; <nl> + <nl> + DialogFragment existingFragment = ( DialogFragment ) fm . findFragmentByTag ( TAG_ERROR_DIALOG ) ; <nl> + if ( existingFragment ! = null ) { <nl> + / / Just show the latest error <nl> + existingFragment . dismiss ( ) ; <nl> + } <nl> + <nl> + android . support . v4 . app . DialogFragment errorFragment = ( android . support . v4 . app . DialogFragment ) factory <nl> + . prepareErrorFragment ( event , finishAfterDialog , argumentsForErrorDialog ) ; <nl> + if ( errorFragment ! = null ) { <nl> + errorFragment . show ( fm , TAG_ERROR_DIALOG ) ; <nl> + } <nl> + } <nl> + <nl> + public static void attachTo ( Activity activity , boolean finishAfterDialog , Bundle argumentsForErrorDialog ) { <nl> + FragmentManager fm = ( ( FragmentActivity ) activity ) . getSupportFragmentManager ( ) ; <nl> + SupportManagerFragment fragment = ( SupportManagerFragment ) fm . findFragmentByTag ( TAG_ERROR_DIALOG_MANAGER ) ; <nl> + if ( fragment = = null ) { <nl> + fragment = new SupportManagerFragment ( ) ; <nl> + fm . beginTransaction ( ) . add ( fragment , TAG_ERROR_DIALOG_MANAGER ) . commit ( ) ; <nl> + fm . executePendingTransactions ( ) ; <nl> + } <nl> + fragment . finishAfterDialog = finishAfterDialog ; <nl> + fragment . argumentsForErrorDialog = argumentsForErrorDialog ; <nl> + } <nl> + } <nl> + <nl> + @ TargetApi ( Build . VERSION_CODES . HONEYCOMB ) <nl> + public static class HoneycombManagerFragment extends android . app . Fragment { <nl> + protected boolean finishAfterDialog ; <nl> + protected Bundle argumentsForErrorDialog ; <nl> + private EventBus eventBus ; <nl> + <nl> + @ Override <nl> + public void onResume ( ) { <nl> + super . onResume ( ) ; <nl> + eventBus = ErrorDialogManager . factory . config . getEventBus ( ) ; <nl> + eventBus . register ( this ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public void onPause ( ) { <nl> + eventBus . unregister ( this ) ; <nl> + super . onPause ( ) ; <nl> + } <nl> + <nl> + public void onEventMainThread ( ThrowableFailureEvent event ) { <nl> + checkLogException ( event ) ; <nl> + <nl> + / / Execute pending commits before finding to avoid multiple error fragments being shown <nl> + android . app . FragmentManager fm = getFragmentManager ( ) ; <nl> + fm . executePendingTransactions ( ) ; <nl> + <nl> + android . app . DialogFragment existingFragment = ( android . app . DialogFragment ) fm <nl> + . findFragmentByTag ( TAG_ERROR_DIALOG ) ; <nl> + if ( existingFragment ! = null ) { <nl> + / / Just show the latest error <nl> + existingFragment . dismiss ( ) ; <nl> + } <nl> + <nl> + android . app . DialogFragment errorFragment = ( android . app . DialogFragment ) factory . prepareErrorFragment ( event , <nl> + finishAfterDialog , argumentsForErrorDialog ) ; <nl> + if ( errorFragment ! = null ) { <nl> + errorFragment . show ( fm , TAG_ERROR_DIALOG ) ; <nl> + } <nl> + } <nl> + <nl> + public static void attachTo ( Activity activity , boolean finishAfterDialog , Bundle argumentsForErrorDialog ) { <nl> + android . app . FragmentManager fm = activity . getFragmentManager ( ) ; <nl> + HoneycombManagerFragment fragment = ( HoneycombManagerFragment ) fm <nl> + . findFragmentByTag ( TAG_ERROR_DIALOG_MANAGER ) ; <nl> + if ( fragment = = null ) { <nl> + fragment = new HoneycombManagerFragment ( ) ; <nl> + fm . beginTransaction ( ) . add ( fragment , TAG_ERROR_DIALOG_MANAGER ) . commit ( ) ; <nl> + fm . executePendingTransactions ( ) ; <nl> + } <nl> + fragment . finishAfterDialog = finishAfterDialog ; <nl> + fragment . argumentsForErrorDialog = argumentsForErrorDialog ; <nl> + } <nl> + } <nl> + <nl> + / * * Must be set by the application . * / <nl> + public static ErrorDialogFragmentFactory < ? > factory ; <nl> + <nl> + protected static final String TAG_ERROR_DIALOG = \" de . greenrobot . eventbus . error_dialog \" ; <nl> + protected static final String TAG_ERROR_DIALOG_MANAGER = \" de . greenrobot . eventbus . error_dialog_manager \" ; <nl> + <nl> + public static final String KEY_TITLE = \" de . greenrobot . eventbus . errordialog . title \" ; <nl> + public static final String KEY_MESSAGE = \" de . greenrobot . eventbus . errordialog . message \" ; <nl> + public static final String KEY_FINISH_AFTER_DIALOG = \" de . greenrobot . eventbus . errordialog . finish_after_dialog \" ; <nl> + public static final String KEY_ICON_ID = \" de . greenrobot . eventbus . errordialog . icon_id \" ; <nl> + public static final String KEY_EVENT_TYPE_ON_CLOSE = \" de . greenrobot . eventbus . errordialog . event_type_on_close \" ; <nl> + <nl> + public static void attachTo ( Activity activity ) { <nl> + attachTo ( activity , false , null ) ; <nl> + } <nl> + <nl> + public static void attachTo ( Activity activity , boolean finishAfterDialog ) { <nl> + attachTo ( activity , finishAfterDialog , null ) ; <nl> + } <nl> + <nl> + public static void attachTo ( Activity activity , boolean finishAfterDialog , Bundle argumentsForErrorDialog ) { <nl> + if ( factory = = null ) { <nl> + throw new RuntimeException ( \" You must set the static factory field to configure error dialogs for your app . \" ) ; <nl> + } <nl> + if ( isSupportActivity ( activity ) ) { <nl> + SupportManagerFragment . attachTo ( activity , finishAfterDialog , argumentsForErrorDialog ) ; <nl> + } else { <nl> + HoneycombManagerFragment . attachTo ( activity , finishAfterDialog , argumentsForErrorDialog ) ; <nl> + } <nl> + } <nl> + <nl> + private static boolean isSupportActivity ( Activity activity ) { <nl> + boolean isSupport = false ; <nl> + for ( Class < ? > c = activity . getClass ( ) . getSuperclass ( ) ; ; c = c . getSuperclass ( ) ) { <nl> + if ( c = = null ) { <nl> + throw new RuntimeException ( \" Illegal activity type : \" + activity . getClass ( ) ) ; <nl> + } <nl> + String name = c . getName ( ) ; <nl> + if ( name . equals ( \" android . support . v4 . app . FragmentActivity \" ) ) { <nl> + isSupport = true ; <nl> + break ; <nl> + } else if ( name . startsWith ( \" com . actionbarsherlock . app \" ) <nl> + & & ( name . endsWith ( \" . SherlockActivity \" ) | | name . endsWith ( \" . SherlockListActivity \" ) | | name <nl> + . endsWith ( \" . SherlockPreferenceActivity \" ) ) ) { <nl> + throw new RuntimeException ( \" Please use SherlockFragmentActivity . Illegal activity : \" + name ) ; <nl> + } else if ( name . equals ( \" android . app . Activity \" ) ) { <nl> + if ( Build . VERSION . SDK_INT < Build . VERSION_CODES . HONEYCOMB ) { <nl> + throw new RuntimeException ( <nl> + \" Illegal activity without fragment support . Either use Android 3 . 0 + or android . support . v4 . app . FragmentActivity . \" ) ; <nl> + } <nl> + break ; <nl> + } <nl> + } <nl> + return isSupport ; <nl> + } <nl> + <nl> + protected static void checkLogException ( ThrowableFailureEvent event ) { <nl> + if ( factory . config . logExceptions ) { <nl> + String tag = factory . config . tagForLoggingExceptions ; <nl> + if ( tag = = null ) { <nl> + tag = EventBus . TAG ; <nl> + } <nl> + Log . i ( tag , \" Error dialog manager received exception \" , event . throwable ) ; <nl> + } <nl> + } <nl> + <nl> + } <nl>\n", "msg": "register ErrorDialogManager in onCreate to avoid loosing failure events\n"}
{"diff_id": 20120, "repo": "oracle/graal\n", "sha": "5cba1098b3e5cd99f8187802eab2ec8a1c781171\n", "time": "2019-01-11T17:24:28Z\n", "diff": "mmm a / substratevm / src / com . oracle . svm . reflect / src / com / oracle / svm / reflect / hosted / ReflectionDataBuilder . java <nl> ppp b / substratevm / src / com . oracle . svm . reflect / src / com / oracle / svm / reflect / hosted / ReflectionDataBuilder . java <nl> <nl> <nl> public class ReflectionDataBuilder implements RuntimeReflectionSupport { <nl> <nl> + private static final DynamicHub . ReflectionData arrayReflectionData ; <nl> + <nl> + static { <nl> + Method [ ] publicArrayMethods ; <nl> + try { <nl> + Method reflectionDataMethod = findMethod ( Class . class , \" reflectionData \" ) ; <nl> + Class < ? > originalReflectionDataClass = Class . forName ( \" java . lang . Class $ ReflectionData \" ) ; <nl> + Field publicMethodsField = findField ( originalReflectionDataClass , \" publicMethods \" ) ; <nl> + <nl> + Class < ? > clazz = Object [ ] . class ; <nl> + clazz . getMethods ( ) ; <nl> + Object originalReflectionData = reflectionDataMethod . invoke ( clazz ) ; <nl> + publicArrayMethods = ( Method [ ] ) publicMethodsField . get ( originalReflectionData ) ; <nl> + } catch ( ReflectiveOperationException e ) { <nl> + throw VMError . shouldNotReachHere ( e ) ; <nl> + } <nl> + <nl> + / / array classes only have methods inherited from Object <nl> + arrayReflectionData = new DynamicHub . ReflectionData ( <nl> + new Field [ 0 ] , <nl> + new Field [ 0 ] , <nl> + new Method [ 0 ] , <nl> + publicArrayMethods , <nl> + new Constructor < ? > [ 0 ] , <nl> + new Constructor < ? > [ 0 ] , <nl> + null , <nl> + new Field [ 0 ] , <nl> + new Method [ 0 ] , <nl> + null ) ; <nl> + } <nl> + <nl> private boolean modified ; <nl> private boolean sealed ; <nl> <nl> protected void duringAnalysis ( DuringAnalysisAccess a ) { <nl> * to the set of processed classes so that the ReflectionData is initialized below . <nl> * / <nl> allClasses . add ( originalClass ) ; <nl> + } else if ( originalClass ! = null & & originalClass . isArray ( ) ) { <nl> + / / Always register reflection data for array classes <nl> + allClasses . add ( originalClass ) ; <nl> } <nl> } <nl> <nl> protected void duringAnalysis ( DuringAnalysisAccess a ) { <nl> <nl> try { <nl> Object originalReflectionData = reflectionDataMethod . invoke ( clazz ) ; <nl> - hub . setReflectionData ( new DynamicHub . ReflectionData ( <nl> - filterFields ( declaredFieldsField . get ( originalReflectionData ) , reflectionFields . keySet ( ) , access . getMetaAccess ( ) ) , <nl> - filterFields ( publicFieldsField . get ( originalReflectionData ) , reflectionFields . keySet ( ) , access . getMetaAccess ( ) ) , <nl> - filterMethods ( declaredMethodsField . get ( originalReflectionData ) , reflectionMethods , access . getMetaAccess ( ) ) , <nl> - filterMethods ( publicMethodsField . get ( originalReflectionData ) , reflectionMethods , access . getMetaAccess ( ) ) , <nl> - filterConstructors ( declaredConstructorsField . get ( originalReflectionData ) , reflectionMethods , access . getMetaAccess ( ) ) , <nl> - filterConstructors ( publicConstructorsField . get ( originalReflectionData ) , reflectionMethods , access . getMetaAccess ( ) ) , <nl> - nullaryConstructor ( declaredConstructorsField . get ( originalReflectionData ) , reflectionMethods ) , <nl> - filterFields ( declaredPublicFieldsField . get ( originalReflectionData ) , reflectionFields . keySet ( ) , access . getMetaAccess ( ) ) , <nl> - filterMethods ( declaredPublicMethodsField . get ( originalReflectionData ) , reflectionMethods , access . getMetaAccess ( ) ) , <nl> - enclosingMethodOrConstructor ( clazz ) ) ) ; <nl> + DynamicHub . ReflectionData reflectionData ; <nl> + <nl> + if ( type . isArray ( ) ) { <nl> + / / Always register reflection data for array classes <nl> + reflectionData = arrayReflectionData ; <nl> + } else { <nl> + reflectionData = new DynamicHub . ReflectionData ( <nl> + filterFields ( declaredFieldsField . get ( originalReflectionData ) , reflectionFields . keySet ( ) , access . getMetaAccess ( ) ) , <nl> + filterFields ( publicFieldsField . get ( originalReflectionData ) , reflectionFields . keySet ( ) , access . getMetaAccess ( ) ) , <nl> + filterMethods ( declaredMethodsField . get ( originalReflectionData ) , reflectionMethods , access . getMetaAccess ( ) ) , <nl> + filterMethods ( publicMethodsField . get ( originalReflectionData ) , reflectionMethods , access . getMetaAccess ( ) ) , <nl> + filterConstructors ( declaredConstructorsField . get ( originalReflectionData ) , reflectionMethods , access . getMetaAccess ( ) ) , <nl> + filterConstructors ( publicConstructorsField . get ( originalReflectionData ) , reflectionMethods , access . getMetaAccess ( ) ) , <nl> + nullaryConstructor ( declaredConstructorsField . get ( originalReflectionData ) , reflectionMethods ) , <nl> + filterFields ( declaredPublicFieldsField . get ( originalReflectionData ) , reflectionFields . keySet ( ) , access . getMetaAccess ( ) ) , <nl> + filterMethods ( declaredPublicMethodsField . get ( originalReflectionData ) , reflectionMethods , access . getMetaAccess ( ) ) , <nl> + enclosingMethodOrConstructor ( clazz ) ) ; <nl> + } <nl> + <nl> + hub . setReflectionData ( reflectionData ) ; <nl> } catch ( IllegalAccessException | IllegalArgumentException | InvocationTargetException ex ) { <nl> throw VMError . shouldNotReachHere ( ex ) ; <nl> } <nl>\n", "msg": "Make reflection data for array classes always available\n"}
{"diff_id": 20180, "repo": "ReactiveX/RxJava\n", "sha": "eb0609513909b7856a56c34bc065991d3626c283\n", "time": "2013-11-26T21:04:41Z\n", "diff": "mmm a / rxjava - core / src / main / java / rx / Observable . java <nl> ppp b / rxjava - core / src / main / java / rx / Observable . java <nl> public Subscription onSubscribe ( Observer < ? super T > observer ) { <nl> * Returns an Observable that emits a single item and then completes on a <nl> * specified scheduler . <nl> * < p > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / just . s . png \" > <nl> + * < p > <nl> * This is a scheduler version of { @ link Observable # just ( Object ) } . <nl> * <nl> * @ param value the item to pass to the { @ link Observer } ' s <nl> public Subscription onSubscribe ( Observer < ? super T > observer ) { <nl> * @ param t1 an Observable to be concatenated <nl> * @ param t2 an Observable to be concatenated <nl> * @ param t3 an Observable to be concatenated <nl> - * <nl> * @ return an Observable that emits items that are the result of combining <nl> * the items emitted by the { @ code source } Observables , one after <nl> * the other <nl> public Subscription onSubscribe ( Observer < ? super T > observer ) { <nl> / * * <nl> * Emits an item each time interval ( containing a sequential number ) . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / interval . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / interval . s . png \" > <nl> * <nl> * @ param interval interval size in time units ( see below ) <nl> * @ param unit time units to use for the interval size <nl> public Subscription onSubscribe ( Observer < ? super T > observer ) { <nl> * Note : If events keep firing faster than the timeout then no data will be <nl> * emitted . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / debounce . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / debounce . s . png \" > <nl> * < p > <nl> * Information on debounce vs throttle : <nl> * < p > <nl> public Subscription onSubscribe ( Observer < ? super T > observer ) { <nl> * Note : If events keep firing faster than the timeout then no data will be <nl> * emitted . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / throttleWithTimeout . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / throttleWithTimeout . s . png \" > <nl> * < p > <nl> * Information on debounce vs throttle : <nl> * < p > <nl> public Subscription onSubscribe ( Observer < ? super T > observer ) { <nl> * This differs from { @ link # throttleLast } in that this only tracks passage <nl> * of time whereas { @ link # throttleLast } ticks at scheduled intervals . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / throttleFirst . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / throttleFirst . s . png \" > <nl> * <nl> * @ param skipDuration time to wait before sending another item after <nl> * emitting the last item <nl> public Subscription onSubscribe ( Observer < ? super T > observer ) { <nl> * scheduled interval whereas { @ link # throttleFirst } does not tick , it just <nl> * tracks passage of time . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / throttleLast . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / throttleLast . s . png \" > <nl> * <nl> * @ param intervalDuration duration of windows within which the last item <nl> * will be emitted <nl> * @ param unit the unit of time for the specified interval <nl> + * @ param scheduler the { @ link Scheduler } to use internally to manage the <nl> + * timers that handle timeout for each event <nl> * @ return an Observable that performs the throttle operation <nl> * @ see < a href = \" https : / / github . com / Netflix / RxJava / wiki / Filtering - Observables # takelast \" > RxJava Wiki : throttleLast ( ) < / a > <nl> * @ see # sample ( long , TimeUnit , Scheduler ) <nl> public Subscription onSubscribe ( Observer < ? super T > observer ) { <nl> / * * <nl> * Converts a { @ link Future } into an Observable . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / from . Future . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / from . Future . s . png \" > <nl> * < p > <nl> * You can convert any object that supports the { @ link Future } interface <nl> * into an Observable that emits the return value of the { @ link Future # get } <nl> public Boolean call ( T first , T second ) { <nl> / * * <nl> * Creates an Observable that produces buffers of collected values . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / buffer5 . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / buffer5 . s . png \" > <nl> * < p > <nl> * This Observable produces connected , non - overlapping buffers , each of a <nl> * fixed duration specified by the < code > timespan < / code > argument . When the <nl> public Boolean call ( T first , T second ) { <nl> * first ) . When the source Observable completes or encounters an error , the <nl> * current buffer is emitted and the event is propagated . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / buffer6 . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / buffer6 . s . png \" > <nl> * <nl> * @ param timespan the period of time each buffer collects values before it <nl> * should be emitted and replaced with a new buffer <nl> public Boolean call ( T first , T second ) { <nl> * source Observable completes or encounters an error , the current buffer is <nl> * emitted and the event is propagated . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / buffer7 . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / buffer7 . s . png \" > <nl> * <nl> * @ param timespan the period of time each buffer collects values before it <nl> * should be emitted <nl> public Boolean call ( T first , T second ) { <nl> * source Observable completes or encounters an error , the current window is <nl> * emitted and the event is propagated . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / window5 . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / window5 . s . png \" > <nl> * <nl> * @ param timespan the period of time each window collects items before it <nl> * should be emitted and replaced with a new window <nl> public Boolean call ( T first , T second ) { <nl> * first ) . When the source Observable completes or encounters an error , the <nl> * current window is emitted and the event is propagated . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / window6 . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / window6 . s . png \" > <nl> * <nl> * @ param timespan the period of time each window collects values before it <nl> * should be emitted and replaced with a new window <nl> public Boolean call ( T first , T second ) { <nl> * source Observable completes or encounters an error , the current window is <nl> * emitted and the event is propagated . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / window7 . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / window7 . s . png \" > <nl> * <nl> * @ param timespan the period of time each window collects values before it <nl> * should be emitted <nl> public Integer call ( Integer t1 , T t2 ) { <nl> * { @ link Scheduler } <nl> * @ see < a href = \" https : / / github . com / Netflix / RxJava / wiki / Observable - Utility - Operators # parallel \" > RxJava Wiki : parallel ( ) < / a > <nl> * / <nl> - <nl> public < R > Observable < R > parallel ( final Func1 < Observable < T > , Observable < R > > f , final Scheduler s ) { <nl> return OperationParallel . parallel ( this , f , s ) ; <nl> } <nl> public Integer call ( Integer t1 , T t2 ) { <nl> * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / parallelMerge . png \" > <nl> * <nl> * @ param parallelObservables the number of Observables to merge into <nl> + * @ param scheduler <nl> * @ return an Observable of Observables constrained to number defined by <nl> * < code > parallelObservables < / code > . <nl> * @ see < a href = \" https : / / github . com / Netflix / RxJava / wiki / Combining - Observables # parallelmerge \" > RxJava Wiki : parallelMerge ( ) < / a > <nl> public Integer call ( Integer t1 , T t2 ) { <nl> * Returns an Observable that emits the results of sampling the items <nl> * emitted by the source Observable at a specified time interval . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / sample . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / sample . s . png \" > <nl> * <nl> * @ param period the sampling rate <nl> * @ param unit the { @ link TimeUnit } in which < code > period < / code > is defined <nl> public Boolean call ( T t ) { <nl> * isn ' t received within the specified timeout duration starting from its <nl> * predecessor , a TimeoutException is propagated to the observer . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / timeout . 1 . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / timeout . 1s . png \" > <nl> * <nl> * @ param timeout maximum duration between values before a timeout occurs <nl> * @ param timeUnit the unit of time which applies to the <nl> public Boolean call ( T t ) { <nl> * predecessor , the other observable sequence is used to produce future <nl> * messages from that point on . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / timeout . 2 . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / timeout . 2s . png \" > <nl> * <nl> * @ param timeout maximum duration between values before a timeout occurs <nl> * @ param timeUnit the unit of time which applies to the <nl> public Boolean call ( T t ) { <nl> * Records the time interval between consecutive items emitted by an <nl> * Observable , using the specified Scheduler to compute time intervals . <nl> * < p > <nl> - * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / timeInterval . png \" > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / timeInterval . s . png \" > <nl> * <nl> * @ param scheduler Scheduler used to compute time intervals <nl> * @ return an Observable that emits time interval information items <nl> public void onNext ( T args ) { } <nl> <nl> / * * <nl> * Invokes an action for each item emitted by an Observable . <nl> + * < p > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / doOnEach . e . png \" > <nl> * <nl> * @ param onNext the action to invoke for each item in the source sequence <nl> * @ param onError the action to invoke when the source Observable calls <nl> public void onNext ( T args ) { <nl> <nl> / * * <nl> * Invokes an action for each item emitted by an Observable . <nl> + * < p > <nl> + * < img width = \" 640 \" src = \" https : / / raw . github . com / wiki / Netflix / RxJava / images / rx - operators / doOnEach . ce . png \" > <nl> * <nl> * @ param onNext the action to invoke for each item in the source sequence <nl> * @ param onError the action to invoke when the source Observable calls <nl> public void onNext ( T args ) { <nl> <nl> } ; <nl> <nl> - <nl> return create ( OperationDoOnEach . doOnEach ( this , observer ) ) ; <nl> } <nl> <nl>\n", "msg": "visually distinguish operators that use schedulers ; add distinct doOnEach diagrams\n"}
{"diff_id": 20211, "repo": "oracle/graal\n", "sha": "b4f618758ff7c302b5ce15ba6f64ece826983725\n", "time": "2020-09-03T14:05:03Z\n", "diff": "mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / Target_com_oracle_truffle_espresso_polyglot_Polyglot . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / Target_com_oracle_truffle_espresso_polyglot_Polyglot . java <nl> public static boolean isForeignObject ( @ Host ( Object . class ) StaticObject object ) { <nl> } <nl> } <nl> <nl> + / / TODO : remove eager conversion once TruffleString is available <nl> + / * <nl> + * Eager String conversion is necessary here since there ' s no way to access the <nl> + * content / chars of foreign strings without a full conversion . <nl> + * / <nl> + if ( targetKlass = = meta . java_lang_String ) { <nl> + if ( ! interopLibrary . isString ( value . rawForeignObject ( ) ) ) { <nl> + throw Meta . throwExceptionWithMessage ( meta . java_lang_ClassCastException , \" Cannot cast a non - string foreign object to string \" ) ; <nl> + } <nl> + try { <nl> + return meta . toGuestString ( interopLibrary . asString ( value . rawForeignObject ( ) ) ) ; <nl> + } catch ( UnsupportedMessageException e ) { <nl> + CompilerDirectives . transferToInterpreter ( ) ; <nl> + throw EspressoError . shouldNotReachHere ( \" Contract violation : if isString returns true , asString must succeed . \" ) ; <nl> + } <nl> + } <nl> + <nl> try { <nl> ToEspressoNode . checkHasAllFieldsOrThrow ( value . rawForeignObject ( ) , ( ObjectKlass ) targetKlass , interopLibrary , meta ) ; <nl> } catch ( ClassCastException e ) { <nl>\n", "msg": "Eagerly convert a foreign value to string when Polyglot . cast ' ing to java . lang . String\n"}
{"diff_id": 20218, "repo": "oracle/graal\n", "sha": "defa36f486001f07d9e4254687d53f3ca050de7b\n", "time": "2015-09-23T00:43:05Z\n", "diff": "mmm a / graal / com . oracle . graal . truffle / src / com / oracle / graal / truffle / OptimizedCallTarget . java <nl> ppp b / graal / com . oracle . graal . truffle / src / com / oracle / graal / truffle / OptimizedCallTarget . java <nl> private void interpreterCall ( ) { <nl> } <nl> } <nl> <nl> - public void compile ( ) { <nl> + public final void compile ( ) { <nl> if ( ! isCompiling ( ) ) { <nl> compiling = true ; <nl> runtime . compile ( this , TruffleBackgroundCompilation . getValue ( ) & & ! TruffleCompilationExceptionsAreThrown . getValue ( ) ) ; <nl>\n", "msg": "Make method final to improve code that has a MethodHandle to it\n"}
{"diff_id": 20282, "repo": "spring-projects/spring-framework\n", "sha": "0933734fbb5dae4c523b3bc0fcfb30a927ddc209\n", "time": "2012-11-29T22:08:34Z\n", "diff": "mmm a / spring - jms / src / main / java / org / springframework / jms / listener / DefaultMessageListenerContainer . java <nl> ppp b / spring - jms / src / main / java / org / springframework / jms / listener / DefaultMessageListenerContainer . java <nl> public void setConcurrency ( String concurrency ) { <nl> * to scale the consumption of messages coming in from a queue . However , <nl> * note that any ordering guarantees are lost once multiple consumers are <nl> * registered . In general , stick with 1 consumer for low - volume queues . <nl> - * < p > < b > Do not raise the number of concurrent consumers for a topic . < / b > <nl> - * This would lead to concurrent consumption of the same message , <nl> - * which is hardly ever desirable . <nl> + * < p > < b > Do not raise the number of concurrent consumers for a topic , <nl> + * unless vendor - specific setup measures clearly allow for it . < / b > <nl> + * With regular setup , this would lead to concurrent consumption <nl> + * of the same message , which is hardly ever desirable . <nl> * < p > < b > This setting can be modified at runtime , for example through JMX . < / b > <nl> * @ see # setMaxConcurrentConsumers <nl> * / <nl> public final int getIdleTaskExecutionLimit ( ) { <nl> } <nl> } <nl> <nl> - @ Override <nl> - protected void validateConfiguration ( ) { <nl> - super . validateConfiguration ( ) ; <nl> - synchronized ( this . lifecycleMonitor ) { <nl> - if ( isSubscriptionDurable ( ) & & this . concurrentConsumers ! = 1 ) { <nl> - throw new IllegalArgumentException ( \" Only 1 concurrent consumer supported for durable subscription \" ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> <nl> / / mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - <nl> / / Implementation of AbstractMessageListenerContainer ' s template methods <nl>\n", "msg": "DefaultMessageListenerContainer allows for concurrent subscription consumers on WebLogic / ActiveMQ\n"}
{"diff_id": 20367, "repo": "libgdx/libgdx\n", "sha": "2337a333882ac8eb11d6d7c807c28ea7f85326d9\n", "time": "2014-03-23T12:23:07Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / math / CatmullRomSpline . java <nl> ppp b / gdx / src / com / badlogic / gdx / math / CatmullRomSpline . java <nl> public float approximate ( final T in , final int near ) { <nl> P3 = in ; <nl> n = n > 0 ? n - 1 : spanCount - 1 ; <nl> } <nl> - float L1 = P1 . dst ( P2 ) ; <nl> - float L2 = P3 . dst ( P2 ) ; <nl> - float L3 = P3 . dst ( P1 ) ; <nl> - float s = ( L2 * L2 + L1 * L1 - L3 * L3 ) / ( 2 * L1 ) ; <nl> + float L1Sqr = P1 . dst2 ( P2 ) ; <nl> + float L2Sqr = P3 . dst2 ( P2 ) ; <nl> + float L3Sqr = P3 . dst2 ( P1 ) ; <nl> + float L1 = ( float ) Math . sqrt ( L1Sqr ) ; <nl> + float s = ( L2Sqr + L1Sqr - L3Sqr ) / ( 2f * L1 ) ; <nl> float u = MathUtils . clamp ( ( L1 - s ) / L1 , 0f , 1f ) ; <nl> return ( ( float ) n + u ) / spanCount ; <nl> } <nl>\n", "msg": "Small optimization to avoid unnecessary square roots\n"}
{"diff_id": 20373, "repo": "apache/flink\n", "sha": "4fc3bcf382a4c99ac88adebaf1d950bba0cc7b53\n", "time": "2018-02-24T14:04:56Z\n", "diff": "mmm a / flink - runtime / src / main / java / org / apache / flink / runtime / jobmaster / slotpool / SlotSharingManager . java <nl> ppp b / flink - runtime / src / main / java / org / apache / flink / runtime / jobmaster / slotpool / SlotSharingManager . java <nl> public boolean release ( Throwable cause ) { <nl> if ( parent ! = null ) { <nl> / / we remove ourselves from our parent if we no longer have children <nl> parent . releaseChild ( getGroupId ( ) ) ; <nl> - } else { <nl> + } else if ( allTaskSlots . remove ( getSlotRequestId ( ) ) ! = null ) { <nl> / / we are the root node - - > remove the root node from the list of task slots <nl> - allTaskSlots . remove ( getSlotRequestId ( ) ) ; <nl> <nl> if ( ! slotContextFuture . isDone ( ) | | slotContextFuture . isCompletedExceptionally ( ) ) { <nl> synchronized ( lock ) { <nl>\n", "msg": "[ hotfix ] Avoid redundant slot release operations\n"}
{"diff_id": 20390, "repo": "google/ExoPlayer\n", "sha": "6bd0ba887c70e500724b4fc87d40db74f8d0c019\n", "time": "2017-08-31T15:33:43Z\n", "diff": "mmm a / library / hls / src / main / java / com / google / android / exoplayer2 / source / hls / HlsChunkSource . java <nl> ppp b / library / hls / src / main / java / com / google / android / exoplayer2 / source / hls / HlsChunkSource . java <nl> public void clear ( ) { <nl> private byte [ ] scratchSpace ; <nl> private IOException fatalError ; <nl> private HlsUrl expectedPlaylistUrl ; <nl> + private boolean independentSegments ; <nl> <nl> private Uri encryptionKeyUri ; <nl> private byte [ ] encryptionKey ; <nl> public void getNextChunk ( HlsMediaChunk previous , long playbackPositionUs , HlsChu <nl> int oldVariantIndex = previous = = null ? C . INDEX_UNSET <nl> : trackGroup . indexOf ( previous . trackFormat ) ; <nl> expectedPlaylistUrl = null ; <nl> - / / Use start time of the previous chunk rather than its end time because switching format will <nl> - / / require downloading overlapping segments . <nl> - long bufferedDurationUs = previous = = null ? 0 <nl> - : Math . max ( 0 , previous . startTimeUs - playbackPositionUs ) ; <nl> + / / Unless segments are known to be independent , switching variant will require downloading <nl> + / / overlapping segments . Hence we use the start time of the previous chunk rather than its end <nl> + / / time for this case . <nl> + long bufferedDurationUs = previous = = null ? 0 : Math . max ( 0 , <nl> + ( independentSegments ? previous . endTimeUs : previous . startTimeUs ) - playbackPositionUs ) ; <nl> <nl> / / Select the variant . <nl> trackSelection . updateSelectedTrack ( bufferedDurationUs ) ; <nl> public void getNextChunk ( HlsMediaChunk previous , long playbackPositionUs , HlsChu <nl> return ; <nl> } <nl> HlsMediaPlaylist mediaPlaylist = playlistTracker . getPlaylistSnapshot ( selectedUrl ) ; <nl> + independentSegments = mediaPlaylist . hasIndependentSegmentsTag ; <nl> <nl> / / Select the chunk . <nl> int chunkMediaSequence ; <nl> if ( previous = = null | | switchingVariant ) { <nl> long targetPositionUs = previous = = null ? playbackPositionUs <nl> - : mediaPlaylist . hasIndependentSegmentsTag ? previous . endTimeUs : previous . startTimeUs ; <nl> + : independentSegments ? previous . endTimeUs : previous . startTimeUs ; <nl> if ( ! mediaPlaylist . hasEndTag & & targetPositionUs > = mediaPlaylist . getEndTimeUs ( ) ) { <nl> / / If the playlist is too old to contain the chunk , we need to refresh it . <nl> chunkMediaSequence = mediaPlaylist . mediaSequence + mediaPlaylist . segments . size ( ) ; <nl>\n", "msg": "Allow more aggressive switching for HLS with independent segments\n"}
{"diff_id": 20407, "repo": "bazelbuild/bazel\n", "sha": "321243d44811542137522d5c6fa89bd0b5ee3549\n", "time": "2020-05-27T05:26:41Z\n", "diff": "mmm a / src / tools / android / java / com / google / devtools / build / android / desugar / langmodel / MethodDeclInfo . java <nl> ppp b / src / tools / android / java / com / google / devtools / build / android / desugar / langmodel / MethodDeclInfo . java <nl> <nl> <nl> public abstract ImmutableList < String > exceptions ( ) ; <nl> <nl> + public static MethodDeclInfoBuilder builder ( ) { <nl> + return new AutoValue_MethodDeclInfo . Builder ( ) <nl> + . setSignature ( null ) <nl> + . setExceptions ( ImmutableList . of ( ) ) ; <nl> + } <nl> + <nl> public static MethodDeclInfo create ( <nl> MethodKey methodKey , <nl> int ownerAccess , <nl> int memberAccess , <nl> @ Nullable String signature , <nl> @ Nullable String [ ] exceptions ) { <nl> - return create ( <nl> - methodKey , <nl> - ownerAccess , <nl> - memberAccess , <nl> - signature , <nl> - exceptions = = null ? ImmutableList . of ( ) : ImmutableList . copyOf ( exceptions ) ) ; <nl> + return builder ( ) <nl> + . setMethodKey ( methodKey ) <nl> + . setOwnerAccess ( ownerAccess ) <nl> + . setMemberAccess ( memberAccess ) <nl> + . setSignature ( signature ) <nl> + . setExceptionArray ( exceptions ) <nl> + . build ( ) ; <nl> } <nl> <nl> - private static MethodDeclInfo create ( <nl> - MethodKey methodKey , <nl> - int ownerAccess , <nl> - int memberAccess , <nl> - String signature , <nl> - ImmutableList < String > exceptions ) { <nl> - return new AutoValue_MethodDeclInfo ( <nl> - methodKey , ownerAccess , memberAccess , signature , exceptions ) ; <nl> - } <nl> + public abstract MethodDeclInfoBuilder toBuilder ( ) ; <nl> <nl> public final ClassName owner ( ) { <nl> return methodKey ( ) . owner ( ) ; <nl> public final boolean isInterfaceMethod ( ) { <nl> <nl> / * * The synthetic constructor for a private constructor . * / <nl> public final MethodDeclInfo bridgeOfConstructor ( ClassName nestCompanion ) { <nl> - return create ( <nl> - methodKey ( ) . bridgeOfConstructor ( nestCompanion ) , <nl> - ownerAccess ( ) , <nl> - ( memberAccess ( ) & ~ ACC_PRIVATE ) | ACC_SYNTHETIC , <nl> - / * signature = * / null , <nl> - exceptions ( ) ) ; <nl> + int memberAccess = ( memberAccess ( ) & ~ ACC_PRIVATE ) | ACC_SYNTHETIC ; <nl> + return toBuilder ( ) <nl> + . setMethodKey ( methodKey ( ) . bridgeOfConstructor ( nestCompanion ) ) <nl> + . setMemberAccess ( memberAccess ) <nl> + . build ( ) ; <nl> } <nl> <nl> / * * The synthetic bridge method for a private static method in a class . * / <nl> public final MethodDeclInfo bridgeOfClassStaticMethod ( ) { <nl> - return create ( <nl> - methodKey ( ) . bridgeOfClassStaticMethod ( ) , <nl> - ownerAccess ( ) , <nl> - ACC_STATIC | ACC_SYNTHETIC , <nl> - / * signature = * / null , <nl> - exceptions ( ) ) ; <nl> + return toBuilder ( ) <nl> + . setMethodKey ( methodKey ( ) . bridgeOfClassStaticMethod ( ) ) <nl> + . setMemberAccess ( ACC_STATIC | ACC_SYNTHETIC ) <nl> + . build ( ) ; <nl> } <nl> <nl> / * * The synthetic bridge method for a private instance method in a class . * / <nl> public final MethodDeclInfo bridgeOfClassInstanceMethod ( ) { <nl> - return create ( <nl> - methodKey ( ) . bridgeOfClassInstanceMethod ( ) , <nl> - ownerAccess ( ) , <nl> - / * memberAccess = * / ACC_STATIC | ACC_SYNTHETIC , <nl> - / * signature = * / null , <nl> - exceptions ( ) ) ; <nl> + return toBuilder ( ) <nl> + . setMethodKey ( methodKey ( ) . bridgeOfClassInstanceMethod ( ) ) <nl> + . setMemberAccess ( ACC_STATIC | ACC_SYNTHETIC ) <nl> + . build ( ) ; <nl> } <nl> <nl> / * * The substitute method for a private static method in an interface . * / <nl> public final MethodDeclInfo substituteOfInterfaceStaticMethod ( ) { <nl> - return create ( <nl> - methodKey ( ) . substituteOfInterfaceStaticMethod ( ) , <nl> - ownerAccess ( ) , <nl> - ( memberAccess ( ) & ~ 0xf ) | ACC_PUBLIC | ACC_STATIC , <nl> - / * signature = * / null , <nl> - exceptions ( ) ) ; <nl> + return toBuilder ( ) <nl> + . setMethodKey ( methodKey ( ) . substituteOfInterfaceStaticMethod ( ) ) <nl> + . setMemberAccess ( ( memberAccess ( ) & ~ 0xf ) | ACC_PUBLIC | ACC_STATIC ) <nl> + . build ( ) ; <nl> } <nl> <nl> / * * The substitute method for a private instance method in an interface . * / <nl> public final MethodDeclInfo substituteOfInterfaceInstanceMethod ( ) { <nl> - return create ( <nl> - methodKey ( ) . substituteOfInterfaceInstanceMethod ( ) , <nl> - ownerAccess ( ) , <nl> - ( memberAccess ( ) & ~ 0xf ) | ACC_PUBLIC | ACC_STATIC , / / Unset static and access modifier bits . <nl> - / * signature = * / null , <nl> - exceptions ( ) ) ; <nl> + / / Unset static and access modifier bits . <nl> + return toBuilder ( ) <nl> + . setMethodKey ( methodKey ( ) . substituteOfInterfaceInstanceMethod ( ) ) <nl> + . setMemberAccess ( ( memberAccess ( ) & ~ 0xf ) | ACC_PUBLIC | ACC_STATIC ) <nl> + . build ( ) ; <nl> } <nl> <nl> public final MethodVisitor accept ( ClassVisitor cv ) { <nl> public final MethodVisitor accept ( ClassVisitor cv ) { <nl> <nl> @ Override <nl> public MethodDeclInfo acceptTypeMapper ( TypeMapper typeMapper ) { <nl> - return create ( <nl> - methodKey ( ) . acceptTypeMapper ( typeMapper ) , <nl> - ownerAccess ( ) , <nl> - memberAccess ( ) , <nl> - typeMapper . mapSignature ( signature ( ) , / * typeSignature = * / false ) , <nl> - typeMapper . mapTypes ( exceptionArray ( ) ) ) ; <nl> + return toBuilder ( ) <nl> + . setMethodKey ( methodKey ( ) . acceptTypeMapper ( typeMapper ) ) <nl> + . setSignature ( typeMapper . mapSignature ( signature ( ) , / * typeSignature = * / false ) ) <nl> + . setExceptionArray ( typeMapper . mapTypes ( exceptionArray ( ) ) ) <nl> + . build ( ) ; <nl> } <nl> <nl> @ Override <nl> public int compareTo ( MethodDeclInfo other ) { <nl> return methodKey ( ) . compareTo ( other . methodKey ( ) ) ; <nl> } <nl> + <nl> + / * * The builder for { @ link MethodDeclInfo } . * / <nl> + @ AutoValue . Builder <nl> + public abstract static class MethodDeclInfoBuilder { <nl> + <nl> + public abstract MethodDeclInfoBuilder setMethodKey ( MethodKey value ) ; <nl> + <nl> + public abstract MethodDeclInfoBuilder setOwnerAccess ( int value ) ; <nl> + <nl> + public abstract MethodDeclInfoBuilder setMemberAccess ( int value ) ; <nl> + <nl> + public abstract MethodDeclInfoBuilder setSignature ( String value ) ; <nl> + <nl> + public abstract MethodDeclInfoBuilder setExceptions ( ImmutableList < String > value ) ; <nl> + <nl> + public final MethodDeclInfoBuilder setExceptionArray ( String [ ] exceptions ) { <nl> + return setExceptions ( <nl> + exceptions = = null ? ImmutableList . of ( ) : ImmutableList . copyOf ( exceptions ) ) ; <nl> + } <nl> + <nl> + public abstract MethodDeclInfo build ( ) ; <nl> + } <nl> } <nl>\n", "msg": "Migrate MethodDeclInfo to use @ AutoValue Builder Pattern\n"}
{"diff_id": 20479, "repo": "zxing/zxing\n", "sha": "5798f4039849845f4637f3d2871b040ffd4e2f2c\n", "time": "2010-11-11T16:15:35Z\n", "diff": "mmm a / android / src / com / google / zxing / client / android / ViewfinderView . java <nl> ppp b / android / src / com / google / zxing / client / android / ViewfinderView . java <nl> public void onDraw ( Canvas canvas ) { <nl> lastPossibleResultPoints = currentPossible ; <nl> paint . setAlpha ( OPAQUE ) ; <nl> paint . setColor ( resultPointColor ) ; <nl> - for ( ResultPoint point : currentPossible ) { <nl> - canvas . drawCircle ( frame . left + ( int ) ( point . getX ( ) * scaleX ) , <nl> - frame . top + ( int ) ( point . getY ( ) * scaleY ) , <nl> - 6 . 0f , paint ) ; <nl> + synchronized ( currentPossible ) { <nl> + for ( ResultPoint point : currentPossible ) { <nl> + canvas . drawCircle ( frame . left + ( int ) ( point . getX ( ) * scaleX ) , <nl> + frame . top + ( int ) ( point . getY ( ) * scaleY ) , <nl> + 6 . 0f , paint ) ; <nl> + } <nl> } <nl> } <nl> if ( currentLast ! = null ) { <nl> paint . setAlpha ( OPAQUE / 2 ) ; <nl> paint . setColor ( resultPointColor ) ; <nl> - for ( ResultPoint point : currentLast ) { <nl> - canvas . drawCircle ( frame . left + ( int ) ( point . getX ( ) * scaleX ) , <nl> - frame . top + ( int ) ( point . getY ( ) * scaleY ) , <nl> - 3 . 0f , paint ) ; <nl> + synchronized ( currentLast ) { <nl> + for ( ResultPoint point : currentLast ) { <nl> + canvas . drawCircle ( frame . left + ( int ) ( point . getX ( ) * scaleX ) , <nl> + frame . top + ( int ) ( point . getY ( ) * scaleY ) , <nl> + 3 . 0f , paint ) ; <nl> + } <nl> } <nl> } <nl> <nl> public void drawResultBitmap ( Bitmap barcode ) { <nl> } <nl> <nl> public void addPossibleResultPoint ( ResultPoint point ) { <nl> - possibleResultPoints . add ( point ) ; <nl> + synchronized ( possibleResultPoints ) { <nl> + possibleResultPoints . add ( point ) ; <nl> + } <nl> } <nl> <nl> } <nl>\n", "msg": "Another paranoid attempt to avoid Wildfire problem\n"}
{"diff_id": 20488, "repo": "oracle/graal\n", "sha": "16d335f1d36bc9de2ede1f983fa81e0285fdc0f6\n", "time": "2018-10-10T14:35:36Z\n", "diff": "mmm a / substratevm / src / com . oracle . svm . hosted / src / com / oracle / svm / hosted / ClassValueFeature . java <nl> ppp b / substratevm / src / com . oracle . svm . hosted / src / com / oracle / svm / hosted / ClassValueFeature . java <nl> private static boolean hasValue ( ClassValue < ? > v , Class < ? > c ) { <nl> try { <nl> Map < ? , ? > map = ( Map < ? , ? > ) CLASS_VALUE_MAP . get ( c ) ; <nl> final Object id = IDENTITY . get ( v ) ; <nl> - final boolean res = map . containsKey ( id ) ; <nl> + final boolean res = map ! = null & & map . containsKey ( id ) ; <nl> return res ; <nl> } catch ( RuntimeException ex ) { <nl> throw ex ; <nl>\n", "msg": "handle null entry in ClassValue map\n"}
{"diff_id": 20551, "repo": "square/okhttp\n", "sha": "6587a862cf4e60832a07dea2c1b420493b5a7e93\n", "time": "2014-02-11T17:04:18Z\n", "diff": "mmm a / okcurl / src / main / java / com / squareup / okhttp / curl / Main . java <nl> ppp b / okcurl / src / main / java / com / squareup / okhttp / curl / Main . java <nl> private static String protocols ( ) { <nl> } ) ) ; <nl> } <nl> <nl> + @ Option ( name = { \" - X \" , \" - - request \" } , description = \" Specify request command to use \" , <nl> + allowedValues = { \" GET \" , \" HEAD \" } ) <nl> + public String method = \" GET \" ; <nl> + <nl> @ Option ( name = { \" - H \" , \" - - header \" } , description = \" Custom header to pass to server \" ) <nl> public List < String > headers ; <nl> <nl> private OkHttpClient getConfiguredClient ( ) { <nl> <nl> private Request getConfiguredRequest ( ) { <nl> Request . Builder request = new Request . Builder ( ) ; <nl> + request . method ( method , null ) ; <nl> request . url ( url ) ; <nl> if ( headers ! = null ) { <nl> for ( String header : headers ) { <nl>\n", "msg": "Add - X to okcurl , permitting HEAD requests .\n"}
{"diff_id": 20600, "repo": "bazelbuild/bazel\n", "sha": "d1f93854d2954b6356e4908ae8f91875ea2a24ca\n", "time": "2015-04-16T18:36:31Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / rules / java / JavaCommon . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / java / JavaCommon . java <nl> public static final void validateConstraint ( RuleContext ruleContext , <nl> } <nl> } <nl> <nl> + / * * <nl> + * Creates an action to aggregate all metadata artifacts into a single <nl> + * & lt ; target_name & gt ; _instrumented . jar file . <nl> + * / <nl> + public static void createInstrumentedJarAction ( RuleContext ruleContext , JavaSemantics semantics , <nl> + List < Artifact > metadataArtifacts , Artifact instrumentedJar , String mainClass ) { <nl> + / / In Jacoco ' s setup , metadata artifacts are real jars . <nl> + new DeployArchiveBuilder ( semantics , ruleContext ) <nl> + . setOutputJar ( instrumentedJar ) <nl> + / / We need to save the original mainClass because we ' re going to run inside CoverageRunner <nl> + . setJavaStartClass ( mainClass ) <nl> + . setAttributes ( new JavaTargetAttributes . Builder ( semantics ) . build ( ) ) <nl> + . addRuntimeJars ( ImmutableList . copyOf ( metadataArtifacts ) ) <nl> + . setCompression ( DeployArchiveBuilder . Compression . UNCOMPRESSED ) <nl> + . build ( ) ; <nl> + } <nl> + <nl> public void setClassPathFragment ( ClasspathConfiguredFragment classpathFragment ) { <nl> this . classpathFragment = classpathFragment ; <nl> } <nl>\n", "msg": "Add a function to JavaCommon to create instrumented jars .\n"}
{"diff_id": 20660, "repo": "elastic/elasticsearch\n", "sha": "3b585e5a5e5a23b549f2e6fea719556b82592898\n", "time": "2014-12-10T10:10:32Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / index / gateway / local / LocalIndexShardGateway . java <nl> ppp b / src / main / java / org / elasticsearch / index / gateway / local / LocalIndexShardGateway . java <nl> public void recover ( boolean indexShouldExists , RecoveryState recoveryState ) thro <nl> <nl> final Set < String > typesToUpdate = Sets . newHashSet ( ) ; <nl> try { <nl> + logger . trace ( \" recovering translog file : { } length : { } \" , recoveringTranslogFile , Files . size ( recoveringTranslogFile ) ) ; <nl> TranslogStream stream = TranslogStreams . translogStreamFor ( recoveringTranslogFile ) ; <nl> try { <nl> in = stream . openInput ( recoveringTranslogFile ) ; <nl> } catch ( TruncatedTranslogException e ) { <nl> / / file is empty or header has been half - written and should be ignored <nl> - logger . trace ( \" ignoring truncation exception , the translog is either empty or half - written ( [ { } ] ) \" , e . getMessage ( ) ) ; <nl> + logger . trace ( \" ignoring truncation exception , the translog is either empty or half - written \" , e ) ; <nl> } <nl> while ( true ) { <nl> if ( in = = null ) { <nl> public void recover ( boolean indexShouldExists , RecoveryState recoveryState ) thro <nl> operation = stream . read ( in ) ; <nl> } catch ( EOFException e ) { <nl> / / ignore , not properly written the last op <nl> - logger . trace ( \" ignoring translog EOF exception , the last operation was not properly written ( [ { } ] ) \" , e . getMessage ( ) ) ; <nl> + logger . trace ( \" ignoring translog EOF exception , the last operation was not properly written \" , e ) ; <nl> break ; <nl> } catch ( IOException e ) { <nl> / / ignore , not properly written last op <nl> - logger . trace ( \" ignoring translog IO exception , the last operation was not properly written ( [ { } ] ) \" , e . getMessage ( ) ) ; <nl> + logger . trace ( \" ignoring translog IO exception , the last operation was not properly written \" , e ) ; <nl> break ; <nl> } <nl> try { <nl>\n", "msg": "Add more trace logging to gateway translog recovery\n"}
{"diff_id": 20786, "repo": "google/ExoPlayer\n", "sha": "c991b80c856f0d2f8cfb8afb8106a0fc05b625ae\n", "time": "2018-01-15T11:24:57Z\n", "diff": "mmm a / library / core / src / main / java / com / google / android / exoplayer2 / extractor / mp4 / Mp4Extractor . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / extractor / mp4 / Mp4Extractor . java <nl> private void processMoovAtom ( ContainerAtom moov ) throws ParserException { <nl> int firstVideoTrackIndex = C . INDEX_UNSET ; <nl> long durationUs = C . TIME_UNSET ; <nl> List < Mp4Track > tracks = new ArrayList < > ( ) ; <nl> - long earliestSampleOffset = Long . MAX_VALUE ; <nl> <nl> Metadata metadata = null ; <nl> GaplessInfoHolder gaplessInfoHolder = new GaplessInfoHolder ( ) ; <nl> private void processMoovAtom ( ContainerAtom moov ) throws ParserException { <nl> firstVideoTrackIndex = tracks . size ( ) ; <nl> } <nl> tracks . add ( mp4Track ) ; <nl> - <nl> - long firstSampleOffset = trackSampleTable . offsets [ 0 ] ; <nl> - if ( firstSampleOffset < earliestSampleOffset ) { <nl> - earliestSampleOffset = firstSampleOffset ; <nl> - } <nl> } <nl> this . firstVideoTrackIndex = firstVideoTrackIndex ; <nl> this . durationUs = durationUs ; <nl>\n", "msg": "Rmeove unused variable in Mp4Extractor and HeifExtractor .\n"}
{"diff_id": 20793, "repo": "elastic/elasticsearch\n", "sha": "3126c9b39d5bdcab50afa1899db62488f19daa47\n", "time": "2015-04-01T15:32:01Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / common / logging / log4j / LogConfigurator . java <nl> ppp b / src / main / java / org / elasticsearch / common / logging / log4j / LogConfigurator . java <nl> <nl> <nl> import com . google . common . collect . ImmutableList ; <nl> import com . google . common . collect . ImmutableMap ; <nl> + <nl> import org . apache . log4j . PropertyConfigurator ; <nl> + import org . apache . log4j . rolling . SizeBasedTriggeringPolicy ; <nl> import org . elasticsearch . ElasticsearchException ; <nl> import org . elasticsearch . common . collect . MapBuilder ; <nl> import org . elasticsearch . common . settings . ImmutableSettings ; <nl> <nl> . put ( \" telnet \" , \" org . apache . log4j . net . TelnetAppender \" ) <nl> / / policies <nl> . put ( \" timeBased \" , \" org . apache . log4j . rolling . TimeBasedRollingPolicy \" ) <nl> + . put ( \" sizeBased \" , \" org . apache . log4j . rolling . SizeBasedTriggeringPolicy \" ) <nl> / / layouts <nl> . put ( \" simple \" , \" org . apache . log4j . SimpleLayout \" ) <nl> . put ( \" html \" , \" org . apache . log4j . HTMLLayout \" ) <nl>\n", "msg": "add ability to specify a SizeBasedTriggeringPolicy for log configuration\n"}
{"diff_id": 20837, "repo": "netty/netty\n", "sha": "b7e6a86c1e9b5920af696e7f7149d4675fbf0485\n", "time": "2013-07-05T05:07:51Z\n", "diff": "mmm a / transport / src / main / java / io / netty / channel / MessageList . java <nl> ppp b / transport / src / main / java / io / netty / channel / MessageList . java <nl> public T get ( int index ) { <nl> return elements [ index ] ; <nl> } <nl> <nl> + / * * <nl> + * Returns the first message in this list . <nl> + * <nl> + * @ throws NoSuchElementException if this list is empty <nl> + * / <nl> + public T first ( ) { <nl> + if ( size ! = 0 ) { <nl> + return elements [ 0 ] ; <nl> + } else { <nl> + throw new NoSuchElementException ( ) ; <nl> + } <nl> + } <nl> + <nl> + / * * <nl> + * Returns the last message in this list . <nl> + * <nl> + * @ throws NoSuchElementException if this list is empty <nl> + * / <nl> + public T last ( ) { <nl> + if ( size ! = 0 ) { <nl> + return elements [ size - 1 ] ; <nl> + } else { <nl> + throw new NoSuchElementException ( ) ; <nl> + } <nl> + } <nl> + <nl> / * * <nl> * Sets the message on the given index . <nl> * / <nl>\n", "msg": "Add MessageList . first ( ) and last ( ) for convenience .\n"}
{"diff_id": 20952, "repo": "redisson/redisson\n", "sha": "3e0f02cbf88e399986c2e52d9f75444baf107fad\n", "time": "2016-01-21T12:02:04Z\n", "diff": "mmm a / src / main / java / org / redisson / cluster / ClusterConnectionManager . java <nl> ppp b / src / main / java / org / redisson / cluster / ClusterConnectionManager . java <nl> <nl> import java . util . Collections ; <nl> import java . util . HashMap ; <nl> import java . util . HashSet ; <nl> + import java . util . Iterator ; <nl> import java . util . List ; <nl> import java . util . Map ; <nl> import java . util . Set ; <nl> <nl> import org . redisson . client . RedisClient ; <nl> import org . redisson . client . RedisConnection ; <nl> import org . redisson . client . RedisConnectionException ; <nl> + import org . redisson . client . RedisException ; <nl> import org . redisson . client . protocol . RedisCommands ; <nl> import org . redisson . cluster . ClusterNodeInfo . Flag ; <nl> import org . redisson . connection . CRC16 ; <nl> + import org . redisson . connection . ClientConnectionsEntry . FreezeReason ; <nl> + import org . redisson . connection . ClientConnectionsEntry . NodeType ; <nl> import org . redisson . connection . MasterSlaveConnectionManager ; <nl> import org . redisson . connection . MasterSlaveEntry ; <nl> import org . redisson . connection . SingleEntry ; <nl> - import org . redisson . connection . ClientConnectionsEntry . FreezeReason ; <nl> - import org . redisson . connection . ClientConnectionsEntry . NodeType ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> public ClusterConnectionManager ( ClusterServersConfig cfg , Config config ) { <nl> this . config = create ( cfg ) ; <nl> init ( this . config ) ; <nl> <nl> + Exception lastException = null ; <nl> for ( URI addr : cfg . getNodeAddresses ( ) ) { <nl> - RedisConnection connection = connect ( cfg , addr , true ) ; <nl> - if ( connection = = null ) { <nl> - continue ; <nl> - } <nl> - <nl> - String nodesValue = connection . sync ( RedisCommands . CLUSTER_NODES ) ; <nl> + Future < RedisConnection > connectionFuture = connect ( cfg , addr ) ; <nl> + try { <nl> + RedisConnection connection = connectionFuture . syncUninterruptibly ( ) . getNow ( ) ; <nl> + String nodesValue = connection . sync ( RedisCommands . CLUSTER_NODES ) ; <nl> + <nl> + Collection < ClusterPartition > partitions = parsePartitions ( nodesValue ) ; <nl> + List < Future < Collection < Future < Void > > > > futures = new ArrayList < Future < Collection < Future < Void > > > > ( ) ; <nl> + for ( ClusterPartition partition : partitions ) { <nl> + Future < Collection < Future < Void > > > masterFuture = addMasterEntry ( partition , cfg ) ; <nl> + futures . add ( masterFuture ) ; <nl> + } <nl> <nl> - Collection < ClusterPartition > partitions = parsePartitions ( nodesValue ) ; <nl> - for ( ClusterPartition partition : partitions ) { <nl> - Collection < Future < Void > > s = addMasterEntry ( partition , cfg , true ) ; <nl> - for ( Future < Void > future : s ) { <nl> - future . syncUninterruptibly ( ) ; <nl> + for ( Future < Collection < Future < Void > > > masterFuture : futures ) { <nl> + masterFuture . syncUninterruptibly ( ) ; <nl> + for ( Future < Void > future : masterFuture . getNow ( ) ) { <nl> + future . syncUninterruptibly ( ) ; <nl> + } <nl> } <nl> + break ; <nl> + } catch ( Exception e ) { <nl> + lastException = e ; <nl> + log . warn ( e . getMessage ( ) ) ; <nl> } <nl> - <nl> - break ; <nl> } <nl> <nl> if ( lastPartitions . isEmpty ( ) ) { <nl> - throw new RedisConnectionException ( \" Can ' t connect to servers ! \" ) ; <nl> + throw new RedisConnectionException ( \" Can ' t connect to servers ! \" , lastException ) ; <nl> } <nl> <nl> monitorClusterChange ( cfg ) ; <nl> } <nl> <nl> - private RedisConnection connect ( ClusterServersConfig cfg , URI addr , boolean skipLogging ) { <nl> + private Future < RedisConnection > connect ( ClusterServersConfig cfg , final URI addr ) { <nl> RedisConnection connection = nodeConnections . get ( addr ) ; <nl> if ( connection ! = null ) { <nl> - return connection ; <nl> + return newSucceededFuture ( connection ) ; <nl> } <nl> + <nl> RedisClient client = createClient ( addr . getHost ( ) , addr . getPort ( ) , cfg . getConnectTimeout ( ) ) ; <nl> - try { <nl> - connection = client . connect ( ) ; <nl> - nodeConnections . put ( addr , connection ) ; <nl> - } catch ( RedisConnectionException e ) { <nl> - if ( ! skipLogging ) { <nl> - log . warn ( e . getMessage ( ) , e ) ; <nl> - } <nl> - } catch ( Exception e ) { <nl> - if ( ! skipLogging ) { <nl> - log . error ( e . getMessage ( ) , e ) ; <nl> - } <nl> - } <nl> - if ( connection ! = null & & ! connection . isActive ( ) ) { <nl> - if ( ! skipLogging ) { <nl> - log . warn ( \" connection to { } is not active ! \" , connection . getRedisClient ( ) . getAddr ( ) ) ; <nl> + final Promise < RedisConnection > result = newPromise ( ) ; <nl> + Future < RedisConnection > future = client . connectAsync ( ) ; <nl> + future . addListener ( new FutureListener < RedisConnection > ( ) { <nl> + @ Override <nl> + public void operationComplete ( Future < RedisConnection > future ) throws Exception { <nl> + if ( ! future . isSuccess ( ) ) { <nl> + result . setFailure ( future . cause ( ) ) ; <nl> + return ; <nl> + } <nl> + <nl> + RedisConnection connection = future . getNow ( ) ; <nl> + Promise < RedisConnection > promise = newPromise ( ) ; <nl> + connectListener . onConnect ( promise , connection , NodeType . MASTER , config ) ; <nl> + promise . addListener ( new FutureListener < RedisConnection > ( ) { <nl> + @ Override <nl> + public void operationComplete ( Future < RedisConnection > future ) throws Exception { <nl> + if ( ! future . isSuccess ( ) ) { <nl> + result . setFailure ( future . cause ( ) ) ; <nl> + return ; <nl> + } <nl> + <nl> + RedisConnection connection = future . getNow ( ) ; <nl> + if ( connection . isActive ( ) ) { <nl> + nodeConnections . put ( addr , connection ) ; <nl> + result . setSuccess ( connection ) ; <nl> + } else { <nl> + connection . closeAsync ( ) ; <nl> + result . setFailure ( new RedisException ( \" Connection to \" + connection . getRedisClient ( ) . getAddr ( ) + \" is not active ! \" ) ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> } <nl> - connection . closeAsync ( ) ; <nl> - connection = null ; <nl> - } <nl> - if ( connection = = null ) { <nl> - nodeConnections . remove ( addr ) ; <nl> - } <nl> - return connection ; <nl> + } ) ; <nl> + <nl> + return result ; <nl> } <nl> <nl> @ Override <nl> protected void initEntry ( MasterSlaveServersConfig config ) { <nl> } <nl> <nl> - private Collection < Future < Void > > addMasterEntry ( final ClusterPartition partition , ClusterServersConfig cfg , boolean skipLogging ) { <nl> + private Future < Collection < Future < Void > > > addMasterEntry ( final ClusterPartition partition , final ClusterServersConfig cfg ) { <nl> if ( partition . isMasterFail ( ) ) { <nl> - log . warn ( \" Failed to add master : { } for slot ranges : { } . Reason - server has FAIL flag \" , partition . getMasterAddress ( ) , partition . getSlotRanges ( ) ) ; <nl> - Future < Void > f = newSucceededFuture ( null ) ; <nl> - return Collections . singletonList ( f ) ; <nl> + RedisException e = new RedisException ( \" Failed to add master : \" + <nl> + partition . getMasterAddress ( ) + \" for slot ranges : \" + <nl> + partition . getSlotRanges ( ) + \" . Reason - server has FAIL flag \" ) ; <nl> + return newFailedFuture ( e ) ; <nl> } <nl> <nl> - RedisConnection connection = connect ( cfg , partition . getMasterAddress ( ) , skipLogging ) ; <nl> - if ( connection = = null ) { <nl> - Future < Void > f = newSucceededFuture ( null ) ; <nl> - return Collections . singletonList ( f ) ; <nl> - } <nl> - Map < String , String > params = connection . sync ( RedisCommands . CLUSTER_INFO ) ; <nl> - if ( \" fail \" . equals ( params . get ( \" cluster_state \" ) ) ) { <nl> - log . warn ( \" Failed to add master : { } for slot ranges : { } . Reason - cluster_state : fail \" , partition . getMasterAddress ( ) , partition . getSlotRanges ( ) ) ; <nl> - Future < Void > f = newSucceededFuture ( null ) ; <nl> - return Collections . singletonList ( f ) ; <nl> - } <nl> - <nl> - MasterSlaveServersConfig config = create ( cfg ) ; <nl> - config . setMasterAddress ( partition . getMasterAddress ( ) ) ; <nl> - <nl> - final AtomicReference < MasterSlaveEntry > entry = new AtomicReference < MasterSlaveEntry > ( ) ; <nl> - List < Future < Void > > futures = new ArrayList < Future < Void > > ( ) ; <nl> - if ( isReadFromSlaves ) { <nl> - config . setSlaveAddresses ( partition . getSlaveAddresses ( ) ) ; <nl> - <nl> - MasterSlaveEntry e = new MasterSlaveEntry ( partition . getSlotRanges ( ) , this , config ) ; <nl> - List < Future < Void > > fs = e . initSlaveBalancer ( config ) ; <nl> - futures . addAll ( fs ) ; <nl> - entry . set ( e ) ; <nl> - <nl> - log . info ( \" slaves : { } added for slot ranges : { } \" , partition . getSlaveAddresses ( ) , partition . getSlotRanges ( ) ) ; <nl> - } else { <nl> - SingleEntry e = new SingleEntry ( partition . getSlotRanges ( ) , this , config ) ; <nl> - entry . set ( e ) ; <nl> - } <nl> - <nl> - Future < Void > f = entry . get ( ) . setupMasterEntry ( config . getMasterAddress ( ) . getHost ( ) , config . getMasterAddress ( ) . getPort ( ) ) ; <nl> - f . addListener ( new FutureListener < Void > ( ) { <nl> + final Promise < Collection < Future < Void > > > result = newPromise ( ) ; <nl> + Future < RedisConnection > connectionFuture = connect ( cfg , partition . getMasterAddress ( ) ) ; <nl> + connectionFuture . addListener ( new FutureListener < RedisConnection > ( ) { <nl> @ Override <nl> - public void operationComplete ( Future < Void > future ) throws Exception { <nl> + public void operationComplete ( Future < RedisConnection > future ) throws Exception { <nl> if ( ! future . isSuccess ( ) ) { <nl> + result . setFailure ( future . cause ( ) ) ; <nl> return ; <nl> } <nl> - for ( ClusterSlotRange slotRange : partition . getSlotRanges ( ) ) { <nl> - addEntry ( slotRange , entry . get ( ) ) ; <nl> - lastPartitions . put ( slotRange , partition ) ; <nl> + <nl> + final RedisConnection connection = future . getNow ( ) ; <nl> + if ( connection = = null ) { <nl> + Collection < Future < Void > > f = Collections . < Future < Void > > emptyList ( ) ; <nl> + result . setSuccess ( f ) ; <nl> + return ; <nl> } <nl> <nl> - log . info ( \" master : { } added for slot ranges : { } \" , partition . getMasterAddress ( ) , partition . getSlotRanges ( ) ) ; <nl> + Future < Map < String , String > > clusterFuture = connection . async ( RedisCommands . CLUSTER_INFO ) ; <nl> + clusterFuture . addListener ( new FutureListener < Map < String , String > > ( ) { <nl> + <nl> + @ Override <nl> + public void operationComplete ( Future < Map < String , String > > future ) throws Exception { <nl> + if ( ! future . isSuccess ( ) ) { <nl> + log . error ( \" Can ' t execute CLUSTER_INFO with \" + connection . getRedisClient ( ) . getAddr ( ) , future . cause ( ) ) ; <nl> + result . setFailure ( future . cause ( ) ) ; <nl> + return ; <nl> + } <nl> + <nl> + Map < String , String > params = future . getNow ( ) ; <nl> + if ( \" fail \" . equals ( params . get ( \" cluster_state \" ) ) ) { <nl> + RedisException e = new RedisException ( \" Failed to add master : \" + <nl> + partition . getMasterAddress ( ) + \" for slot ranges : \" + <nl> + partition . getSlotRanges ( ) + \" . Reason - cluster_state : fail \" ) ; <nl> + result . setFailure ( e ) ; <nl> + return ; <nl> + } <nl> + <nl> + MasterSlaveServersConfig config = create ( cfg ) ; <nl> + config . setMasterAddress ( partition . getMasterAddress ( ) ) ; <nl> + <nl> + final MasterSlaveEntry e ; <nl> + List < Future < Void > > futures = new ArrayList < Future < Void > > ( ) ; <nl> + if ( isReadFromSlaves ) { <nl> + config . setSlaveAddresses ( partition . getSlaveAddresses ( ) ) ; <nl> + <nl> + e = new MasterSlaveEntry ( partition . getSlotRanges ( ) , ClusterConnectionManager . this , config ) ; <nl> + List < Future < Void > > fs = e . initSlaveBalancer ( config ) ; <nl> + futures . addAll ( fs ) ; <nl> + <nl> + log . info ( \" slaves : { } added for slot ranges : { } \" , partition . getSlaveAddresses ( ) , partition . getSlotRanges ( ) ) ; <nl> + } else { <nl> + e = new SingleEntry ( partition . getSlotRanges ( ) , ClusterConnectionManager . this , config ) ; <nl> + } <nl> + <nl> + Future < Void > f = e . setupMasterEntry ( config . getMasterAddress ( ) . getHost ( ) , config . getMasterAddress ( ) . getPort ( ) ) ; <nl> + f . addListener ( new FutureListener < Void > ( ) { <nl> + @ Override <nl> + public void operationComplete ( Future < Void > future ) throws Exception { <nl> + if ( ! future . isSuccess ( ) ) { <nl> + return ; <nl> + } <nl> + for ( ClusterSlotRange slotRange : partition . getSlotRanges ( ) ) { <nl> + addEntry ( slotRange , e ) ; <nl> + lastPartitions . put ( slotRange , partition ) ; <nl> + } <nl> + <nl> + log . info ( \" master : { } added for slot ranges : { } \" , partition . getMasterAddress ( ) , partition . getSlotRanges ( ) ) ; <nl> + } <nl> + } ) ; <nl> + futures . add ( f ) ; <nl> + result . setSuccess ( futures ) ; <nl> + } <nl> + } ) ; <nl> + <nl> } <nl> } ) ; <nl> - futures . add ( f ) ; <nl> - return futures ; <nl> + <nl> + return result ; <nl> } <nl> <nl> private void monitorClusterChange ( final ClusterServersConfig cfg ) { <nl> monitorFuture = GlobalEventExecutor . INSTANCE . scheduleWithFixedDelay ( new Runnable ( ) { <nl> @ Override <nl> public void run ( ) { <nl> - try { <nl> - for ( ClusterPartition partition : lastPartitions . values ( ) ) { <nl> - for ( URI uri : partition . getAllAddresses ( ) ) { <nl> - RedisConnection connection = connect ( cfg , uri , false ) ; <nl> - if ( connection = = null ) { <nl> - continue ; <nl> - } <nl> - <nl> - updateClusterState ( cfg , connection ) ; <nl> - return ; <nl> - } <nl> - } <nl> - } catch ( Exception e ) { <nl> - log . error ( e . getMessage ( ) , e ) ; <nl> + List < URI > nodes = new ArrayList < URI > ( ) ; <nl> + List < URI > slaves = new ArrayList < URI > ( ) ; <nl> + AtomicReference < Throwable > lastException = new AtomicReference < Throwable > ( ) ; <nl> + for ( ClusterPartition partition : lastPartitions . values ( ) ) { <nl> + nodes . add ( partition . getMasterAddress ( ) ) ; <nl> + slaves . addAll ( partition . getSlaveAddresses ( ) ) ; <nl> } <nl> + nodes . addAll ( slaves ) ; <nl> + <nl> + checkClusterState ( cfg , nodes . iterator ( ) , lastException ) ; <nl> } <nl> + <nl> } , cfg . getScanInterval ( ) , cfg . getScanInterval ( ) , TimeUnit . MILLISECONDS ) ; <nl> } <nl> <nl> - private void updateClusterState ( ClusterServersConfig cfg , RedisConnection connection ) { <nl> - String nodesValue = connection . sync ( RedisCommands . CLUSTER_NODES ) ; <nl> - log . debug ( \" cluster nodes state from { } : \\ n { } \" , connection . getRedisClient ( ) . getAddr ( ) , nodesValue ) ; <nl> + private void checkClusterState ( final ClusterServersConfig cfg , final Iterator < URI > iterator , final AtomicReference < Throwable > lastException ) { <nl> + if ( ! iterator . hasNext ( ) ) { <nl> + log . error ( \" Can ' t update cluster state \" , lastException . get ( ) ) ; <nl> + return ; <nl> + } <nl> + URI uri = iterator . next ( ) ; <nl> + Future < RedisConnection > connectionFuture = connect ( cfg , uri ) ; <nl> + connectionFuture . addListener ( new FutureListener < RedisConnection > ( ) { <nl> + @ Override <nl> + public void operationComplete ( Future < RedisConnection > future ) throws Exception { <nl> + if ( ! future . isSuccess ( ) ) { <nl> + lastException . set ( future . cause ( ) ) ; <nl> + checkClusterState ( cfg , iterator , lastException ) ; <nl> + return ; <nl> + } <nl> + <nl> + RedisConnection connection = future . getNow ( ) ; <nl> + updateClusterState ( cfg , connection ) ; <nl> + } <nl> + } ) ; <nl> + } <nl> + <nl> + private void updateClusterState ( final ClusterServersConfig cfg , final RedisConnection connection ) { <nl> + Future < String > future = connection . async ( RedisCommands . CLUSTER_NODES ) ; <nl> + future . addListener ( new FutureListener < String > ( ) { <nl> + @ Override <nl> + public void operationComplete ( Future < String > future ) throws Exception { <nl> + if ( ! future . isSuccess ( ) ) { <nl> + log . error ( \" Can ' t execute CLUSTER_NODES with \" + connection . getRedisClient ( ) . getAddr ( ) , future . cause ( ) ) ; <nl> + return ; <nl> + } <nl> + <nl> + String nodesValue = future . getNow ( ) ; <nl> + log . debug ( \" cluster nodes state from { } : \\ n { } \" , connection . getRedisClient ( ) . getAddr ( ) , nodesValue ) ; <nl> <nl> - Collection < ClusterPartition > newPartitions = parsePartitions ( nodesValue ) ; <nl> - checkMasterNodesChange ( newPartitions ) ; <nl> - checkSlaveNodesChange ( newPartitions ) ; <nl> - checkSlotsChange ( cfg , newPartitions ) ; <nl> + Collection < ClusterPartition > newPartitions = parsePartitions ( nodesValue ) ; <nl> + checkMasterNodesChange ( newPartitions ) ; <nl> + checkSlaveNodesChange ( newPartitions ) ; <nl> + checkSlotsChange ( cfg , newPartitions ) ; <nl> + } <nl> + } ) ; <nl> } <nl> <nl> private void checkSlaveNodesChange ( Collection < ClusterPartition > newPartitions ) { <nl> private void checkSlotsChange ( ClusterServersConfig cfg , Collection < ClusterPartit <nl> if ( ! addedSlots . isEmpty ( ) ) { <nl> log . info ( \" { } slots found to add \" , addedSlots ) ; <nl> } <nl> - for ( ClusterSlotRange slot : addedSlots ) { <nl> + for ( final ClusterSlotRange slot : addedSlots ) { <nl> ClusterPartition partition = find ( newPartitions , slot ) ; <nl> boolean masterFound = false ; <nl> for ( MasterSlaveEntry entry : getEntries ( ) . values ( ) ) { <nl> private void checkSlotsChange ( ClusterServersConfig cfg , Collection < ClusterPartit <nl> } <nl> } <nl> if ( ! masterFound ) { <nl> - addMasterEntry ( partition , cfg , false ) ; <nl> + Future < Collection < Future < Void > > > future = addMasterEntry ( partition , cfg ) ; <nl> + future . addListener ( new FutureListener < Collection < Future < Void > > > ( ) { <nl> + @ Override <nl> + public void operationComplete ( Future < Collection < Future < Void > > > future ) throws Exception { <nl> + if ( ! future . isSuccess ( ) ) { <nl> + log . error ( \" New cluster slot range \" + slot + \" without master node detected \" , future . cause ( ) ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Cluster configuration with password handling . ClusterConnectionManager optimization .\n"}
{"diff_id": 21023, "repo": "oracle/graal\n", "sha": "488774a804a8c8216af9e2d2e59f53d87d981fb8\n", "time": "2014-11-17T18:32:55Z\n", "diff": "mmm a / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / framemap / DelayedFrameMapBuilder . java <nl> ppp b / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / framemap / DelayedFrameMapBuilder . java <nl> public VirtualStackSlot allocateSpillSlot ( LIRKind kind ) { <nl> public TrackedVirtualStackSlot ( LIRKind lirKind ) { <nl> super ( lirKind ) ; <nl> } <nl> - <nl> - public abstract StackSlot transform ( ) ; <nl> } <nl> <nl> class SimpleVirtualStackSlot extends TrackedVirtualStackSlot { <nl> public SimpleVirtualStackSlot ( LIRKind lirKind ) { <nl> super ( lirKind ) ; <nl> } <nl> <nl> - @ Override <nl> - public StackSlot transform ( ) { <nl> - return frameMap . allocateSpillSlot ( getLIRKind ( ) ) ; <nl> - } <nl> - <nl> } <nl> <nl> class VirtualStackSlotRange extends TrackedVirtualStackSlot { <nl> public VirtualStackSlotRange ( int slots , BitSet objects ) { <nl> this . objects = ( BitSet ) objects . clone ( ) ; <nl> } <nl> <nl> - @ Override <nl> - public StackSlot transform ( ) { <nl> - return frameMap . allocateStackSlots ( getSlots ( ) , getObjects ( ) ) ; <nl> - } <nl> - <nl> public int getSlots ( ) { <nl> return slots ; <nl> } <nl>\n", "msg": "DelayedFrameMapBuilder : remove TrackedVirtualStackSlot . transform ( ) .\n"}
{"diff_id": 21087, "repo": "apache/flink\n", "sha": "afd05d3fd7e10445c3d9363bf541538d003b0c35\n", "time": "2019-10-13T13:43:03Z\n", "diff": "mmm a / flink - runtime / src / test / java / org / apache / flink / runtime / scheduler / FailingExecutionVertexOperationsDecorator . java <nl> ppp b / flink - runtime / src / test / java / org / apache / flink / runtime / scheduler / FailingExecutionVertexOperationsDecorator . java <nl> <nl> package org . apache . flink . runtime . scheduler ; <nl> <nl> import org . apache . flink . runtime . JobException ; <nl> - import org . apache . flink . runtime . concurrent . FutureUtils ; <nl> import org . apache . flink . runtime . executiongraph . ExecutionVertex ; <nl> <nl> import java . util . concurrent . CompletableFuture ; <nl> <nl> <nl> private boolean failDeploy ; <nl> <nl> - private boolean failCancel ; <nl> - <nl> public FailingExecutionVertexOperationsDecorator ( final ExecutionVertexOperations delegate ) { <nl> this . delegate = checkNotNull ( delegate ) ; <nl> } <nl> public void deploy ( final ExecutionVertex executionVertex ) throws JobException { <nl> <nl> @ Override <nl> public CompletableFuture < ? > cancel ( final ExecutionVertex executionVertex ) { <nl> - if ( failCancel ) { <nl> - return FutureUtils . completedExceptionally ( new RuntimeException ( \" Expected \" ) ) ; <nl> - } else { <nl> return delegate . cancel ( executionVertex ) ; <nl> - } <nl> } <nl> <nl> public void enableFailDeploy ( ) { <nl> public void disableFailDeploy ( ) { <nl> failDeploy = false ; <nl> } <nl> <nl> - public void enableFailCancel ( ) { <nl> - failCancel = true ; <nl> - } <nl> - <nl> - public void disableFailCancel ( ) { <nl> - failCancel = false ; <nl> - } <nl> } <nl>\n", "msg": "[ hotfix ] [ tests ] Remove unused methods from FailingExecutionVertexOperationsDecorator\n"}
{"diff_id": 21314, "repo": "zxing/zxing\n", "sha": "0e4ef00d34f7f17a5e46d6e8f540e550740b0edd\n", "time": "2012-11-10T15:02:49Z\n", "diff": "mmm a / core / src / com / google / zxing / oned / rss / expanded / decoders / FieldParser . java <nl> ppp b / core / src / com / google / zxing / oned / rss / expanded / decoders / FieldParser . java <nl> <nl> { \" 8100 \" , 6 } , <nl> { \" 8101 \" , 10 } , <nl> { \" 8102 \" , 2 } , <nl> - { \" 8110 \" , VARIABLE_LENGTH , 30 } , <nl> + { \" 8110 \" , VARIABLE_LENGTH , 70 } , <nl> + { \" 8200 \" , VARIABLE_LENGTH , 70 } , <nl> } ; <nl> <nl> private FieldParser ( ) { <nl>\n", "msg": "Issue 1432 errata from GS1 spec and support for additional var length product field 8200\n"}
{"diff_id": 21446, "repo": "oracle/graal\n", "sha": "997b7cacdba5701808dd3be288d4194d3e4d7873\n", "time": "2015-02-06T03:33:04Z\n", "diff": "mmm a / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / java / ArrayLengthNode . java <nl> ppp b / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / java / ArrayLengthNode . java <nl> public ArrayLengthNode ( ValueNode array ) { <nl> } <nl> <nl> public static ValueNode create ( ValueNode forValue , ConstantReflectionProvider constantReflection ) { <nl> - ValueNode length = readArrayLength ( forValue , constantReflection ) ; <nl> + ValueNode length = readArrayLengthConstant ( forValue , constantReflection ) ; <nl> if ( length ! = null ) { <nl> return length ; <nl> } <nl> public static ValueNode readArrayLength ( ValueNode originalArray , ConstantReflect <nl> / / Ensure that any proxies on the original value end up on the length value <nl> return reproxyValue ( originalArray , length ) ; <nl> } <nl> + return readArrayLengthConstant ( originalArray , constantReflection ) ; <nl> + } <nl> + <nl> + private static ValueNode readArrayLengthConstant ( ValueNode originalArray , ConstantReflectionProvider constantReflection ) { <nl> ValueNode array = GraphUtil . unproxify ( originalArray ) ; <nl> if ( constantReflection ! = null & & array . isConstant ( ) & & ! array . isNullConstant ( ) ) { <nl> JavaConstant constantValue = array . asJavaConstant ( ) ; <nl>\n", "msg": "Do only constant folding when creating a new array length node in the parser .\n"}
{"diff_id": 21494, "repo": "apache/flink\n", "sha": "11aa9b6d74f3ff8951b3dd8f4a33a87810cb1649\n", "time": "2019-01-07T13:08:38Z\n", "diff": "mmm a / flink - runtime / src / main / java / org / apache / flink / runtime / registration / RegisteredRpcConnection . java <nl> ppp b / flink - runtime / src / main / java / org / apache / flink / runtime / registration / RegisteredRpcConnection . java <nl> public RegisteredRpcConnection ( Logger log , String targetAddress , F fencingToken , <nl> / / Life cycle <nl> / / mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm <nl> <nl> - @ SuppressWarnings ( \" unchecked \" ) <nl> public void start ( ) { <nl> checkState ( ! closed , \" The RPC connection is already closed \" ) ; <nl> checkState ( ! isConnected ( ) & & pendingRegistration = = null , \" The RPC connection is already started \" ) ; <nl>\n", "msg": "[ hotfix ] [ runtime ] Remove redundant suppression\n"}
{"diff_id": 21530, "repo": "oracle/graal\n", "sha": "34c25b7c704bef06a15c3a74cebc4ce7e9a1012e\n", "time": "2017-10-02T14:52:00Z\n", "diff": "mmm a / truffle / src / com . oracle . truffle . nfi / src / com / oracle / truffle / nfi / LibFFIType . java <nl> ppp b / truffle / src / com . oracle . truffle . nfi / src / com / oracle / truffle / nfi / LibFFIType . java <nl> static LibFFIType createArrayType ( NFIContext ctx , NativeSimpleType simpleType ) { <nl> } <nl> <nl> private static Number asNumber ( Object object ) { <nl> - if ( object instanceof Number ) { <nl> + if ( object instanceof Byte | | <nl> + object instanceof Short | | <nl> + object instanceof Integer | | <nl> + object instanceof Long | | <nl> + object instanceof Float | | <nl> + object instanceof Double ) { <nl> return ( Number ) object ; <nl> } else if ( object instanceof Boolean ) { <nl> return ( Boolean ) object ? 1 : 0 ; <nl>\n", "msg": "Make type check more precise to disallow custom Number subclasses in native interop .\n"}
{"diff_id": 21548, "repo": "spring-projects/spring-framework\n", "sha": "58e270f7da55256e1eedeccab4c10424cfff4d51\n", "time": "2012-02-15T20:11:29Z\n", "diff": "mmm a / org . springframework . jms / src / main / java / org / springframework / jms / connection / JmsTransactionManager . java <nl> ppp b / org . springframework . jms / src / main / java / org / springframework / jms / connection / JmsTransactionManager . java <nl> <nl> * @ see TransactionAwareConnectionFactoryProxy <nl> * @ see org . springframework . jms . core . JmsTemplate <nl> * / <nl> + @ SuppressWarnings ( \" serial \" ) <nl> public class JmsTransactionManager extends AbstractPlatformTransactionManager <nl> implements ResourceTransactionManager , InitializingBean { <nl> <nl> protected void doBegin ( Object transaction , TransactionDefinition definition ) { <nl> getConnectionFactory ( ) , txObject . getResourceHolder ( ) ) ; <nl> } <nl> catch ( JMSException ex ) { <nl> - if ( session ! = null ) { <nl> - try { <nl> - session . close ( ) ; <nl> - } <nl> - catch ( Throwable ex2 ) { <nl> - / / ignore <nl> - } <nl> - } <nl> if ( con ! = null ) { <nl> try { <nl> con . close ( ) ; <nl>\n", "msg": "Prune dead code from JmsTransactionManager # doBegin\n"}
{"diff_id": 21552, "repo": "elastic/elasticsearch\n", "sha": "287789be53166cac1d1f247b07bdfdbb617042ef\n", "time": "2015-08-21T15:05:31Z\n", "diff": "mmm a / core / src / main / java / org / elasticsearch / bootstrap / Bootstrap . java <nl> ppp b / core / src / main / java / org / elasticsearch / bootstrap / Bootstrap . java <nl> private void stop ( ) { <nl> keepAliveLatch . countDown ( ) ; <nl> } <nl> } <nl> + <nl> + / * * Calls doMain ( ) , but with special formatting of errors * / <nl> + public static void main ( String [ ] args ) throws StartupError { <nl> + try { <nl> + doMain ( args ) ; <nl> + } catch ( Throwable t ) { <nl> + throw new StartupError ( t ) ; <nl> + } <nl> + } <nl> <nl> - public static void main ( String [ ] args ) throws Throwable { <nl> + public static void doMain ( String [ ] args ) throws Throwable { <nl> BootstrapCLIParser bootstrapCLIParser = new BootstrapCLIParser ( ) ; <nl> CliTool . ExitStatus status = bootstrapCLIParser . execute ( args ) ; <nl> <nl> public static void main ( String [ ] args ) throws Throwable { <nl> Loggers . enableConsoleLogging ( ) ; <nl> } <nl> <nl> - throw new StartupError ( e ) ; <nl> + throw e ; <nl> } <nl> } <nl> <nl>\n", "msg": "Use StartupError to format all exceptions hitting the console\n"}
{"diff_id": 21582, "repo": "dbeaver/dbeaver\n", "sha": "0ec383011d86e072545df72117de149050211eec\n", "time": "2020-03-06T09:35:16Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . model / src / org / jkiss / dbeaver / model / DBValueFormatting . java <nl> ppp b / plugins / org . jkiss . dbeaver . model / src / org / jkiss / dbeaver / model / DBValueFormatting . java <nl> <nl> import java . lang . reflect . Array ; <nl> import java . math . BigDecimal ; <nl> import java . math . BigInteger ; <nl> - import java . math . RoundingMode ; <nl> import java . text . DecimalFormat ; <nl> import java . text . DecimalFormatSymbols ; <nl> import java . text . ParseException ; <nl> <nl> static { <nl> / / NATIVE_FLOAT_FORMATTER . setMaximumFractionDigits ( NumberDataFormatter . MAX_FLOAT_FRACTION_DIGITS ) ; <nl> NATIVE_FLOAT_FORMATTER . setDecimalSeparatorAlwaysShown ( false ) ; <nl> - NATIVE_FLOAT_FORMATTER . setRoundingMode ( RoundingMode . UNNECESSARY ) ; <nl> + / / NATIVE_FLOAT_FORMATTER . setRoundingMode ( RoundingMode . UNNECESSARY ) ; <nl> <nl> / / NATIVE_DOUBLE_FORMATTER . setMaximumFractionDigits ( 340 ) ; <nl> NATIVE_DOUBLE_FORMATTER . setDecimalSeparatorAlwaysShown ( false ) ; <nl> - NATIVE_DOUBLE_FORMATTER . setRoundingMode ( RoundingMode . UNNECESSARY ) ; <nl> + / / NATIVE_DOUBLE_FORMATTER . setRoundingMode ( RoundingMode . UNNECESSARY ) ; <nl> } <nl> <nl> @ NotNull <nl>\n", "msg": "Native float formatter fix ( use default rounding mode )\n"}
{"diff_id": 21703, "repo": "spring-projects/spring-framework\n", "sha": "49f3046f6637030743a1560f37245cd0dffc95a5\n", "time": "2015-04-24T15:40:13Z\n", "diff": "mmm a / spring - core / src / main / java / org / springframework / core / io / support / PathMatchingResourcePatternResolver . java <nl> ppp b / spring - core / src / main / java / org / springframework / core / io / support / PathMatchingResourcePatternResolver . java <nl> <nl> / * <nl> - * Copyright 2002 - 2014 the original author or authors . <nl> + * Copyright 2002 - 2015 the original author or authors . <nl> * <nl> * Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> * you may not use this file except in compliance with the License . <nl> <nl> import java . util . Set ; <nl> import java . util . jar . JarEntry ; <nl> import java . util . jar . JarFile ; <nl> + import java . util . zip . ZipException ; <nl> <nl> import org . apache . commons . logging . Log ; <nl> import org . apache . commons . logging . LogFactory ; <nl> protected boolean isJarResource ( Resource resource ) throws IOException { <nl> / / being arbitrary as long as following the entry format . <nl> / / We ' ll also handle paths with and without leading \" file : \" prefix . <nl> String urlFile = rootDirResource . getURL ( ) . getFile ( ) ; <nl> - int separatorIndex = urlFile . indexOf ( ResourceUtils . JAR_URL_SEPARATOR ) ; <nl> - if ( separatorIndex ! = - 1 ) { <nl> - jarFileUrl = urlFile . substring ( 0 , separatorIndex ) ; <nl> - rootEntryPath = urlFile . substring ( separatorIndex + ResourceUtils . JAR_URL_SEPARATOR . length ( ) ) ; <nl> - jarFile = getJarFile ( jarFileUrl ) ; <nl> + try { <nl> + int separatorIndex = urlFile . indexOf ( ResourceUtils . JAR_URL_SEPARATOR ) ; <nl> + if ( separatorIndex ! = - 1 ) { <nl> + jarFileUrl = urlFile . substring ( 0 , separatorIndex ) ; <nl> + rootEntryPath = urlFile . substring ( separatorIndex + ResourceUtils . JAR_URL_SEPARATOR . length ( ) ) ; <nl> + jarFile = getJarFile ( jarFileUrl ) ; <nl> + } <nl> + else { <nl> + jarFile = new JarFile ( urlFile ) ; <nl> + jarFileUrl = urlFile ; <nl> + rootEntryPath = \" \" ; <nl> + } <nl> + newJarFile = true ; <nl> } <nl> - else { <nl> - jarFile = new JarFile ( urlFile ) ; <nl> - jarFileUrl = urlFile ; <nl> - rootEntryPath = \" \" ; <nl> + catch ( ZipException ex ) { <nl> + if ( logger . isDebugEnabled ( ) ) { <nl> + logger . debug ( \" Skipping invalid jar classpath entry [ \" + urlFile + \" ] \" ) ; <nl> + } <nl> + return Collections . emptySet ( ) ; <nl> } <nl> - newJarFile = true ; <nl> } <nl> <nl> try { <nl>\n", "msg": "PathMatchingResourcePatternResolver skips invalid jar classpath entries\n"}
{"diff_id": 21724, "repo": "libgdx/libgdx\n", "sha": "1c2d6c1c368d977acc68d7087cdf005bfa9d0058\n", "time": "2012-12-06T02:01:20Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / utils / Json . java <nl> ppp b / gdx / src / com / badlogic / gdx / utils / Json . java <nl> public void writeField ( Object object , String fieldName , String jsonName , Class <nl> } <nl> } <nl> <nl> + / * * @ param value May be null . * / <nl> public void writeValue ( String name , Object value ) { <nl> try { <nl> writer . name ( name ) ; <nl> } catch ( IOException ex ) { <nl> throw new SerializationException ( ex ) ; <nl> } <nl> - writeValue ( value , value . getClass ( ) , null ) ; <nl> + if ( value = = null ) <nl> + writeValue ( value , null , null ) ; <nl> + else <nl> + writeValue ( value , value . getClass ( ) , null ) ; <nl> } <nl> <nl> - / * * @ param knownType May be null if the type is unknown . * / <nl> + / * * @ param value May be null . <nl> + * @ param knownType May be null if the type is unknown . * / <nl> public void writeValue ( String name , Object value , Class knownType ) { <nl> try { <nl> writer . name ( name ) ; <nl> public void writeValue ( String name , Object value , Class knownType ) { <nl> writeValue ( value , knownType , null ) ; <nl> } <nl> <nl> - / * * @ param knownType May be null if the type is unknown . <nl> + / * * @ param value May be null . <nl> + * @ param knownType May be null if the type is unknown . <nl> * @ param elementType May be null if the type is unknown . * / <nl> public void writeValue ( String name , Object value , Class knownType , Class elementType ) { <nl> try { <nl> public void writeValue ( String name , Object value , Class knownType , Class elemen <nl> writeValue ( value , knownType , elementType ) ; <nl> } <nl> <nl> + / * * @ param value May be null . * / <nl> public void writeValue ( Object value ) { <nl> - writeValue ( value , value . getClass ( ) , null ) ; <nl> + if ( value = = null ) <nl> + writeValue ( value , null , null ) ; <nl> + else <nl> + writeValue ( value , value . getClass ( ) , null ) ; <nl> } <nl> <nl> - / * * @ param knownType May be null if the type is unknown . * / <nl> + / * * @ param value May be null . <nl> + * @ param knownType May be null if the type is unknown . * / <nl> public void writeValue ( Object value , Class knownType ) { <nl> writeValue ( value , knownType , null ) ; <nl> } <nl> <nl> - / * * @ param knownType May be null if the type is unknown . <nl> + / * * @ param value May be null . <nl> + * @ param knownType May be null if the type is unknown . <nl> * @ param elementType May be null if the type is unknown . * / <nl> public void writeValue ( Object value , Class knownType , Class elementType ) { <nl> try { <nl> public void writeType ( Class type ) { <nl> if ( debug ) System . out . println ( \" Writing type : \" + type . getName ( ) ) ; <nl> } <nl> <nl> - / * * @ param type May be null if the type is unknown . * / <nl> + / * * @ param type May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T fromJson ( Class < T > type , Reader reader ) { <nl> return ( T ) readValue ( type , null , new JsonReader ( ) . parse ( reader ) ) ; <nl> } <nl> <nl> / * * @ param type May be null if the type is unknown . <nl> - * @ param elementType May be null if the type is unknown . * / <nl> + * @ param elementType May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T fromJson ( Class < T > type , Class elementType , Reader reader ) { <nl> return ( T ) readValue ( type , elementType , new JsonReader ( ) . parse ( reader ) ) ; <nl> } <nl> <nl> - / * * @ param type May be null if the type is unknown . * / <nl> + / * * @ param type May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T fromJson ( Class < T > type , InputStream input ) { <nl> return ( T ) readValue ( type , null , new JsonReader ( ) . parse ( input ) ) ; <nl> } <nl> <nl> / * * @ param type May be null if the type is unknown . <nl> - * @ param elementType May be null if the type is unknown . * / <nl> + * @ param elementType May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T fromJson ( Class < T > type , Class elementType , InputStream input ) { <nl> return ( T ) readValue ( type , elementType , new JsonReader ( ) . parse ( input ) ) ; <nl> } <nl> <nl> - / * * @ param type May be null if the type is unknown . * / <nl> + / * * @ param type May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T fromJson ( Class < T > type , FileHandle file ) { <nl> try { <nl> return ( T ) readValue ( type , null , new JsonReader ( ) . parse ( file ) ) ; <nl> public void writeType ( Class type ) { <nl> } <nl> <nl> / * * @ param type May be null if the type is unknown . <nl> - * @ param elementType May be null if the type is unknown . * / <nl> + * @ param elementType May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T fromJson ( Class < T > type , Class elementType , FileHandle file ) { <nl> try { <nl> return ( T ) readValue ( type , elementType , new JsonReader ( ) . parse ( file ) ) ; <nl> public void writeType ( Class type ) { <nl> } <nl> } <nl> <nl> - / * * @ param type May be null if the type is unknown . * / <nl> + / * * @ param type May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T fromJson ( Class < T > type , char [ ] data , int offset , int length ) { <nl> return ( T ) readValue ( type , null , new JsonReader ( ) . parse ( data , offset , length ) ) ; <nl> } <nl> <nl> / * * @ param type May be null if the type is unknown . <nl> - * @ param elementType May be null if the type is unknown . * / <nl> + * @ param elementType May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T fromJson ( Class < T > type , Class elementType , char [ ] data , int offset , int length ) { <nl> return ( T ) readValue ( type , elementType , new JsonReader ( ) . parse ( data , offset , length ) ) ; <nl> } <nl> <nl> - / * * @ param type May be null if the type is unknown . * / <nl> + / * * @ param type May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T fromJson ( Class < T > type , String json ) { <nl> return ( T ) readValue ( type , null , new JsonReader ( ) . parse ( json ) ) ; <nl> } <nl> <nl> - / * * @ param type May be null if the type is unknown . * / <nl> + / * * @ param type May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T fromJson ( Class < T > type , Class elementType , String json ) { <nl> return ( T ) readValue ( type , elementType , new JsonReader ( ) . parse ( json ) ) ; <nl> } <nl> public void readFields ( Object object , Object jsonData ) { <nl> } <nl> } <nl> <nl> - / * * @ param type May be null if the type is unknown . * / <nl> + / * * @ param type May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T readValue ( String name , Class < T > type , Object jsonData ) { <nl> OrderedMap jsonMap = ( OrderedMap ) jsonData ; <nl> return ( T ) readValue ( type , null , jsonMap . get ( name ) ) ; <nl> } <nl> <nl> - / * * @ param type May be null if the type is unknown . * / <nl> + / * * @ param type May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T readValue ( String name , Class < T > type , T defaultValue , Object jsonData ) { <nl> OrderedMap jsonMap = ( OrderedMap ) jsonData ; <nl> Object jsonValue = jsonMap . get ( name ) ; <nl> public void readFields ( Object object , Object jsonData ) { <nl> } <nl> <nl> / * * @ param type May be null if the type is unknown . <nl> - * @ param elementType May be null if the type is unknown . * / <nl> + * @ param elementType May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T readValue ( String name , Class < T > type , Class elementType , Object jsonData ) { <nl> OrderedMap jsonMap = ( OrderedMap ) jsonData ; <nl> return ( T ) readValue ( type , elementType , jsonMap . get ( name ) ) ; <nl> } <nl> <nl> / * * @ param type May be null if the type is unknown . <nl> - * @ param elementType May be null if the type is unknown . * / <nl> + * @ param elementType May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T readValue ( String name , Class < T > type , Class elementType , T defaultValue , Object jsonData ) { <nl> OrderedMap jsonMap = ( OrderedMap ) jsonData ; <nl> Object jsonValue = jsonMap . get ( name ) ; <nl> public void readFields ( Object object , Object jsonData ) { <nl> } <nl> <nl> / * * @ param type May be null if the type is unknown . <nl> - * @ param elementType May be null if the type is unknown . * / <nl> + * @ param elementType May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T readValue ( Class < T > type , Class elementType , T defaultValue , Object jsonData ) { <nl> return ( T ) readValue ( type , elementType , jsonData ) ; <nl> } <nl> <nl> - / * * @ param type May be null if the type is unknown . * / <nl> + / * * @ param type May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T readValue ( Class < T > type , Object jsonData ) { <nl> return ( T ) readValue ( type , null , jsonData ) ; <nl> } <nl> <nl> / * * @ param type May be null if the type is unknown . <nl> - * @ param elementType May be null if the type is unknown . * / <nl> + * @ param elementType May be null if the type is unknown . <nl> + * @ return May be null . * / <nl> public < T > T readValue ( Class < T > type , Class elementType , Object jsonData ) { <nl> if ( jsonData = = null ) return null ; <nl> <nl>\n", "msg": "1159 , fixed passing null to Json writeValue methods . Javadocs for returning null .\n"}
{"diff_id": 21811, "repo": "spring-projects/spring-framework\n", "sha": "047eefd2e29551a60dac2519e7f8cc7522be6864\n", "time": "2020-01-09T14:56:09Z\n", "diff": "mmm a / spring - aop / src / main / java / org / springframework / aop / framework / AopContext . java <nl> ppp b / spring - aop / src / main / java / org / springframework / aop / framework / AopContext . java <nl> public static Object currentProxy ( ) throws IllegalStateException { <nl> Object proxy = currentProxy . get ( ) ; <nl> if ( proxy = = null ) { <nl> throw new IllegalStateException ( <nl> - \" Cannot find current proxy : Set ' exposeProxy ' property on Advised to ' true ' to make it available . \" ) ; <nl> + \" Cannot find current proxy : Set ' exposeProxy ' property on Advised to ' true ' to make it available . \" + <nl> + \" Also Check AopContext . currentProxy ( ) invoke in the origin thread . \" ) ; <nl> } <nl> return proxy ; <nl> } <nl>\n", "msg": "Improve exception message in AopContext . currentProxy ( )\n"}
{"diff_id": 21841, "repo": "netty/netty\n", "sha": "6b637ab22ffc1bc7976a4582303af4d446e12310\n", "time": "2012-06-04T18:49:31Z\n", "diff": "mmm a / transport / src / main / java / io / netty / channel / DefaultChannelPipeline . java <nl> ppp b / transport / src / main / java / io / netty / channel / DefaultChannelPipeline . java <nl> public synchronized ChannelPipeline addFirst ( EventExecutor executor , final Strin <nl> if ( ! newCtx . channel ( ) . isRegistered ( ) | | newCtx . executor ( ) . inEventLoop ( ) ) { <nl> addFirst0 ( name , handler , nextCtx , newCtx ) ; <nl> } else { <nl> - ChannelPipelineModificationRunnable runnable = new ChannelPipelineModificationRunnable ( ) { <nl> - <nl> - @ Override <nl> - protected void runTask ( ) { <nl> - checkDuplicateName ( name ) ; <nl> + try { <nl> + newCtx . executor ( ) . submit ( new Runnable ( ) { <nl> + <nl> + @ Override <nl> + public void run ( ) { <nl> + checkDuplicateName ( name ) ; <nl> <nl> - addFirst0 ( name , handler , nextCtx , newCtx ) ; <nl> - } <nl> - <nl> - } ; <nl> - <nl> - newCtx . executor ( ) . execute ( runnable ) ; <nl> - runnable . await ( ) ; <nl> + addFirst0 ( name , handler , nextCtx , newCtx ) ; <nl> + } <nl> + } ) . get ( ) ; <nl> + } catch ( Throwable t ) { <nl> + throw new ChannelException ( t ) ; <nl> + } <nl> + <nl> } <nl> <nl> return this ; <nl> public synchronized ChannelPipeline addLast ( EventExecutor executor , final String <nl> if ( ! newTail . channel ( ) . isRegistered ( ) | | newTail . executor ( ) . inEventLoop ( ) ) { <nl> addLast0 ( name , handler , oldTail , newTail ) ; <nl> } else { <nl> - ChannelPipelineModificationRunnable runnable = new ChannelPipelineModificationRunnable ( ) { <nl> - <nl> - @ Override <nl> - protected void runTask ( ) { <nl> - checkDuplicateName ( name ) ; <nl> + try { <nl> + newTail . executor ( ) . submit ( new Runnable ( ) { <nl> + <nl> + @ Override <nl> + public void run ( ) { <nl> + checkDuplicateName ( name ) ; <nl> <nl> - addLast0 ( name , handler , oldTail , newTail ) ; <nl> - } <nl> - <nl> - } ; <nl> + addLast0 ( name , handler , oldTail , newTail ) ; <nl> + } <nl> + } ) . get ( ) ; <nl> + } catch ( Throwable t ) { <nl> + throw new ChannelException ( t ) ; <nl> + } <nl> <nl> - newTail . executor ( ) . execute ( runnable ) ; <nl> - runnable . await ( ) ; <nl> } <nl> return this ; <nl> } <nl> public synchronized ChannelPipeline addBefore ( EventExecutor executor , String bas <nl> if ( ! newCtx . channel ( ) . isRegistered ( ) | | newCtx . executor ( ) . inEventLoop ( ) ) { <nl> addBefore0 ( name , handler , ctx , newCtx ) ; <nl> } else { <nl> - ChannelPipelineModificationRunnable runnable = new ChannelPipelineModificationRunnable ( ) { <nl> - <nl> - @ Override <nl> - protected void runTask ( ) { <nl> - checkDuplicateName ( name ) ; <nl> + try { <nl> + newCtx . executor ( ) . submit ( new Runnable ( ) { <nl> + <nl> + @ Override <nl> + public void run ( ) { <nl> + checkDuplicateName ( name ) ; <nl> <nl> - addBefore0 ( name , handler , ctx , newCtx ) ; <nl> - } <nl> - <nl> - } ; <nl> - <nl> - newCtx . executor ( ) . execute ( runnable ) ; <nl> - runnable . await ( ) ; <nl> + addBefore0 ( name , handler , ctx , newCtx ) ; <nl> + } <nl> + } ) . get ( ) ; <nl> + } catch ( Throwable t ) { <nl> + throw new ChannelException ( t ) ; <nl> + } <nl> } <nl> return this ; <nl> } <nl> public synchronized ChannelPipeline addAfter ( EventExecutor executor , String base <nl> if ( ! newCtx . channel ( ) . isRegistered ( ) | | newCtx . executor ( ) . inEventLoop ( ) ) { <nl> addAfter0 ( name , handler , ctx , newCtx ) ; <nl> } else { <nl> - ChannelPipelineModificationRunnable runnable = new ChannelPipelineModificationRunnable ( ) { <nl> - <nl> - @ Override <nl> - protected void runTask ( ) { <nl> - checkDuplicateName ( name ) ; <nl> - <nl> - addAfter0 ( name , handler , ctx , newCtx ) ; <nl> - } <nl> - <nl> - } ; <nl> - <nl> - newCtx . executor ( ) . execute ( runnable ) ; <nl> - runnable . await ( ) ; <nl> + try { <nl> + newCtx . executor ( ) . submit ( new Runnable ( ) { <nl> + <nl> + @ Override <nl> + public void run ( ) { <nl> + checkDuplicateName ( name ) ; <nl> + <nl> + addAfter0 ( name , handler , ctx , newCtx ) ; <nl> + } <nl> + } ) . get ( ) ; <nl> + } catch ( Throwable t ) { <nl> + throw new ChannelException ( t ) ; <nl> + } <nl> } <nl> <nl> } <nl> private DefaultChannelHandlerContext remove ( final DefaultChannelHandlerContext c <nl> if ( ! ctx . channel ( ) . isRegistered ( ) | | ctx . executor ( ) . inEventLoop ( ) ) { <nl> remove0 ( ctx ) ; <nl> } else { <nl> - ChannelPipelineModificationRunnable runnable = new ChannelPipelineModificationRunnable ( ) { <nl> - <nl> - @ Override <nl> - protected void runTask ( ) { <nl> - remove0 ( ctx ) ; <nl> + try { <nl> + ctx . executor ( ) . submit ( new Runnable ( ) { <nl> + <nl> + @ Override <nl> + public void run ( ) { <nl> + remove0 ( ctx ) ; <nl> <nl> - } <nl> - <nl> - } ; <nl> - <nl> - ctx . executor ( ) . execute ( runnable ) ; <nl> - runnable . await ( ) ; <nl> + } <nl> + } ) . get ( ) ; <nl> + } catch ( Throwable t ) { <nl> + throw new ChannelException ( t ) ; <nl> + } <nl> } <nl> <nl> } <nl> public synchronized ChannelHandler removeLast ( ) { <nl> if ( ! oldTail . channel ( ) . isRegistered ( ) | | oldTail . executor ( ) . inEventLoop ( ) ) { <nl> removeLast0 ( oldTail ) ; <nl> } else { <nl> - ChannelPipelineModificationRunnable runnable = new ChannelPipelineModificationRunnable ( ) { <nl> + try { <nl> + oldTail . executor ( ) . submit ( new Runnable ( ) { <nl> + <nl> + @ Override <nl> + public void run ( ) { <nl> + removeLast0 ( oldTail ) ; <nl> <nl> - @ Override <nl> - protected void runTask ( ) { <nl> - removeLast0 ( oldTail ) ; <nl> - } <nl> - <nl> - } ; <nl> + } <nl> + } ) . get ( ) ; <nl> + } catch ( Throwable t ) { <nl> + throw new ChannelException ( t ) ; <nl> + } <nl> <nl> - oldTail . executor ( ) . execute ( runnable ) ; <nl> - runnable . await ( ) ; <nl> } <nl> <nl> return oldTail . handler ( ) ; <nl> private ChannelHandler replace ( final DefaultChannelHandlerContext ctx , final Str <nl> if ( ! newCtx . channel ( ) . isRegistered ( ) | | newCtx . executor ( ) . inEventLoop ( ) ) { <nl> replace0 ( ctx , newName , newHandler , newCtx ) ; <nl> } else { <nl> - ChannelPipelineModificationRunnable runnable = new ChannelPipelineModificationRunnable ( ) { <nl> + try { <nl> + newCtx . executor ( ) . submit ( new Runnable ( ) { <nl> + <nl> + @ Override <nl> + public void run ( ) { <nl> + replace0 ( ctx , newName , newHandler , newCtx ) ; <nl> <nl> - @ Override <nl> - protected void runTask ( ) { <nl> - replace0 ( ctx , newName , newHandler , newCtx ) ; <nl> - } <nl> - <nl> - } ; <nl> - newCtx . executor ( ) . execute ( runnable ) ; <nl> - runnable . await ( ) ; <nl> + } <nl> + } ) . get ( ) ; <nl> + } catch ( Throwable t ) { <nl> + throw new ChannelException ( t ) ; <nl> + } <nl> } <nl> <nl> } <nl> public void flush ( ChannelOutboundHandlerContext ctx , <nl> unsafe . flush ( future ) ; <nl> } <nl> } <nl> - <nl> - private abstract class ChannelPipelineModificationRunnable implements Runnable { <nl> - private ChannelException cause ; <nl> - <nl> - @ Override <nl> - public final void run ( ) { <nl> - try { <nl> - runTask ( ) ; <nl> - <nl> - } catch ( Throwable t ) { <nl> - if ( t instanceof ChannelException ) { <nl> - cause = ( ChannelException ) t ; <nl> - } else { <nl> - this . cause = new ChannelException ( t ) ; <nl> - } <nl> - } finally { <nl> - synchronized ( ChannelPipelineModificationRunnable . this ) { <nl> - notifyAll ( ) ; <nl> - } <nl> - } <nl> - <nl> - } <nl> - <nl> - protected abstract void runTask ( ) ; <nl> - <nl> - void await ( ) { <nl> - try { <nl> - synchronized ( ChannelPipelineModificationRunnable . this ) { <nl> - wait ( ) ; <nl> - } <nl> - if ( cause ! = null ) { <nl> - throw cause ; <nl> - } <nl> - } catch ( InterruptedException e ) { <nl> - throw new ChannelException ( e ) ; <nl> - } <nl> - } <nl> - <nl> - } <nl> } <nl>\n", "msg": "No need for a custom Runnable implementation , just use EventExecutor . submit ( . . ) . get ( ) . Thanks @ trusting for review\n"}
{"diff_id": 21893, "repo": "oracle/graal\n", "sha": "29bef338f090caad5935d62edf33d2dfef8fdca6\n", "time": "2020-10-08T11:03:50Z\n", "diff": "mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / Method . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / Method . java <nl> <nl> / / the parts of the method that can change when it ' s redefined <nl> / / are encapsulated within the methodVersion <nl> @ CompilationFinal volatile MethodVersion methodVersion ; <nl> - @ CompilationFinal private Assumption removedByRedefinition ; <nl> + @ CompilationFinal private final Assumption removedByRedefinition = Truffle . getRuntime ( ) . createAssumption ( ) ; <nl> <nl> public Method identity ( ) { <nl> return proxy = = null ? this : proxy ; <nl> public MethodVersion getMethodVersion ( ) { <nl> } <nl> <nl> public void removedByRedefinition ( ) { <nl> - if ( removedByRedefinition = = null ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - removedByRedefinition = Truffle . getRuntime ( ) . createAssumption ( ) ; <nl> - } <nl> removedByRedefinition . invalidate ( ) ; <nl> } <nl> <nl> public boolean isRemovedByRedefition ( ) { <nl> - return removedByRedefinition ! = null & & ! removedByRedefinition . isValid ( ) ; <nl> + return ! removedByRedefinition . isValid ( ) ; <nl> } <nl> <nl> public final class MethodVersion implements MethodRef { <nl>\n", "msg": "Restore eager creation on removed by redefinition assumptions on methods\n"}
{"diff_id": 21902, "repo": "eclipse-vertx/vert.x\n", "sha": "2fed49c7752002c8c542bb12d6de4ada3f54d04a\n", "time": "2019-03-14T17:34:28Z\n", "diff": "mmm a / src / main / java / io / vertx / core / impl / DeploymentManager . java <nl> ppp b / src / main / java / io / vertx / core / impl / DeploymentManager . java <nl> public synchronized void doUndeploy ( ContextInternal undeployingContext , Handler < <nl> status = ST_UNDEPLOYED ; <nl> AtomicInteger undeployCount = new AtomicInteger ( ) ; <nl> int numToUndeploy = verticles . size ( ) ; <nl> + if ( parent ! = null ) { <nl> + parent . removeChild ( this ) ; <nl> + } <nl> for ( VerticleHolder verticleHolder : verticles ) { <nl> ContextImpl context = verticleHolder . context ; <nl> context . runOnContext ( v - > { <nl> public synchronized void doUndeploy ( ContextInternal undeployingContext , Handler < <nl> verticleHolder . verticle . stop ( stopFuture ) ; <nl> } catch ( Throwable t ) { <nl> stopFuture . fail ( t ) ; <nl> - } finally { <nl> - / / Remove the deployment from any parents <nl> - if ( parent ! = null ) { <nl> - parent . removeChild ( this ) ; <nl> - } <nl> } <nl> } ) ; <nl> } <nl>\n", "msg": "Remove child deployment before stopping verticles when the verticle deployement status becomes undeployed to avoid race condition with concurrent undeployment of the verticle\n"}
{"diff_id": 21904, "repo": "oracle/graal\n", "sha": "ad7f499ccf6b90b91e97e89c91575645dc591279\n", "time": "2016-01-12T10:56:23Z\n", "diff": "mmm a / graal / com . oracle . graal . truffle . hotspot / src / com / oracle / graal / truffle / hotspot / nfi / HotSpotNativeFunctionHandle . java <nl> ppp b / graal / com . oracle . graal . truffle . hotspot / src / com / oracle / graal / truffle / hotspot / nfi / HotSpotNativeFunctionHandle . java <nl> <nl> import com . oracle . graal . debug . Debug ; <nl> import com . oracle . graal . debug . Debug . Scope ; <nl> import com . oracle . nfi . api . NativeFunctionHandle ; <nl> + import com . oracle . truffle . api . CompilerDirectives ; <nl> <nl> public class HotSpotNativeFunctionHandle implements NativeFunctionHandle { <nl> <nl> public Object call ( Object . . . args ) { <nl> traceResult ( res ) ; <nl> return res ; <nl> } catch ( InvalidInstalledCodeException e ) { <nl> + CompilerDirectives . transferToInterpreter ( ) ; <nl> throw JVMCIError . shouldNotReachHere ( \" Execution of GNFI Callstub failed : \" + name ) ; <nl> } <nl> } <nl>\n", "msg": "Add CompilerDirectives # transferToInterpreter to catch block in NFI call method .\n"}
{"diff_id": 21961, "repo": "elastic/elasticsearch\n", "sha": "9bd7f2c65bb125023007dfea2934e223499ad2d0\n", "time": "2018-01-17T12:42:20Z\n", "diff": "mmm a / server / src / main / java / org / elasticsearch / index / analysis / SynonymTokenFilterFactory . java <nl> ppp b / server / src / main / java / org / elasticsearch / index / analysis / SynonymTokenFilterFactory . java <nl> public SynonymTokenFilterFactory ( IndexSettings indexSettings , Environment env , A <nl> <nl> if ( settings . get ( \" ignore_case \" ) ! = null ) { <nl> deprecationLogger . deprecated ( <nl> - \" This tokenize synonyms with whatever tokenizer and token filters appear before it in the chain . \" + <nl> - \" If you need ignore case with this filter , you should set lowercase filter before this \" ) ; <nl> + \" The ignore_case option on the synonym_graph filter is deprecated . \" + <nl> + \" Instead , insert a lowercase filter in the filter chain before the synonym_graph filter . \" ) ; <nl> } <nl> <nl> this . expand = settings . getAsBoolean ( \" expand \" , true ) ; <nl>\n", "msg": "Improve wording in deprecation message ( )\n"}
{"diff_id": 22019, "repo": "elastic/elasticsearch\n", "sha": "a49e1c0062aaabcaf573f0ac530237883971436b\n", "time": "2017-03-30T08:10:32Z\n", "diff": "mmm a / core / src / main / java / org / elasticsearch / search / slice / TermsSliceQuery . java <nl> ppp b / core / src / main / java / org / elasticsearch / search / slice / TermsSliceQuery . java <nl> <nl> import org . apache . lucene . search . ConstantScoreScorer ; <nl> import org . apache . lucene . util . BytesRef ; <nl> import org . apache . lucene . util . DocIdSetBuilder ; <nl> + import org . apache . lucene . util . StringHelper ; <nl> <nl> import java . io . IOException ; <nl> <nl> <nl> * < b > NOTE < / b > : Documents with no value for that field are ignored . <nl> * / <nl> public final class TermsSliceQuery extends SliceQuery { <nl> + / / Fixed seed for computing term hashCode <nl> + private static final int SEED = 7919 ; <nl> + <nl> public TermsSliceQuery ( String field , int id , int max ) { <nl> super ( field , id , max ) ; <nl> } <nl> private DocIdSet build ( LeafReader reader ) throws IOException { <nl> final TermsEnum te = terms . iterator ( ) ; <nl> PostingsEnum docsEnum = null ; <nl> for ( BytesRef term = te . next ( ) ; term ! = null ; term = te . next ( ) ) { <nl> - int hashCode = term . hashCode ( ) ; <nl> + / / use a fixed seed instead of term . hashCode ( ) otherwise this query may return inconsistent results when <nl> + / / running on another replica ( StringHelper sets its default seed at startup with current time ) <nl> + int hashCode = StringHelper . murmurhash3_x86_32 ( term , SEED ) ; <nl> if ( contains ( hashCode ) ) { <nl> docsEnum = te . postings ( docsEnum , PostingsEnum . NONE ) ; <nl> builder . add ( docsEnum ) ; <nl>\n", "msg": "Use a fixed seed for computing term hashCode in TermsSliceQuery ( )\n"}
{"diff_id": 22058, "repo": "oracle/graal\n", "sha": "18100055e1f07c0fdec1762cc0679455bdb6b60e\n", "time": "2014-12-15T17:51:08Z\n", "diff": "mmm a / graal / com . oracle . graal . hotspot . amd64 / src / com / oracle / graal / hotspot / amd64 / AMD64HotSpotNodeLIRBuilder . java <nl> ppp b / graal / com . oracle . graal . hotspot . amd64 / src / com / oracle / graal / hotspot / amd64 / AMD64HotSpotNodeLIRBuilder . java <nl> protected void emitDirectCall ( DirectCallTargetNode callTarget , Value result , Val <nl> @ Override <nl> protected void emitIndirectCall ( IndirectCallTargetNode callTarget , Value result , Value [ ] parameters , Value [ ] temps , LIRFrameState callState ) { <nl> if ( callTarget instanceof HotSpotIndirectCallTargetNode ) { <nl> - AllocatableValue metaspaceMethod = AMD64 . rbx . asValue ( ) ; <nl> - gen . emitMove ( metaspaceMethod , operand ( ( ( HotSpotIndirectCallTargetNode ) callTarget ) . metaspaceMethod ( ) ) ) ; <nl> - AllocatableValue targetAddress = AMD64 . rax . asValue ( ) ; <nl> - gen . emitMove ( targetAddress , operand ( callTarget . computedAddress ( ) ) ) ; <nl> - append ( new AMD64IndirectCallOp ( callTarget . targetMethod ( ) , result , parameters , temps , metaspaceMethod , targetAddress , callState ) ) ; <nl> + Value metaspaceMethodSrc = operand ( ( ( HotSpotIndirectCallTargetNode ) callTarget ) . metaspaceMethod ( ) ) ; <nl> + Value targetAddressSrc = operand ( callTarget . computedAddress ( ) ) ; <nl> + AllocatableValue metaspaceMethodDst = AMD64 . rbx . asValue ( metaspaceMethodSrc . getLIRKind ( ) ) ; <nl> + AllocatableValue targetAddressDst = AMD64 . rax . asValue ( targetAddressSrc . getLIRKind ( ) ) ; <nl> + gen . emitMove ( metaspaceMethodDst , metaspaceMethodSrc ) ; <nl> + gen . emitMove ( targetAddressDst , targetAddressSrc ) ; <nl> + append ( new AMD64IndirectCallOp ( callTarget . targetMethod ( ) , result , parameters , temps , metaspaceMethodDst , targetAddressDst , callState ) ) ; <nl> } else { <nl> super . emitIndirectCall ( callTarget , result , parameters , temps , callState ) ; <nl> } <nl>\n", "msg": "AMD64HotSpotNodeLIRBuilder : fix kinds for emitIndirectCall ( ) values .\n"}
{"diff_id": 22183, "repo": "bazelbuild/bazel\n", "sha": "60209517b01f8efadd9f7a83ee7eb96d4648c331\n", "time": "2018-04-13T17:36:04Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / rules / java / JavaCompilationArgs . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / java / JavaCompilationArgs . java <nl> <nl> / / B } , B depends on { C , D } , C depends on { junit3 } , and D depends on { junit4 } , <nl> / / the classpath of A will have junit3 before junit4 . <nl> <nl> + @ AutoCodec <nl> public static final JavaCompilationArgs EMPTY_ARGS = <nl> JavaCompilationArgs . create ( <nl> NestedSetBuilder . < Artifact > create ( Order . NAIVE_LINK_ORDER ) , <nl> public Builder addTransitiveArgs ( JavaCompilationArgs args , ClasspathType type ) { <nl> * Builds a { @ link JavaCompilationArgs } object . <nl> * / <nl> public JavaCompilationArgs build ( ) { <nl> + if ( runtimeJarsBuilder . isEmpty ( ) <nl> + & & compileTimeJarsBuilder . isEmpty ( ) <nl> + & & fullCompileTimeJarsBuilder . isEmpty ( ) <nl> + & & instrumentationMetadataBuilder . isEmpty ( ) ) { <nl> + return EMPTY_ARGS ; <nl> + } <nl> return JavaCompilationArgs . create ( <nl> runtimeJarsBuilder . build ( ) , <nl> compileTimeJarsBuilder . build ( ) , <nl>\n", "msg": "Use canonical EMPTY_ARGS JavaCompilationArgs object if all nested set builders are empty , and @ AutoCodec EMPTY_ARGS .\n"}
{"diff_id": 22476, "repo": "google/guava\n", "sha": "644e9182d9929ade7252719fb6b685efbbe84acb\n", "time": "2018-07-10T19:39:13Z\n", "diff": "mmm a / guava / src / com / google / common / collect / ImmutableMultiset . java <nl> ppp b / guava / src / com / google / common / collect / ImmutableMultiset . java <nl> public Builder ( ) { <nl> } <nl> } <nl> <nl> - @ WeakOuter <nl> static final class ElementSet < E > extends ImmutableSet . Indexed < E > { <nl> private final List < Entry < E > > entries ; <nl> + / / TODO ( cpovirk ) : @ Weak ? <nl> private final Multiset < E > delegate ; <nl> <nl> ElementSet ( List < Entry < E > > entries , Multiset < E > delegate ) { <nl>\n", "msg": "Remove @ WeakOuter from ImmutableMultiset . ElementSet . @ WeakOuter is useful for inner classes but not for static nested classes .\n"}
{"diff_id": 22517, "repo": "google/ExoPlayer\n", "sha": "c0e633fbe118878c778bfa1fe7c2efccac1b0e22\n", "time": "2019-11-17T04:39:01Z\n", "diff": "mmm a / library / core / src / main / java / com / google / android / exoplayer2 / ExoPlayerImplInternal . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / ExoPlayerImplInternal . java <nl> private void handleSourceInfoRefreshEndedPlayback ( ) { <nl> * @ throws IllegalSeekPositionException If the window index of the seek position is outside the <nl> * bounds of the timeline . <nl> * / <nl> + @ Nullable <nl> private Pair < Object , Long > resolveSeekPosition ( <nl> SeekPosition seekPosition , boolean trySubsequentPeriods ) { <nl> Timeline timeline = playbackInfo . timeline ; <nl> private void handleSourceInfoRefreshEndedPlayback ( ) { <nl> } <nl> if ( trySubsequentPeriods ) { <nl> / / Try and find a subsequent period from the seek timeline in the internal timeline . <nl> + @ Nullable <nl> Object periodUid = resolveSubsequentPeriod ( periodPosition . first , seekTimeline , timeline ) ; <nl> if ( periodUid ! = null ) { <nl> - / / We found one . Map the SeekPosition onto the corresponding default position . <nl> + / / We found one . Use the default position of the corresponding window . <nl> return getPeriodPosition ( <nl> - timeline , timeline . getPeriod ( periodIndex , period ) . windowIndex , C . TIME_UNSET ) ; <nl> + timeline , timeline . getPeriodByUid ( periodUid , period ) . windowIndex , C . TIME_UNSET ) ; <nl> } <nl> } <nl> / / We didn ' t find one . Give up . <nl>\n", "msg": "use getPeriodByUid when searching for subsequent period of seek timeline\n"}
{"diff_id": 22567, "repo": "bazelbuild/bazel\n", "sha": "5bd8209268c8d5f68dfdd410d59aab389de89bc2\n", "time": "2016-01-15T09:22:24Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / CcCommon . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / CcCommon . java <nl> <nl> import com . google . devtools . build . lib . collect . nestedset . NestedSetBuilder ; <nl> import com . google . devtools . build . lib . collect . nestedset . Order ; <nl> import com . google . devtools . build . lib . packages . BuildType ; <nl> + import com . google . devtools . build . lib . rules . apple . Platform ; <nl> import com . google . devtools . build . lib . rules . cpp . CcToolchainFeatures . FeatureConfiguration ; <nl> import com . google . devtools . build . lib . rules . cpp . CppConfiguration . DynamicMode ; <nl> import com . google . devtools . build . lib . rules . cpp . CppConfiguration . HeadersCheckingMode ; <nl> public CcCommon ( RuleContext ruleContext , FeatureConfiguration featureConfigurati <nl> CppHelper . expandAttribute ( ruleContext , result , \" linkopts \" , linkopt , true ) ; <nl> } <nl> } <nl> + <nl> + if ( Platform . isApplePlatform ( cppConfiguration . getTargetCpu ( ) ) & & result . contains ( \" - static \" ) ) { <nl> + ruleContext . attributeError ( <nl> + \" linkopts \" , \" Apple builds do not support statically linked binaries \" ) ; <nl> + } <nl> + <nl> return ImmutableList . copyOf ( result ) ; <nl> } <nl> <nl>\n", "msg": "Better error message for attempted builds of statically linked binaries targeting Apple platforms .\n"}
{"diff_id": 22592, "repo": "oracle/graal\n", "sha": "41cc737bcbd90bc2131fafc35053f30340c804ae\n", "time": "2017-10-24T16:58:39Z\n", "diff": "new file mode 100644 <nl> index 000000000000 . . d8e38370a3f3 <nl> mmm / dev / null <nl> ppp b / compiler / src / org . graalvm . compiler . core . test / src / org / graalvm / compiler / core / test / SubWordReturnTest . java <nl> <nl> + / * <nl> + * Copyright ( c ) 2017 , Oracle and / or its affiliates . All rights reserved . <nl> + * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER . <nl> + * <nl> + * This code is free software ; you can redistribute it and / or modify it <nl> + * under the terms of the GNU General Public License version 2 only , as <nl> + * published by the Free Software Foundation . <nl> + * <nl> + * This code is distributed in the hope that it will be useful , but WITHOUT <nl> + * ANY WARRANTY ; without even the implied warranty of MERCHANTABILITY or <nl> + * FITNESS FOR A PARTICULAR PURPOSE . See the GNU General Public License <nl> + * version 2 for more details ( a copy is included in the LICENSE file that <nl> + * accompanied this code ) . <nl> + * <nl> + * You should have received a copy of the GNU General Public License version <nl> + * 2 along with this work ; if not , write to the Free Software Foundation , <nl> + * Inc . , 51 Franklin St , Fifth Floor , Boston , MA 02110 - 1301 USA . <nl> + * <nl> + * Please contact Oracle , 500 Oracle Parkway , Redwood Shores , CA 94065 USA <nl> + * or visit www . oracle . com if you need additional information or have any <nl> + * questions . <nl> + * / <nl> + package org . graalvm . compiler . core . test ; <nl> + <nl> + import java . util . ArrayList ; <nl> + import java . util . List ; <nl> + import jdk . vm . ci . meta . JavaKind ; <nl> + import jdk . vm . ci . meta . ResolvedJavaMethod ; <nl> + import org . junit . Test ; <nl> + import org . junit . runner . RunWith ; <nl> + import org . junit . runners . Parameterized ; <nl> + import org . junit . runners . Parameterized . Parameters ; <nl> + import org . objectweb . asm . ClassWriter ; <nl> + import org . objectweb . asm . FieldVisitor ; <nl> + import org . objectweb . asm . MethodVisitor ; <nl> + import org . objectweb . asm . Opcodes ; <nl> + <nl> + @ RunWith ( Parameterized . class ) <nl> + public class SubWordReturnTest extends GraalCompilerTest { <nl> + <nl> + private final JavaKind kind ; <nl> + private final int value ; <nl> + <nl> + private final String generatedClassName ; <nl> + private final String generatedClassNameInternal ; <nl> + <nl> + private final String testMethodName ; <nl> + <nl> + / * * <nl> + * The { @ link AsmLoader } generates a class looking like this for the types byte , short , int and <nl> + * char . <nl> + * / <nl> + static class ByteGetter { <nl> + <nl> + / / private static int intField = 1000000 ; <nl> + <nl> + private static byte get ( ) { <nl> + / / GETSTATIC intField <nl> + / / IRETURN <nl> + return 0 ; <nl> + } <nl> + <nl> + public static int testByteSnippet ( ) { <nl> + return get ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ Parameters ( name = \" { 0 } , { 1 } \" ) <nl> + public static List < Object [ ] > data ( ) { <nl> + ArrayList < Object [ ] > ret = new ArrayList < > ( ) ; <nl> + for ( int i : new int [ ] { 1000000 , 1000001 , - 1000000 , - 1 } ) { <nl> + ret . add ( new Object [ ] { JavaKind . Boolean , i } ) ; <nl> + ret . add ( new Object [ ] { JavaKind . Byte , i } ) ; <nl> + ret . add ( new Object [ ] { JavaKind . Short , i } ) ; <nl> + ret . add ( new Object [ ] { JavaKind . Char , i } ) ; <nl> + } <nl> + return ret ; <nl> + } <nl> + <nl> + public SubWordReturnTest ( JavaKind kind , int value ) { <nl> + this . kind = kind ; <nl> + this . value = value ; <nl> + <nl> + this . generatedClassName = SubWordReturnTest . class . getName ( ) + \" $ \" + kind . toString ( ) + \" Getter \" ; <nl> + this . generatedClassNameInternal = generatedClassName . replace ( ' . ' , ' / ' ) ; <nl> + this . testMethodName = \" test \" + kind . name ( ) + \" Snippet \" ; <nl> + } <nl> + <nl> + @ Test <nl> + public void test ( ) throws ClassNotFoundException { <nl> + Class < ? > testClass = new AsmLoader ( SubWordReturnTest . class . getClassLoader ( ) ) . findClass ( generatedClassName ) ; <nl> + ResolvedJavaMethod method = getResolvedJavaMethod ( testClass , testMethodName ) ; <nl> + test ( method , null ) ; <nl> + } <nl> + <nl> + class AsmLoader extends ClassLoader implements Opcodes { <nl> + <nl> + Class < ? > loaded ; <nl> + <nl> + AsmLoader ( ClassLoader parent ) { <nl> + super ( parent ) ; <nl> + } <nl> + <nl> + @ Override <nl> + protected Class < ? > findClass ( String name ) throws ClassNotFoundException { <nl> + if ( name . equals ( generatedClassName ) ) { <nl> + if ( loaded = = null ) { <nl> + byte [ ] gen = generateClass ( ) ; <nl> + loaded = defineClass ( name , gen , 0 , gen . length ) ; <nl> + } <nl> + return loaded ; <nl> + } else { <nl> + return super . findClass ( name ) ; <nl> + } <nl> + } <nl> + <nl> + private byte [ ] generateClass ( ) { <nl> + ClassWriter cw = new ClassWriter ( 0 ) ; <nl> + cw . visit ( 52 , ACC_SUPER | ACC_PUBLIC , generatedClassNameInternal , null , \" java / lang / Object \" , null ) ; <nl> + <nl> + FieldVisitor intField = cw . visitField ( ACC_PRIVATE | ACC_STATIC , \" intField \" , \" I \" , null , value ) ; <nl> + intField . visitEnd ( ) ; <nl> + <nl> + MethodVisitor get = cw . visitMethod ( ACC_PRIVATE | ACC_STATIC , \" get \" , \" ( ) \" + kind . getTypeChar ( ) , null , null ) ; <nl> + get . visitCode ( ) ; <nl> + get . visitFieldInsn ( GETSTATIC , generatedClassNameInternal , \" intField \" , \" I \" ) ; <nl> + get . visitInsn ( IRETURN ) ; <nl> + get . visitMaxs ( 1 , 0 ) ; <nl> + get . visitEnd ( ) ; <nl> + <nl> + MethodVisitor snippet = cw . visitMethod ( ACC_PUBLIC | ACC_STATIC , testMethodName , \" ( ) I \" , null , null ) ; <nl> + snippet . visitCode ( ) ; <nl> + snippet . visitMethodInsn ( INVOKESTATIC , generatedClassNameInternal , \" get \" , \" ( ) \" + kind . getTypeChar ( ) , false ) ; <nl> + snippet . visitInsn ( IRETURN ) ; <nl> + snippet . visitMaxs ( 1 , 0 ) ; <nl> + snippet . visitEnd ( ) ; <nl> + <nl> + cw . visitEnd ( ) ; <nl> + return cw . toByteArray ( ) ; <nl> + } <nl> + } <nl> + <nl> + } <nl>\n", "msg": "Unit test for bytecode returning wrong integer type .\n"}
{"diff_id": 22608, "repo": "elastic/elasticsearch\n", "sha": "01495172d25c6b487f1a35c1e660201bb915d750\n", "time": "2015-10-09T15:10:52Z\n", "diff": "mmm a / core / src / main / java / org / elasticsearch / common / cache / Cache . java <nl> ppp b / core / src / main / java / org / elasticsearch / common / cache / Cache . java <nl> public void invalidateAll ( ) { <nl> weight = 0 ; <nl> } <nl> } finally { <nl> - for ( int i = 0 ; i < NUMBER_OF_SEGMENTS ; i + + ) { <nl> + for ( int i = NUMBER_OF_SEGMENTS - 1 ; i > = 0 ; i - - ) { <nl> if ( haveSegmentLock [ i ] ) { <nl> segments [ i ] . segmentLock . writeLock ( ) . unlock ( ) ; <nl> } <nl>\n", "msg": "Release locks in reverse order of acquisition\n"}
{"diff_id": 22849, "repo": "bumptech/glide\n", "sha": "69fead82c64c47084af8c540dcfdf805021a3fec\n", "time": "2017-01-19T00:04:07Z\n", "diff": "mmm a / library / src / main / java / com / bumptech / glide / load / engine / DecodeJob . java <nl> ppp b / library / src / main / java / com / bumptech / glide / load / engine / DecodeJob . java <nl> public void onDataFetcherReady ( Key sourceKey , Object data , DataFetcher < ? > fetche <nl> @ Override <nl> public void onDataFetcherFailed ( Key attemptedKey , Exception e , DataFetcher < ? > fetcher , <nl> DataSource dataSource ) { <nl> + fetcher . cleanup ( ) ; <nl> GlideException exception = new GlideException ( \" Fetching data failed \" , e ) ; <nl> exception . setLoggingDetails ( attemptedKey , dataSource , fetcher . getDataClass ( ) ) ; <nl> exceptions . add ( exception ) ; <nl>\n", "msg": "Close the url connection after receiving an Http error when trying to load a\n"}
{"diff_id": 22868, "repo": "oracle/graal\n", "sha": "2cada93c0d424352b3139a516bb06fd00e86baa2\n", "time": "2013-04-12T15:22:54Z\n", "diff": "mmm a / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / bridge / CompilerToVMImpl . java <nl> ppp b / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / bridge / CompilerToVMImpl . java <nl> public Object executeCompiledMethod ( Object arg1 , Object arg2 , Object arg3 , long <nl> return executeCompiledMethodIntrinsic ( arg1 , arg2 , arg3 , nativeMethod ) ; <nl> } <nl> <nl> + / * * <nl> + * Direct call to the given nativeMethod with three object arguments and an object return value . <nl> + * This method does not have an implementation on the C + + side , but its entry points ( from <nl> + * interpreter and from compiled code ) are directly pointing to a manually generated assembly <nl> + * stub that does the necessary argument shuffling and a tail call via an indirect jump to the <nl> + * verified entry point of the given native method . <nl> + * / <nl> private static native Object executeCompiledMethodIntrinsic ( Object arg1 , Object arg2 , Object arg3 , long nativeMethod ) ; <nl> } <nl>\n", "msg": "Comments and # ifdef GRAAL for recent changes to C + + code for calling nmethods directly .\n"}
{"diff_id": 23064, "repo": "SeleniumHQ/selenium\n", "sha": "9b041165457915895883be4b8aa5566774276acc\n", "time": "2013-08-12T07:02:03Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / ie / InternetExplorerDriver . java <nl> ppp b / java / client / src / org / openqa / selenium / ie / InternetExplorerDriver . java <nl> <nl> <nl> package org . openqa . selenium . ie ; <nl> <nl> + import com . google . common . base . Predicate ; <nl> import com . google . common . base . Throwables ; <nl> + import com . google . common . collect . Maps ; <nl> <nl> import org . openqa . selenium . Capabilities ; <nl> import org . openqa . selenium . OutputType ; <nl> import org . openqa . selenium . Platform ; <nl> + import org . openqa . selenium . Proxy ; <nl> import org . openqa . selenium . TakesScreenshot ; <nl> import org . openqa . selenium . WebDriverException ; <nl> import org . openqa . selenium . browserlaunchers . WindowsProxyManager ; <nl> <nl> import org . openqa . selenium . remote . service . DriverCommandExecutor ; <nl> <nl> import java . io . File ; <nl> + import java . util . HashSet ; <nl> + import java . util . Set ; <nl> <nl> import static org . openqa . selenium . remote . CapabilityType . PROXY ; <nl> <nl> <nl> * / <nl> public final static String FORCE_CREATE_PROCESS = \" ie . forceCreateProcessApi \" ; <nl> <nl> + / * * <nl> + * Capability that defines to clean browser cache before launching IE by IEDriverServer . <nl> + * / <nl> + public final static String IE_ENSURE_CLEAN_SESSION = \" ie . ensureCleanSession \" ; <nl> + <nl> + / * * <nl> + * Capability that defines setting the proxy information for a single IE process <nl> + * without affecting the proxy settings of other instances of IE . <nl> + * / <nl> + public final static String IE_USE_PRE_PROCESS_PROXY = \" ie . usePerProcessProxy \" ; <nl> + <nl> / * * <nl> * Capability that defines used IE CLI switches . <nl> * / <nl> public final static String IE_SWITCHES = \" ie . browserCommandLineSwitches \" ; <nl> <nl> + / * * <nl> + * @ deprecated please set this option as True and allow IEDriverServer sets up proxy . <nl> + * In next releases it will be set to True by default . <nl> + * <nl> + * Capability that defines used proxy setter . Currently it ' s False by default . <nl> + * <nl> + * False means WindowsProxyManager will be used for setting proxy settings . <nl> + * True means IEDriverServer will be used for setting proxy settings . <nl> + * <nl> + * Be note that using both variants in concurrent drivers at the same node <nl> + * may lead to undefined behaviour . <nl> + * / <nl> + @ Deprecated <nl> + public final static String IE_SET_PROXY_BY_SERVER = \" ie . setProxyByServer \" ; <nl> + <nl> / * * <nl> * Port which is used by default . <nl> * / <nl> private final static int DEFAULT_PORT = 0 ; <nl> <nl> + / * * <nl> + * To set proxy by server or not . <nl> + * / <nl> + private final boolean setProxyByServer ; <nl> + <nl> / * * <nl> * Proxy manager . <nl> * / <nl> public InternetExplorerDriver ( WindowsProxyManager proxy , InternetExplorerDriverS <nl> if ( capabilities = = null ) { <nl> capabilities = DesiredCapabilities . internetExplorer ( ) ; <nl> } <nl> + <nl> + setProxyByServer = useServerForProxy ( capabilities ) ; <nl> + <nl> if ( proxy = = null ) { <nl> proxyManager = setupProxy ( capabilities ) ; <nl> } else { <nl> private void run ( InternetExplorerDriverService service , Capabilities capabilitie <nl> <nl> setCommandExecutor ( new DriverCommandExecutor ( service ) ) ; <nl> <nl> - startSession ( capabilities ) ; <nl> + startSession ( updateCapabilities ( capabilities ) ) ; <nl> } <nl> <nl> @ Override <nl> private InternetExplorerDriverService setupService ( Capabilities caps , int port ) <nl> <nl> private WindowsProxyManager setupProxy ( Capabilities caps ) { <nl> / / do not create proxy manager if it ' s not requested . see issue 4135 <nl> - if ( caps = = null | | caps . getCapability ( PROXY ) = = null ) { <nl> + / / also do not create proxy manager if it will be managed by server . <nl> + if ( caps = = null | | caps . getCapability ( PROXY ) = = null | | setProxyByServer ) { <nl> return null ; <nl> } <nl> <nl> private WindowsProxyManager setupProxy ( Capabilities caps ) { <nl> } <nl> <nl> private void prepareProxy ( Capabilities caps ) { <nl> - if ( caps = = null | | caps . getCapability ( PROXY ) = = null ) { <nl> + / / do not prepare proxy manager if it will be managed by server . <nl> + if ( caps = = null | | caps . getCapability ( PROXY ) = = null | | setProxyByServer ) { <nl> return ; <nl> } <nl> <nl> public void run ( ) { <nl> } ; <nl> Runtime . getRuntime ( ) . addShutdownHook ( cleanupThread ) ; <nl> } <nl> + <nl> + / * * <nl> + * Determine to use server for setting proxy or not . <nl> + * <nl> + * @ param caps capabilties <nl> + * @ return to use or not <nl> + * / <nl> + private boolean useServerForProxy ( Capabilities caps ) { <nl> + if ( caps = = null | | caps . getCapability ( IE_SET_PROXY_BY_SERVER ) = = null ) { <nl> + return false ; <nl> + } <nl> + <nl> + return ( Boolean ) caps . getCapability ( IE_SET_PROXY_BY_SERVER ) ; <nl> + } <nl> + <nl> + / * * <nl> + * if proxy will be not managed by server overwrite proxy capability so <nl> + * server will do nothing . <nl> + * / <nl> + private Capabilities updateCapabilities ( Capabilities capabilities ) { <nl> + if ( capabilities = = null | | capabilities . getCapability ( PROXY ) = = null | | setProxyByServer ) { <nl> + return capabilities ; <nl> + } <nl> + <nl> + Proxy proxy = new Proxy ( ) ; <nl> + proxy . setProxyType ( Proxy . ProxyType . SYSTEM ) ; <nl> + ( ( DesiredCapabilities ) capabilities ) . setCapability ( PROXY , proxy ) ; <nl> + <nl> + return capabilities ; <nl> + } <nl> + <nl> } <nl> \\ No newline at end of file <nl>\n", "msg": "Introduced capability ie . setProxyByServer to select how IE browser proxy will be set up -\n"}
{"diff_id": 23103, "repo": "bazelbuild/bazel\n", "sha": "b7cdfa68f20801625e9a83383ce00eb0a1367a47\n", "time": "2015-04-28T15:15:19Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / rules / objc / ObjcCommon . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / objc / ObjcCommon . java <nl> <nl> * / <nl> ImmutableList < PathFragment > headerSearchPaths ( ) { <nl> ImmutableList . Builder < PathFragment > paths = new ImmutableList . Builder < > ( ) ; <nl> - PathFragment packageFragment = ruleContext . getLabel ( ) . getPackageFragment ( ) ; <nl> + PathFragment packageFragment = <nl> + ruleContext . getLabel ( ) . getPackageIdentifier ( ) . getPathFragment ( ) ; <nl> List < PathFragment > rootFragments = ImmutableList . of ( <nl> packageFragment , <nl> ruleContext . getConfiguration ( ) . getGenfilesFragment ( ) . getRelative ( packageFragment ) ) ; <nl> ObjcCommon build ( ) { <nl> . addAll ( SDK_FRAMEWORK , attributes . sdkFrameworks ( ) ) <nl> . addAll ( WEAK_SDK_FRAMEWORK , attributes . weakSdkFrameworks ( ) ) <nl> . addAll ( SDK_DYLIB , attributes . sdkDylibs ( ) ) ; <nl> - } <nl> - <nl> + } <nl> + <nl> if ( resourceAttributes . isPresent ( ) ) { <nl> ResourceAttributes attributes = resourceAttributes . get ( ) ; <nl> objcProvider <nl>\n", "msg": "Fix objective C rules to work with external repositories\n"}
{"diff_id": 23105, "repo": "Netflix/Hystrix\n", "sha": "d3d5b6e41a5505b64d56f874bde35b28915e46ae\n", "time": "2016-01-14T09:34:41Z\n", "diff": "mmm a / hystrix - core / src / main / java / com / netflix / hystrix / AbstractCommand . java <nl> ppp b / hystrix - core / src / main / java / com / netflix / hystrix / AbstractCommand . java <nl> <nl> * / <nl> package com . netflix . hystrix ; <nl> <nl> - import java . lang . ref . Reference ; <nl> - import java . util . List ; <nl> - import java . util . concurrent . ConcurrentHashMap ; <nl> - import java . util . concurrent . RejectedExecutionException ; <nl> - import java . util . concurrent . TimeoutException ; <nl> - import java . util . concurrent . atomic . AtomicBoolean ; <nl> - import java . util . concurrent . atomic . AtomicInteger ; <nl> - import java . util . concurrent . atomic . AtomicReference ; <nl> - <nl> - import com . netflix . hystrix . exception . HystrixTimeoutException ; <nl> - import org . slf4j . Logger ; <nl> - import org . slf4j . LoggerFactory ; <nl> - <nl> - import rx . Notification ; <nl> - import rx . Observable ; <nl> - import rx . Observable . OnSubscribe ; <nl> - import rx . Observable . Operator ; <nl> - import rx . Subscriber ; <nl> - import rx . functions . Action0 ; <nl> - import rx . functions . Action1 ; <nl> - import rx . functions . Func0 ; <nl> - import rx . functions . Func1 ; <nl> - import rx . subjects . ReplaySubject ; <nl> - import rx . subscriptions . CompositeSubscription ; <nl> - <nl> import com . netflix . hystrix . HystrixCircuitBreaker . NoOpCircuitBreaker ; <nl> import com . netflix . hystrix . HystrixCommandProperties . ExecutionIsolationStrategy ; <nl> import com . netflix . hystrix . exception . HystrixBadRequestException ; <nl> import com . netflix . hystrix . exception . HystrixRuntimeException ; <nl> import com . netflix . hystrix . exception . HystrixRuntimeException . FailureType ; <nl> + import com . netflix . hystrix . exception . HystrixTimeoutException ; <nl> import com . netflix . hystrix . strategy . HystrixPlugins ; <nl> import com . netflix . hystrix . strategy . concurrency . HystrixConcurrencyStrategy ; <nl> import com . netflix . hystrix . strategy . concurrency . HystrixContextRunnable ; <nl> <nl> import com . netflix . hystrix . strategy . properties . HystrixProperty ; <nl> import com . netflix . hystrix . util . HystrixTimer ; <nl> import com . netflix . hystrix . util . HystrixTimer . TimerListener ; <nl> + import org . slf4j . Logger ; <nl> + import org . slf4j . LoggerFactory ; <nl> + import rx . Notification ; <nl> + import rx . Observable ; <nl> + import rx . Observable . OnSubscribe ; <nl> + import rx . Observable . Operator ; <nl> + import rx . Subscriber ; <nl> + import rx . functions . Action0 ; <nl> + import rx . functions . Action1 ; <nl> + import rx . functions . Func0 ; <nl> + import rx . functions . Func1 ; <nl> + import rx . subjects . ReplaySubject ; <nl> + import rx . subscriptions . CompositeSubscription ; <nl> + <nl> + import java . lang . ref . Reference ; <nl> + import java . util . List ; <nl> + import java . util . concurrent . ConcurrentHashMap ; <nl> + import java . util . concurrent . RejectedExecutionException ; <nl> + import java . util . concurrent . TimeoutException ; <nl> + import java . util . concurrent . atomic . AtomicBoolean ; <nl> + import java . util . concurrent . atomic . AtomicInteger ; <nl> + import java . util . concurrent . atomic . AtomicReference ; <nl> <nl> / * package * / abstract class AbstractCommand < R > implements HystrixInvokableInfo < R > , HystrixObservable < R > { <nl> private static final Logger logger = LoggerFactory . getLogger ( AbstractCommand . class ) ; <nl> <nl> return name ; <nl> } <nl> <nl> + <nl> + <nl> protected AbstractCommand ( HystrixCommandGroupKey group , HystrixCommandKey key , HystrixThreadPoolKey threadPoolKey , HystrixCircuitBreaker circuitBreaker , HystrixThreadPool threadPool , <nl> HystrixCommandProperties . Setter commandPropertiesDefaults , HystrixThreadPoolProperties . Setter threadPoolPropertiesDefaults , <nl> HystrixCommandMetrics metrics , TryableSemaphore fallbackSemaphore , TryableSemaphore executionSemaphore , <nl> HystrixPropertiesStrategy propertiesStrategy , HystrixCommandExecutionHook executionHook ) { <nl> <nl> - / * <nl> - * CommandGroup initialization <nl> - * / <nl> - if ( group = = null ) { <nl> + this . commandGroup = initGroupKey ( group ) ; <nl> + this . commandKey = initCommandKey ( key , getClass ( ) ) ; <nl> + this . properties = initCommandProperties ( this . commandKey , propertiesStrategy , commandPropertiesDefaults ) ; <nl> + this . threadPoolKey = initThreadPoolKey ( threadPoolKey , this . commandGroup , this . properties . executionIsolationThreadPoolKeyOverride ( ) . get ( ) ) ; <nl> + this . metrics = initMetrics ( metrics , this . commandGroup , this . threadPoolKey , this . commandKey , this . properties ) ; <nl> + this . circuitBreaker = initCircuitBreaker ( this . properties . circuitBreakerEnabled ( ) . get ( ) , circuitBreaker , this . commandGroup , this . commandKey , this . properties , this . metrics ) ; <nl> + this . threadPool = initThreadPool ( threadPool , this . threadPoolKey , threadPoolPropertiesDefaults ) ; <nl> + <nl> + <nl> + / / Strategies from plugins <nl> + this . eventNotifier = HystrixPlugins . getInstance ( ) . getEventNotifier ( ) ; <nl> + this . concurrencyStrategy = HystrixPlugins . getInstance ( ) . getConcurrencyStrategy ( ) ; <nl> + HystrixMetricsPublisherFactory . createOrRetrievePublisherForCommand ( this . commandKey , this . commandGroup , this . metrics , this . circuitBreaker , this . properties ) ; <nl> + this . executionHook = initExecutionHook ( executionHook ) ; <nl> + <nl> + this . requestCache = HystrixRequestCache . getInstance ( this . commandKey , this . concurrencyStrategy ) ; <nl> + this . currentRequestLog = initRequestLog ( this . properties . requestLogEnabled ( ) . get ( ) , this . concurrencyStrategy ) ; <nl> + <nl> + / * fallback semaphore override if applicable * / <nl> + this . fallbackSemaphoreOverride = fallbackSemaphore ; <nl> + <nl> + / * execution semaphore override if applicable * / <nl> + this . executionSemaphoreOverride = executionSemaphore ; <nl> + } <nl> + <nl> + private static HystrixCommandGroupKey initGroupKey ( final HystrixCommandGroupKey fromConstructor ) { <nl> + if ( fromConstructor = = null ) { <nl> throw new IllegalStateException ( \" HystrixCommandGroup can not be NULL \" ) ; <nl> } else { <nl> - this . commandGroup = group ; <nl> + return fromConstructor ; <nl> } <nl> + } <nl> <nl> - / * <nl> - * CommandKey initialization <nl> - * / <nl> - if ( key = = null | | key . name ( ) . trim ( ) . equals ( \" \" ) ) { <nl> - final String keyName = getDefaultNameFromClass ( getClass ( ) ) ; <nl> - this . commandKey = HystrixCommandKey . Factory . asKey ( keyName ) ; <nl> + private static HystrixCommandKey initCommandKey ( final HystrixCommandKey fromConstructor , Class < ? > clazz ) { <nl> + if ( fromConstructor = = null | | fromConstructor . name ( ) . trim ( ) . equals ( \" \" ) ) { <nl> + final String keyName = getDefaultNameFromClass ( clazz ) ; <nl> + return HystrixCommandKey . Factory . asKey ( keyName ) ; <nl> } else { <nl> - this . commandKey = key ; <nl> + return fromConstructor ; <nl> } <nl> + } <nl> <nl> - / * <nl> - * Properties initialization <nl> - * / <nl> + private static HystrixCommandProperties initCommandProperties ( HystrixCommandKey commandKey , HystrixPropertiesStrategy propertiesStrategy , HystrixCommandProperties . Setter commandPropertiesDefaults ) { <nl> if ( propertiesStrategy = = null ) { <nl> - this . properties = HystrixPropertiesFactory . getCommandProperties ( this . commandKey , commandPropertiesDefaults ) ; <nl> + return HystrixPropertiesFactory . getCommandProperties ( commandKey , commandPropertiesDefaults ) ; <nl> } else { <nl> / / used for unit testing <nl> - this . properties = propertiesStrategy . getCommandProperties ( this . commandKey , commandPropertiesDefaults ) ; <nl> + return propertiesStrategy . getCommandProperties ( commandKey , commandPropertiesDefaults ) ; <nl> } <nl> + } <nl> <nl> - / * <nl> - * ThreadPoolKey <nl> - * <nl> - * This defines which thread - pool this command should run on . <nl> - * <nl> - * It uses the HystrixThreadPoolKey if provided , then defaults to use HystrixCommandGroup . <nl> - * <nl> - * It can then be overridden by a property if defined so it can be changed at runtime . <nl> - * / <nl> - if ( this . properties . executionIsolationThreadPoolKeyOverride ( ) . get ( ) = = null ) { <nl> + / * <nl> + * ThreadPoolKey <nl> + * <nl> + * This defines which thread - pool this command should run on . <nl> + * <nl> + * It uses the HystrixThreadPoolKey if provided , then defaults to use HystrixCommandGroup . <nl> + * <nl> + * It can then be overridden by a property if defined so it can be changed at runtime . <nl> + * / <nl> + private static HystrixThreadPoolKey initThreadPoolKey ( HystrixThreadPoolKey threadPoolKey , HystrixCommandGroupKey groupKey , String threadPoolKeyOverride ) { <nl> + if ( threadPoolKeyOverride = = null ) { <nl> / / we don ' t have a property overriding the value so use either HystrixThreadPoolKey or HystrixCommandGroup <nl> if ( threadPoolKey = = null ) { <nl> / * use HystrixCommandGroup if HystrixThreadPoolKey is null * / <nl> - this . threadPoolKey = HystrixThreadPoolKey . Factory . asKey ( commandGroup . name ( ) ) ; <nl> + return HystrixThreadPoolKey . Factory . asKey ( groupKey . name ( ) ) ; <nl> } else { <nl> - this . threadPoolKey = threadPoolKey ; <nl> + return threadPoolKey ; <nl> } <nl> } else { <nl> / / we have a property defining the thread - pool so use it instead <nl> - this . threadPoolKey = HystrixThreadPoolKey . Factory . asKey ( properties . executionIsolationThreadPoolKeyOverride ( ) . get ( ) ) ; <nl> + return HystrixThreadPoolKey . Factory . asKey ( threadPoolKeyOverride ) ; <nl> } <nl> + } <nl> <nl> - / * strategy : HystrixEventNotifier * / <nl> - this . eventNotifier = HystrixPlugins . getInstance ( ) . getEventNotifier ( ) ; <nl> - <nl> - / * strategy : HystrixConcurrentStrategy * / <nl> - this . concurrencyStrategy = HystrixPlugins . getInstance ( ) . getConcurrencyStrategy ( ) ; <nl> - <nl> - / * <nl> - * Metrics initialization <nl> - * / <nl> - if ( metrics = = null ) { <nl> - this . metrics = HystrixCommandMetrics . getInstance ( this . commandKey , this . commandGroup , this . threadPoolKey , this . properties ) ; <nl> + private static HystrixCommandMetrics initMetrics ( HystrixCommandMetrics fromConstructor , HystrixCommandGroupKey groupKey , <nl> + HystrixThreadPoolKey threadPoolKey , HystrixCommandKey commandKey , <nl> + HystrixCommandProperties properties ) { <nl> + if ( fromConstructor = = null ) { <nl> + return HystrixCommandMetrics . getInstance ( commandKey , groupKey , threadPoolKey , properties ) ; <nl> } else { <nl> - this . metrics = metrics ; <nl> + return fromConstructor ; <nl> } <nl> + } <nl> <nl> - / * <nl> - * CircuitBreaker initialization <nl> - * / <nl> - if ( this . properties . circuitBreakerEnabled ( ) . get ( ) ) { <nl> - if ( circuitBreaker = = null ) { <nl> + private static HystrixCircuitBreaker initCircuitBreaker ( boolean enabled , HystrixCircuitBreaker fromConstructor , <nl> + HystrixCommandGroupKey groupKey , HystrixCommandKey commandKey , <nl> + HystrixCommandProperties properties , HystrixCommandMetrics metrics ) { <nl> + if ( enabled ) { <nl> + if ( fromConstructor = = null ) { <nl> / / get the default implementation of HystrixCircuitBreaker <nl> - this . circuitBreaker = HystrixCircuitBreaker . Factory . getInstance ( this . commandKey , this . commandGroup , this . properties , this . metrics ) ; <nl> + return HystrixCircuitBreaker . Factory . getInstance ( commandKey , groupKey , properties , metrics ) ; <nl> } else { <nl> - this . circuitBreaker = circuitBreaker ; <nl> + return fromConstructor ; <nl> } <nl> } else { <nl> - this . circuitBreaker = new NoOpCircuitBreaker ( ) ; <nl> + return new NoOpCircuitBreaker ( ) ; <nl> } <nl> + } <nl> <nl> - / * strategy : HystrixMetricsPublisherCommand * / <nl> - HystrixMetricsPublisherFactory . createOrRetrievePublisherForCommand ( this . commandKey , this . commandGroup , this . metrics , this . circuitBreaker , this . properties ) ; <nl> - <nl> - / * strategy : HystrixCommandExecutionHook * / <nl> - if ( executionHook = = null ) { <nl> - this . executionHook = new ExecutionHookDeprecationWrapper ( HystrixPlugins . getInstance ( ) . getCommandExecutionHook ( ) ) ; <nl> + private static HystrixCommandExecutionHook initExecutionHook ( HystrixCommandExecutionHook fromConstructor ) { <nl> + if ( fromConstructor = = null ) { <nl> + return new ExecutionHookDeprecationWrapper ( HystrixPlugins . getInstance ( ) . getCommandExecutionHook ( ) ) ; <nl> } else { <nl> / / used for unit testing <nl> - if ( executionHook instanceof ExecutionHookDeprecationWrapper ) { <nl> - this . executionHook = executionHook ; <nl> + if ( fromConstructor instanceof ExecutionHookDeprecationWrapper ) { <nl> + return fromConstructor ; <nl> } else { <nl> - this . executionHook = new ExecutionHookDeprecationWrapper ( executionHook ) ; <nl> + return new ExecutionHookDeprecationWrapper ( fromConstructor ) ; <nl> } <nl> } <nl> + } <nl> <nl> - / * <nl> - * ThreadPool initialization <nl> - * / <nl> - if ( threadPool = = null ) { <nl> + private static HystrixThreadPool initThreadPool ( HystrixThreadPool fromConstructor , HystrixThreadPoolKey threadPoolKey , HystrixThreadPoolProperties . Setter threadPoolPropertiesDefaults ) { <nl> + if ( fromConstructor = = null ) { <nl> / / get the default implementation of HystrixThreadPool <nl> - this . threadPool = HystrixThreadPool . Factory . getInstance ( this . threadPoolKey , threadPoolPropertiesDefaults ) ; <nl> + return HystrixThreadPool . Factory . getInstance ( threadPoolKey , threadPoolPropertiesDefaults ) ; <nl> } else { <nl> - this . threadPool = threadPool ; <nl> + return fromConstructor ; <nl> } <nl> + } <nl> <nl> - / * fallback semaphore override if applicable * / <nl> - this . fallbackSemaphoreOverride = fallbackSemaphore ; <nl> - <nl> - / * execution semaphore override if applicable * / <nl> - this . executionSemaphoreOverride = executionSemaphore ; <nl> - <nl> - / * setup the request cache for this instance * / <nl> - this . requestCache = HystrixRequestCache . getInstance ( this . commandKey , this . concurrencyStrategy ) ; <nl> - <nl> - if ( properties . requestLogEnabled ( ) . get ( ) ) { <nl> + private static HystrixRequestLog initRequestLog ( boolean enabled , HystrixConcurrencyStrategy concurrencyStrategy ) { <nl> + if ( enabled ) { <nl> / * store reference to request log regardless of which thread later hits it * / <nl> - currentRequestLog = HystrixRequestLog . getCurrentRequest ( concurrencyStrategy ) ; <nl> + return HystrixRequestLog . getCurrentRequest ( concurrencyStrategy ) ; <nl> } else { <nl> - currentRequestLog = null ; <nl> + return null ; <nl> } <nl> } <nl> <nl>\n", "msg": "Modularized command constructor logic to make it easier to read\n"}
{"diff_id": 23154, "repo": "jenkinsci/jenkins\n", "sha": "be5438b3b3c1a84cd5b4272bbd6d2329a4064ac7\n", "time": "2011-02-17T01:48:45Z\n", "diff": "mmm a / remoting / src / main / java / hudson / remoting / forward / CopyThread . java <nl> ppp b / remoting / src / main / java / hudson / remoting / forward / CopyThread . java <nl> <nl> import java . io . IOException ; <nl> import java . io . InputStream ; <nl> import java . io . OutputStream ; <nl> + import java . util . logging . Level ; <nl> + import java . util . logging . Logger ; <nl> <nl> / * * <nl> * Copies a stream and close them at EOF . <nl> <nl> * @ author Kohsuke Kawaguchi <nl> * / <nl> final class CopyThread extends Thread { <nl> + private static final Logger LOGGER = Logger . getLogger ( CopyThread . class . getName ( ) ) ; <nl> private final InputStream in ; <nl> private final OutputStream out ; <nl> <nl> public void run ( ) { <nl> out . close ( ) ; <nl> } <nl> } catch ( IOException e ) { <nl> - / / TODO : what to do ? <nl> + LOGGER . log ( Level . WARNING , \" Exception while copying in thread : \" + getName ( ) , e ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Log out exceptions that happen in copy threads .\n"}
{"diff_id": 23181, "repo": "apache/flink\n", "sha": "42578b67a302b44978d1591c1b1b6572197d7391\n", "time": "2015-02-18T16:43:53Z\n", "diff": "mmm a / flink - runtime / src / test / java / org / apache / flink / runtime / blob / BlobServerGetTest . java <nl> ppp b / flink - runtime / src / test / java / org / apache / flink / runtime / blob / BlobServerGetTest . java <nl> public void testGetFailsDuringStreaming ( ) { <nl> try { <nl> byte [ ] remainder = new byte [ data . length - 2 * receiveBuffer . length ] ; <nl> BlobUtils . readFully ( is , remainder , 0 , remainder . length , null ) ; <nl> - fail ( ) ; <nl> + / / we tolerate that this succeeds , as the receiver socket may have buffered <nl> + / / everything already <nl> } <nl> catch ( IOException e ) { <nl> / / expected <nl>\n", "msg": "[ blob manager ] Fix flakey test .\n"}
{"diff_id": 23206, "repo": "spring-projects/spring-boot\n", "sha": "ffd6e8d7eb944d8a3613e40e6aa1f6aa57127046\n", "time": "2015-12-02T14:00:30Z\n", "diff": "mmm a / spring - boot - autoconfigure / src / main / java / org / springframework / boot / autoconfigure / security / SecurityFilterAutoConfiguration . java <nl> ppp b / spring - boot - autoconfigure / src / main / java / org / springframework / boot / autoconfigure / security / SecurityFilterAutoConfiguration . java <nl> <nl> * <nl> * @ author Rob Winch <nl> * @ author Phillip Webb <nl> + * @ author Andy Wilkinson <nl> * @ since 1 . 3 <nl> * / <nl> @ Configuration <nl> public DelegatingFilterProxyRegistrationBean securityFilterChainRegistration ( <nl> <nl> private EnumSet < DispatcherType > getDispatcherTypes ( <nl> SecurityProperties securityProperties ) { <nl> + if ( securityProperties . getFilterDispatcherTypes ( ) = = null ) { <nl> + return null ; <nl> + } <nl> Set < DispatcherType > dispatcherTypes = new HashSet < DispatcherType > ( ) ; <nl> for ( String dispatcherType : securityProperties . getFilterDispatcherTypes ( ) ) { <nl> dispatcherTypes . add ( DispatcherType . valueOf ( dispatcherType ) ) ; <nl>\n", "msg": "Handle null security filter dispatcher types gracefully\n"}
{"diff_id": 23256, "repo": "facebook/fresco\n", "sha": "0708c8770ae0a0f1e923fa7567f88e2995bb9e45\n", "time": "2016-10-12T17:16:34Z\n", "diff": "mmm a / imagepipeline - base / src / main / java / com / facebook / imageformat / ImageFormatChecker . java <nl> ppp b / imagepipeline - base / src / main / java / com / facebook / imageformat / ImageFormatChecker . java <nl> public ImageFormat determineImageFormat ( final InputStream is ) throws IOException <nl> } <nl> } <nl> } <nl> - return mDefaultFormatChecker . determineFormat ( imageHeaderBytes , headerSize ) ; <nl> + ImageFormat format = mDefaultFormatChecker . determineFormat ( imageHeaderBytes , headerSize ) ; <nl> + if ( format = = null ) { <nl> + format = ImageFormat . UNKNOWN ; <nl> + } <nl> + return format ; <nl> } <nl> <nl> private void updateMaxHeaderLength ( ) { <nl>\n", "msg": "Added null check so that we always return an ImageFormat\n"}
{"diff_id": 23259, "repo": "SeleniumHQ/selenium\n", "sha": "643c20eddcf12e7951b23bfc626e8000905f8c1d\n", "time": "2011-08-15T20:09:34Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / android / AndroidDriver . java <nl> ppp b / java / client / src / org / openqa / selenium / android / AndroidDriver . java <nl> <nl> <nl> / * * <nl> * The default constructor assumes the remote server is listening at <nl> - * http : / / localhost : 8080 / hub <nl> + * http : / / localhost : 8080 / wd / hub <nl> * / <nl> public AndroidDriver ( ) { <nl> this ( getDefaultUrl ( ) ) ; <nl>\n", "msg": "DanielWagnerHall : Updating javadoc since this changed a couple of releases ago\n"}
{"diff_id": 23308, "repo": "SeleniumHQ/selenium\n", "sha": "697d41f76af914aaebe2e5c62ad8be5eb6ea3294\n", "time": "2015-09-17T09:28:30Z\n", "diff": "mmm a / java / client / test / org / openqa / selenium / environment / webserver / CookieServlet . java <nl> ppp b / java / client / test / org / openqa / selenium / environment / webserver / CookieServlet . java <nl> protected void doGet ( HttpServletRequest request , HttpServletResponse response ) <nl> <nl> } else if ( \" deleteAll \" . equals ( action ) ) { <nl> for ( Cookie cookie : request . getCookies ( ) ) { <nl> - System . out . println ( cookie ) ; <nl> cookie . setValue ( \" \" ) ; <nl> cookie . setPath ( \" / \" ) ; <nl> cookie . setMaxAge ( 0 ) ; <nl>\n", "msg": "Deleting redundant logging to console in tests\n"}
{"diff_id": 23372, "repo": "square/picasso\n", "sha": "e5b091f642087f0b458d2c5596a3f6c97f25bd61\n", "time": "2014-03-15T05:00:06Z\n", "diff": "mmm a / picasso / src / main / java / com / squareup / picasso / RequestCreator . java <nl> ppp b / picasso / src / main / java / com / squareup / picasso / RequestCreator . java <nl> public void fetch ( ) { <nl> } <nl> if ( data . hasImage ( ) ) { <nl> Request finalData = picasso . transformRequest ( data . build ( ) ) ; <nl> - String key = createKey ( finalData ) ; <nl> + String key = createKey ( finalData , new StringBuilder ( ) ) ; <nl> <nl> Action action = new FetchAction ( picasso , finalData , skipMemoryCache , key ) ; <nl> picasso . enqueueAndSubmit ( action ) ; <nl>\n", "msg": "Use new string builder for fetch ( ) requests\n"}
{"diff_id": 23527, "repo": "oracle/graal\n", "sha": "5fece1b1080e98d308493b7761c61205e22c4b19\n", "time": "2016-07-18T00:08:18Z\n", "diff": "mmm a / projects / com . oracle . truffle . llvm . nodes . impl / src / com / oracle / truffle / llvm / nodes / impl / memory / LLVMStoreNode . java <nl> ppp b / projects / com . oracle . truffle . llvm . nodes . impl / src / com / oracle / truffle / llvm / nodes / impl / memory / LLVMStoreNode . java <nl> <nl> * / <nl> package com . oracle . truffle . llvm . nodes . impl . memory ; <nl> <nl> + import com . oracle . truffle . api . CompilerDirectives ; <nl> import com . oracle . truffle . api . dsl . NodeChild ; <nl> import com . oracle . truffle . api . dsl . NodeChildren ; <nl> import com . oracle . truffle . api . dsl . NodeField ; <nl> public void execute ( LLVMAddress address , LLVMAddress value ) { <nl> LLVMMemory . putAddress ( address , value ) ; <nl> } <nl> <nl> + @ SuppressWarnings ( \" unused \" ) <nl> + @ Specialization <nl> + public void execute ( LLVMAddress address , TruffleObject value ) { <nl> + CompilerDirectives . bailout ( \" unsupported operation \" ) ; <nl> + throw new UnsupportedOperationException ( \" Sulong can ' t store a Truffle object in a native memory address \" ) ; <nl> + } <nl> + <nl> } <nl> <nl> @ NodeChild ( type = LLVMFunctionNode . class , value = \" valueNode \" ) <nl>\n", "msg": "Give a proper error when trying to store a Truffle object in a native address\n"}
{"diff_id": 23554, "repo": "material-components/material-components-android\n", "sha": "20bbf1523bde968df8f1337a6c1e9edf2b7aa4b9\n", "time": "2018-09-14T15:04:01Z\n", "diff": "mmm a / lib / java / com / google / android / material / shape / MaterialShapeDrawable . java <nl> ppp b / lib / java / com / google / android / material / shape / MaterialShapeDrawable . java <nl> <nl> <nl> private static final float HALF_PI = ( float ) ( Math . PI / 2 . 0 ) ; <nl> <nl> - private final Paint paint = new Paint ( Paint . ANTI_ALIAS_FLAG ) ; <nl> + private final Paint fillPaint = new Paint ( Paint . ANTI_ALIAS_FLAG ) ; <nl> <nl> / / Inter - method state . <nl> private final Matrix [ ] cornerTransforms = new Matrix [ 4 ] ; <nl> public MaterialShapeDrawable ( ) { <nl> public MaterialShapeDrawable ( @ Nullable ShapePathModel shapePathModel ) { <nl> this . shapedViewModel = shapePathModel ; <nl> strokePaint . setStyle ( Style . STROKE ) ; <nl> - paint . setStyle ( Style . FILL ) ; <nl> + fillPaint . setStyle ( Style . FILL ) ; <nl> <nl> for ( int i = 0 ; i < 4 ; i + + ) { <nl> cornerTransforms [ i ] = new Matrix ( ) ; <nl> public ColorStateList getTintList ( ) { <nl> } <nl> <nl> / * * <nl> - * @ return the stroke ' s current { @ link ColorStateList } <nl> + * Get the stroke ' s current { @ link ColorStateList } . <nl> + * <nl> + * @ return the stroke ' s current { @ link ColorStateList } . <nl> * / <nl> public ColorStateList getStrokeTintList ( ) { <nl> return strokeTintList ; <nl> public void setTint ( @ ColorInt int tintColor ) { <nl> setTintList ( ColorStateList . valueOf ( tintColor ) ) ; <nl> } <nl> <nl> - / * * @ param tintList the { @ link ColorStateList } for the shape ' s stroke * / <nl> + / * * <nl> + * Set the shape ' s stroke { @ link ColorStateList } <nl> + * <nl> + * @ param tintList the { @ link ColorStateList } for the shape ' s stroke . <nl> + * / <nl> public void setStrokeTintList ( ColorStateList tintList ) { <nl> this . strokeTintList = tintList ; <nl> updateTintFilter ( ) ; <nl> invalidateSelf ( ) ; <nl> } <nl> <nl> - / * * @ param tintColor an int representing the Color to use for the shape ' s stroke * / <nl> + / * * <nl> + * Set the shape ' s stroke color . <nl> + * <nl> + * @ param tintColor an int representing the Color to use for the shape ' s stroke . <nl> + * / <nl> public void setStrokeTint ( @ ColorInt int tintColor ) { <nl> setStrokeTintList ( ColorStateList . valueOf ( tintColor ) ) ; <nl> } <nl> <nl> - / * Get the int representing the Color of the shape ' s stroke in the current state * / <nl> + / * * Get the int representing the Color of the shape ' s stroke in the current state . <nl> + * <nl> + * @ return the stroke ' s current color . <nl> + * * / <nl> @ ColorInt <nl> public int getStrokeTint ( ) { <nl> return strokePaint . getColor ( ) ; <nl> public void setAlpha ( @ IntRange ( from = 0 , to = 255 ) int alpha ) { <nl> <nl> @ Override <nl> public void setColorFilter ( @ Nullable ColorFilter colorFilter ) { <nl> - paint . setColorFilter ( colorFilter ) ; <nl> + fillPaint . setColorFilter ( colorFilter ) ; <nl> invalidateSelf ( ) ; <nl> } <nl> <nl> public void setColorFilter ( @ Nullable ColorFilter colorFilter ) { <nl> public Region getTransparentRegion ( ) { <nl> Rect bounds = getBounds ( ) ; <nl> transparentRegion . set ( bounds ) ; <nl> - transformPath ( bounds , path ) ; <nl> + calculatePath ( bounds , path ) ; <nl> scratchRegion . setPath ( path , transparentRegion ) ; <nl> transparentRegion . op ( scratchRegion , Op . DIFFERENCE ) ; <nl> return transparentRegion ; <nl> public void setShadowColor ( int shadowColor ) { <nl> * @ return current paint flags . <nl> * / <nl> public int getPaintFlags ( ) { <nl> - return paint . getFlags ( ) ; <nl> + return fillPaint . getFlags ( ) ; <nl> } <nl> <nl> / * * <nl> public int getPaintFlags ( ) { <nl> * @ param flags the desired flags . <nl> * / <nl> public void setPaintFlags ( int flags ) { <nl> - paint . setFlags ( flags ) ; <nl> + fillPaint . setFlags ( flags ) ; <nl> strokePaint . setFlags ( flags ) ; <nl> invalidateSelf ( ) ; <nl> } <nl> public float getStrokeWidth ( ) { <nl> * @ param strokeWidth desired stroke width . <nl> * / <nl> public void setStrokeWidth ( float strokeWidth ) { <nl> - paint . setStrokeWidth ( strokeWidth ) ; <nl> + fillPaint . setStrokeWidth ( strokeWidth ) ; <nl> strokePaint . setStrokeWidth ( strokeWidth ) ; <nl> invalidateSelf ( ) ; <nl> } <nl> <nl> - / * * Returns whether the shape has a fill * / <nl> - public boolean hasFill ( ) { <nl> + / * * Returns whether the shape has a fill . * / <nl> + private boolean hasFill ( ) { <nl> return paintStyle = = Style . FILL_AND_STROKE | | paintStyle = = Style . FILL ; <nl> } <nl> <nl> - / * * Returns whether the shape has a stroke with a positive width * / <nl> - public boolean hasStroke ( ) { <nl> + / * * Returns whether the shape has a stroke with a positive width . * / <nl> + private boolean hasStroke ( ) { <nl> return ( paintStyle = = Style . FILL_AND_STROKE | | paintStyle = = Style . STROKE ) <nl> & & strokePaint . getStrokeWidth ( ) > 0 ; <nl> } <nl> <nl> @ Override <nl> public void draw ( Canvas canvas ) { <nl> - paint . setColorFilter ( tintFilter ) ; <nl> - final int prevAlpha = paint . getAlpha ( ) ; <nl> - paint . setAlpha ( modulateAlpha ( prevAlpha , alpha ) ) ; <nl> + fillPaint . setColorFilter ( tintFilter ) ; <nl> + final int prevAlpha = fillPaint . getAlpha ( ) ; <nl> + fillPaint . setAlpha ( modulateAlpha ( prevAlpha , alpha ) ) ; <nl> <nl> strokePaint . setColorFilter ( strokeTintFilter ) ; <nl> final int prevStrokeAlpha = strokePaint . getAlpha ( ) ; <nl> strokePaint . setAlpha ( modulateAlpha ( prevStrokeAlpha , alpha ) ) ; <nl> <nl> if ( shadowElevation > 0 & & shadowEnabled ) { <nl> - paint . setShadowLayer ( shadowRadius , 0 , shadowElevation , shadowColor ) ; <nl> + fillPaint . setShadowLayer ( shadowRadius , 0 , shadowElevation , shadowColor ) ; <nl> } <nl> <nl> Rect bounds = getBounds ( ) ; <nl> if ( shapedViewModel ! = null ) { <nl> - transformPath ( bounds , path ) ; <nl> + calculatePath ( bounds , path ) ; <nl> if ( hasFill ( ) ) { <nl> - canvas . drawPath ( path , paint ) ; <nl> + canvas . drawPath ( path , fillPaint ) ; <nl> } <nl> if ( hasStroke ( ) ) { <nl> canvas . drawPath ( path , strokePaint ) ; <nl> } <nl> } else { <nl> if ( hasFill ( ) ) { <nl> - canvas . drawRect ( bounds , paint ) ; <nl> + canvas . drawRect ( bounds , fillPaint ) ; <nl> } <nl> if ( hasStroke ( ) ) { <nl> canvas . drawRect ( bounds , strokePaint ) ; <nl> } <nl> } <nl> <nl> - paint . setAlpha ( prevAlpha ) ; <nl> + fillPaint . setAlpha ( prevAlpha ) ; <nl> strokePaint . setAlpha ( prevStrokeAlpha ) ; <nl> } <nl> <nl> public void draw ( Canvas canvas ) { <nl> * @ param path the returned path out - var . <nl> * @ return the generated path . <nl> * / <nl> - public void getPathForSize ( Rect bounds , Path path ) { <nl> + private void calculatePathForSize ( Rect bounds , Path path ) { <nl> path . rewind ( ) ; <nl> <nl> if ( shapedViewModel = = null ) { <nl> public void getPathForSize ( Rect bounds , Path path ) { <nl> / / corner treatment . <nl> for ( int index = 0 ; index < 4 ; index + + ) { <nl> setCornerPathAndTransform ( index , bounds ) ; <nl> - setEdgeAndTransform ( index ) ; <nl> + setEdgePathAndTransform ( index ) ; <nl> } <nl> <nl> / / Apply corners and edges to the path in clockwise interleaving sequence : top - left corner , top <nl> private void setCornerPathAndTransform ( int index , Rect bounds ) { <nl> cornerTransforms [ index ] . preRotate ( ( float ) Math . toDegrees ( prevEdgeAngle ) ) ; <nl> } <nl> <nl> - private void setEdgeAndTransform ( int index ) { <nl> + private void setEdgePathAndTransform ( int index ) { <nl> scratch [ 0 ] = cornerPaths [ index ] . endX ; <nl> scratch [ 1 ] = cornerPaths [ index ] . endY ; <nl> cornerTransforms [ index ] . mapPoints ( scratch ) ; <nl> private float angleOfEdge ( int index ) { <nl> return HALF_PI * ( ( index + 4 ) % 4 ) ; <nl> } <nl> <nl> - private void transformPath ( Rect bounds , Path path ) { <nl> - getPathForSize ( bounds , path ) ; <nl> + private void calculatePath ( Rect bounds , Path path ) { <nl> + calculatePathForSize ( bounds , path ) ; <nl> if ( scale = = 1f ) { <nl> return ; <nl> } <nl> private void transformPath ( Rect bounds , Path path ) { <nl> } <nl> <nl> private void updateTintFilter ( ) { <nl> - tintFilter = computeTintFilter ( tintList , tintMode ) ; <nl> - strokeTintFilter = computeTintFilter ( strokeTintList , tintMode ) ; <nl> + tintFilter = calculateTintFilter ( tintList , tintMode ) ; <nl> + strokeTintFilter = calculateTintFilter ( strokeTintList , tintMode ) ; <nl> if ( useTintColorForShadow ) { <nl> shadowColor = tintList . getColorForState ( getState ( ) , Color . TRANSPARENT ) ; <nl> } <nl> } <nl> <nl> @ Nullable <nl> - private PorterDuffColorFilter computeTintFilter ( <nl> + private PorterDuffColorFilter calculateTintFilter ( <nl> ColorStateList tintList , PorterDuff . Mode tintMode ) { <nl> if ( tintList = = null | | tintMode = = null ) { <nl> return null ; <nl>\n", "msg": "Improvements to readability and javadoc of MaterialShapeDrawable\n"}
{"diff_id": 23555, "repo": "zxing/zxing\n", "sha": "7d878d701e9fa46bb71073cc89dd66beb5b15c16\n", "time": "2014-04-18T10:06:08Z\n", "diff": "mmm a / core / src / main / java / com / google / zxing / qrcode / detector / FinderPatternFinder . java <nl> ppp b / core / src / main / java / com / google / zxing / qrcode / detector / FinderPatternFinder . java <nl> protected static boolean foundPatternCross ( int [ ] stateCount ) { <nl> * @ return true if proportions are withing expected limits <nl> * / <nl> private boolean crossCheckDiagonal ( int startI , int centerJ , int maxCount , int originalStateCountTotal ) { <nl> - int maxI = image . getHeight ( ) ; <nl> - int maxJ = image . getWidth ( ) ; <nl> int [ ] stateCount = getCrossCheckStateCount ( ) ; <nl> <nl> / / Start counting up , left from center finding black center mass <nl> int i = 0 ; <nl> - while ( startI - i > = 0 & & image . get ( centerJ - i , startI - i ) ) { <nl> + while ( startI > = i & & centerJ > = i & & image . get ( centerJ - i , startI - i ) ) { <nl> stateCount [ 2 ] + + ; <nl> i + + ; <nl> } <nl> <nl> - if ( ( startI - i < 0 ) | | ( centerJ - i < 0 ) ) { <nl> + if ( startI < i | | centerJ < i ) { <nl> return false ; <nl> } <nl> <nl> / / Continue up , left finding white space <nl> - while ( ( startI - i > = 0 ) & & ( centerJ - i > = 0 ) & & ! image . get ( centerJ - i , startI - i ) & & stateCount [ 1 ] < = maxCount ) { <nl> + while ( startI > = i & & centerJ > = i & & ! image . get ( centerJ - i , startI - i ) & & <nl> + stateCount [ 1 ] < = maxCount ) { <nl> stateCount [ 1 ] + + ; <nl> i + + ; <nl> } <nl> <nl> / / If already too many modules in this state or ran off the edge : <nl> - if ( ( startI - i < 0 ) | | ( centerJ - i < 0 ) | | stateCount [ 1 ] > maxCount ) { <nl> + if ( startI < i | | centerJ < i | | stateCount [ 1 ] > maxCount ) { <nl> return false ; <nl> } <nl> <nl> / / Continue up , left finding black border <nl> - while ( ( startI - i > = 0 ) & & ( centerJ - i > = 0 ) & & image . get ( centerJ - i , startI - i ) & & stateCount [ 0 ] < = maxCount ) { <nl> + while ( startI > = i & & centerJ > = i & & image . get ( centerJ - i , startI - i ) & & <nl> + stateCount [ 0 ] < = maxCount ) { <nl> stateCount [ 0 ] + + ; <nl> i + + ; <nl> } <nl> private boolean crossCheckDiagonal ( int startI , int centerJ , int maxCount , int or <nl> return false ; <nl> } <nl> <nl> + int maxI = image . getHeight ( ) ; <nl> + int maxJ = image . getWidth ( ) ; <nl> + <nl> / / Now also count down , right from center <nl> i = 1 ; <nl> - while ( ( startI + i < maxI ) & & ( centerJ + i < maxJ ) & & image . get ( centerJ + i , startI + i ) ) { <nl> + while ( startI + i < maxI & & centerJ + i < maxJ & & image . get ( centerJ + i , startI + i ) ) { <nl> stateCount [ 2 ] + + ; <nl> i + + ; <nl> } <nl> <nl> / / Ran off the edge ? <nl> - if ( ( startI + i > = maxI ) | | ( centerJ + i > = maxJ ) ) { <nl> + if ( startI + i > = maxI | | centerJ + i > = maxJ ) { <nl> return false ; <nl> } <nl> <nl> - while ( ( startI + i < maxI ) & & ( centerJ + i < maxJ ) & & ! image . get ( centerJ + i , startI + i ) & & stateCount [ 3 ] < maxCount ) { <nl> + while ( startI + i < maxI & & centerJ + i < maxJ & & ! image . get ( centerJ + i , startI + i ) & & <nl> + stateCount [ 3 ] < maxCount ) { <nl> stateCount [ 3 ] + + ; <nl> i + + ; <nl> } <nl> <nl> - if ( ( startI + i > = maxI ) | | ( centerJ + i > = maxJ ) | | stateCount [ 3 ] > = maxCount ) { <nl> + if ( startI + i > = maxI | | centerJ + i > = maxJ | | stateCount [ 3 ] > = maxCount ) { <nl> return false ; <nl> } <nl> <nl> - while ( ( startI + i < maxI ) & & ( centerJ + i < maxJ ) & & image . get ( centerJ + i , startI + i ) & & stateCount [ 4 ] < maxCount ) { <nl> + while ( startI + i < maxI & & centerJ + i < maxJ & & image . get ( centerJ + i , startI + i ) & & <nl> + stateCount [ 4 ] < maxCount ) { <nl> stateCount [ 4 ] + + ; <nl> i + + ; <nl> } <nl>\n", "msg": "Issue add range check and simplify some conditions\n"}
{"diff_id": 23574, "repo": "oracle/graal\n", "sha": "7e5c81cac9f16bde1b8d7a7c9aaf1d19ccabb954\n", "time": "2019-11-05T11:30:45Z\n", "diff": "mmm a / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / OptimizedCallTarget . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / OptimizedCallTarget . java <nl> <nl> private static final String NODE_REWRITING_ASSUMPTION_NAME = \" nodeRewritingAssumption \" ; <nl> static final String CALL_BOUNDARY_METHOD_NAME = \" callProxy \" ; <nl> static final String CALL_INLINED_METHOD_NAME = \" call \" ; <nl> + private static final AtomicReferenceFieldUpdater < OptimizedCallTarget , SpeculationLog > SPECULATION_LOG_UPDATER = AtomicReferenceFieldUpdater . newUpdater ( OptimizedCallTarget . class , <nl> + SpeculationLog . class , \" speculationLog \" ) ; <nl> + private static final AtomicReferenceFieldUpdater < OptimizedCallTarget , Assumption > NODE_REWRITING_ASSUMPTION_UPDATER = AtomicReferenceFieldUpdater . newUpdater ( OptimizedCallTarget . class , <nl> + Assumption . class , \" nodeRewritingAssumption \" ) ; <nl> + private static final WeakReference < OptimizedDirectCallNode > UNINITIALIZED_SINGLE_CALL = new WeakReference < > ( null ) ; <nl> + private static final String SPLIT_LOG_FORMAT = \" [ truffle ] [ poly - event ] % - 70s % s \" ; <nl> <nl> / * * The AST to be executed when this call target is called . * / <nl> private final RootNode rootNode ; <nl> <nl> private volatile SpeculationLog speculationLog ; <nl> private volatile int callSitesKnown ; <nl> <nl> - private static final AtomicReferenceFieldUpdater < OptimizedCallTarget , SpeculationLog > SPECULATION_LOG_UPDATER = AtomicReferenceFieldUpdater . newUpdater ( OptimizedCallTarget . class , <nl> - SpeculationLog . class , \" speculationLog \" ) ; <nl> - <nl> / * * <nl> * When this field is not null , this { @ link OptimizedCallTarget } is { @ linkplain # isCompiling ( ) <nl> * being compiled } . < br / > <nl> <nl> * ensures that all compiled methods that inline this call target are properly invalidated . <nl> * / <nl> private volatile Assumption nodeRewritingAssumption ; <nl> - private static final AtomicReferenceFieldUpdater < OptimizedCallTarget , Assumption > NODE_REWRITING_ASSUMPTION_UPDATER = AtomicReferenceFieldUpdater . newUpdater ( OptimizedCallTarget . class , <nl> - Assumption . class , \" nodeRewritingAssumption \" ) ; <nl> private volatile OptimizedDirectCallNode callSiteForSplit ; <nl> @ CompilationFinal private volatile String nameCache ; <nl> private final int uninitializedNodeCount ; <nl> <nl> - private static final WeakReference < OptimizedDirectCallNode > UNINITIALIZED = new WeakReference < > ( null ) ; <nl> - private volatile WeakReference < OptimizedDirectCallNode > singleCallNode = UNINITIALIZED ; <nl> + private volatile WeakReference < OptimizedDirectCallNode > singleCallNode = UNINITIALIZED_SINGLE_CALL ; <nl> private boolean needsSplit ; <nl> - private static final String SPLIT_LOG_FORMAT = \" [ truffle ] [ poly - event ] % - 70s % s \" ; <nl> <nl> - public OptimizedCallTarget ( OptimizedCallTarget sourceCallTarget , RootNode rootNode ) { <nl> + protected OptimizedCallTarget ( OptimizedCallTarget sourceCallTarget , RootNode rootNode ) { <nl> assert sourceCallTarget = = null | | sourceCallTarget . sourceCallTarget = = null : \" Cannot create a clone of a cloned CallTarget \" ; <nl> this . sourceCallTarget = sourceCallTarget ; <nl> this . speculationLog = sourceCallTarget ! = null ? sourceCallTarget . getSpeculationLog ( ) : null ; <nl> this . rootNode = rootNode ; <nl> - final GraalTVMCI tvmci = runtime ( ) . getTvmci ( ) ; <nl> this . engine = GraalTVMCI . getEngineData ( rootNode ) ; <nl> / / Do not adopt children of OSRRootNodes ; we want to preserve the parent of the LoopNode . <nl> + final GraalTVMCI tvmci = runtime ( ) . getTvmci ( ) ; <nl> this . uninitializedNodeCount = ! ( rootNode instanceof OSRRootNode ) ? tvmci . adoptChildrenAndCount ( this . rootNode ) : - 1 ; <nl> tvmci . setCallTarget ( rootNode , this ) ; <nl> - / / getCompilationProfile ( ) ; <nl> } <nl> <nl> / * * <nl> synchronized void addDirectCallNode ( OptimizedDirectCallNode directCallNode ) { <nl> WeakReference < OptimizedDirectCallNode > nodeRef = singleCallNode ; <nl> if ( nodeRef ! = null ) { <nl> / / we only remember at most one call site <nl> - if ( nodeRef = = UNINITIALIZED ) { <nl> + if ( nodeRef = = UNINITIALIZED_SINGLE_CALL ) { <nl> singleCallNode = new WeakReference < > ( directCallNode ) ; <nl> } else if ( nodeRef . get ( ) = = directCallNode ) { <nl> / / nothing to do same call site <nl> synchronized void removeDirectCallNode ( OptimizedDirectCallNode directCallNode ) { <nl> WeakReference < OptimizedDirectCallNode > nodeRef = singleCallNode ; <nl> if ( nodeRef ! = null ) { <nl> / / we only remember at most one call site <nl> - if ( nodeRef = = UNINITIALIZED ) { <nl> + if ( nodeRef = = UNINITIALIZED_SINGLE_CALL ) { <nl> / / nothing to do <nl> return ; <nl> } else if ( nodeRef . get ( ) = = directCallNode ) { <nl> / / reset if its the only call site <nl> - singleCallNode = UNINITIALIZED ; <nl> + singleCallNode = UNINITIALIZED_SINGLE_CALL ; <nl> } else { <nl> singleCallNode = null ; <nl> } <nl>\n", "msg": "Move static fields to the top of the class . Reduce visibility of OptimizedCallTarget constructor .\n"}
{"diff_id": 23624, "repo": "bazelbuild/bazel\n", "sha": "9cc3f1e31058cf490358915fdd1f8f5a220669d2\n", "time": "2020-07-23T09:41:22Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / buildtool / BuildTool . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / buildtool / BuildTool . java <nl> private void dumpSkyframeStateAfterBuild ( <nl> / * includeActionCmdLine = * / false , <nl> / * includeArtifacts = * / true , <nl> / * actionFilters = * / null , <nl> - / * includeParamFiles = * / true , <nl> + / * includeParamFiles = * / false , <nl> aqueryOutputHandler ) ; <nl> ( ( SequencedSkyframeExecutor ) env . getSkyframeExecutor ( ) ) . dumpSkyframeState ( actionGraphDump ) ; <nl> aqueryOutputHandler . close ( ) ; <nl>\n", "msg": "Disable param files for aquery - dump - after - build .\n"}
{"diff_id": 23666, "repo": "oracle/graal\n", "sha": "57f57c87ebf61cf256035dd5050e4ff97d8b8f76\n", "time": "2020-08-05T13:44:22Z\n", "diff": "mmm a / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / OptimizedIndirectCallNode . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / OptimizedIndirectCallNode . java <nl> public Object call ( CallTarget target , Object . . . arguments ) { <nl> Node prev = encapsulating . set ( null ) ; <nl> try { <nl> return ( ( OptimizedCallTarget ) target ) . callIndirect ( prev , arguments ) ; <nl> + } catch ( Throwable t ) { <nl> + GraalRuntimeAccessor . LANGUAGE . onThrowable ( prev , null , t , null ) ; <nl> + throw OptimizedCallTarget . rethrow ( t ) ; <nl> } finally { <nl> encapsulating . set ( prev ) ; <nl> } <nl>\n", "msg": "[ GR - 25371 ] Add missing call to onThrowable ( ) for the uncached OptimizedIndirectCallNode\n"}
{"diff_id": 23725, "repo": "SeleniumHQ/selenium\n", "sha": "7759ff447500992dd46727ea7f3807218d00be81\n", "time": "2016-06-26T04:19:05Z\n", "diff": "mmm a / java / client / test / org / openqa / selenium / testing / drivers / SynthesizedFirefoxDriver . java <nl> ppp b / java / client / test / org / openqa / selenium / testing / drivers / SynthesizedFirefoxDriver . java <nl> <nl> <nl> package org . openqa . selenium . testing . drivers ; <nl> <nl> + import static org . junit . Assert . fail ; <nl> import static org . openqa . selenium . testing . DevMode . isInDevMode ; <nl> <nl> + import com . google . common . base . Throwables ; <nl> import com . google . common . collect . ImmutableMap ; <nl> <nl> import org . openqa . selenium . BuckBuild ; <nl> import org . openqa . selenium . Capabilities ; <nl> + import org . openqa . selenium . WebDriverException ; <nl> import org . openqa . selenium . firefox . FirefoxDriver ; <nl> import org . openqa . selenium . firefox . FirefoxProfile ; <nl> import org . openqa . selenium . remote . DesiredCapabilities ; <nl> <nl> import java . io . File ; <nl> import java . io . IOException ; <nl> import java . io . InputStream ; <nl> + import java . io . Reader ; <nl> import java . net . URL ; <nl> import java . nio . file . Files ; <nl> import java . nio . file . Path ; <nl> private static Capabilities tweakCapabilities ( Capabilities desiredCaps ) { <nl> <nl> private static FirefoxProfile createTemporaryProfile ( ) { <nl> if ( ! isInDevMode ( ) ) { <nl> - FirefoxProfile profile = new FirefoxProfile ( ) ; <nl> + FirefoxProfile profile = new CustomProfile ( ) ; <nl> <nl> if ( Boolean . getBoolean ( \" webdriver . debug \" ) ) { <nl> try { <nl> private static FirefoxProfile createTemporaryProfile ( ) { <nl> } <nl> <nl> try { <nl> - FirefoxProfile profile = new FirefoxProfile ( ) ; <nl> + FirefoxProfile profile = new CustomProfile ( ) ; <nl> if ( Boolean . getBoolean ( \" webdriver . debug \" ) ) { <nl> <nl> Firebug . addTo ( profile ) ; <nl> private static FirefoxProfile copyExtensionTo ( FirefoxProfile profile ) throws IOE <nl> profile . addExtension ( ext ) ; <nl> return profile ; <nl> } <nl> + <nl> + private static class CustomProfile extends FirefoxProfile { <nl> + <nl> + private static Path prefs ; <nl> + <nl> + @ Override <nl> + protected Reader onlyOverrideThisIfYouKnowWhatYouAreDoing ( ) { <nl> + try { <nl> + return super . onlyOverrideThisIfYouKnowWhatYouAreDoing ( ) ; <nl> + } catch ( RuntimeException e ) { <nl> + if ( ! DevMode . isInDevMode ( ) ) { <nl> + throw e ; <nl> + } <nl> + } <nl> + <nl> + prefs = actuallyGetPrefsPath ( ) ; <nl> + <nl> + try { <nl> + return Files . newBufferedReader ( prefs ) ; <nl> + } catch ( IOException e ) { <nl> + fail ( Throwables . getStackTraceAsString ( e ) ) ; <nl> + throw new RuntimeException ( e ) ; <nl> + } <nl> + } <nl> + <nl> + private Path actuallyGetPrefsPath ( ) { <nl> + if ( prefs ! = null ) { <nl> + return prefs ; <nl> + } <nl> + <nl> + synchronized ( CustomProfile . class ) { <nl> + if ( prefs = = null ) { <nl> + try { <nl> + prefs = new BuckBuild ( ) . of ( \" / / javascript / firefox - driver : webdriver_prefs \" ) . go ( ) ; <nl> + } catch ( IOException ioe ) { <nl> + throw new WebDriverException ( ioe ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + return prefs ; <nl> + } <nl> + } <nl> } <nl> <nl>\n", "msg": "Allow tests using the SynthesizedFirefoxDriver to work from an IDE .\n"}
{"diff_id": 23801, "repo": "SeleniumHQ/selenium\n", "sha": "6477098e3f295faa884734805d1a4af38f07f135\n", "time": "2015-09-15T14:12:02Z\n", "diff": "mmm a / java / client / test / org / openqa / selenium / SvgElementTest . java <nl> ppp b / java / client / test / org / openqa / selenium / SvgElementTest . java <nl> <nl> @ Test <nl> public void testShouldClickOnGraphVisualElements ( ) { <nl> assumeFalse ( \" IE version < 9 doesn ' t support SVG \" , isOldIe ( driver ) ) ; <nl> - assumeFalse ( \" Firefox 3 . 0 with native events doesn ' t support SVG \" , <nl> - isFirefox30 ( driver ) & & isNativeEventsEnabled ( driver ) ) ; <nl> <nl> driver . get ( pages . svgPage ) ; <nl> WebElement svg = driver . findElement ( By . cssSelector ( \" svg \" ) ) ; <nl> private static WebElement findAppleElement ( List < WebElement > textElements ) { <nl> @ Test <nl> public void testShouldClickOnGraphTextElements ( ) { <nl> assumeFalse ( \" IE version < 9 doesn ' t support SVG \" , isOldIe ( driver ) ) ; <nl> - assumeFalse ( \" Firefox 3 . 0 with native events doesn ' t support SVG \" , <nl> - isFirefox30 ( driver ) & & isNativeEventsEnabled ( driver ) ) ; <nl> <nl> driver . get ( pages . svgPage ) ; <nl> WebElement svg = driver . findElement ( By . cssSelector ( \" svg \" ) ) ; <nl>\n", "msg": "Deleting outdated assumes for unsupported Firefox version\n"}
{"diff_id": 23914, "repo": "oracle/graal\n", "sha": "7853363a4c55409a54c1e089db7dd9fbff1050cd\n", "time": "2020-04-15T12:28:01Z\n", "diff": "mmm a / substratevm / src / com . oracle . svm . core . graal . llvm / src / com / oracle / svm / core / graal / llvm / util / LLVMObjectFileReader . java <nl> ppp b / substratevm / src / com . oracle . svm . core . graal . llvm / src / com / oracle / svm / core / graal / llvm / util / LLVMObjectFileReader . java <nl> <nl> import com . oracle . svm . shadowed . org . bytedeco . llvm . LLVM . LLVMSymbolIteratorRef ; <nl> import com . oracle . svm . shadowed . org . bytedeco . llvm . global . LLVM ; <nl> <nl> + import jdk . vm . ci . code . DebugInfo ; <nl> + import jdk . vm . ci . code . ReferenceMap ; <nl> import jdk . vm . ci . code . site . Call ; <nl> import jdk . vm . ci . code . site . Infopoint ; <nl> import jdk . vm . ci . code . site . InfopointReason ; <nl> public void readStackMap ( LLVMStackMapInfo info , CompilationResult compilation , R <nl> for ( int actualPcOffset : info . getPatchpointOffsets ( call . pcOffset ) ) { <nl> SubstrateReferenceMap referenceMap = new SubstrateReferenceMap ( ) ; <nl> info . forEachStatepointOffset ( call . pcOffset , actualPcOffset , referenceMap : : markReferenceAtOffset ) ; <nl> - call . debugInfo . setReferenceMap ( referenceMap ) ; <nl> stackMapDumper . dumpCallSite ( call , actualPcOffset , referenceMap ) ; <nl> - <nl> - newInfopoints . add ( new Call ( call . target , actualPcOffset , call . size , call . direct , call . debugInfo ) ) ; <nl> + newInfopoints . add ( new Call ( call . target , actualPcOffset , call . size , call . direct , copyWithReferenceMap ( call . debugInfo , referenceMap ) ) ) ; <nl> } <nl> } <nl> } <nl> public void readStackMap ( LLVMStackMapInfo info , CompilationResult compilation , R <nl> newInfopoints . forEach ( compilation : : addInfopoint ) ; <nl> } <nl> <nl> + private static DebugInfo copyWithReferenceMap ( DebugInfo debugInfo , ReferenceMap referenceMap ) { <nl> + DebugInfo newInfo = new DebugInfo ( debugInfo . getBytecodePosition ( ) , debugInfo . getVirtualObjectMapping ( ) ) ; <nl> + newInfo . setCalleeSaveInfo ( debugInfo . getCalleeSaveInfo ( ) ) ; <nl> + newInfo . setReferenceMap ( referenceMap ) ; <nl> + return newInfo ; <nl> + } <nl> + <nl> public static final class LLVMTextSectionInfo { <nl> private final long codeSize ; <nl> private final Map < Integer , String > offsetToSymbol = new TreeMap < > ( ) ; <nl>\n", "msg": "Avoid reusing the same reference map for duplicated calls\n"}
{"diff_id": 23987, "repo": "SeleniumHQ/selenium\n", "sha": "f48f97f39ac7f4ce349a2a83838e277e4cfc0b73\n", "time": "2013-09-06T02:03:03Z\n", "diff": "mmm a / java / server / src / org / openqa / selenium / remote / server / DefaultDriverSessions . java <nl> ppp b / java / server / src / org / openqa / selenium / remote / server / DefaultDriverSessions . java <nl> public DefaultDriverSessions ( ) { <nl> this ( Platform . getCurrent ( ) , new DefaultDriverFactory ( ) ) ; <nl> } <nl> <nl> + public DefaultDriverSessions ( <nl> + DriverFactory factory , Map < Capabilities , Class < ? extends WebDriver > > drivers ) { <nl> + this . factory = factory ; <nl> + for ( Map . Entry < Capabilities , Class < ? extends WebDriver > > entry : drivers . entrySet ( ) ) { <nl> + registerDriver ( entry . getKey ( ) , entry . getValue ( ) ) ; <nl> + } <nl> + } <nl> + <nl> protected DefaultDriverSessions ( Platform runningOn , DriverFactory factory ) { <nl> this . factory = factory ; <nl> registerDefaults ( runningOn ) ; <nl>\n", "msg": "Support configuring a Selenium server without the default set of driver configurations .\n"}
{"diff_id": 24048, "repo": "bazelbuild/bazel\n", "sha": "34b7dd3ae377c89d5652b9df7f9d85bed5b0c679\n", "time": "2018-12-12T02:55:40Z\n", "diff": "mmm a / src / tools / android / java / com / google / devtools / build / android / desugar / CorePackageRenamer . java <nl> ppp b / src / tools / android / java / com / google / devtools / build / android / desugar / CorePackageRenamer . java <nl> <nl> / / limitations under the License . <nl> package com . google . devtools . build . android . desugar ; <nl> <nl> + import static com . google . common . base . Preconditions . checkState ; <nl> + <nl> import org . objectweb . asm . ClassVisitor ; <nl> + import org . objectweb . asm . MethodVisitor ; <nl> import org . objectweb . asm . commons . ClassRemapper ; <nl> + import org . objectweb . asm . commons . MethodRemapper ; <nl> + import org . objectweb . asm . commons . Remapper ; <nl> <nl> / * * <nl> - * A visitor that renames packages so configured using { @ link CoreLibrarySupport } . . <nl> + * A visitor that renames packages so configured using { @ link CoreLibrarySupport } . <nl> * / <nl> class CorePackageRenamer extends ClassRemapper { <nl> <nl> + private String internalName ; <nl> + <nl> public CorePackageRenamer ( ClassVisitor cv , CoreLibrarySupport support ) { <nl> - super ( cv , support . getRemapper ( ) ) ; <nl> + super ( cv , new CorePackageRemapper ( support ) ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public void visit ( int version , int access , String name , String signature , String superName , <nl> + String [ ] interfaces ) { <nl> + internalName = name ; <nl> + super . visit ( version , access , name , signature , superName , interfaces ) ; <nl> + } <nl> + <nl> + @ Override <nl> + protected CoreMethodRemapper createMethodRemapper ( MethodVisitor methodVisitor ) { <nl> + return new CoreMethodRemapper ( methodVisitor , remapper ) ; <nl> + } <nl> + <nl> + private class CoreMethodRemapper extends MethodRemapper { <nl> + <nl> + public CoreMethodRemapper ( MethodVisitor methodVisitor , <nl> + Remapper remapper ) { <nl> + super ( methodVisitor , remapper ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public void visitMethodInsn ( int opcode , String owner , String name , String descriptor , <nl> + boolean isInterface ) { <nl> + CorePackageRemapper remapper = ( CorePackageRemapper ) this . remapper ; <nl> + remapper . didSomething = false ; <nl> + super . visitMethodInsn ( opcode , owner , name , descriptor , isInterface ) ; <nl> + / / TODO ( b / 79121791 ) : Make this more precise : look for all unsupported core library members <nl> + checkState ( ! remapper . didSomething <nl> + | | ! owner . startsWith ( \" android / \" ) | | owner . startsWith ( \" android / support / \" ) , <nl> + \" % s calls % s . % s % s which is not supported with core library desugaring . Please file \" <nl> + + \" a feature request to support this method \" , internalName , owner , name , descriptor ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public void visitFieldInsn ( int opcode , String owner , String name , String descriptor ) { <nl> + CorePackageRemapper remapper = ( CorePackageRemapper ) this . remapper ; <nl> + remapper . didSomething = false ; <nl> + super . visitFieldInsn ( opcode , owner , name , descriptor ) ; <nl> + / / TODO ( b / 79121791 ) : Make this more precise : look for all unsupported core library members <nl> + checkState ( ! remapper . didSomething <nl> + | | ! owner . startsWith ( \" android / \" ) | | owner . startsWith ( \" android / support / \" ) , <nl> + \" % s accesses % s . % s : % s which is not supported with core library desugaring . Please file \" <nl> + + \" a feature request to support this field \" , internalName , owner , name , descriptor ) ; <nl> + } <nl> + } <nl> + <nl> + / * * ASM { @ link Remapper } based on { @ link CoreLibrarySupport } . * / <nl> + private static class CorePackageRemapper extends Remapper { <nl> + <nl> + private final CoreLibrarySupport support ; <nl> + boolean didSomething = false ; <nl> + <nl> + CorePackageRemapper ( CoreLibrarySupport support ) { <nl> + this . support = support ; <nl> + } <nl> + <nl> + @ Override <nl> + public String map ( String typeName ) { <nl> + if ( support . isRenamedCoreLibrary ( typeName ) ) { <nl> + didSomething = true ; <nl> + return support . renameCoreLibrary ( typeName ) ; <nl> + } <nl> + return typeName ; <nl> + } <nl> } <nl> } <nl>\n", "msg": "Simple build - time check for uses of desugared core library methods .\n"}
{"diff_id": 24113, "repo": "oracle/graal\n", "sha": "b0ce6c73c95db59d75fb328336583e30912834b3\n", "time": "2016-09-23T08:02:18Z\n", "diff": "mmm a / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / HotSpotGraalCompiler . java <nl> ppp b / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / HotSpotGraalCompiler . java <nl> <nl> public static class Options { <nl> / / @ formatter : off <nl> @ Option ( help = \" Enable Compilation counters . Compilation counters count the number of compilations for each method . \" , type = OptionType . Debug ) <nl> - public static final OptionValue < Boolean > EnableCompilationCounters = new StableOptionValue < > ( true ) ; <nl> + public static final OptionValue < Boolean > EnableCompilationCounters = new StableOptionValue < > ( false ) ; <nl> @ Option ( help = \" An upper bound for the number of compilations of a method to fail . \" , type = OptionType . Debug ) <nl> public static final OptionValue < Integer > CompilationCountersUpperBound = new StableOptionValue < > ( 256 ) ; <nl> @ Option ( help = \" Reaching the upper bound for the number of compilations of a method is considered fatal and will exit the VM . \" , type = OptionType . Debug ) <nl> public static final OptionValue < Boolean > CompilationCountersExceededIsFatal = new StableOptionValue < > ( true ) ; <nl> @ Option ( help = \" Enable a watchdog thread for each compiler thread . \" + <nl> \" A watchdog threads reports long running compilations and kills the VM if a certain time bound is reached . \" , type = OptionType . Debug ) <nl> - public static final OptionValue < Boolean > MonitorCompilerThreads = new StableOptionValue < > ( true ) ; <nl> + public static final OptionValue < Boolean > MonitorCompilerThreads = new StableOptionValue < > ( false ) ; <nl> @ Option ( help = \" Kill a Compiler Thread and exit the VM if the FatalNumberOfCompilerThreadStackTraces last stack traces are the equal . \" , type = OptionType . Debug ) <nl> public static final OptionValue < Boolean > StaleCompilerThreadsAreFatal = new StableOptionValue < > ( true ) ; <nl> @ Option ( help = \" Number of equal stack traces for the compiler thread until it is killed \" , type = OptionType . Debug ) <nl> void dumpCounters ( PrintStream s ) { <nl> * / <nl> WATCHING_NO_STACK_INSPECTION , <nl> / * * <nl> - * The watchdog thread is fully monitoring the compiler thread . It takes stake <nl> + * The watchdog thread is fully monitoring the compiler thread . It takes stack <nl> * traces periodically and sleeps again until the next period . If the number of <nl> * stack traces reaches a certain upper bound and those stack traces are equal it <nl> * will shut down the entire VM with an error . <nl> public void run ( ) { <nl> ellapsedWatchingTime = 0 ; <nl> if ( Options . StaleCompilerThreadsAreFatal . getValue ( ) ) { <nl> if ( nrOfStackTraces > Options . FatalNumberOfCompilerThreadStackTraces . getValue ( ) ) { <nl> - TTY . println ( \" % s took N stack traces , which is considered fatal , we quit now [ compiling method % s ] . Printing Stack Trace . . . \" , getTracePrefix ( ) , <nl> + TTY . println ( \" % s took N stack traces , which is considered fatal , VM will quit now [ compiling method % s ] . Printing Stack Trace . . . \" , getTracePrefix ( ) , <nl> lastSet ) ; <nl> printStackTraceTTY ( ) ; <nl> System . exit ( - 1 ) ; <nl>\n", "msg": "compilation monitoring : run full bootstrap task with watchdog enabled\n"}
{"diff_id": 24154, "repo": "apache/flink\n", "sha": "6fbde344548d456104567f34d63f4a5744719757\n", "time": "2011-04-04T12:44:59Z\n", "diff": "mmm a / nephele / nephele - visualization / src / main / java / eu / stratosphere / nephele / visualization / swt / SWTVisualizationGUI . java <nl> ppp b / nephele / nephele - visualization / src / main / java / eu / stratosphere / nephele / visualization / swt / SWTVisualizationGUI . java <nl> <nl> import org . eclipse . swt . widgets . TreeItem ; <nl> import org . eclipse . swt . widgets . Widget ; <nl> <nl> + import eu . stratosphere . nephele . client . AbstractJobResult ; <nl> + import eu . stratosphere . nephele . client . JobCancelResult ; <nl> import eu . stratosphere . nephele . configuration . GlobalConfiguration ; <nl> import eu . stratosphere . nephele . event . job . AbstractEvent ; <nl> import eu . stratosphere . nephele . event . job . ExecutionStateChangeEvent ; <nl> public void widgetSelected ( SelectionEvent arg0 ) { <nl> } <nl> } ) ; <nl> <nl> + final MenuItem jobMenuItem = new MenuItem ( this . menuBar , SWT . CASCADE ) ; <nl> + jobMenuItem . setText ( \" & Job \" ) ; <nl> + <nl> + final Menu jobMenu = new Menu ( this . shell , SWT . DROP_DOWN ) ; <nl> + jobMenuItem . setMenu ( jobMenu ) ; <nl> + <nl> + final MenuItem cancelJobItem = new MenuItem ( jobMenu , SWT . PUSH ) ; <nl> + cancelJobItem . setText ( \" & Cancel job \" ) ; <nl> + cancelJobItem . addSelectionListener ( new SelectionAdapter ( ) { <nl> + <nl> + @ Override <nl> + public void widgetSelected ( SelectionEvent arg0 ) { <nl> + cancelJob ( ) ; <nl> + shell . setMenuBar ( null ) ; <nl> + } <nl> + } ) ; <nl> + <nl> final MenuItem diagnosisMenuItem = new MenuItem ( this . menuBar , SWT . CASCADE ) ; <nl> diagnosisMenuItem . setText ( \" & Diagnosis \" ) ; <nl> <nl> private void logBufferUtilization ( ) { <nl> } catch ( IOException ioe ) { <nl> final MessageBox msgBox = new MessageBox ( this . shell , SWT . OK | SWT . ICON_ERROR ) ; <nl> msgBox . setText ( \" Logging failed for job \" + visualizationData . getJobID ( ) ) ; <nl> - msgBox . setText ( \" Logging of buffer utilization failed for job \" + visualizationData . getJobID ( ) <nl> + msgBox . setMessage ( \" Logging of buffer utilization failed for job \" + visualizationData . getJobID ( ) <nl> + \" : \\ r \\ n \\ r \\ n \" + ioe . getMessage ( ) ) ; <nl> } <nl> } <nl> private void viewJavaDoc ( ) { <nl> <nl> org . eclipse . swt . program . Program . launch ( JAVA_DOC_URL ) ; <nl> } <nl> + <nl> + private void cancelJob ( ) { <nl> + <nl> + if ( this . jobTree . getItemCount ( ) = = 0 ) { <nl> + final MessageBox msgBox = new MessageBox ( this . shell , SWT . OK | SWT . ICON_ERROR ) ; <nl> + msgBox . setText ( \" No job available \" ) ; <nl> + msgBox . setMessage ( \" No job to cancel . \" ) ; <nl> + msgBox . open ( ) ; <nl> + return ; <nl> + } <nl> + <nl> + final TreeItem [ ] selectedItems = this . jobTree . getSelection ( ) ; <nl> + if ( selectedItems . length = = 0 ) { <nl> + final MessageBox msgBox = new MessageBox ( this . shell , SWT . OK | SWT . ICON_INFORMATION ) ; <nl> + msgBox . setText ( \" No job selected \" ) ; <nl> + msgBox . setMessage ( \" Please select at least one job to cancel . \" ) ; <nl> + msgBox . open ( ) ; <nl> + return ; <nl> + } <nl> + <nl> + for ( int i = 0 ; i < selectedItems . length ; i + + ) { <nl> + <nl> + final TreeItem selectedItem = selectedItems [ i ] ; <nl> + final GraphVisualizationData visualizationData = ( GraphVisualizationData ) selectedItem . getData ( ) ; <nl> + if ( visualizationData = = null ) { <nl> + continue ; <nl> + } <nl> + <nl> + try { <nl> + final JobCancelResult cjr = this . jobManager . cancelJob ( visualizationData . getJobID ( ) ) ; <nl> + <nl> + if ( cjr . getReturnCode ( ) = = AbstractJobResult . ReturnCode . ERROR ) { <nl> + final MessageBox msgBox = new MessageBox ( this . shell , SWT . OK | SWT . ICON_ERROR ) ; <nl> + msgBox . setText ( \" Canceling job \" + visualizationData . getJobID ( ) + \" failed \" ) ; <nl> + msgBox . setMessage ( \" Canceling job \" + visualizationData . getJobID ( ) <nl> + + \" failed : \\ r \\ n \\ r \\ n \" + cjr . getDescription ( ) ) ; <nl> + } <nl> + <nl> + } catch ( IOException ioe ) { <nl> + final MessageBox msgBox = new MessageBox ( this . shell , SWT . OK | SWT . ICON_ERROR ) ; <nl> + msgBox . setText ( \" Canceling job \" + visualizationData . getJobID ( ) + \" failed \" ) ; <nl> + msgBox . setMessage ( \" Canceling job \" + visualizationData . getJobID ( ) <nl> + + \" failed : \\ r \\ n \\ r \\ n \" + ioe . getMessage ( ) ) ; <nl> + } <nl> + } <nl> + <nl> + final MessageBox msgBox = new MessageBox ( this . shell , SWT . OK | SWT . ICON_INFORMATION ) ; <nl> + msgBox . setText ( \" Job ( s ) succesfully canceled \" ) ; <nl> + msgBox . setMessage ( \" The selected jobs have been successfully canceled . \" ) ; <nl> + msgBox . open ( ) ; <nl> + <nl> + } <nl> } <nl>\n", "msg": "Added menu item to cancel job to visualization\n"}
{"diff_id": 24161, "repo": "elastic/elasticsearch\n", "sha": "8f91743768de7f3e9d1482c76a9cff8fe741834a\n", "time": "2018-04-16T15:51:08Z\n", "diff": "mmm a / qa / full - cluster - restart / src / test / java / org / elasticsearch / upgrades / FullClusterRestartIT . java <nl> ppp b / qa / full - cluster - restart / src / test / java / org / elasticsearch / upgrades / FullClusterRestartIT . java <nl> public void testRecovery ( ) throws IOException { <nl> shouldHaveTranslog = randomBoolean ( ) ; <nl> <nl> indexRandomDocuments ( count , true , true , i - > jsonBuilder ( ) . startObject ( ) . field ( \" field \" , \" value \" ) . endObject ( ) ) ; <nl> + <nl> + / / make sure all recoveries are done <nl> + ensureNoInitializingShards ( ) ; <nl> / / Explicitly flush so we ' re sure to have a bunch of documents in the Lucene index <nl> client ( ) . performRequest ( \" POST \" , \" / _flush \" ) ; <nl> if ( shouldHaveTranslog ) { <nl>\n", "msg": "FullClusterRestartIT . testRecovery should wait for all initializing shards\n"}
{"diff_id": 24197, "repo": "spring-projects/spring-framework\n", "sha": "676ad125a18d3729618ed9289cf2618d3797d1ce\n", "time": "2013-12-02T12:10:41Z\n", "diff": "mmm a / spring - core / src / main / java / org / springframework / util / CollectionUtils . java <nl> ppp b / spring - core / src / main / java / org / springframework / util / CollectionUtils . java <nl> <nl> / * <nl> - * Copyright 2002 - 2012 the original author or authors . <nl> + * Copyright 2002 - 2013 the original author or authors . <nl> * <nl> * Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> * you may not use this file except in compliance with the License . <nl> <nl> public abstract class CollectionUtils { <nl> <nl> / * * <nl> - * Return { @ code true } if the supplied Collection is { @ code null } <nl> - * or empty . Otherwise , return { @ code false } . <nl> + * Return { @ code true } if the supplied Collection is { @ code null } or empty . <nl> + * Otherwise , return { @ code false } . <nl> * @ param collection the Collection to check <nl> * @ return whether the given Collection is empty <nl> * / <nl> public static boolean isEmpty ( Collection < ? > collection ) { <nl> } <nl> <nl> / * * <nl> - * Return { @ code true } if the supplied Map is { @ code null } <nl> - * or empty . Otherwise , return { @ code false } . <nl> + * Return { @ code true } if the supplied Map is { @ code null } or empty . <nl> + * Otherwise , return { @ code false } . <nl> * @ param map the Map to check <nl> * @ return whether the given Map is empty <nl> * / <nl> public static boolean isEmpty ( Map < ? , ? > map ) { <nl> } <nl> <nl> / * * <nl> - * Convert the supplied array into a List . A primitive array gets <nl> - * converted into a List of the appropriate wrapper type . <nl> - * < p > A { @ code null } source value will be converted to an <nl> - * empty List . <nl> + * Convert the supplied array into a List . A primitive array gets converted <nl> + * into a List of the appropriate wrapper type . <nl> + * < p > < b > NOTE : < / b > Generally prefer the standard { @ link Arrays # asList } method . <nl> + * This { @ code arrayToList } method is just meant to deal with an incoming Object <nl> + * value that might be an { @ code Object [ ] } or a primitive array at runtime . <nl> + * < p > A { @ code null } source value will be converted to an empty List . <nl> * @ param source the ( potentially primitive ) array <nl> * @ return the converted List result <nl> * @ see ObjectUtils # toObjectArray ( Object ) <nl> + * @ see Arrays # asList ( Object [ ] ) <nl> * / <nl> - @ SuppressWarnings ( \" unchecked \" ) <nl> - public static < E > List < E > arrayToList ( Object source ) { <nl> - return ( List < E > ) Arrays . asList ( ObjectUtils . toObjectArray ( source ) ) ; <nl> + @ SuppressWarnings ( \" rawtypes \" ) <nl> + public static List arrayToList ( Object source ) { <nl> + return Arrays . asList ( ObjectUtils . toObjectArray ( source ) ) ; <nl> } <nl> <nl> / * * <nl>\n", "msg": "Reverted arrayToList signature to return plain List\n"}
{"diff_id": 24220, "repo": "oracle/graal\n", "sha": "6021a32a725db071c0e34df4802fc75e0c6b973c\n", "time": "2018-12-05T00:18:37Z\n", "diff": "mmm a / substratevm / src / com . oracle . svm . hosted / src / com / oracle / svm / hosted / analysis / Inflation . java <nl> ppp b / substratevm / src / com . oracle . svm . hosted / src / com / oracle / svm / hosted / analysis / Inflation . java <nl> <nl> import java . util . concurrent . ForkJoinPool ; <nl> import java . util . regex . Pattern ; <nl> <nl> + import org . graalvm . compiler . core . common . SuppressSVMWarnings ; <nl> import org . graalvm . compiler . graph . NodeSourcePosition ; <nl> import org . graalvm . compiler . options . OptionValues ; <nl> import org . graalvm . word . WordBase ; <nl> <nl> import jdk . vm . ci . meta . JavaConstant ; <nl> import jdk . vm . ci . meta . JavaKind ; <nl> import jdk . vm . ci . meta . ResolvedJavaType ; <nl> - import org . graalvm . compiler . core . common . SuppressSVMWarnings ; <nl> + import sun . reflect . generics . reflectiveObjects . ParameterizedTypeImpl ; <nl> <nl> public class Inflation extends BigBang { <nl> private Set < AnalysisField > handledUnknownValueFields ; <nl> private void fillGenericInfo ( AnalysisType type , DynamicHub hub ) { <nl> Type [ ] allGenericInterfaces ; <nl> try { <nl> allGenericInterfaces = javaClass . getGenericInterfaces ( ) ; <nl> - } catch ( MalformedParameterizedTypeException t ) { <nl> + } catch ( MalformedParameterizedTypeException | TypeNotPresentException t ) { <nl> / * <nl> * Loading generic interfaces can fail due to missing types . Ignore the exception and <nl> * return an empty array . <nl> private void fillGenericInfo ( AnalysisType type , DynamicHub hub ) { <nl> allGenericInterfaces = new Type [ 0 ] ; <nl> } <nl> <nl> - Type [ ] genericInterfaces = Arrays . stream ( allGenericInterfaces ) . filter ( this : : filterGenericInterfaces ) . toArray ( Type [ ] : : new ) ; <nl> + Type [ ] genericInterfaces = Arrays . stream ( allGenericInterfaces ) . filter ( this : : isTypeAllowed ) . toArray ( Type [ ] : : new ) ; <nl> Type [ ] cachedGenericInterfaces = genericInterfacesMap . computeIfAbsent ( new GenericInterfacesEncodingKey ( genericInterfaces ) , k - > genericInterfaces ) ; <nl> - Type genericSuperClass = javaClass . getGenericSuperclass ( ) ; <nl> + Type genericSuperClass ; <nl> + try { <nl> + genericSuperClass = javaClass . getGenericSuperclass ( ) ; <nl> + } catch ( MalformedParameterizedTypeException | TypeNotPresentException t ) { <nl> + / * <nl> + * Loading the generic super class can fail due to missing types . Ignore the exception <nl> + * and return null . <nl> + * / <nl> + genericSuperClass = null ; <nl> + } <nl> + if ( ! isTypeAllowed ( genericSuperClass ) ) { <nl> + genericSuperClass = null ; <nl> + } <nl> hub . setGenericInfo ( GenericInfo . factory ( typeParameters , cachedGenericInterfaces , genericSuperClass ) ) ; <nl> } <nl> <nl> private void fillAnnotatedSuperInfo ( AnalysisType type , DynamicHub hub ) { <nl> Class < ? > javaClass = type . getJavaClass ( ) ; <nl> <nl> - AnnotatedType annotatedSuperclass = javaClass . getAnnotatedSuperclass ( ) ; <nl> + AnnotatedType annotatedSuperclass ; <nl> + try { <nl> + annotatedSuperclass = javaClass . getAnnotatedSuperclass ( ) ; <nl> + } catch ( MalformedParameterizedTypeException | TypeNotPresentException t ) { <nl> + / * <nl> + * Loading the annotated super class can fail due to missing types . Ignore the exception <nl> + * and return null . <nl> + * / <nl> + annotatedSuperclass = null ; <nl> + } <nl> + if ( annotatedSuperclass ! = null & & ! isTypeAllowed ( annotatedSuperclass . getType ( ) ) ) { <nl> + annotatedSuperclass = null ; <nl> + } <nl> <nl> AnnotatedType [ ] allAnnotatedInterfaces ; <nl> try { <nl> allAnnotatedInterfaces = javaClass . getAnnotatedInterfaces ( ) ; <nl> - } catch ( MalformedParameterizedTypeException t ) { <nl> + } catch ( MalformedParameterizedTypeException | TypeNotPresentException t ) { <nl> / * <nl> * Loading annotated interfaces can fail due to missing types . Ignore the exception and <nl> * return an empty array . <nl> private void fillAnnotatedSuperInfo ( AnalysisType type , DynamicHub hub ) { <nl> } <nl> <nl> AnnotatedType [ ] annotatedInterfaces = Arrays . stream ( allAnnotatedInterfaces ) <nl> - . filter ( ai - > filterGenericInterfaces ( ai . getType ( ) ) ) . toArray ( AnnotatedType [ ] : : new ) ; <nl> + . filter ( ai - > isTypeAllowed ( ai . getType ( ) ) ) . toArray ( AnnotatedType [ ] : : new ) ; <nl> AnnotatedType [ ] cachedAnnotatedInterfaces = annotatedInterfacesMap . computeIfAbsent ( <nl> new AnnotatedInterfacesEncodingKey ( annotatedInterfaces ) , k - > annotatedInterfaces ) ; <nl> hub . setAnnotatedSuperInfo ( AnnotatedSuperInfo . factory ( annotatedSuperclass , cachedAnnotatedInterfaces ) ) ; <nl> } <nl> <nl> - private boolean filterGenericInterfaces ( Type t ) { <nl> + private boolean isTypeAllowed ( Type t ) { <nl> if ( t instanceof Class ) { <nl> Optional < ? extends ResolvedJavaType > resolved = metaAccess . optionalLookupJavaType ( ( Class < ? > ) t ) ; <nl> return resolved . isPresent ( ) & & universe . hostVM ( ) . platformSupported ( resolved . get ( ) ) ; <nl> + } else if ( t instanceof ParameterizedTypeImpl ) { <nl> + ParameterizedTypeImpl paramType = ( ParameterizedTypeImpl ) t ; <nl> + Type [ ] typeArgs = paramType . getActualTypeArguments ( ) ; <nl> + for ( Type typeArg : typeArgs ) { <nl> + if ( typeArg instanceof Class < ? > ) { <nl> + Class < ? > typeArgAsClass = ( Class < ? > ) typeArg ; <nl> + if ( NativeImageClassLoader . classIsMissing ( typeArgAsClass ) ) { <nl> + / * The type argument is a missing class . * / <nl> + return false ; <nl> + } <nl> + } <nl> + } <nl> } <nl> - <nl> return true ; <nl> } <nl> <nl>\n", "msg": "Be more defensive with missing classes referenced in generic signatures .\n"}
{"diff_id": 24283, "repo": "jenkinsci/jenkins\n", "sha": "b9658d5a558b20c7cf53cb10c719132a7f972670\n", "time": "2009-02-24T05:23:02Z\n", "diff": "mmm a / core / src / main / java / hudson / tasks / BuildStepDescriptor . java <nl> ppp b / core / src / main / java / hudson / tasks / BuildStepDescriptor . java <nl> <nl> <nl> import java . util . List ; <nl> import java . util . ArrayList ; <nl> - import java . util . Collection ; <nl> <nl> / * * <nl> * { @ link Descriptor } for { @ link Builder } and { @ link Publisher } . <nl> protected BuildStepDescriptor ( ) { <nl> <nl> / * * <nl> * Fiters a descriptor for { @ link BuildStep } s by using { @ link BuildStepDescriptor # isApplicable ( Class ) } . <nl> - * <nl> - * @ deprecated as of 1 . 286 . <nl> - * Use the { @ link Collection } version which is more general . <nl> * / <nl> public static < T extends BuildStep & Describable < T > > <nl> List < Descriptor < T > > filter ( List < Descriptor < T > > base , Class < ? extends AbstractProject > type ) { <nl> - return filter ( ( Collection < Descriptor < T > > ) base , type ) ; <nl> - } <nl> - <nl> - / * * <nl> - * Fiters a descriptor for { @ link BuildStep } s by using { @ link BuildStepDescriptor # isApplicable ( Class ) } . <nl> - * / <nl> - public static < T extends BuildStep & Describable < T > > <nl> - List < Descriptor < T > > filter ( Collection < ? extends Descriptor < T > > base , Class < ? extends AbstractProject > type ) { <nl> List < Descriptor < T > > r = new ArrayList < Descriptor < T > > ( base . size ( ) ) ; <nl> for ( Descriptor < T > d : base ) { <nl> if ( d instanceof BuildStepDescriptor ) { <nl> protected BuildStepDescriptor ( ) { <nl> } <nl> return r ; <nl> } <nl> - <nl> } <nl>\n", "msg": "now that ExtensionList is a List , this wasn ' t necessary after all . Reverting the previous change\n"}
{"diff_id": 24306, "repo": "oracle/graal\n", "sha": "ffa635c50e301c33fc92a5d00fc9af740ef851e0\n", "time": "2015-06-26T13:51:50Z\n", "diff": "mmm a / truffle / com . oracle . truffle . api / src / com / oracle / truffle / api / impl / Accessor . java <nl> ppp b / truffle / com . oracle . truffle . api / src / com / oracle / truffle / api / impl / Accessor . java <nl> protected Object invoke ( Object obj , Object [ ] args ) throws IOException { <nl> throw new IOException ( \" No symbol invoker found ! \" ) ; <nl> } <nl> <nl> + / * * <nl> + * Don ' t call me . I am here only to let NetBeans debug any Truffle project . <nl> + * <nl> + * @ param args <nl> + * / <nl> + public static void main ( String . . . args ) { <nl> + throw new IllegalStateException ( ) ; <nl> + } <nl> } <nl>\n", "msg": "Allows debugging and executing any project ' s unittest from inside of NetBeans . Added - - attach localhost : 8000 option to allow the JVM to attach to IDE ' s ( and any other ) JPDA server .\n"}
{"diff_id": 24410, "repo": "netty/netty\n", "sha": "2c390ae66b42fc7f28e3aa3b5f6eebdd1fd1cbfc\n", "time": "2016-03-18T00:08:13Z\n", "diff": "mmm a / transport - native - epoll / src / main / java / io / netty / channel / epoll / EpollChannelOption . java <nl> ppp b / transport - native - epoll / src / main / java / io / netty / channel / epoll / EpollChannelOption . java <nl> <nl> public static final ChannelOption < Boolean > IP_FREEBIND = ChannelOption . valueOf ( \" IP_FREEBIND \" ) ; <nl> public static final ChannelOption < Integer > TCP_FASTOPEN = valueOf ( T , \" TCP_FASTOPEN \" ) ; <nl> public static final ChannelOption < Integer > TCP_DEFER_ACCEPT = ChannelOption . valueOf ( T , \" TCP_DEFER_ACCEPT \" ) ; <nl> - public static final ChannelOption < Integer > TCP_QUICKACK = ChannelOption . valueOf ( T , \" TCP_QUICKACK \" ) ; <nl> + public static final ChannelOption < Boolean > TCP_QUICKACK = ChannelOption . valueOf ( T , \" TCP_QUICKACK \" ) ; <nl> <nl> public static final ChannelOption < DomainSocketReadMode > DOMAIN_SOCKET_READ_MODE = <nl> ChannelOption . valueOf ( T , \" DOMAIN_SOCKET_READ_MODE \" ) ; <nl>\n", "msg": "[ ] Fix type of EpollChannelOption . TCP_QUICKACK\n"}
{"diff_id": 24466, "repo": "netty/netty\n", "sha": "f53db96a3e3b12269f85e870820b52fb8f679ed5\n", "time": "2013-03-25T10:06:58Z\n", "diff": "mmm a / buffer / src / main / java / io / netty / buffer / package - info . java <nl> ppp b / buffer / src / main / java / io / netty / buffer / package - info . java <nl> <nl> * type . <nl> * < pre > <nl> * / / The composite type is compatible with the component type . <nl> - * ChannelBuffer message = ChannelBuffers . wrappedBuffer ( header , body ) ; <nl> + * { @ link ByteBuf } message = { @ link Unpooled } . wrappedBuffer ( header , body ) ; <nl> * <nl> * / / Therefore , you can even create a composite by mixing a composite and an <nl> * / / ordinary buffer . <nl> - * ChannelBuffer messageWithFooter = ChannelBuffers . wrappedBuffer ( message , footer ) ; <nl> + * { @ link ByteBuf } messageWithFooter = { @ link Unpooled } . wrappedBuffer ( message , footer ) ; <nl> * <nl> - * / / Because the composite is still a ChannelBuffer , you can access its content <nl> + * / / Because the composite is still a { @ link ByteBuf } , you can access its content <nl> * / / easily , and the accessor method will behave just like it ' s a single buffer <nl> * / / even if the region you want to access spans over multiple components . The <nl> * / / unsigned integer being read here is located across body and footer . <nl> <nl> * difficult and inconvenient to calculate the length precisely . It is just <nl> * like when you build a { @ link java . lang . String } . You often estimate the length <nl> * of the resulting string and let { @ link java . lang . StringBuffer } expand itself <nl> - * on demand . Netty allows you to do the same via a < em > dynamic < / em > buffer <nl> - * which is created by the <nl> - * { @ link io . netty . buffer . Unpooled # dynamicBuffer ( ) } method . <nl> + * on demand . <nl> * < pre > <nl> * / / A new dynamic buffer is created . Internally , the actual buffer is created <nl> * / / lazily to avoid potentially wasted memory space . <nl> - * ChannelBuffer b = ChannelBuffers . dynamicBuffer ( 4 ) ; <nl> + * { @ link ByteBuf } b = { @ link Unpooled } . buffer ( 4 ) ; <nl> * <nl> * / / When the first write attempt is made , the internal buffer is created with <nl> * / / the specified initial capacity ( 4 ) . <nl>\n", "msg": "[ ] Fix references to ChannelBuffer and ChannelBuffers\n"}
{"diff_id": 24507, "repo": "eugenp/tutorials\n", "sha": "5e5e742a6fdbef353a90653953ff9416fdcc37e9\n", "time": "2020-03-13T19:25:17Z\n", "diff": "mmm a / core - java - modules / core - java - concurrency - basic - 2 / src / test / java / com / baeldung / concurrent / atomic / AtomicMarkableReferenceUnitTest . java <nl> ppp b / core - java - modules / core - java - concurrency - basic - 2 / src / test / java / com / baeldung / concurrent / atomic / AtomicMarkableReferenceUnitTest . java <nl> <nl> package com . baeldung . concurrent . atomic ; <nl> <nl> - import java . util . Objects ; <nl> import java . util . concurrent . atomic . AtomicMarkableReference ; <nl> import org . junit . jupiter . api . Assertions ; <nl> import org . junit . jupiter . api . Test ; <nl> <nl> this . name = name ; <nl> } <nl> <nl> - @ Override <nl> - public boolean equals ( Object obj ) { <nl> - if ( this = = obj ) { <nl> - return true ; <nl> - } <nl> - if ( obj = = null ) { <nl> - return false ; <nl> - } <nl> - if ( ! ( obj instanceof Employee ) ) <nl> - return false ; <nl> - Employee employee = ( Employee ) obj ; <nl> - return id = = employee . id & & name . equals ( employee . name ) ; <nl> + public int getId ( ) { <nl> + return id ; <nl> } <nl> <nl> - @ Override <nl> - public int hashCode ( ) { <nl> - return Objects . hash ( id , name ) ; <nl> + public void setId ( int id ) { <nl> + this . id = id ; <nl> + } <nl> + <nl> + public String getName ( ) { <nl> + return name ; <nl> } <nl> + <nl> + public void setName ( String name ) { <nl> + this . name = name ; <nl> + } <nl> } <nl> <nl> @ Test <nl>\n", "msg": "BAEL - 3859 Remove unnecessary equals and hashcode overriden methods .\n"}
{"diff_id": 24544, "repo": "elastic/elasticsearch\n", "sha": "c41843afec56b24faae0b21ac7df0e5e2354866b\n", "time": "2015-08-31T08:42:38Z\n", "diff": "mmm a / core / src / main / java / org / elasticsearch / index / query / TermsQueryBuilder . java <nl> ppp b / core / src / main / java / org / elasticsearch / index / query / TermsQueryBuilder . java <nl> protected Query doToQuery ( QueryShardContext context ) throws IOException { <nl> if ( termsLookup . index ( ) = = null ) { <nl> termsLookup . index ( context . index ( ) . name ( ) ) ; <nl> } <nl> - terms = context . indexQueryParserService ( ) . handleTermsLookup ( termsLookup ) ; <nl> + terms = context . handleTermsLookup ( termsLookup ) ; <nl> } else { <nl> terms = values ; <nl> } <nl>\n", "msg": "Internal : call context . handleTermsLookup rather than context . indexQueryParserService ( ) . handleTermsLookup ( ) in TermsQueryBuilder # toQuery\n"}
{"diff_id": 24664, "repo": "elastic/elasticsearch\n", "sha": "83e561d19f8aa2f3733db0ed159dc3f19f4b5272\n", "time": "2012-02-01T19:17:07Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / discovery / zen / ZenDiscovery . java <nl> ppp b / src / main / java / org / elasticsearch / discovery / zen / ZenDiscovery . java <nl> <nl> import org . elasticsearch . ElasticSearchIllegalStateException ; <nl> import org . elasticsearch . cluster . * ; <nl> import org . elasticsearch . cluster . block . ClusterBlocks ; <nl> + import org . elasticsearch . cluster . metadata . IndexMetaData ; <nl> import org . elasticsearch . cluster . metadata . MetaData ; <nl> import org . elasticsearch . cluster . node . DiscoveryNode ; <nl> import org . elasticsearch . cluster . node . DiscoveryNodeService ; <nl> public ClusterState execute ( ClusterState currentState ) { <nl> / / same for metadata <nl> if ( newState . metaData ( ) . version ( ) = = currentState . metaData ( ) . version ( ) ) { <nl> builder . metaData ( currentState . metaData ( ) ) ; <nl> + } else { <nl> + / / if its not the same version , only copy over new indices or ones that changed the version <nl> + MetaData . Builder metaDataBuilder = MetaData . builder ( ) . metaData ( newState . metaData ( ) ) . removeAllIndices ( ) ; <nl> + for ( IndexMetaData indexMetaData : newState . metaData ( ) ) { <nl> + IndexMetaData currentIndexMetaData = currentState . metaData ( ) . index ( indexMetaData . index ( ) ) ; <nl> + if ( currentIndexMetaData = = null | | currentIndexMetaData . version ( ) ! = indexMetaData . version ( ) ) { <nl> + metaDataBuilder . put ( indexMetaData , false ) ; <nl> + } else { <nl> + metaDataBuilder . put ( currentIndexMetaData , false ) ; <nl> + } <nl> + } <nl> + builder . metaData ( metaDataBuilder ) ; <nl> } <nl> <nl> return builder . build ( ) ; <nl>\n", "msg": "only update new versioned index or new indices when a new cluster state is received\n"}
{"diff_id": 24716, "repo": "facebookarchive/stetho\n", "sha": "b02daa5d75ac0339914a05f007c9b91932b7c81e\n", "time": "2015-04-11T22:42:57Z\n", "diff": "mmm a / stetho / src / main / java / com / facebook / stetho / inspector / protocol / module / Database . java <nl> ppp b / stetho / src / main / java / com / facebook / stetho / inspector / protocol / module / Database . java <nl> <nl> <nl> import com . facebook . stetho . common . Util ; <nl> import com . facebook . stetho . inspector . database . DatabasePeerManager ; <nl> + import com . facebook . stetho . inspector . jsonrpc . JsonRpcException ; <nl> import com . facebook . stetho . inspector . jsonrpc . JsonRpcPeer ; <nl> import com . facebook . stetho . inspector . jsonrpc . JsonRpcResult ; <nl> + import com . facebook . stetho . inspector . jsonrpc . protocol . JsonRpcError ; <nl> import com . facebook . stetho . inspector . protocol . ChromeDevtoolsDomain ; <nl> import com . facebook . stetho . inspector . protocol . ChromeDevtoolsMethod ; <nl> import com . facebook . stetho . json . ObjectMapper ; <nl> public void disable ( JsonRpcPeer peer , JSONObject params ) { <nl> } <nl> <nl> @ ChromeDevtoolsMethod <nl> - public JsonRpcResult getDatabaseTableNames ( JsonRpcPeer peer , JSONObject params ) { <nl> + public JsonRpcResult getDatabaseTableNames ( JsonRpcPeer peer , JSONObject params ) <nl> + throws JsonRpcException { <nl> GetDatabaseTableNamesRequest request = mObjectMapper . convertValue ( params , <nl> GetDatabaseTableNamesRequest . class ) ; <nl> - GetDatabaseTableNamesResponse response = new GetDatabaseTableNamesResponse ( ) ; <nl> - response . tableNames = mDatabasePeerManager . getDatabaseTableNames ( request . databaseId ) ; <nl> - return response ; <nl> + try { <nl> + GetDatabaseTableNamesResponse response = new GetDatabaseTableNamesResponse ( ) ; <nl> + response . tableNames = mDatabasePeerManager . getDatabaseTableNames ( request . databaseId ) ; <nl> + return response ; <nl> + } catch ( SQLiteException e ) { <nl> + throw new JsonRpcException ( <nl> + new JsonRpcError ( <nl> + JsonRpcError . ErrorCode . INVALID_REQUEST , <nl> + e . toString ( ) , <nl> + null / * data * / ) ) ; <nl> + } <nl> } <nl> <nl> @ ChromeDevtoolsMethod <nl>\n", "msg": "Work around a subtle race condition in Database . getDatabaseTableNames\n"}
{"diff_id": 24769, "repo": "google/gson\n", "sha": "f418ab69a271ff60429e32f75389b2c62fe2674a\n", "time": "2009-04-03T21:24:38Z\n", "diff": "mmm a / gson / src / main / java / com / google / gson / JsonPrimitive . java <nl> ppp b / gson / src / main / java / com / google / gson / JsonPrimitive . java <nl> private static boolean isPrimitiveOrString ( Object target ) { <nl> } <nl> return false ; <nl> } <nl> + <nl> + @ Override <nl> + public int hashCode ( ) { <nl> + return ( value = = null ) ? 31 : value . hashCode ( ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public boolean equals ( Object obj ) { <nl> + if ( this = = obj ) return true ; <nl> + if ( obj = = null ) return false ; <nl> + if ( getClass ( ) ! = obj . getClass ( ) ) return false ; <nl> + JsonPrimitive other = ( JsonPrimitive ) obj ; <nl> + if ( value = = null ) { <nl> + if ( other . value ! = null ) return false ; <nl> + } else if ( ! value . equals ( other . value ) ) return false ; <nl> + return true ; <nl> + } <nl> } <nl>\n", "msg": "Implementing hashcode and equals for JsonPrimitives as value type equality .\n"}
{"diff_id": 24802, "repo": "spring-projects/spring-framework\n", "sha": "f7f2327f60f88a284d613530c4c749349f6bc479\n", "time": "2016-05-29T11:22:00Z\n", "diff": "mmm a / spring - web / src / main / java / org / springframework / http / server / ServletServerHttpRequest . java <nl> ppp b / spring - web / src / main / java / org / springframework / http / server / ServletServerHttpRequest . java <nl> <nl> <nl> import org . springframework . http . HttpHeaders ; <nl> import org . springframework . http . HttpMethod ; <nl> + import org . springframework . http . InvalidMediaTypeException ; <nl> import org . springframework . http . MediaType ; <nl> import org . springframework . util . Assert ; <nl> import org . springframework . util . LinkedCaseInsensitiveMap ; <nl> public URI getURI ( ) { <nl> public HttpHeaders getHeaders ( ) { <nl> if ( this . headers = = null ) { <nl> this . headers = new HttpHeaders ( ) ; <nl> + <nl> for ( Enumeration < ? > headerNames = this . servletRequest . getHeaderNames ( ) ; headerNames . hasMoreElements ( ) ; ) { <nl> String headerName = ( String ) headerNames . nextElement ( ) ; <nl> for ( Enumeration < ? > headerValues = this . servletRequest . getHeaders ( headerName ) ; <nl> public HttpHeaders getHeaders ( ) { <nl> this . headers . add ( headerName , headerValue ) ; <nl> } <nl> } <nl> + <nl> / / HttpServletRequest exposes some headers as properties : we should include those if not already present <nl> - MediaType contentType = this . headers . getContentType ( ) ; <nl> - if ( contentType = = null ) { <nl> - String requestContentType = this . servletRequest . getContentType ( ) ; <nl> - if ( StringUtils . hasLength ( requestContentType ) ) { <nl> - contentType = MediaType . parseMediaType ( requestContentType ) ; <nl> - this . headers . setContentType ( contentType ) ; <nl> + try { <nl> + MediaType contentType = this . headers . getContentType ( ) ; <nl> + if ( contentType = = null ) { <nl> + String requestContentType = this . servletRequest . getContentType ( ) ; <nl> + if ( StringUtils . hasLength ( requestContentType ) ) { <nl> + contentType = MediaType . parseMediaType ( requestContentType ) ; <nl> + this . headers . setContentType ( contentType ) ; <nl> + } <nl> } <nl> - } <nl> - if ( contentType ! = null & & contentType . getCharset ( ) = = null ) { <nl> - String requestEncoding = this . servletRequest . getCharacterEncoding ( ) ; <nl> - if ( StringUtils . hasLength ( requestEncoding ) ) { <nl> - Charset charSet = Charset . forName ( requestEncoding ) ; <nl> - Map < String , String > params = new LinkedCaseInsensitiveMap < String > ( ) ; <nl> - params . putAll ( contentType . getParameters ( ) ) ; <nl> - params . put ( \" charset \" , charSet . toString ( ) ) ; <nl> - MediaType newContentType = new MediaType ( contentType . getType ( ) , contentType . getSubtype ( ) , params ) ; <nl> - this . headers . setContentType ( newContentType ) ; <nl> + if ( contentType ! = null & & contentType . getCharset ( ) = = null ) { <nl> + String requestEncoding = this . servletRequest . getCharacterEncoding ( ) ; <nl> + if ( StringUtils . hasLength ( requestEncoding ) ) { <nl> + Charset charSet = Charset . forName ( requestEncoding ) ; <nl> + Map < String , String > params = new LinkedCaseInsensitiveMap < String > ( ) ; <nl> + params . putAll ( contentType . getParameters ( ) ) ; <nl> + params . put ( \" charset \" , charSet . toString ( ) ) ; <nl> + MediaType newContentType = new MediaType ( contentType . getType ( ) , contentType . getSubtype ( ) , params ) ; <nl> + this . headers . setContentType ( newContentType ) ; <nl> + } <nl> } <nl> } <nl> + catch ( InvalidMediaTypeException ex ) { <nl> + / / Ignore : simply not exposing an invalid content type in HttpHeaders . . . <nl> + } <nl> + <nl> if ( this . headers . getContentLength ( ) < 0 ) { <nl> int requestContentLength = this . servletRequest . getContentLength ( ) ; <nl> if ( requestContentLength ! = - 1 ) { <nl> public HttpHeaders getHeaders ( ) { <nl> } <nl> } <nl> } <nl> + <nl> return this . headers ; <nl> } <nl> <nl>\n", "msg": "ServletServerHttpRequest . getHeaders ( ) ignores invalid content type\n"}
{"diff_id": 24927, "repo": "jenkinsci/jenkins\n", "sha": "3ea134b6931afc75902d120f8652cdfe2efcca6a\n", "time": "2009-01-27T10:23:25Z\n", "diff": "mmm a / core / src / main / java / hudson / model / Hudson . java <nl> ppp b / core / src / main / java / hudson / model / Hudson . java <nl> public Object getTarget ( ) { <nl> | | rest . startsWith ( \" / accessDenied \" ) <nl> | | rest . startsWith ( \" / signup \" ) <nl> | | rest . startsWith ( \" / jnlpJars / \" ) <nl> + | | rest . startsWith ( \" / tcpSlaveAgentListener \" ) <nl> | | rest . startsWith ( \" / securityRealm \" ) ) <nl> return this ; / / URLs that are always visible without READ permission <nl> throw e ; <nl>\n", "msg": "Allow anonymous access to the path of slave agent listener . It must be used by only slave agents . It would NOT mean to publish JNLP files including secret key .\n"}
{"diff_id": 24934, "repo": "material-components/material-components-android\n", "sha": "a239a141398ce43f5b1f6609faea268bca95bf51\n", "time": "2018-08-28T20:31:27Z\n", "diff": "mmm a / lib / java / com / google / android / material / textfield / TextInputLayout . java <nl> ppp b / lib / java / com / google / android / material / textfield / TextInputLayout . java <nl> private void assignBoxBackgroundByMode ( ) { <nl> / / Make boxBackground a CutoutDrawable if in outline mode , there is a hint , and <nl> / / boxBackground isn ' t already a CutoutDrawable . <nl> boxBackground = new CutoutDrawable ( ) ; <nl> - } else if ( ! ( boxBackground instanceof GradientDrawable ) ) { <nl> - / / Otherwise , make boxBackground a GradientDrawable if it isn ' t already . <nl> + } else if ( boxBackground = = null ) { <nl> + / / Otherwise , make boxBackground a GradientDrawable if it hasn ' t yet been initialized . <nl> boxBackground = new GradientDrawable ( ) ; <nl> } <nl> } <nl>\n", "msg": "Use null check instead of instanceOf for boxBackground ' s GradientDrawable initialization .\n"}
{"diff_id": 24985, "repo": "eclipse-vertx/vert.x\n", "sha": "cff6158cb8dd3b6fad6751b8fbf335407eb52e34\n", "time": "2018-10-09T15:37:38Z\n", "diff": "mmm a / src / test / java / io / vertx / test / verticles / FaultToleranceVerticle . java <nl> ppp b / src / test / java / io / vertx / test / verticles / FaultToleranceVerticle . java <nl> public void start ( ) throws Exception { <nl> JsonObject config = config ( ) ; <nl> id = config . getInteger ( \" id \" ) ; <nl> numAddresses = config . getInteger ( \" addressesCount \" ) ; <nl> - <nl> List < Future > registrationFutures = new ArrayList < > ( numAddresses ) ; <nl> for ( int i = 0 ; i < numAddresses ; i + + ) { <nl> Future < Void > registrationFuture = Future . future ( ) ; <nl> registrationFutures . add ( registrationFuture ) ; <nl> vertx . eventBus ( ) . consumer ( createAddress ( id , i ) , msg - > msg . reply ( \" pong \" ) ) . completionHandler ( registrationFuture . completer ( ) ) ; <nl> } <nl> - <nl> Future < Void > registrationFuture = Future . future ( ) ; <nl> registrationFutures . add ( registrationFuture ) ; <nl> vertx . eventBus ( ) . consumer ( \" ping \" , this : : ping ) . completionHandler ( registrationFuture . completer ( ) ) ; <nl> - <nl> CompositeFuture . all ( registrationFutures ) . setHandler ( ar - > { <nl> if ( ar . succeeded ( ) ) { <nl> - vertx . eventBus ( ) . send ( \" control \" , \" start \" , control - > { <nl> - if ( control . failed ( ) ) { <nl> - log . error ( \" Failed to send ' start ' message \" , control . cause ( ) ) ; <nl> - } <nl> - } ) ; <nl> + vertx . eventBus ( ) . send ( \" control \" , \" start \" ) ; <nl> } <nl> } ) ; <nl> } <nl> private void ping ( Message < JsonArray > message ) { <nl> for ( int i = 0 ; i < jsonArray . size ( ) ; i + + ) { <nl> int node = jsonArray . getInteger ( i ) ; <nl> for ( int j = 0 ; j < numAddresses ; j + + ) { <nl> - String address = createAddress ( node , j ) ; <nl> - vertx . eventBus ( ) . send ( address , \" ping \" , ar - > { <nl> + vertx . eventBus ( ) . send ( createAddress ( node , j ) , \" ping \" , ar - > { <nl> if ( ar . succeeded ( ) ) { <nl> - vertx . eventBus ( ) . send ( \" control \" , \" pong \" , control - > { <nl> - if ( control . failed ( ) ) { <nl> - log . error ( \" Failed to send ' pong ' message for : \" + address , control . cause ( ) ) ; <nl> - } <nl> - } ) ; <nl> + vertx . eventBus ( ) . send ( \" control \" , \" pong \" ) ; <nl> } else { <nl> Throwable cause = ar . cause ( ) ; <nl> if ( cause instanceof ReplyException ) { <nl> ReplyException replyException = ( ReplyException ) cause ; <nl> if ( replyException . failureType ( ) = = ReplyFailure . NO_HANDLERS ) { <nl> - vertx . eventBus ( ) . send ( \" control \" , \" noHandlers \" , control - > { <nl> - if ( control . failed ( ) ) { <nl> - log . error ( \" Failed to send ' noHandlers ' message \" , control . cause ( ) ) ; <nl> - } <nl> - } ) ; <nl> + vertx . eventBus ( ) . send ( \" control \" , \" noHandlers \" ) ; <nl> return ; <nl> } <nl> } <nl>\n", "msg": "Revert \" Added some logging to FaultToleranceVerticle to debug FaultToleranceTest issues \"\n"}
{"diff_id": 24992, "repo": "alibaba/Sentinel\n", "sha": "6765130f1bcd72c8bed0c4a9d55c59ca03c596fe\n", "time": "2018-11-15T09:09:23Z\n", "diff": "mmm a / sentinel - core / src / main / java / com / alibaba / csp / sentinel / init / InitExecutor . java <nl> ppp b / sentinel - core / src / main / java / com / alibaba / csp / sentinel / init / InitExecutor . java <nl> public static void doInit ( ) { <nl> ServiceLoader < InitFunc > loader = ServiceLoader . load ( InitFunc . class ) ; <nl> List < OrderWrapper > initList = new ArrayList < OrderWrapper > ( ) ; <nl> for ( InitFunc initFunc : loader ) { <nl> - RecordLog . info ( \" [ Sentinel InitExecutor ] Found init func : \" + initFunc . getClass ( ) . getCanonicalName ( ) ) ; <nl> + RecordLog . info ( \" [ InitExecutor ] Found init func : \" + initFunc . getClass ( ) . getCanonicalName ( ) ) ; <nl> insertSorted ( initList , initFunc ) ; <nl> } <nl> for ( OrderWrapper w : initList ) { <nl> w . func . init ( ) ; <nl> - RecordLog . info ( String . format ( \" [ Sentinel InitExecutor ] Initialized : % s with order % d \" , <nl> + RecordLog . info ( String . format ( \" [ InitExecutor ] Initialized : % s with order % d \" , <nl> w . func . getClass ( ) . getCanonicalName ( ) , w . order ) ) ; <nl> } <nl> } catch ( Exception ex ) { <nl> - RecordLog . info ( \" [ Sentinel InitExecutor ] Init failed \" , ex ) ; <nl> + RecordLog . warn ( \" [ InitExecutor ] Init failed \" , ex ) ; <nl> ex . printStackTrace ( ) ; <nl> + } catch ( Error error ) { <nl> + RecordLog . warn ( \" [ InitExecutor ] Init failed with fatal error \" , error ) ; <nl> + error . printStackTrace ( ) ; <nl> + throw error ; <nl> } <nl> } <nl> <nl>\n", "msg": "Add log for fatal error when InitExecutor failed\n"}
{"diff_id": 25009, "repo": "oracle/graal\n", "sha": "f1b5b8acb28506ca7d037dbfcac7733212269207\n", "time": "2018-11-14T14:52:03Z\n", "diff": "mmm a / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / OptimizedCallTarget . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / OptimizedCallTarget . java <nl> private boolean maybeSetNeedsSplit ( int depth , List < Node > toDump ) { <nl> if ( TruffleRuntimeOptions . getValue ( SharedTruffleRuntimeOptions . TruffleExperimentalSplittingDumpDecisions ) ) { <nl> pullOutParentChain ( onlyCaller , toDump ) ; <nl> } <nl> - needsSplit | = callerTarget . maybeSetNeedsSplit ( depth + 1 , toDump ) ; <nl> + if ( callerTarget . maybeSetNeedsSplit ( depth + 1 , toDump ) ) { <nl> + needsSplit = true ; <nl> + } <nl> } <nl> } <nl> } else { <nl>\n", "msg": "More thread - safe assignment for needs split .\n"}
{"diff_id": 25187, "repo": "google/guava\n", "sha": "3f24df5f4ff41d0b70fdc8845bd4c4cadca896e2\n", "time": "2016-07-09T03:41:26Z\n", "diff": "mmm a / guava - tests / test / com / google / common / util / concurrent / UncaughtExceptionHandlersTest . java <nl> ppp b / guava - tests / test / com / google / common / util / concurrent / UncaughtExceptionHandlersTest . java <nl> <nl> <nl> package com . google . common . util . concurrent ; <nl> <nl> - import static org . easymock . EasyMock . createMock ; <nl> - import static org . easymock . EasyMock . replay ; <nl> - import static org . easymock . EasyMock . verify ; <nl> + import static org . mockito . Mockito . mock ; <nl> + import static org . mockito . Mockito . verify ; <nl> <nl> import com . google . common . util . concurrent . UncaughtExceptionHandlers . Exiter ; <nl> <nl> <nl> private Runtime runtimeMock ; <nl> <nl> @ Override protected void setUp ( ) { <nl> - runtimeMock = createMock ( Runtime . class ) ; <nl> + runtimeMock = mock ( Runtime . class ) ; <nl> } <nl> <nl> public void testExiter ( ) { <nl> - runtimeMock . exit ( 1 ) ; <nl> - replay ( runtimeMock ) ; <nl> new Exiter ( runtimeMock ) . uncaughtException ( new Thread ( ) , new Exception ( ) ) ; <nl> - verify ( runtimeMock ) ; <nl> + verify ( runtimeMock ) . exit ( 1 ) ; <nl> } <nl> } <nl>\n", "msg": "Migrate from easymock to mockito in javatests / com / google / common / util / concurrent\n"}
{"diff_id": 25191, "repo": "google/ExoPlayer\n", "sha": "1cfb68bf68dbc52f8841c5540007bed42699c87c\n", "time": "2020-05-29T17:34:10Z\n", "diff": "mmm a / library / extractor / src / main / java / com / google / android / exoplayer2 / extractor / rawcc / RawCcExtractor . java <nl> ppp b / library / extractor / src / main / java / com / google / android / exoplayer2 / extractor / rawcc / RawCcExtractor . java <nl> public RawCcExtractor ( Format format ) { <nl> public void init ( ExtractorOutput output ) { <nl> output . seekMap ( new SeekMap . Unseekable ( C . TIME_UNSET ) ) ; <nl> trackOutput = output . track ( 0 , C . TRACK_TYPE_TEXT ) ; <nl> - output . endTracks ( ) ; <nl> trackOutput . format ( format ) ; <nl> + output . endTracks ( ) ; <nl> } <nl> <nl> @ Override <nl>\n", "msg": "Change order of RawCcExtractor init to call format before endTracks .\n"}
{"diff_id": 25233, "repo": "elastic/elasticsearch\n", "sha": "a84777e9904a1f432691869a30c50c431d903dbe\n", "time": "2014-07-11T08:22:11Z\n", "diff": "mmm a / src / test / java / org / elasticsearch / index / store / CorruptedFileTest . java <nl> ppp b / src / test / java / org / elasticsearch / index / store / CorruptedFileTest . java <nl> <nl> import com . google . common . base . Predicate ; <nl> import org . apache . lucene . codecs . CodecUtil ; <nl> import org . apache . lucene . index . CheckIndex ; <nl> + import org . apache . lucene . index . IndexFileNames ; <nl> import org . apache . lucene . index . MergePolicy ; <nl> import org . apache . lucene . index . NoMergePolicy ; <nl> import org . apache . lucene . store . * ; <nl> <nl> import org . junit . Test ; <nl> <nl> import java . io . * ; <nl> - import java . util . ArrayList ; <nl> - import java . util . Arrays ; <nl> - import java . util . Collections ; <nl> - import java . util . List ; <nl> + import java . util . * ; <nl> import java . util . concurrent . CopyOnWriteArrayList ; <nl> import java . util . concurrent . CountDownLatch ; <nl> import java . util . concurrent . ExecutionException ; <nl> private ShardRouting corruptRandomFile ( ) throws IOException { <nl> assertTrue ( shardRouting . assignedToNode ( ) ) ; <nl> String nodeId = shardRouting . currentNodeId ( ) ; <nl> NodesStatsResponse nodeStatses = client ( ) . admin ( ) . cluster ( ) . prepareNodesStats ( nodeId ) . setFs ( true ) . get ( ) ; <nl> - File fileToCorrupt = null ; <nl> + Set < File > files = new TreeSet < > ( ) ; / / treeset makes sure iteration order is deterministic <nl> for ( FsStats . Info info : nodeStatses . getNodes ( ) [ 0 ] . getFs ( ) ) { <nl> String path = info . getPath ( ) ; <nl> final String relativeDataLocationPath = \" indices / test / \" + Integer . toString ( shardRouting . getId ( ) ) + \" / index \" ; <nl> File file = new File ( path , relativeDataLocationPath ) ; <nl> - final File [ ] files = file . listFiles ( new FileFilter ( ) { <nl> + files . addAll ( Arrays . asList ( file . listFiles ( new FileFilter ( ) { <nl> @ Override <nl> public boolean accept ( File pathname ) { <nl> - return pathname . isFile ( ) & & ! \" write . lock \" . equals ( pathname . getName ( ) ) <nl> - & & ! pathname . getName ( ) . endsWith ( \" . del \" ) ; / / temporary fix - del files might be generational and we corrupt an old generation <nl> - / / TODO ( simonw ) : fix this method to select the oldest del gen if we pick a del file <nl> + return pathname . isFile ( ) & & ! \" write . lock \" . equals ( pathname . getName ( ) ) ; <nl> } <nl> - } ) ; <nl> - if ( files . length > 1 ) { <nl> - fileToCorrupt = RandomPicks . randomFrom ( getRandom ( ) , files ) ; <nl> - try ( Directory dir = FSDirectory . open ( file ) ) { <nl> - long checksumBeforeCorruption ; <nl> - try ( IndexInput input = dir . openInput ( fileToCorrupt . getName ( ) , IOContext . DEFAULT ) ) { <nl> - checksumBeforeCorruption = CodecUtil . retrieveChecksum ( input ) ; <nl> - } <nl> - try ( RandomAccessFile raf = new RandomAccessFile ( fileToCorrupt , \" rw \" ) ) { <nl> - raf . seek ( randomIntBetween ( 0 , ( int ) Math . min ( Integer . MAX_VALUE , raf . length ( ) - 1 ) ) ) ; <nl> - long filePointer = raf . getFilePointer ( ) ; <nl> - byte b = raf . readByte ( ) ; <nl> - raf . seek ( filePointer ) ; <nl> - raf . writeByte ( ~ b ) ; <nl> - raf . getFD ( ) . sync ( ) ; <nl> - logger . info ( \" Corrupting file for shard { } - - flipping at position { } from { } to { } file : { } \" , shardRouting , filePointer , Integer . toHexString ( b ) , Integer . toHexString ( ~ b ) , fileToCorrupt . getName ( ) ) ; <nl> - } <nl> - long checksumAfterCorruption ; <nl> - long actualChecksumAfterCorruption ; <nl> - try ( ChecksumIndexInput input = dir . openChecksumInput ( fileToCorrupt . getName ( ) , IOContext . DEFAULT ) ) { <nl> - assertThat ( input . getFilePointer ( ) , is ( 0l ) ) ; <nl> - input . seek ( input . length ( ) - 8 ) ; / / one long is the checksum . . . 8 bytes <nl> - checksumAfterCorruption = input . getChecksum ( ) ; <nl> - actualChecksumAfterCorruption = input . readLong ( ) ; <nl> - } <nl> - / / we need to add assumptions here that the checksums actually really don ' t match there is a small chance to get collisions <nl> - / / in the checksum which is ok though . . . . <nl> - StringBuilder msg = new StringBuilder ( ) ; <nl> - msg . append ( \" Checksum before : [ \" ) . append ( checksumBeforeCorruption ) . append ( \" ] \" ) ; <nl> - msg . append ( \" after : [ \" ) . append ( checksumAfterCorruption ) . append ( \" ] \" ) ; <nl> - msg . append ( \" checksum value after corruption : \" ) . append ( actualChecksumAfterCorruption ) . append ( \" ] \" ) ; <nl> - msg . append ( \" file : \" ) . append ( fileToCorrupt . getName ( ) ) . append ( \" length : \" ) . append ( dir . fileLength ( fileToCorrupt . getName ( ) ) ) ; <nl> - logger . info ( msg . toString ( ) ) ; <nl> - assumeTrue ( \" Checksum collision - \" + msg . toString ( ) , <nl> - checksumAfterCorruption ! = checksumBeforeCorruption / / collision <nl> - | | actualChecksumAfterCorruption ! = checksumBeforeCorruption ) ; / / checksum corrupted <nl> + } ) ) ) ; <nl> + } <nl> + pruneOldDeleteGenerations ( files ) ; <nl> + File fileToCorrupt = null ; <nl> + if ( ! files . isEmpty ( ) ) { <nl> + fileToCorrupt = RandomPicks . randomFrom ( getRandom ( ) , files ) ; <nl> + try ( Directory dir = FSDirectory . open ( fileToCorrupt . getParentFile ( ) ) ) { <nl> + long checksumBeforeCorruption ; <nl> + try ( IndexInput input = dir . openInput ( fileToCorrupt . getName ( ) , IOContext . DEFAULT ) ) { <nl> + checksumBeforeCorruption = CodecUtil . retrieveChecksum ( input ) ; <nl> } <nl> - break ; <nl> + try ( RandomAccessFile raf = new RandomAccessFile ( fileToCorrupt , \" rw \" ) ) { <nl> + raf . seek ( randomIntBetween ( 0 , ( int ) Math . min ( Integer . MAX_VALUE , raf . length ( ) - 1 ) ) ) ; <nl> + long filePointer = raf . getFilePointer ( ) ; <nl> + byte b = raf . readByte ( ) ; <nl> + raf . seek ( filePointer ) ; <nl> + raf . writeByte ( ~ b ) ; <nl> + raf . getFD ( ) . sync ( ) ; <nl> + logger . info ( \" Corrupting file for shard { } - - flipping at position { } from { } to { } file : { } \" , shardRouting , filePointer , Integer . toHexString ( b ) , Integer . toHexString ( ~ b ) , fileToCorrupt . getName ( ) ) ; <nl> + } <nl> + long checksumAfterCorruption ; <nl> + long actualChecksumAfterCorruption ; <nl> + try ( ChecksumIndexInput input = dir . openChecksumInput ( fileToCorrupt . getName ( ) , IOContext . DEFAULT ) ) { <nl> + assertThat ( input . getFilePointer ( ) , is ( 0l ) ) ; <nl> + input . seek ( input . length ( ) - 8 ) ; / / one long is the checksum . . . 8 bytes <nl> + checksumAfterCorruption = input . getChecksum ( ) ; <nl> + actualChecksumAfterCorruption = input . readLong ( ) ; <nl> + } <nl> + / / we need to add assumptions here that the checksums actually really don ' t match there is a small chance to get collisions <nl> + / / in the checksum which is ok though . . . . <nl> + StringBuilder msg = new StringBuilder ( ) ; <nl> + msg . append ( \" Checksum before : [ \" ) . append ( checksumBeforeCorruption ) . append ( \" ] \" ) ; <nl> + msg . append ( \" after : [ \" ) . append ( checksumAfterCorruption ) . append ( \" ] \" ) ; <nl> + msg . append ( \" checksum value after corruption : \" ) . append ( actualChecksumAfterCorruption ) . append ( \" ] \" ) ; <nl> + msg . append ( \" file : \" ) . append ( fileToCorrupt . getName ( ) ) . append ( \" length : \" ) . append ( dir . fileLength ( fileToCorrupt . getName ( ) ) ) ; <nl> + logger . info ( msg . toString ( ) ) ; <nl> + assumeTrue ( \" Checksum collision - \" + msg . toString ( ) , <nl> + checksumAfterCorruption ! = checksumBeforeCorruption / / collision <nl> + | | actualChecksumAfterCorruption ! = checksumBeforeCorruption ) ; / / checksum corrupted <nl> } <nl> } <nl> assertThat ( \" no file corrupted \" , fileToCorrupt , notNullValue ( ) ) ; <nl> return shardRouting ; <nl> } <nl> <nl> + / * * <nl> + * prunes the list of index files such that only the latest del generation files are contained . <nl> + * / <nl> + private void pruneOldDeleteGenerations ( Set < File > files ) { <nl> + final TreeSet < File > delFiles = new TreeSet < > ( ) ; <nl> + for ( File file : files ) { <nl> + if ( file . getName ( ) . endsWith ( \" . del \" ) ) { <nl> + delFiles . add ( file ) ; <nl> + } <nl> + } <nl> + File last = null ; <nl> + for ( File current : delFiles ) { <nl> + if ( last ! = null ) { <nl> + final String newSegmentName = IndexFileNames . parseSegmentName ( current . getName ( ) ) ; <nl> + final String oldSegmentName = IndexFileNames . parseSegmentName ( last . getName ( ) ) ; <nl> + if ( newSegmentName . equals ( oldSegmentName ) ) { <nl> + int oldGen = Integer . parseInt ( IndexFileNames . stripExtension ( IndexFileNames . stripSegmentName ( last . getName ( ) ) ) . replace ( \" _ \" , \" \" ) , Character . MAX_RADIX ) ; <nl> + int newGen = Integer . parseInt ( IndexFileNames . stripExtension ( IndexFileNames . stripSegmentName ( current . getName ( ) ) ) . replace ( \" _ \" , \" \" ) , Character . MAX_RADIX ) ; <nl> + if ( newGen > oldGen ) { <nl> + files . remove ( last ) ; <nl> + } else { <nl> + files . remove ( current ) ; <nl> + continue ; <nl> + } <nl> + } <nl> + } <nl> + last = current ; <nl> + } <nl> + } <nl> + <nl> public List < File > listShardFiles ( ShardRouting routing ) { <nl> NodesStatsResponse nodeStatses = client ( ) . admin ( ) . cluster ( ) . prepareNodesStats ( routing . currentNodeId ( ) ) . setFs ( true ) . get ( ) ; <nl> <nl>\n", "msg": "[ TEST ] Fix CorruptedFileTest to always corrupt the latest delete generation if a . del file is picked\n"}
{"diff_id": 25268, "repo": "signalapp/Signal-Android\n", "sha": "2db2b068c4733b4f6f402336d9f0b792847142e4\n", "time": "2020-07-19T13:32:16Z\n", "diff": "mmm a / app / src / main / java / org / thoughtcrime / securesms / jobs / PushProcessMessageJob . java <nl> ppp b / app / src / main / java / org / thoughtcrime / securesms / jobs / PushProcessMessageJob . java <nl> private boolean shouldIgnore ( @ Nullable SignalServiceContent content ) <nl> return sender . isBlocked ( ) ; <nl> } else if ( content . getTypingMessage ( ) . isPresent ( ) ) { <nl> if ( content . getTypingMessage ( ) . get ( ) . getGroupId ( ) . isPresent ( ) ) { <nl> - GroupId groupId = GroupId . push ( content . getTypingMessage ( ) . get ( ) . getGroupId ( ) . get ( ) ) ; <nl> - return Recipient . externalGroup ( context , groupId ) . isBlocked ( ) ; <nl> + GroupId groupId = GroupId . push ( content . getTypingMessage ( ) . get ( ) . getGroupId ( ) . get ( ) ) ; <nl> + Recipient groupRecipient = Recipient . externalGroup ( context , groupId ) ; <nl> + return groupRecipient . isBlocked ( ) | | ! groupRecipient . isActiveGroup ( ) ; <nl> } else { <nl> return sender . isBlocked ( ) ; <nl> } <nl>\n", "msg": "Do not show typing indicators for inactive groups .\n"}
{"diff_id": 25474, "repo": "oracle/graal\n", "sha": "7ecf72d627db3a82970ccf0354432889cf98bb9c\n", "time": "2020-08-26T18:21:35Z\n", "diff": "mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / nodes / BytecodeNode . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / nodes / BytecodeNode . java <nl> Object executeBody ( VirtualFrame frame ) { <nl> case ALOAD_2 : / / fall through <nl> case ALOAD_3 : putObject ( frame , top , getLocalObject ( frame , curOpcode - ALOAD_0 ) ) ; break ; <nl> <nl> - / / TODO : check if the offsets in the node are correct ( seems correct becasue nothing changes from long / double instruction to int etc ) <nl> case IALOAD : <nl> if ( noForeignObjects . isValid ( ) ) { <nl> putInt ( frame , top - 2 , getInterpreterToVM ( ) . getArrayInt ( peekInt ( frame , top - 1 ) , nullCheck ( peekAndReleaseObject ( frame , top - 2 ) ) ) ) ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 2 ) ; <nl> putInt ( frame , top - 2 , getInterpreterToVM ( ) . getArrayInt ( peekInt ( frame , top - 1 ) , array ) ) ; <nl> } else { <nl> - quickenIntArrayLoad ( frame , top , curBCI ) ; <nl> + quickenArrayLoad ( frame , top , curBCI , JavaKind . Int ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 2 ) ; <nl> putLong ( frame , top - 2 , getInterpreterToVM ( ) . getArrayLong ( peekInt ( frame , top - 1 ) , array ) ) ; <nl> } else { <nl> - quickenLongArrayLoad ( frame , top , curBCI ) ; <nl> + quickenArrayLoad ( frame , top , curBCI , JavaKind . Long ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 2 ) ; <nl> putFloat ( frame , top - 2 , getInterpreterToVM ( ) . getArrayFloat ( peekInt ( frame , top - 1 ) , array ) ) ; <nl> } else { <nl> - quickenFloatArrayLoad ( frame , top , curBCI ) ; <nl> + quickenArrayLoad ( frame , top , curBCI , JavaKind . Float ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 2 ) ; <nl> putDouble ( frame , top - 2 , getInterpreterToVM ( ) . getArrayDouble ( peekInt ( frame , top - 1 ) , array ) ) ; <nl> } else { <nl> - quickenDoubleArrayLoad ( frame , top , curBCI ) ; <nl> + quickenArrayLoad ( frame , top , curBCI , JavaKind . Double ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 2 ) ; <nl> putObject ( frame , top - 2 , getInterpreterToVM ( ) . getArrayObject ( peekInt ( frame , top - 1 ) , array ) ) ; <nl> } else { <nl> - quickenReferenceArrayLoad ( frame , top , curBCI ) ; <nl> + quickenArrayLoad ( frame , top , curBCI , JavaKind . Object ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 2 ) ; <nl> putInt ( frame , top - 2 , getInterpreterToVM ( ) . getArrayByte ( peekInt ( frame , top - 1 ) , array ) ) ; <nl> } else { <nl> - quickenByteArrayLoad ( frame , top , curBCI ) ; <nl> + quickenArrayLoad ( frame , top , curBCI , JavaKind . Byte ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 2 ) ; <nl> putInt ( frame , top - 2 , getInterpreterToVM ( ) . getArrayChar ( peekInt ( frame , top - 1 ) , array ) ) ; <nl> } else { <nl> - quickenCharArrayLoad ( frame , top , curBCI ) ; <nl> + quickenArrayLoad ( frame , top , curBCI , JavaKind . Char ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 2 ) ; <nl> putInt ( frame , top - 2 , getInterpreterToVM ( ) . getArrayShort ( peekInt ( frame , top - 1 ) , array ) ) ; <nl> } else { <nl> - quickenShortArrayLoad ( frame , top , curBCI ) ; <nl> + quickenArrayLoad ( frame , top , curBCI , JavaKind . Short ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 3 ) ; <nl> getInterpreterToVM ( ) . setArrayInt ( peekInt ( frame , top - 1 ) , peekInt ( frame , top - 2 ) , array ) ; <nl> } else { <nl> - quickenIntArrayStore ( frame , top , curBCI ) ; <nl> + quickenArrayStore ( frame , top , curBCI , JavaKind . Int ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 4 ) ; <nl> getInterpreterToVM ( ) . setArrayLong ( peekLong ( frame , top - 1 ) , peekInt ( frame , top - 3 ) , array ) ; <nl> } else { <nl> - quickenLongArrayStore ( frame , top , curBCI ) ; <nl> + quickenArrayStore ( frame , top , curBCI , JavaKind . Long ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 3 ) ; <nl> getInterpreterToVM ( ) . setArrayFloat ( peekFloat ( frame , top - 1 ) , peekInt ( frame , top - 2 ) , array ) ; <nl> } else { <nl> - quickenFloatArrayStore ( frame , top , curBCI ) ; <nl> + quickenArrayStore ( frame , top , curBCI , JavaKind . Float ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 4 ) ; <nl> getInterpreterToVM ( ) . setArrayDouble ( peekDouble ( frame , top - 1 ) , peekInt ( frame , top - 3 ) , array ) ; <nl> } else { <nl> - quickenDoubleArrayStore ( frame , top , curBCI ) ; <nl> + quickenArrayStore ( frame , top , curBCI , JavaKind . Double ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 3 ) ; <nl> getInterpreterToVM ( ) . setArrayObject ( peekObject ( frame , top - 1 ) , peekInt ( frame , top - 2 ) , array ) ; <nl> } else { <nl> - quickenReferenceArrayStore ( frame , top , curBCI ) ; <nl> + quickenArrayStore ( frame , top , curBCI , JavaKind . Object ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 3 ) ; <nl> getInterpreterToVM ( ) . setArrayByte ( ( byte ) peekInt ( frame , top - 1 ) , peekInt ( frame , top - 2 ) , array ) ; <nl> } else { <nl> - quickenByteArrayStore ( frame , top , curBCI ) ; <nl> + quickenArrayStore ( frame , top , curBCI , JavaKind . Byte ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 3 ) ; <nl> getInterpreterToVM ( ) . setArrayChar ( ( char ) peekInt ( frame , top - 1 ) , peekInt ( frame , top - 2 ) , array ) ; <nl> } else { <nl> - quickenCharArrayStore ( frame , top , curBCI ) ; <nl> + quickenArrayStore ( frame , top , curBCI , JavaKind . Char ) ; <nl> } <nl> } <nl> break ; <nl> Object executeBody ( VirtualFrame frame ) { <nl> releaseObject ( frame , top - 3 ) ; <nl> getInterpreterToVM ( ) . setArrayShort ( ( short ) peekInt ( frame , top - 1 ) , peekInt ( frame , top - 2 ) , array ) ; <nl> } else { <nl> - quickenShortArrayStore ( frame , top , curBCI ) ; <nl> + quickenArrayStore ( frame , top , curBCI , JavaKind . Short ) ; <nl> } <nl> } <nl> break ; <nl> public int reQuickenInvoke ( final VirtualFrame frame , int top , int curBCI , int op <nl> } <nl> <nl> / / region quickenForeign <nl> + <nl> public int quickenGetField ( final VirtualFrame frame , int top , int curBCI , int opcode , int statementIndex , Field field ) { <nl> CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> assert opcode = = GETFIELD ; <nl> private void quickenArrayLength ( final VirtualFrame frame , int top , int curBCI ) { <nl> arrayLengthNode . execute ( frame ) ; <nl> } <nl> <nl> - private void quickenByteArrayLoad ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode byteArrayLoadNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - byteArrayLoadNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - byteArrayLoadNode = injectQuick ( curBCI , ByteArrayLoadNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - byteArrayLoadNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenCharArrayLoad ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode charArrayLoadNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - charArrayLoadNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - charArrayLoadNode = injectQuick ( curBCI , CharArrayLoadNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - charArrayLoadNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenShortArrayLoad ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode shortArrayLoadNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - shortArrayLoadNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - shortArrayLoadNode = injectQuick ( curBCI , ShortArrayLoadNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - shortArrayLoadNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenIntArrayLoad ( final VirtualFrame frame , int top , int curBCI ) { <nl> + private void quickenArrayLoad ( final VirtualFrame frame , int top , int curBCI , JavaKind componentKind ) { <nl> CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode intArrayLoadNode ; <nl> + QuickNode arrayLoadNode ; <nl> synchronized ( this ) { <nl> if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - intArrayLoadNode = sparseNodes [ curBCI ] ; <nl> + arrayLoadNode = sparseNodes [ curBCI ] ; <nl> } else { <nl> - intArrayLoadNode = injectQuick ( curBCI , IntArrayLoadNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - intArrayLoadNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenLongArrayLoad ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode longArrayLoadNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - longArrayLoadNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - longArrayLoadNode = injectQuick ( curBCI , LongArrayLoadNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - longArrayLoadNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenFloatArrayLoad ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode floatArrayLoadNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - floatArrayLoadNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - floatArrayLoadNode = injectQuick ( curBCI , FloatArrayLoadNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - floatArrayLoadNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenDoubleArrayLoad ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode doubleArrayLoadNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - doubleArrayLoadNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - doubleArrayLoadNode = injectQuick ( curBCI , DoubleArrayLoadNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - doubleArrayLoadNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenReferenceArrayLoad ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode referenceArrayLoadNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - referenceArrayLoadNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - referenceArrayLoadNode = injectQuick ( curBCI , ReferenceArrayLoadNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - referenceArrayLoadNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenByteArrayStore ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode byteArrayStoreNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - byteArrayStoreNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - byteArrayStoreNode = injectQuick ( curBCI , ByteArrayStoreNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - byteArrayStoreNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenCharArrayStore ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode charArrayStoreNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - charArrayStoreNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - charArrayStoreNode = injectQuick ( curBCI , CharArrayStoreNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - charArrayStoreNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenShortArrayStore ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode shortArrayStoreNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - shortArrayStoreNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - shortArrayStoreNode = injectQuick ( curBCI , ShortArrayStoreNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - shortArrayStoreNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenIntArrayStore ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode intArrayStoreNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - intArrayStoreNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - intArrayStoreNode = injectQuick ( curBCI , IntArrayStoreNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - intArrayStoreNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenLongArrayStore ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode longArrayStoreNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - longArrayStoreNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - longArrayStoreNode = injectQuick ( curBCI , LongArrayStoreNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - longArrayStoreNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenFloatArrayStore ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode floatArrayStoreNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - floatArrayStoreNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - floatArrayStoreNode = injectQuick ( curBCI , FloatArrayStoreNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> - } <nl> - } <nl> - floatArrayStoreNode . execute ( frame ) ; <nl> - } <nl> - <nl> - private void quickenDoubleArrayStore ( final VirtualFrame frame , int top , int curBCI ) { <nl> - CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode doubleArrayStoreNode ; <nl> - synchronized ( this ) { <nl> - if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - doubleArrayStoreNode = sparseNodes [ curBCI ] ; <nl> - } else { <nl> - doubleArrayStoreNode = injectQuick ( curBCI , DoubleArrayStoreNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> + / / @ formatter : off <nl> + switch ( componentKind ) { <nl> + case Boolean : / / fall - through <nl> + case Byte : <nl> + arrayLoadNode = ByteArrayLoadNodeGen . create ( top , curBCI ) ; <nl> + break ; <nl> + case Short : arrayLoadNode = ShortArrayLoadNodeGen . create ( top , curBCI ) ; break ; <nl> + case Char : arrayLoadNode = CharArrayLoadNodeGen . create ( top , curBCI ) ; break ; <nl> + case Int : arrayLoadNode = IntArrayLoadNodeGen . create ( top , curBCI ) ; break ; <nl> + case Float : arrayLoadNode = FloatArrayLoadNodeGen . create ( top , curBCI ) ; break ; <nl> + case Long : arrayLoadNode = LongArrayLoadNodeGen . create ( top , curBCI ) ; break ; <nl> + case Double : arrayLoadNode = DoubleArrayLoadNodeGen . create ( top , curBCI ) ; break ; <nl> + case Object : arrayLoadNode = ReferenceArrayLoadNodeGen . create ( top , curBCI ) ; break ; <nl> + default : <nl> + CompilerDirectives . transferToInterpreter ( ) ; <nl> + throw EspressoError . shouldNotReachHere ( \" unexpected kind \" ) ; <nl> + } <nl> + / / @ formatter : on <nl> + arrayLoadNode = injectQuick ( curBCI , arrayLoadNode , SLIM_QUICK ) ; <nl> } <nl> } <nl> - doubleArrayStoreNode . execute ( frame ) ; <nl> + arrayLoadNode . execute ( frame ) ; <nl> } <nl> <nl> - private void quickenReferenceArrayStore ( final VirtualFrame frame , int top , int curBCI ) { <nl> + private void quickenArrayStore ( final VirtualFrame frame , int top , int curBCI , JavaKind componentKind ) { <nl> CompilerDirectives . transferToInterpreterAndInvalidate ( ) ; <nl> - QuickNode referenceArrayStoreNode ; <nl> + QuickNode arrayStoreNode ; <nl> synchronized ( this ) { <nl> if ( bs . currentBC ( curBCI ) = = SLIM_QUICK ) { <nl> - referenceArrayStoreNode = sparseNodes [ curBCI ] ; <nl> + arrayStoreNode = sparseNodes [ curBCI ] ; <nl> } else { <nl> - referenceArrayStoreNode = injectQuick ( curBCI , ReferenceArrayStoreNodeGen . create ( top , curBCI ) , SLIM_QUICK ) ; <nl> + / / @ formatter : off <nl> + switch ( componentKind ) { <nl> + case Boolean : / / fall - through <nl> + case Byte : <nl> + arrayStoreNode = ByteArrayStoreNodeGen . create ( top , curBCI ) ; <nl> + break ; <nl> + case Short : arrayStoreNode = ShortArrayStoreNodeGen . create ( top , curBCI ) ; break ; <nl> + case Char : arrayStoreNode = CharArrayStoreNodeGen . create ( top , curBCI ) ; break ; <nl> + case Int : arrayStoreNode = IntArrayStoreNodeGen . create ( top , curBCI ) ; break ; <nl> + case Float : arrayStoreNode = FloatArrayStoreNodeGen . create ( top , curBCI ) ; break ; <nl> + case Long : arrayStoreNode = LongArrayStoreNodeGen . create ( top , curBCI ) ; break ; <nl> + case Double : arrayStoreNode = DoubleArrayStoreNodeGen . create ( top , curBCI ) ; break ; <nl> + case Object : arrayStoreNode = ReferenceArrayStoreNodeGen . create ( top , curBCI ) ; break ; <nl> + default : <nl> + CompilerDirectives . transferToInterpreter ( ) ; <nl> + throw EspressoError . shouldNotReachHere ( \" unexpected kind \" ) ; <nl> + } <nl> + / / @ formatter : on <nl> + arrayStoreNode = injectQuick ( curBCI , arrayStoreNode , SLIM_QUICK ) ; <nl> } <nl> } <nl> - referenceArrayStoreNode . execute ( frame ) ; <nl> + arrayStoreNode . execute ( frame ) ; <nl> } <nl> <nl> / / endregion quickenForeign <nl>\n", "msg": "A single method for quickening all array loads / stores\n"}
{"diff_id": 25534, "repo": "oracle/graal\n", "sha": "d421df6d11687a293bbf02908bfa1c14bd532974\n", "time": "2018-02-09T11:04:19Z\n", "diff": "mmm a / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / TruffleTreeDumpHandler . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / TruffleTreeDumpHandler . java <nl> public int blockId ( ASTBlock block ) { <nl> root = makeCallTreeNode ( target ) ; <nl> inlined . nodes . add ( root ) ; <nl> root . properties . put ( \" label \" , target . toString ( ) ) ; <nl> + root . properties . putAll ( ( ( OptimizedCallTarget ) target ) . getDebugProperties ( null ) ) ; <nl> build ( target , root , inlining , this ) ; <nl> } <nl> <nl> private static void build ( RootCallTarget target , CallTreeNode parent , TruffleInl <nl> } else { <nl> callTreeNode . properties . put ( \" inlined \" , \" false \" ) ; <nl> if ( decision ! = null ) { <nl> - callTreeNode . properties . putAll ( decision . getProfile ( ) . getDebugProperties ( ) ) ; <nl> + callTreeNode . properties . putAll ( decision . getTarget ( ) . getDebugProperties ( decision ) ) ; <nl> } <nl> graph . notInlined . nodes . add ( callTreeNode ) ; <nl> } <nl>\n", "msg": "Better handling of debug properties for call tree .\n"}
{"diff_id": 25627, "repo": "bazelbuild/bazel\n", "sha": "9c5e4bf20dec3c8be4d50b406d69ecf84c6e8322\n", "time": "2016-04-18T10:43:25Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / rules / android / DexArchiveAspect . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / android / DexArchiveAspect . java <nl> <nl> import static com . google . devtools . build . lib . packages . Attribute . attr ; <nl> import static com . google . devtools . build . lib . packages . BuildType . LABEL ; <nl> import static com . google . devtools . build . lib . packages . BuildType . LABEL_LIST ; <nl> + import static java . nio . charset . StandardCharsets . ISO_8859_1 ; <nl> <nl> import com . google . common . collect . ImmutableList ; <nl> import com . google . devtools . build . lib . actions . Artifact ; <nl> + import com . google . devtools . build . lib . actions . ParameterFile ; <nl> import com . google . devtools . build . lib . analysis . ConfiguredAspect ; <nl> import com . google . devtools . build . lib . analysis . ConfiguredAspectFactory ; <nl> import com . google . devtools . build . lib . analysis . ConfiguredTarget ; <nl> import com . google . devtools . build . lib . analysis . RuleConfiguredTarget . Mode ; <nl> import com . google . devtools . build . lib . analysis . RuleContext ; <nl> + import com . google . devtools . build . lib . analysis . actions . CustomCommandLine ; <nl> + import com . google . devtools . build . lib . analysis . actions . ParameterFileWriteAction ; <nl> import com . google . devtools . build . lib . analysis . actions . SpawnAction ; <nl> import com . google . devtools . build . lib . cmdline . Label ; <nl> import com . google . devtools . build . lib . packages . AspectDefinition ; <nl> static void createDexArchiveAction ( RuleContext ruleContext , Artifact jar , Artifa <nl> <nl> private static void createDexArchiveAction ( RuleContext ruleContext , String dexbuilderPrereq , <nl> Artifact jar , Artifact dexArchive ) { <nl> + / / Write command line arguments into a params file for compatibility with WorkerSpawnStrategy <nl> + CustomCommandLine . Builder args = new CustomCommandLine . Builder ( ) <nl> + . addExecPath ( \" - - input_jar \" , jar ) <nl> + . addExecPath ( \" - - output_zip \" , dexArchive ) ; <nl> + if ( ruleContext . getConfiguration ( ) . isCodeCoverageEnabled ( ) ) { <nl> + / / Match what we do in AndroidCommon . createDexAction <nl> + args . add ( \" - - nolocals \" ) ; / / TODO ( bazel - team ) : Still needed ? See createDexAction <nl> + } <nl> + Artifact paramFile = <nl> + ruleContext . getDerivedArtifact ( <nl> + ParameterFile . derivePath ( dexArchive . getRootRelativePath ( ) ) , dexArchive . getRoot ( ) ) ; <nl> + ruleContext . registerAction ( <nl> + new ParameterFileWriteAction ( <nl> + ruleContext . getActionOwner ( ) , <nl> + paramFile , <nl> + args . build ( ) , <nl> + ParameterFile . ParameterFileType . UNQUOTED , <nl> + ISO_8859_1 ) ) ; <nl> SpawnAction . Builder dexbuilder = new SpawnAction . Builder ( ) <nl> . setExecutable ( ruleContext . getExecutablePrerequisite ( dexbuilderPrereq , Mode . HOST ) ) <nl> - . addArgument ( \" - - input_jar \" ) <nl> - . addInputArgument ( jar ) <nl> - . addArgument ( \" - - output_zip \" ) <nl> - . addOutputArgument ( dexArchive ) <nl> + / / WorkerSpawnStrategy expects the last argument to be @ paramfile <nl> + . addArgument ( \" @ \" + paramFile . getExecPathString ( ) ) <nl> + . addInput ( jar ) <nl> + . addInput ( paramFile ) <nl> + . addOutput ( dexArchive ) <nl> . setMnemonic ( \" DexBuilder \" ) <nl> . setProgressMessage ( \" Dexing \" + jar . prettyPrint ( ) ) ; <nl> - if ( ruleContext . getConfiguration ( ) . isCodeCoverageEnabled ( ) ) { <nl> - / / Match what we do in AndroidCommon . createDexAction <nl> - dexbuilder . addArgument ( \" - - nolocals \" ) ; / / TODO ( bazel - team ) : Still needed ? See createDexAction <nl> - } <nl> ruleContext . registerAction ( dexbuilder . build ( ruleContext ) ) ; <nl> } <nl> } <nl>\n", "msg": "Use DexBuilder tool such that it can be a persistent worker\n"}
{"diff_id": 25630, "repo": "elastic/elasticsearch\n", "sha": "6aa9be238c7ae3a7168ea0271df6006779b15504\n", "time": "2010-07-06T15:45:19Z\n", "diff": "mmm a / modules / elasticsearch / src / main / java / org / elasticsearch / index / translog / memory / MemoryTranslog . java <nl> ppp b / modules / elasticsearch / src / main / java / org / elasticsearch / index / translog / memory / MemoryTranslog . java <nl> <nl> } <nl> <nl> @ Override public int size ( ) { <nl> - return operations . size ( ) ; <nl> + return operationCounter . get ( ) ; <nl> } <nl> <nl> @ Override public ByteSizeValue estimateMemorySize ( ) { <nl>\n", "msg": "use the atomic integer counter to represent the size\n"}
{"diff_id": 25686, "repo": "bazelbuild/bazel\n", "sha": "cf568dbe0111135053b7c3b299860749a44512b0\n", "time": "2018-02-28T22:55:43Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / query2 / output / ProtoOutputFormatter . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / query2 / output / ProtoOutputFormatter . java <nl> <nl> import com . google . devtools . build . lib . syntax . Type ; <nl> import java . io . IOException ; <nl> import java . io . OutputStream ; <nl> + import java . util . ArrayList ; <nl> import java . util . Collection ; <nl> import java . util . HashMap ; <nl> import java . util . LinkedHashSet ; <nl> <nl> import java . util . Map ; <nl> import java . util . Map . Entry ; <nl> import java . util . Set ; <nl> + import java . util . stream . Collectors ; <nl> import javax . annotation . Nullable ; <nl> <nl> / * * <nl> public void close ( boolean failFast ) throws IOException { <nl> attributeValue , <nl> rule . isAttributeValueExplicitlySpecified ( attr ) , <nl> / * encodeBooleanAndTriStateAsIntegerAndString = * / true ) ; <nl> - rulePb . addAttribute ( serializedAttribute ) ; <nl> serializedAttributes . put ( attr , serializedAttribute ) ; <nl> } <nl> + rulePb . addAllAttribute ( <nl> + serializedAttributes . values ( ) . stream ( ) . distinct ( ) . collect ( Collectors . toList ( ) ) ) ; <nl> <nl> postProcess ( rule , rulePb , serializedAttributes ) ; <nl> <nl> public void close ( boolean failFast ) throws IOException { <nl> ImmutableMultimap < Attribute , Label > aspectsDependencies = <nl> aspectResolver . computeAspectDependencies ( target , dependencyFilter ) ; <nl> / / Add information about additional attributes from aspects . <nl> + List < Build . Attribute > attributes = new ArrayList < > ( aspectsDependencies . asMap ( ) . size ( ) ) ; <nl> for ( Entry < Attribute , Collection < Label > > entry : aspectsDependencies . asMap ( ) . entrySet ( ) ) { <nl> Attribute attribute = entry . getKey ( ) ; <nl> Collection < Label > labels = entry . getValue ( ) ; <nl> public void close ( boolean failFast ) throws IOException { <nl> attributeValue , <nl> / * explicitlySpecified = * / false , <nl> / * encodeBooleanAndTriStateAsIntegerAndString = * / true ) ; <nl> - rulePb . addAttribute ( serializedAttribute ) ; <nl> + attributes . add ( serializedAttribute ) ; <nl> } <nl> + rulePb . addAllAttribute ( attributes . stream ( ) . distinct ( ) . collect ( Collectors . toList ( ) ) ) ; <nl> if ( includeRuleInputsAndOutputs ( ) ) { <nl> / / Add all deps from aspects as rule inputs of current target . <nl> - for ( Label label : aspectsDependencies . values ( ) ) { <nl> - rulePb . addRuleInput ( label . toString ( ) ) ; <nl> - } <nl> - <nl> + aspectsDependencies <nl> + . values ( ) <nl> + . stream ( ) <nl> + . distinct ( ) <nl> + . forEach ( dep - > rulePb . addRuleInput ( dep . toString ( ) ) ) ; <nl> / / Include explicit elements for all direct inputs and outputs of a rule ; <nl> / / this goes beyond what is available from the attributes above , since it <nl> / / may also ( depending on options ) include implicit outputs , <nl> / / host - configuration outputs , and default values . <nl> - for ( Label label : rule . getLabels ( dependencyFilter ) ) { <nl> - rulePb . addRuleInput ( label . toString ( ) ) ; <nl> - } <nl> - for ( OutputFile outputFile : rule . getOutputFiles ( ) ) { <nl> - Label fileLabel = outputFile . getLabel ( ) ; <nl> - rulePb . addRuleOutput ( fileLabel . toString ( ) ) ; <nl> - } <nl> + rule . getLabels ( dependencyFilter ) <nl> + . stream ( ) <nl> + . distinct ( ) <nl> + . forEach ( input - > rulePb . addRuleInput ( input . toString ( ) ) ) ; <nl> + rule . getOutputFiles ( ) <nl> + . stream ( ) <nl> + . distinct ( ) <nl> + . forEach ( output - > rulePb . addRuleOutput ( output . getLabel ( ) . toString ( ) ) ) ; <nl> } <nl> for ( String feature : rule . getFeatures ( ) ) { <nl> rulePb . addDefaultSetting ( feature ) ; <nl>\n", "msg": "Prevent aspects with the same attributes but different names from outputting duplicates of those attributes in query ' s proto output format .\n"}
{"diff_id": 25764, "repo": "TeamNewPipe/NewPipe\n", "sha": "157b0642145623c45a545af72f74f3bab2d68620\n", "time": "2018-06-28T19:01:34Z\n", "diff": "mmm a / app / src / main / java / org / schabi / newpipe / player / BasePlayer . java <nl> ppp b / app / src / main / java / org / schabi / newpipe / player / BasePlayer . java <nl> <nl> / / Intent <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / * / <nl> <nl> - public static final String REPEAT_MODE = \" repeat_mode \" ; <nl> - public static final String PLAYBACK_PITCH = \" playback_pitch \" ; <nl> - public static final String PLAYBACK_SPEED = \" playback_speed \" ; <nl> - public static final String PLAYBACK_SKIP_SILENCE = \" playback_skip_silence \" ; <nl> - public static final String PLAYBACK_QUALITY = \" playback_quality \" ; <nl> - public static final String PLAY_QUEUE_KEY = \" play_queue_key \" ; <nl> - public static final String APPEND_ONLY = \" append_only \" ; <nl> - public static final String SELECT_ON_APPEND = \" select_on_append \" ; <nl> + @ NonNull public static final String REPEAT_MODE = \" repeat_mode \" ; <nl> + @ NonNull public static final String PLAYBACK_PITCH = \" playback_pitch \" ; <nl> + @ NonNull public static final String PLAYBACK_SPEED = \" playback_speed \" ; <nl> + @ NonNull public static final String PLAYBACK_SKIP_SILENCE = \" playback_skip_silence \" ; <nl> + @ NonNull public static final String PLAYBACK_QUALITY = \" playback_quality \" ; <nl> + @ NonNull public static final String PLAY_QUEUE_KEY = \" play_queue_key \" ; <nl> + @ NonNull public static final String APPEND_ONLY = \" append_only \" ; <nl> + @ NonNull public static final String SELECT_ON_APPEND = \" select_on_append \" ; <nl> <nl> / * / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> / / Playback <nl> public void destroyPlayer ( ) { <nl> if ( playQueue ! = null ) playQueue . dispose ( ) ; <nl> if ( audioReactor ! = null ) audioReactor . dispose ( ) ; <nl> if ( playbackManager ! = null ) playbackManager . dispose ( ) ; <nl> - if ( databaseUpdateReactor ! = null ) databaseUpdateReactor . dispose ( ) ; <nl> if ( mediaSessionManager ! = null ) mediaSessionManager . dispose ( ) ; <nl> <nl> if ( playQueueAdapter ! = null ) { <nl> public void destroy ( ) { <nl> destroyPlayer ( ) ; <nl> unregisterBroadcastReceiver ( ) ; <nl> <nl> - if ( mediaSessionManager ! = null ) mediaSessionManager . dispose ( ) ; <nl> + databaseUpdateReactor . clear ( ) ; <nl> + progressUpdateReactor . set ( null ) ; <nl> <nl> - mediaSessionManager = null ; <nl> simpleExoPlayer = null ; <nl> } <nl> <nl> private void processSourceError ( final IOException error ) { <nl> setRecovery ( ) ; <nl> <nl> final Throwable cause = error . getCause ( ) ; <nl> - if ( cause instanceof BehindLiveWindowException ) { <nl> + if ( error instanceof BehindLiveWindowException ) { <nl> reload ( ) ; <nl> } else if ( cause instanceof UnknownHostException ) { <nl> playQueue . error ( / * isNetworkProblem = * / true ) ; <nl> public void seekToDefault ( ) { <nl> private void registerView ( ) { <nl> if ( currentMetadata = = null ) return ; <nl> final StreamInfo currentInfo = currentMetadata . getMetadata ( ) ; <nl> - databaseUpdateReactor . add ( recordManager . onViewed ( currentInfo ) . onErrorComplete ( ) <nl> + final Disposable viewRegister = recordManager . onViewed ( currentInfo ) . onErrorComplete ( ) <nl> . subscribe ( <nl> ignored - > { / * successful * / } , <nl> error - > Log . e ( TAG , \" Player onViewed ( ) failure : \" , error ) <nl> - ) ) ; <nl> + ) ; <nl> + databaseUpdateReactor . add ( viewRegister ) ; <nl> } <nl> <nl> protected void reload ( ) { <nl>\n", "msg": "- Fixed player database and progress disposable disposed when destroying exoplayer .\n"}
{"diff_id": 25815, "repo": "Netflix/Hystrix\n", "sha": "48f0eace4e15d44ad8addfd6cadb1ef3c4a84e70\n", "time": "2016-07-07T00:13:38Z\n", "diff": "mmm a / hystrix - core / src / test / java / com / netflix / hystrix / HystrixObservableCommandTest . java <nl> ppp b / hystrix - core / src / test / java / com / netflix / hystrix / HystrixObservableCommandTest . java <nl> public Boolean call ( Boolean b ) { <nl> return b ; <nl> } <nl> <nl> - } ) . finallyDo ( new Action0 ( ) { <nl> + } ) . doAfterTerminate ( new Action0 ( ) { <nl> <nl> @ Override <nl> public void call ( ) { <nl> public Boolean call ( Boolean b ) { <nl> return b ; <nl> } <nl> <nl> - } ) . finallyDo ( new Action0 ( ) { <nl> + } ) . doAfterTerminate ( new Action0 ( ) { <nl> <nl> @ Override <nl> public void call ( ) { <nl> public Boolean call ( Boolean b ) { <nl> return b ; <nl> } <nl> <nl> - } ) . finallyDo ( new Action0 ( ) { <nl> + } ) . doAfterTerminate ( new Action0 ( ) { <nl> <nl> @ Override <nl> public void call ( ) { <nl>\n", "msg": "Switch usage of Observable . finallyDo to Observable . doAfterTerminate\n"}
{"diff_id": 25816, "repo": "elastic/elasticsearch\n", "sha": "f696ad1d10db04ace39ef1476e2bef1861f6c7df\n", "time": "2016-10-28T13:04:06Z\n", "diff": "mmm a / elasticsearch / src / main / java / org / elasticsearch / xpack / security / authz / store / NativeRolesStore . java <nl> ppp b / elasticsearch / src / main / java / org / elasticsearch / xpack / security / authz / store / NativeRolesStore . java <nl> <nl> import org . elasticsearch . action . search . MultiSearchResponse . Item ; <nl> import org . elasticsearch . action . search . SearchRequest ; <nl> import org . elasticsearch . action . support . ThreadedActionListener ; <nl> + import org . elasticsearch . action . support . TransportActions ; <nl> import org . elasticsearch . cluster . ClusterChangedEvent ; <nl> import org . elasticsearch . cluster . ClusterState ; <nl> import org . elasticsearch . cluster . ClusterStateListener ; <nl> public void onResponse ( GetResponse response ) { <nl> <nl> @ Override <nl> public void onFailure ( Exception e ) { <nl> - if ( e instanceof IndexNotFoundException ) { / / if the index is not there we just claim the role is not there <nl> + / / if the index or the shard is not there / available we just claim the role is not there <nl> + if ( TransportActions . isShardNotAvailableException ( e ) ) { <nl> logger . warn ( ( Supplier < ? > ) ( ) - > new ParameterizedMessage ( \" failed to load role [ { } ] index not available \" , <nl> roleId ) , e ) ; <nl> roleActionListener . onResponse ( RoleAndVersion . NON_EXISTENT ) ; <nl>\n", "msg": "Skip authentication and warn if shards of the . security index are not available\n"}
{"diff_id": 25911, "repo": "oracle/graal\n", "sha": "6a9adc5ce7eed641e765b4e71855e60b2a948162\n", "time": "2019-06-27T11:53:41Z\n", "diff": "mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / FieldTable . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / FieldTable . java <nl> private static void scheduleHole ( int holeStart , int holeEnd , int [ ] counts , List < <nl> int i = 0 ; <nl> <nl> while ( holeSize > 0 & & i < N_PRIMITIVES ) { <nl> - if ( counts [ i ] > 0 & & order [ i ] . getByteCount ( ) < = holeSize ) { <nl> - while ( counts [ i ] > 0 & & order [ i ] . getByteCount ( ) < = holeSize ) { <nl> + int byteCount = order [ i ] . getByteCount ( ) ; <nl> + if ( counts [ i ] > 0 & & byteCount < = holeSize ) { <nl> + while ( counts [ i ] > 0 & & byteCount < = holeSize ) { <nl> counts [ i ] - - ; <nl> - end - = order [ i ] . getByteCount ( ) ; <nl> - holeSize - = order [ i ] . getByteCount ( ) ; <nl> - schedule . add ( new ScheduleEntry ( order [ i ] , end ) ) ; <nl> + int newEnd = end - byteCount ; <nl> + if ( newEnd % byteCount ! = 0 ) { <nl> + int misalignment = newEnd % byteCount ; <nl> + int aligned = newEnd - misalignment ; <nl> + schedule . add ( new ScheduleEntry ( order [ i ] , aligned ) ) ; <nl> + / / We created a new hole of size ` misaligned ` . Try to fill it . <nl> + scheduleHole ( end - misalignment , end , counts , schedule , nextHoles ) ; <nl> + } else { <nl> + end - = byteCount ; <nl> + holeSize - = byteCount ; <nl> + schedule . add ( new ScheduleEntry ( order [ i ] , end ) ) ; <nl> + } <nl> } <nl> } <nl> i + + ; <nl>\n", "msg": "Field filling could spawn unaligned fields . Now corrected\n"}
{"diff_id": 25994, "repo": "dbeaver/dbeaver\n", "sha": "53d8eb6a412c51e4d2e8397b9815d9671f620902\n", "time": "2016-05-25T15:09:23Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . core / src / org / jkiss / dbeaver / ui / controls / itemlist / DatabaseObjectListControl . java <nl> ppp b / plugins / org . jkiss . dbeaver . core / src / org / jkiss / dbeaver / ui / controls / itemlist / DatabaseObjectListControl . java <nl> public void run ( ) <nl> } ; <nl> copyAction . setEnabled ( ! getSelectionProvider ( ) . getSelection ( ) . isEmpty ( ) ) ; <nl> manager . add ( copyAction ) ; <nl> + manager . add ( new Separator ( ) ) ; <nl> + fillCustomActions ( manager ) ; <nl> } <nl> } ) ; <nl> menuMgr . setRemoveAllWhenShown ( true ) ; <nl>\n", "msg": "Database list control context menu refactoring ( fill custom actions )\n"}
{"diff_id": 25996, "repo": "oracle/graal\n", "sha": "1244975d4ae45390684505bcaf91696b45f0bb66\n", "time": "2017-05-17T12:46:51Z\n", "diff": "mmm a / projects / com . oracle . truffle . llvm . nodes / src / com / oracle / truffle / llvm / nodes / func / LLVMInvokeNode . java <nl> ppp b / projects / com . oracle . truffle . llvm . nodes / src / com / oracle / truffle / llvm / nodes / func / LLVMInvokeNode . java <nl> <nl> import com . oracle . truffle . api . frame . FrameSlot ; <nl> import com . oracle . truffle . api . frame . VirtualFrame ; <nl> import com . oracle . truffle . api . nodes . ExplodeLoop ; <nl> + import com . oracle . truffle . api . profiles . ConditionProfile ; <nl> import com . oracle . truffle . api . source . SourceSection ; <nl> import com . oracle . truffle . llvm . runtime . LLVMException ; <nl> import com . oracle . truffle . llvm . runtime . nodes . api . LLVMControlFlowNode ; <nl> public boolean needsBranchProfiling ( ) { <nl> <nl> public abstract void execute ( VirtualFrame frame ) ; <nl> <nl> + private final ConditionProfile profile = ConditionProfile . createCountingProfile ( ) ; <nl> + <nl> @ ExplodeLoop <nl> public void writePhis ( VirtualFrame frame , int successorIndex ) { <nl> - if ( successorIndex = = NORMAL_SUCCESSOR ) { <nl> - for ( int i = 0 ; i < normalPhiWriteNodes . length ; i + + ) { <nl> - normalPhiWriteNodes [ i ] . executeGeneric ( frame ) ; <nl> - } <nl> + if ( profile . profile ( successorIndex = = NORMAL_SUCCESSOR ) ) { <nl> + runNormalPhis ( frame ) ; <nl> } else { <nl> assert successorIndex = = UNWIND_SUCCESSOR ; <nl> - for ( int i = 0 ; i < unwindPhiWriteNodes . length ; i + + ) { <nl> - unwindPhiWriteNodes [ i ] . executeGeneric ( frame ) ; <nl> - } <nl> + runUnwindPhis ( frame ) ; <nl> + } <nl> + } <nl> + <nl> + @ ExplodeLoop <nl> + private void runUnwindPhis ( VirtualFrame frame ) { <nl> + for ( int i = 0 ; i < unwindPhiWriteNodes . length ; i + + ) { <nl> + unwindPhiWriteNodes [ i ] . executeGeneric ( frame ) ; <nl> + } <nl> + } <nl> + <nl> + @ ExplodeLoop <nl> + private void runNormalPhis ( VirtualFrame frame ) { <nl> + for ( int i = 0 ; i < normalPhiWriteNodes . length ; i + + ) { <nl> + normalPhiWriteNodes [ i ] . executeGeneric ( frame ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "Add branch brofile to LLVMInvokeNode an cut off phi code if no unwind necessary .\n"}
{"diff_id": 26016, "repo": "dbeaver/dbeaver\n", "sha": "90ee0d6659e35f131ab2c3d9593a5f0fcc06b89e\n", "time": "2020-01-14T15:45:49Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . model / src / org / jkiss / dbeaver / model / sql / SQLUtils . java <nl> ppp b / plugins / org . jkiss . dbeaver . model / src / org / jkiss / dbeaver / model / sql / SQLUtils . java <nl> public static void appendOrderString ( @ NotNull DBDDataFilter filter , @ NotNull DBP <nl> for ( DBDAttributeConstraint co : filter . getOrderConstraints ( ) ) { <nl> if ( hasOrder ) query . append ( ' , ' ) ; <nl> String orderString = null ; <nl> - if ( co . getAttribute ( ) = = null | | co . getAttribute ( ) instanceof DBDAttributeBindingMeta ) { <nl> + if ( co . getAttribute ( ) = = null | | co . getAttribute ( ) instanceof DBDAttributeBindingMeta | | co . getAttribute ( ) instanceof DBDAttributeBindingType ) { <nl> String orderColumn = co . getAttributeName ( ) ; <nl> if ( co . getAttribute ( ) = = null | | PATTERN_SIMPLE_NAME . matcher ( orderColumn ) . matches ( ) ) { <nl> / / It is a simple column . <nl>\n", "msg": "SQL ordering fix ( do not use indexed columns for type attributes )\n"}
{"diff_id": 26087, "repo": "apache/flink\n", "sha": "24c242977991c124d928798b4d71d569b6a32e4c\n", "time": "2018-02-18T09:12:53Z\n", "diff": "mmm a / flink - yarn / src / main / java / org / apache / flink / yarn / YarnResourceManager . java <nl> ppp b / flink - yarn / src / main / java / org / apache / flink / yarn / YarnResourceManager . java <nl> <nl> <nl> import org . apache . flink . api . java . tuple . Tuple2 ; <nl> import org . apache . flink . configuration . Configuration ; <nl> - import org . apache . flink . configuration . TaskManagerOptions ; <nl> import org . apache . flink . runtime . clusterframework . ApplicationStatus ; <nl> - import org . apache . flink . runtime . clusterframework . BootstrapTools ; <nl> import org . apache . flink . runtime . clusterframework . ContaineredTaskManagerParameters ; <nl> import org . apache . flink . runtime . clusterframework . types . ResourceID ; <nl> import org . apache . flink . runtime . clusterframework . types . ResourceProfile ; <nl> <nl> import java . util . Map ; <nl> import java . util . concurrent . ConcurrentHashMap ; <nl> import java . util . concurrent . ConcurrentMap ; <nl> - import java . util . concurrent . TimeUnit ; <nl> - <nl> - import scala . concurrent . duration . FiniteDuration ; <nl> <nl> / * * <nl> * The yarn implementation of the resource manager . Used when the system is started <nl> private ContainerLaunchContext createTaskExecutorLaunchContext ( Resource resource <nl> taskManagerParameters . taskManagerTotalMemoryMB ( ) , <nl> taskManagerParameters . taskManagerHeapSizeMB ( ) , <nl> taskManagerParameters . taskManagerDirectMemoryLimitMB ( ) ) ; <nl> - int timeout = flinkConfig . getInteger ( TaskManagerOptions . MAX_REGISTRATION_DURATION . key ( ) , <nl> - DEFAULT_TASK_MANAGER_REGISTRATION_DURATION ) ; <nl> - FiniteDuration teRegistrationTimeout = new FiniteDuration ( timeout , TimeUnit . SECONDS ) ; <nl> - final Configuration taskManagerConfig = BootstrapTools . generateTaskManagerConfiguration ( <nl> - flinkConfig , \" \" , 0 , 1 , teRegistrationTimeout ) ; <nl> - log . debug ( \" TaskManager configuration : { } \" , taskManagerConfig ) ; <nl> + <nl> + log . debug ( \" TaskManager configuration : { } \" , flinkConfig ) ; <nl> <nl> ContainerLaunchContext taskExecutorLaunchContext = Utils . createTaskExecutorContext ( <nl> - flinkConfig , yarnConfig , env , <nl> - taskManagerParameters , taskManagerConfig , <nl> - currDir , YarnTaskExecutorRunner . class , log ) ; <nl> + flinkConfig , <nl> + yarnConfig , <nl> + env , <nl> + taskManagerParameters , <nl> + flinkConfig , <nl> + currDir , <nl> + YarnTaskExecutorRunner . class , <nl> + log ) ; <nl> <nl> / / set a special environment variable to uniquely identify this container <nl> taskExecutorLaunchContext . getEnvironment ( ) <nl>\n", "msg": "[ hotfix ] [ yarn ] Remove unnecessary TaskManager configuration generation\n"}
{"diff_id": 26220, "repo": "jenkinsci/jenkins\n", "sha": "2d7e0d96b03ff4aeba4a27bc1dec1355c59fe91c\n", "time": "2016-12-20T15:34:02Z\n", "diff": "mmm a / core / src / main / java / hudson / console / ConsoleNote . java <nl> ppp b / core / src / main / java / hudson / console / ConsoleNote . java <nl> <nl> * { @ link ConsoleNote } always sticks to a particular point in the console output . <nl> * <nl> * < p > <nl> - * This design allows descendant processes of Hudson to emit { @ link ConsoleNote } s . For example , Ant forked <nl> - * by a shell forked by Hudson can put an encoded note in its stdout , and Hudson will correctly understands that . <nl> * The preamble and postamble includes a certain ANSI escape sequence designed in such a way to minimize garbage <nl> * if this output is observed by a human being directly . <nl> * <nl>\n", "msg": "Deleting claimed ability in Javadoc which is no longer supportable .\n"}
{"diff_id": 26273, "repo": "oracle/graal\n", "sha": "b1ff57ce907f9671ef586246a56140fb9ee57f53\n", "time": "2017-06-08T06:54:23Z\n", "diff": "mmm a / projects / com . oracle . truffle . llvm . nodes / src / com / oracle / truffle / llvm / nodes / func / LLVMDispatchNode . java <nl> ppp b / projects / com . oracle . truffle . llvm . nodes / src / com / oracle / truffle / llvm / nodes / func / LLVMDispatchNode . java <nl> protected Object doCachedNative ( VirtualFrame frame , LLVMFunctionDescriptor descr <nl> <nl> protected TruffleObject bindSymbol ( VirtualFrame frame , LLVMFunctionDescriptor descriptor ) { <nl> CompilerAsserts . neverPartOfCompilation ( ) ; <nl> - assert descriptor . getNativeFunction ( ) ! = null ; <nl> + assert descriptor . getNativeFunction ( ) ! = null : descriptor . getName ( ) ; <nl> return LLVMNativeCallUtils . bindNativeSymbol ( LLVMNativeCallUtils . getBindNode ( ) , descriptor . getNativeFunction ( ) , getSignature ( ) ) ; <nl> } <nl> <nl>\n", "msg": "Improve assertion error message in native function binding .\n"}
{"diff_id": 26584, "repo": "google/gson\n", "sha": "73117fe65256dadd2eb9e882b7212e9e878493b7\n", "time": "2008-12-28T00:00:12Z\n", "diff": "mmm a / gson / src / main / java / com / google / gson / DefaultTypeAdapters . java <nl> ppp b / gson / src / main / java / com / google / gson / DefaultTypeAdapters . java <nl> <nl> map . register ( Enum . class , wrapDeserializer ( ENUM_TYPE_ADAPTER ) ) ; <nl> map . register ( URL . class , wrapDeserializer ( URL_TYPE_ADAPTER ) ) ; <nl> map . register ( URI . class , wrapDeserializer ( URI_TYPE_ADAPTER ) ) ; <nl> - map . register ( UUID . class , UUUID_TYPE_ADAPTER ) ; <nl> + map . register ( UUID . class , wrapDeserializer ( UUUID_TYPE_ADAPTER ) ) ; <nl> map . register ( Locale . class , wrapDeserializer ( LOCALE_TYPE_ADAPTER ) ) ; <nl> map . register ( Collection . class , wrapDeserializer ( COLLECTION_TYPE_ADAPTER ) ) ; <nl> map . register ( Map . class , wrapDeserializer ( MAP_TYPE_ADAPTER ) ) ; <nl>\n", "msg": "Wrapping UUID deserializer in exception wrapper to make it consistent with other deserializers\n"}
{"diff_id": 26649, "repo": "oracle/graal\n", "sha": "1f6b69f9f60416a6c827147d66d71462f56fa695\n", "time": "2013-11-08T17:26:04Z\n", "diff": "mmm a / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / replacements / NewObjectSnippets . java <nl> ppp b / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / replacements / NewObjectSnippets . java <nl> <nl> package com . oracle . graal . hotspot . replacements ; <nl> <nl> import static com . oracle . graal . api . code . UnsignedMath . * ; <nl> + import static com . oracle . graal . api . meta . MetaUtil . * ; <nl> import static com . oracle . graal . hotspot . replacements . HotSpotReplacementsUtil . * ; <nl> + import static com . oracle . graal . hotspot . replacements . NewObjectSnippets . Options . * ; <nl> import static com . oracle . graal . nodes . PiArrayNode . * ; <nl> import static com . oracle . graal . nodes . PiNode . * ; <nl> import static com . oracle . graal . nodes . extended . BranchProbabilityNode . * ; <nl> <nl> <nl> public static final LocationIdentity INIT_LOCATION = new NamedLocationIdentity ( \" Initialization \" ) ; <nl> <nl> - public static class Options { <nl> + static class Options { <nl> <nl> / / @ formatter : off <nl> @ Option ( help = \" \" ) <nl> - private static final OptionValue < Boolean > ProfileAllocations = new OptionValue < > ( false ) ; <nl> + static final OptionValue < Boolean > ProfileAllocations = new OptionValue < > ( false ) ; <nl> / / @ formatter : on <nl> } <nl> <nl> private static String createName ( String path , String typeContext ) { <nl> <nl> @ Fold <nl> private static boolean doProfile ( ) { <nl> - return Options . ProfileAllocations . getValue ( ) ; <nl> + return ProfileAllocations . getValue ( ) ; <nl> } <nl> <nl> private static void profileAllocation ( String path , long size , String typeContext ) { <nl> public void lower ( NewInstanceNode newInstanceNode ) { <nl> args . add ( \" hub \" , hub ) ; <nl> args . add ( \" prototypeMarkWord \" , type . prototypeMarkWord ( ) ) ; <nl> args . addConst ( \" fillContents \" , newInstanceNode . fillContents ( ) ) ; <nl> - args . addConst ( \" typeContext \" , MetaUtil . toJavaName ( type , false ) ) ; <nl> + args . addConst ( \" typeContext \" , ProfileAllocations . getValue ( ) ? toJavaName ( type , false ) : \" \" ) ; <nl> <nl> SnippetTemplate template = template ( args ) ; <nl> Debug . log ( \" Lowering allocateInstance in % s : node = % s , template = % s , arguments = % s \" , graph , newInstanceNode , template , args ) ; <nl> public void lower ( NewArrayNode newArrayNode ) { <nl> args . addConst ( \" headerSize \" , headerSize ) ; <nl> args . addConst ( \" log2ElementSize \" , log2ElementSize ) ; <nl> args . addConst ( \" fillContents \" , newArrayNode . fillContents ( ) ) ; <nl> - args . addConst ( \" typeContext \" , MetaUtil . toJavaName ( arrayType , false ) ) ; <nl> + args . addConst ( \" typeContext \" , ProfileAllocations . getValue ( ) ? toJavaName ( arrayType , false ) : \" \" ) ; <nl> <nl> SnippetTemplate template = template ( args ) ; <nl> Debug . log ( \" Lowering allocateArray in % s : node = % s , template = % s , arguments = % s \" , graph , newArrayNode , template , args ) ; <nl>\n", "msg": "disabled type context specialization of allocation snippets unless allocation profiling is enabled\n"}
{"diff_id": 26722, "repo": "spring-projects/spring-framework\n", "sha": "c201a14ea2283ebbab41c5e91ec57c38665d5b2e\n", "time": "2016-12-15T04:11:34Z\n", "diff": "mmm a / spring - web / src / test / java / org / springframework / http / server / reactive / AbstractHttpHandlerIntegrationTests . java <nl> ppp b / spring - web / src / test / java / org / springframework / http / server / reactive / AbstractHttpHandlerIntegrationTests . java <nl> <nl> return new Object [ ] [ ] { <nl> { new JettyHttpServer ( ) } , <nl> { new RxNettyHttpServer ( ) } , <nl> - { new ReactorHttpServer ( ) } , <nl> + / / { new ReactorHttpServer ( ) } , <nl> { new TomcatHttpServer ( base . getAbsolutePath ( ) ) } , <nl> { new UndertowHttpServer ( ) } <nl> } ; <nl>\n", "msg": "Temp disabling reactor - netty to unblock pipeline\n"}
{"diff_id": 26843, "repo": "TheAlgorithms/Java\n", "sha": "19b745215b3bc1bd19c84688a15f1814912494e0\n", "time": "2017-10-27T17:40:50Z\n", "diff": "mmm a / Others / QueueUsingTwoStacks . java <nl> ppp b / Others / QueueUsingTwoStacks . java <nl> public Object remove ( ) { <nl> return this . outStack . pop ( ) ; <nl> } <nl> <nl> + / * * <nl> + * Peek at the element from the front of the queue <nl> + * <nl> + * @ return the new front of the queue <nl> + * / <nl> + public Object peek ( ) { <nl> + if ( this . outStack . isEmpty ( ) ) { <nl> + / / Move all elements from inStack to outStack ( preserving the order ) <nl> + while ( ! this . inStack . isEmpty ( ) ) { <nl> + this . outStack . push ( this . inStack . pop ( ) ) ; <nl> + } <nl> + } <nl> + return this . outStack . peek ( ) ; <nl> + } <nl> + <nl> / * * <nl> * Returns true if the queue is empty <nl> * <nl> public static void main ( String args [ ] ) { <nl> / / outStack : [ ( top ) 2 , 3 , 4 ] <nl> <nl> myQueue . insert ( 5 ) ; <nl> + System . out . println ( myQueue . peek ( ) ) ; / / Will print 2 <nl> / / instack : [ ( top ) 5 ] <nl> / / outStack : [ ( top ) 2 , 3 , 4 ] <nl> <nl> myQueue . remove ( ) ; <nl> + System . out . println ( myQueue . peek ( ) ) ; / / Will print 3 <nl> / / instack : [ ( top ) 5 ] <nl> / / outStack : [ ( top ) 3 , 4 ] <nl> myQueue . remove ( ) ; <nl> + System . out . println ( myQueue . peek ( ) ) ; / / Will print 4 <nl> / / instack : [ ( top ) 5 ] <nl> / / outStack : [ ( top ) 4 ] <nl> myQueue . remove ( ) ; <nl> / / instack : [ ( top ) 5 ] <nl> / / outStack : [ ] <nl> + System . out . println ( myQueue . peek ( ) ) ; / / Will print 5 <nl> + / / instack : [ ] <nl> + / / outStack : [ ( top ) 5 ] <nl> myQueue . remove ( ) ; <nl> / / instack : [ ] <nl> / / outStack : [ ] <nl>\n", "msg": "added peek function for the queue\n"}
{"diff_id": 27030, "repo": "SeleniumHQ/selenium\n", "sha": "24e1166be4e9f91c5240c25518366aaac72dda86\n", "time": "2012-10-11T18:18:19Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / support / ui / FluentWait . java <nl> ppp b / java / client / src / org / openqa / selenium / support / ui / FluentWait . java <nl> public FluentWait ( T input , Clock clock , Sleeper sleeper ) { <nl> * @ param types The types of exceptions to ignore . <nl> * @ return A self reference . <nl> * / <nl> - public FluentWait < T > ignoreAll ( Collection < Class < ? extends Throwable > > types ) { <nl> + public < K extends Throwable > FluentWait < T > ignoreAll ( Collection < Class < ? extends K > > types ) { <nl> ignoredExceptions . addAll ( types ) ; <nl> return this ; <nl> } <nl>\n", "msg": "JasonLeyba : Generic trickery to make a method in FluentWait friendlier .\n"}
{"diff_id": 27110, "repo": "SeleniumHQ/selenium\n", "sha": "72781bf7e4d8e288857c33719e35173b2e049523\n", "time": "2007-09-06T22:48:52Z\n", "diff": "mmm a / server - coreless / src / main / java / org / openqa / selenium / server / InjectionHelper . java <nl> ppp b / server - coreless / src / main / java / org / openqa / selenium / server / InjectionHelper . java <nl> <nl> public class InjectionHelper { <nl> static Log log = LogFactory . getLog ( InjectionHelper . class ) ; <nl> private static boolean failOnError = true ; <nl> - private static final boolean INJECT_SCRIPT_TAGS = true ; <nl> + private static boolean INJECT_SCRIPT_TAGS = true ; <nl> private static HashMap < String , HashMap < String , String > > jsStateInitializersBySessionId = new HashMap < String , HashMap < String , String > > ( ) ; <nl> private static HashMap < String , String > sessionIdToUniqueId = new HashMap < String , String > ( ) ; <nl> <nl> private static HashMap < String , String > contentTransformations = new HashMap < String , String > ( ) ; <nl> private static List < String > userJsInjectionFiles = new LinkedList < String > ( ) ; <nl> <nl> + public static void setInjectScriptTags ( boolean injectScriptTags ) { <nl> + InjectionHelper . INJECT_SCRIPT_TAGS = injectScriptTags ; <nl> + } <nl> + <nl> public static void saveJsStateInitializer ( String sessionId , String uniqueId , String jsVarName , String jsStateInitializer ) { <nl> / / when a new uniqueId is seen for a given sessionId , that means the page has <nl> / / reloaded and the old state should be discarded <nl> private static int getBOMLength ( byte [ ] buf ) { <nl> / / ( int ) ( new String ( buf ) ) . charAt ( 2 ) <nl> / / ( int ) 191 <nl> / / ( new String ( buf ) ) . charAt ( 2 ) <nl> - / / ( char )  <nl> + / / ( char )   <nl> / / ( int ) ( new String ( buf ) ) . charAt ( 3 ) <nl> / / ( int ) 10 <nl> / / <nl>\n", "msg": "allow API users to override the injection behavior a bit\n"}
{"diff_id": 27122, "repo": "SeleniumHQ/selenium\n", "sha": "998d62d6334f445e176b55f35bd3b56efc2948e3\n", "time": "2013-02-12T18:41:11Z\n", "diff": "mmm a / java / client / test / org / openqa / selenium / browserlaunchers / LauncherUtilsUnitTest . java <nl> ppp b / java / client / test / org / openqa / selenium / browserlaunchers / LauncherUtilsUnitTest . java <nl> <nl> <nl> package org . openqa . selenium . browserlaunchers ; <nl> <nl> - import static org . junit . Assert . assertEquals ; <nl> - import static org . junit . Assert . assertFalse ; <nl> - import static org . junit . Assert . assertNotNull ; <nl> - import static org . junit . Assert . assertTrue ; <nl> - import static org . openqa . selenium . remote . CapabilityType . ForSeleniumServer . AVOIDING_PROXY ; <nl> - import static org . openqa . selenium . remote . CapabilityType . ForSeleniumServer . ONLY_PROXYING_SELENIUM_TRAFFIC ; <nl> + import com . google . common . base . Throwables ; <nl> + import com . google . common . io . Files ; <nl> <nl> import org . junit . Test ; <nl> import org . openqa . selenium . remote . DesiredCapabilities ; <nl> <nl> import java . io . File ; <nl> - import java . io . FileInputStream ; <nl> import java . io . FileWriter ; <nl> import java . io . IOException ; <nl> + import java . nio . charset . Charset ; <nl> + <nl> + import static org . junit . Assert . assertEquals ; <nl> + import static org . junit . Assert . assertFalse ; <nl> + import static org . junit . Assert . assertNotNull ; <nl> + import static org . junit . Assert . assertTrue ; <nl> + import static org . openqa . selenium . remote . CapabilityType . ForSeleniumServer . AVOIDING_PROXY ; <nl> + import static org . openqa . selenium . remote . CapabilityType . ForSeleniumServer . ONLY_PROXYING_SELENIUM_TRAFFIC ; <nl> <nl> public class LauncherUtilsUnitTest { <nl> <nl> private void doProxyPacTest ( boolean avoidProxy , String nonProxyHosts , String pro <nl> } <nl> <nl> private String getFileContent ( String path ) { <nl> - File f = new File ( path ) ; <nl> - FileInputStream input = null ; <nl> try { <nl> - input = new FileInputStream ( f ) ; <nl> - byte buf [ ] = new byte [ 2048 ] ; <nl> - int len = input . read ( buf ) ; <nl> - return new String ( buf , 0 , len ) ; <nl> - } catch ( Exception e ) { <nl> - throw new RuntimeException ( e ) ; <nl> - } finally { <nl> - if ( input ! = null ) { <nl> - try { <nl> - input . close ( ) ; <nl> - } catch ( IOException e ) { <nl> - throw new RuntimeException ( e ) ; <nl> - } <nl> - } <nl> + return Files . toString ( new File ( path ) , Charset . defaultCharset ( ) ) ; <nl> + } catch ( IOException e ) { <nl> + throw Throwables . propagate ( e ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Read files using an api from guava libraries to let us delete some code .\n"}
{"diff_id": 27259, "repo": "google/ExoPlayer\n", "sha": "6db895bd7b4a69fa9208aaa446440e65251d0ce4\n", "time": "2017-11-17T18:48:42Z\n", "diff": "mmm a / library / core / src / main / java / com / google / android / exoplayer2 / audio / DefaultAudioSink . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / audio / DefaultAudioSink . java <nl> <nl> import java . lang . reflect . Method ; <nl> import java . nio . ByteBuffer ; <nl> import java . nio . ByteOrder ; <nl> + import java . util . ArrayDeque ; <nl> import java . util . ArrayList ; <nl> - import java . util . LinkedList ; <nl> <nl> / * * <nl> * Plays audio data . The implementation delegates to an { @ link AudioTrack } and handles playback <nl> public InvalidAudioTrackTimestampException ( String detailMessage ) { <nl> private final ConditionVariable releasingConditionVariable ; <nl> private final long [ ] playheadOffsets ; <nl> private final AudioTrackUtil audioTrackUtil ; <nl> - private final LinkedList < PlaybackParametersCheckpoint > playbackParametersCheckpoints ; <nl> + private final ArrayDeque < PlaybackParametersCheckpoint > playbackParametersCheckpoints ; <nl> <nl> @ Nullable private Listener listener ; <nl> / * * <nl> public DefaultAudioSink ( @ Nullable AudioCapabilities audioCapabilities , <nl> drainingAudioProcessorIndex = C . INDEX_UNSET ; <nl> this . audioProcessors = new AudioProcessor [ 0 ] ; <nl> outputBuffers = new ByteBuffer [ 0 ] ; <nl> - playbackParametersCheckpoints = new LinkedList < > ( ) ; <nl> + playbackParametersCheckpoints = new ArrayDeque < > ( ) ; <nl> } <nl> <nl> @ Override <nl>\n", "msg": "Use ArrayDeque for playback parameters checkpoints\n"}
{"diff_id": 27384, "repo": "oracle/graal\n", "sha": "284cd376cc478d72d0e382ae0c9020dd49992484\n", "time": "2020-01-21T18:05:32Z\n", "diff": "new file mode 100644 <nl> index 000000000000 . . 44ad6548cb27 <nl> mmm / dev / null <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / JavaVersionUtil . java <nl> <nl> + / * <nl> + * Copyright ( c ) 2020 , 2020 , Oracle and / or its affiliates . All rights reserved . <nl> + * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER . <nl> + * <nl> + * This code is free software ; you can redistribute it and / or modify it <nl> + * under the terms of the GNU General Public License version 2 only , as <nl> + * published by the Free Software Foundation . <nl> + * <nl> + * This code is distributed in the hope that it will be useful , but WITHOUT <nl> + * ANY WARRANTY ; without even the implied warranty of MERCHANTABILITY or <nl> + * FITNESS FOR A PARTICULAR PURPOSE . See the GNU General Public License <nl> + * version 2 for more details ( a copy is included in the LICENSE file that <nl> + * accompanied this code ) . <nl> + * <nl> + * You should have received a copy of the GNU General Public License version <nl> + * 2 along with this work ; if not , write to the Free Software Foundation , <nl> + * Inc . , 51 Franklin St , Fifth Floor , Boston , MA 02110 - 1301 USA . <nl> + * <nl> + * Please contact Oracle , 500 Oracle Parkway , Redwood Shores , CA 94065 USA <nl> + * or visit www . oracle . com if you need additional information or have any <nl> + * questions . <nl> + * / <nl> + package com . oracle . truffle . espresso . substitutions ; <nl> + <nl> + / * * <nl> + * Interface to query the host JVM version . <nl> + * / <nl> + public final class JavaVersionUtil { <nl> + <nl> + private static int getJavaSpecificationVersion ( ) { <nl> + String value = System . getProperty ( \" java . specification . version \" ) ; <nl> + if ( value . startsWith ( \" 1 . \" ) ) { <nl> + value = value . substring ( 2 ) ; <nl> + } <nl> + return Integer . parseInt ( value ) ; <nl> + } <nl> + <nl> + / * * <nl> + * The integer value corresponding to the value of the { @ code java . specification . version } system <nl> + * property after any leading { @ code \" 1 . \" } has been stripped . <nl> + * / <nl> + public static final int JAVA_SPEC = getJavaSpecificationVersion ( ) ; <nl> + <nl> + private JavaVersionUtil ( ) { <nl> + } <nl> + } <nl>\n", "msg": "Add util class to get host Java version .\n"}
{"diff_id": 27497, "repo": "spring-projects/spring-boot\n", "sha": "76df3fc496238e0a557ba92620196bcafaf50655\n", "time": "2017-11-02T18:54:04Z\n", "diff": "mmm a / spring - boot - project / spring - boot - autoconfigure / src / main / java / org / springframework / boot / autoconfigure / flyway / FlywayProperties . java <nl> ppp b / spring - boot - project / spring - boot - autoconfigure / src / main / java / org / springframework / boot / autoconfigure / flyway / FlywayProperties . java <nl> <nl> * use vendor - specific locations . <nl> * / <nl> private List < String > locations = new ArrayList < > ( <nl> - Collections . singletonList ( \" db / migration \" ) ) ; <nl> + Collections . singletonList ( \" classpath : db / migration \" ) ) ; <nl> <nl> / * * <nl> * Check that migration scripts location exists . <nl>\n", "msg": "Use explicit classpath : prefix for Flyway location\n"}
{"diff_id": 27561, "repo": "ReactiveX/RxJava\n", "sha": "d4c1da01b157262b326b21cd97a844fcdedc7c6e\n", "time": "2018-07-12T07:28:57Z\n", "diff": "mmm a / src / main / java / io / reactivex / Single . java <nl> ppp b / src / main / java / io / reactivex / Single . java <nl> <nl> / * * <nl> * Hides the identity of the current Single , including the Disposable that is sent <nl> * to the downstream via { @ code onSubscribe ( ) } . <nl> + * < p > <nl> + * < img width = \" 640 \" height = \" 458 \" src = \" https : / / raw . github . com / wiki / ReactiveX / RxJava / images / rx - operators / Single . hide . png \" alt = \" \" > <nl> * < dl > <nl> * < dt > < b > Scheduler : < / b > < / dt > <nl> * < dd > { @ code hide } does not operate by default on a particular { @ link Scheduler } . < / dd > <nl>\n", "msg": "Add marble diagram for Single . hide operator ( )\n"}
{"diff_id": 27606, "repo": "oracle/graal\n", "sha": "aee868ac763b651f796b8faa773399f178dabc3c\n", "time": "2014-07-02T11:52:25Z\n", "diff": "mmm a / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / alloc / LinearScan . java <nl> ppp b / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / alloc / LinearScan . java <nl> void changeSpillState ( Interval interval , int spillPos ) { <nl> abstract boolean apply ( Interval i ) ; <nl> } <nl> <nl> - private static Interval addToListSortedByDefinition ( Interval first , Interval interval ) { <nl> - assert first ! = null ; <nl> - if ( first = = Interval . EndMarker ) { <nl> - interval . next = Interval . EndMarker ; <nl> - return interval ; <nl> - } <nl> - <nl> - int spillPos = interval . spillDefinitionPos ( ) ; <nl> - if ( first . spillDefinitionPos ( ) > spillPos ) { <nl> - interval . next = first ; <nl> - return interval ; <nl> - } <nl> - Interval current = first ; <nl> - while ( current . next ! = Interval . EndMarker & & current . next . spillDefinitionPos ( ) < spillPos ) { <nl> - current = current . next ; <nl> - } <nl> - interval . next = current . next ; <nl> - current . next = interval ; <nl> - return first ; <nl> - } <nl> - <nl> - private Interval . Pair createSortedByDefinitionLists ( IntervalPredicate isList1 , IntervalPredicate isList2 ) { <nl> - assert isSorted ( sortedIntervals ) : \" interval list is not sorted \" ; <nl> - <nl> - Interval list1 = Interval . EndMarker ; <nl> - Interval list2 = Interval . EndMarker ; <nl> - <nl> - Interval v ; <nl> - <nl> - int n = sortedIntervals . length ; <nl> - for ( int i = 0 ; i < n ; i + + ) { <nl> - v = sortedIntervals [ i ] ; <nl> - if ( v = = null ) { <nl> - continue ; <nl> - } <nl> - <nl> - if ( isList1 . apply ( v ) ) { <nl> - list1 = addToListSortedByDefinition ( list1 , v ) ; <nl> - } else if ( isList2 = = null | | isList2 . apply ( v ) ) { <nl> - list2 = addToListSortedByDefinition ( list2 , v ) ; <nl> - } <nl> - } <nl> - <nl> - return new Interval . Pair ( list1 , list2 ) ; <nl> - } <nl> - <nl> - private static final IntervalPredicate mustStoreAtDominatorORDefinition = new IntervalPredicate ( ) { <nl> + private static final IntervalPredicate mustStoreAtDefinition = new IntervalPredicate ( ) { <nl> <nl> @ Override <nl> public boolean apply ( Interval i ) { <nl> - return i . isSplitParent ( ) & & ( i . spillState ( ) = = SpillState . StoreAtDefinition | | i . spillState ( ) = = SpillState . SpillInDominator ) ; <nl> + return i . isSplitParent ( ) & & i . spillState ( ) = = SpillState . StoreAtDefinition ; <nl> } <nl> } ; <nl> <nl> void eliminateSpillMoves ( ) { <nl> / / collect all intervals that must be stored after their definition . <nl> / / the list is sorted by Interval . spillDefinitionPos <nl> Interval interval ; <nl> - interval = createSortedByDefinitionLists ( mustStoreAtDominatorORDefinition , null ) . first ; <nl> + interval = createUnhandledLists ( mustStoreAtDefinition , null ) . first ; <nl> if ( DetailedAsserts . getValue ( ) ) { <nl> checkIntervals ( interval ) ; <nl> } <nl> void eliminateSpillMoves ( ) { <nl> List < LIRInstruction > instructions = ir . getLIRforBlock ( block ) ; <nl> int numInst = instructions . size ( ) ; <nl> <nl> - / / iterate all instructions of the block . <nl> - for ( int j = 0 ; j < numInst ; j + + ) { <nl> + / / iterate all instructions of the block . skip the first <nl> + / / because it is always a label <nl> + for ( int j = 1 ; j < numInst ; j + + ) { <nl> LIRInstruction op = instructions . get ( j ) ; <nl> int opId = op . id ( ) ; <nl> <nl> void eliminateSpillMoves ( ) { <nl> / / insert move from register to stack just after <nl> / / the beginning of the interval <nl> assert interval = = Interval . EndMarker | | interval . spillDefinitionPos ( ) > = opId : \" invalid order \" ; <nl> - assert interval = = Interval . EndMarker | | <nl> - ( interval . isSplitParent ( ) & & ( interval . spillState ( ) = = SpillState . StoreAtDefinition | | interval . spillState ( ) = = SpillState . SpillInDominator ) ) : \" invalid interval \" ; <nl> + assert interval = = Interval . EndMarker | | ( interval . isSplitParent ( ) & & interval . spillState ( ) = = SpillState . StoreAtDefinition ) : \" invalid interval \" ; <nl> <nl> while ( interval ! = Interval . EndMarker & & interval . spillDefinitionPos ( ) = = opId ) { <nl> if ( ! interval . canMaterialize ( ) ) { <nl> void eliminateSpillMoves ( ) { <nl> insertionBuffer . init ( instructions ) ; <nl> } <nl> <nl> - / / if we spill in a dominator we need to find the right location <nl> - AllocatableValue fromLocation = interval . spillState ( ) = = SpillState . SpillInDominator ? interval . getSplitChildAtOpId ( opId , OperandMode . DEF , this ) . location ( ) <nl> - : interval . location ( ) ; <nl> + AllocatableValue fromLocation = interval . location ( ) ; <nl> AllocatableValue toLocation = canonicalSpillOpr ( interval ) ; <nl> <nl> assert isRegister ( fromLocation ) : \" from operand must be a register but is : \" + fromLocation + \" toLocation = \" + toLocation + \" spillState = \" + interval . spillState ( ) ; <nl> assert isStackSlot ( toLocation ) : \" to operand must be a stack slot \" ; <nl> <nl> - if ( interval . spillState ( ) = = SpillState . SpillInDominator ) { <nl> - / * <nl> - * SpillInDominator spill positions are always at the beginning <nl> - * of a basic block . We need to skip the moves inserted by data <nl> - * flow resolution to ensure data integrity . <nl> - * / <nl> - assert isBlockBegin ( opId ) & & j = = 0 : \" SpillInDominator spill position must be at the beginning of a block ! \" ; <nl> - int pos = 1 ; <nl> - <nl> - if ( block . getPredecessorCount ( ) = = 1 ) { <nl> - / * <nl> - * We need to be careful because data flow resolution code <nl> - * might have been inserted . <nl> - * / <nl> - while ( instructions . get ( pos ) . id ( ) = = - 1 ) { <nl> - pos + + ; <nl> - } <nl> - assert pos < instructions . size ( ) : String . format ( \" Cannot move spill move out of the current block ! ( pos : % d , # inst : % d , block : % s \" , pos , instructions . size ( ) , <nl> - block ) ; <nl> - if ( pos > 1 & & pos = = instructions . size ( ) - 1 ) { <nl> - / * <nl> - * We are at the end of the block and there were <nl> - * resolution moves . <nl> - * / <nl> - if ( block . getSuccessorCount ( ) > 1 ) { <nl> - / * <nl> - * The current block might have resolution code for <nl> - * the incoming and the outgoing edge . To ensure <nl> - * that we use the right location and do not <nl> - * overwrite an outgoing location we take the <nl> - * location at the end of the ( only ) predecessor <nl> - * block . <nl> - * / <nl> - AbstractBlock < ? > pred = block . getPredecessors ( ) . get ( 0 ) ; <nl> - if ( pred . getSuccessorCount ( ) < = 1 ) { <nl> - / / TODO ( je ) fall back to spill at definition <nl> - throw new GraalInternalError ( \" Cannot find a position for the spill in dominator move ! \" + pred + \" - > \" + block ) ; <nl> - } <nl> - int lastId = getLastLirInstructionId ( pred ) ; <nl> - AllocatableValue predFromLocation = interval . getSplitChildAtOpId ( lastId , OperandMode . DEF , this ) . location ( ) ; <nl> - fromLocation = predFromLocation ; <nl> - pos = 1 ; <nl> - } <nl> - } <nl> - } <nl> - insertionBuffer . append ( pos , ir . getSpillMoveFactory ( ) . createMove ( toLocation , fromLocation ) ) ; <nl> - } else { <nl> - insertionBuffer . append ( j + 1 , ir . getSpillMoveFactory ( ) . createMove ( toLocation , fromLocation ) ) ; <nl> - } <nl> + insertionBuffer . append ( j + 1 , ir . getSpillMoveFactory ( ) . createMove ( toLocation , fromLocation ) ) ; <nl> <nl> Debug . log ( \" inserting move after definition of interval % d to stack slot % s at opId % d \" , interval . operandNumber , interval . spillSlot ( ) , opId ) ; <nl> } <nl> private static void checkIntervals ( Interval interval ) { <nl> while ( temp ! = Interval . EndMarker ) { <nl> assert temp . spillDefinitionPos ( ) > 0 : \" invalid spill definition pos \" ; <nl> if ( prev ! = null ) { <nl> + assert temp . from ( ) > = prev . from ( ) : \" intervals not sorted \" ; <nl> assert temp . spillDefinitionPos ( ) > = prev . spillDefinitionPos ( ) : \" when intervals are sorted by from : then they must also be sorted by spillDefinitionPos \" ; <nl> } <nl> <nl> assert temp . spillSlot ( ) ! = null | | temp . canMaterialize ( ) : \" interval has no spill slot assigned \" ; <nl> assert temp . spillDefinitionPos ( ) > = temp . from ( ) : \" invalid order \" ; <nl> + assert temp . spillDefinitionPos ( ) < = temp . from ( ) + 2 : \" only intervals defined once at their start - pos can be optimized \" ; <nl> <nl> Debug . log ( \" interval % d ( from % d to % d ) must be stored at % d \" , temp . operandNumber , temp . from ( ) , temp . to ( ) , temp . spillDefinitionPos ( ) ) ; <nl> <nl>\n", "msg": "LSRA spill optimization : backout changesets obsoleted by eager spill move placement .\n"}
{"diff_id": 27670, "repo": "jenkinsci/jenkins\n", "sha": "f8146742ed7b4b3111f437b343fba8274848ef21\n", "time": "2014-10-06T16:54:24Z\n", "diff": "mmm a / core / src / main / java / hudson / model / Run . java <nl> ppp b / core / src / main / java / hudson / model / Run . java <nl> public void reload ( ) throws IOException { <nl> protected void onLoad ( ) { <nl> for ( Action a : getAllActions ( ) ) { <nl> if ( a instanceof RunAction2 ) { <nl> - ( ( RunAction2 ) a ) . onLoad ( this ) ; <nl> + try { <nl> + ( ( RunAction2 ) a ) . onLoad ( this ) ; <nl> + } catch ( RuntimeException x ) { <nl> + LOGGER . log ( WARNING , \" failed to load \" + a + \" from \" + getDataFile ( ) , x ) ; <nl> + getActions ( ) . remove ( a ) ; / / if possible ; might be in an inconsistent state <nl> + } <nl> } else if ( a instanceof RunAction ) { <nl> ( ( RunAction ) a ) . onLoad ( ) ; <nl> } <nl>\n", "msg": "Better robustness when action loading fails .\n"}
{"diff_id": 27753, "repo": "bazelbuild/bazel\n", "sha": "ac4eb7541894df082b99f48e168009203dce3402\n", "time": "2019-09-06T16:12:18Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / skyframe / SkyFunctionEnvironment . java <nl> ppp b / src / main / java / com / google / devtools / build / skyframe / SkyFunctionEnvironment . java <nl> public void post ( ExtendedEventHandler . Postable e ) { <nl> ? request . excludedKeys <nl> : depKeys . getAllElementsAsIterable ( ) ) ; <nl> if ( batchMap . size ( ) ! = depKeys . numElements ( ) ) { <nl> - NodeEntry inFlightEntry = null ; <nl> - try { <nl> - inFlightEntry = evaluatorContext . getGraph ( ) . get ( null , Reason . OTHER , requestor ) ; <nl> - } catch ( InterruptedException e ) { <nl> - logger . atWarning ( ) . withCause ( e ) . log ( <nl> - \" Interrupted while getting parent entry for % s for crash \" , requestor ) ; <nl> - / / We ' re crashing , don ' t mask it . <nl> - Thread . currentThread ( ) . interrupt ( ) ; <nl> - } <nl> Set < SkyKey > difference = Sets . difference ( depKeys . toSet ( ) , batchMap . keySet ( ) ) ; <nl> - logger . atSevere ( ) . log ( \" Missing keys for % s : % s \\ n \\ n % s \" , requestor , difference , inFlightEntry ) ; <nl> evaluatorContext <nl> . getGraphInconsistencyReceiver ( ) <nl> . noteInconsistencyAndMaybeThrow ( <nl>\n", "msg": "Remove unnecessary logging statement from batchPrefetch .\n"}
{"diff_id": 27775, "repo": "bazelbuild/bazel\n", "sha": "9be852e2e9622a87d9b145fe6fe4218e23343d66\n", "time": "2015-05-28T14:33:19Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / syntax / Parser . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / syntax / Parser . java <nl> <nl> <nl> package com . google . devtools . build . lib . syntax ; <nl> <nl> + import static com . google . devtools . build . lib . syntax . Parser . ParsingMode . BUILD ; <nl> + import static com . google . devtools . build . lib . syntax . Parser . ParsingMode . PYTHON ; <nl> + import static com . google . devtools . build . lib . syntax . Parser . ParsingMode . SKYLARK ; <nl> + <nl> import com . google . common . annotations . VisibleForTesting ; <nl> import com . google . common . base . Preconditions ; <nl> import com . google . common . base . Supplier ; <nl> public ParseResult ( List < Statement > statements , List < Comment > comments , boolean c <nl> } <nl> } <nl> <nl> + / * * <nl> + * ParsingMode is used to select which features the parser should accept . <nl> + * / <nl> + public enum ParsingMode { <nl> + / * * Used for parsing BUILD files * / <nl> + BUILD , <nl> + / * * Used for parsing . bzl files * / <nl> + SKYLARK , <nl> + / * * Used for syntax checking , ignoring all Python blocks ( e . g . def , class , try ) * / <nl> + PYTHON , <nl> + } <nl> + <nl> private static final EnumSet < TokenKind > STATEMENT_TERMINATOR_SET = <nl> - EnumSet . of ( TokenKind . EOF , TokenKind . NEWLINE ) ; <nl> + EnumSet . of ( TokenKind . EOF , TokenKind . NEWLINE ) ; <nl> <nl> private static final EnumSet < TokenKind > LIST_TERMINATOR_SET = <nl> EnumSet . of ( TokenKind . EOF , TokenKind . RBRACKET , TokenKind . SEMI ) ; <nl> public ParseResult ( List < Statement > statements , List < Comment > comments , boolean c <nl> private final Lexer lexer ; <nl> private final EventHandler eventHandler ; <nl> private final List < Comment > comments ; <nl> - private final boolean parsePython ; <nl> - / * * Whether advanced language constructs are allowed * / <nl> - private boolean skylarkMode = false ; <nl> + private final ParsingMode parsingMode ; <nl> <nl> private static final Map < TokenKind , Operator > binaryOperators = <nl> new ImmutableMap . Builder < TokenKind , Operator > ( ) <nl> public ParseResult ( List < Statement > statements , List < Comment > comments , boolean c <nl> <nl> private List < Path > includedFiles ; <nl> <nl> - private Parser ( Lexer lexer , EventHandler eventHandler , CachingPackageLocator locator , <nl> - boolean parsePython ) { <nl> + private Parser ( <nl> + Lexer lexer , <nl> + EventHandler eventHandler , <nl> + CachingPackageLocator locator , <nl> + ParsingMode parsingMode ) { <nl> this . lexer = lexer ; <nl> this . eventHandler = eventHandler ; <nl> - this . parsePython = parsePython ; <nl> + this . parsingMode = parsingMode ; <nl> this . tokens = lexer . getTokens ( ) . iterator ( ) ; <nl> this . comments = new ArrayList < > ( ) ; <nl> this . locator = locator ; <nl> private Parser ( Lexer lexer , EventHandler eventHandler , CachingPackageLocator loc <nl> } <nl> <nl> private Parser ( Lexer lexer , EventHandler eventHandler , CachingPackageLocator locator ) { <nl> - this ( lexer , eventHandler , locator , false / * parsePython * / ) ; <nl> - } <nl> - <nl> - public Parser setSkylarkMode ( boolean skylarkMode ) { <nl> - this . skylarkMode = skylarkMode ; <nl> - return this ; <nl> + this ( lexer , eventHandler , locator , BUILD ) ; <nl> } <nl> <nl> / * * <nl> public Parser setSkylarkMode ( boolean skylarkMode ) { <nl> * encountered during parsing are reported via \" reporter \" . <nl> * / <nl> public static ParseResult parseFile ( <nl> - Lexer lexer , EventHandler eventHandler , CachingPackageLocator locator , <nl> - boolean parsePython ) { <nl> - Parser parser = new Parser ( lexer , eventHandler , locator , parsePython ) ; <nl> + Lexer lexer , EventHandler eventHandler , CachingPackageLocator locator , boolean parsePython ) { <nl> + ParsingMode parsingMode = parsePython ? PYTHON : BUILD ; <nl> + Parser parser = new Parser ( lexer , eventHandler , locator , parsingMode ) ; <nl> List < Statement > statements = parser . parseFileInput ( ) ; <nl> - return new ParseResult ( statements , parser . comments , <nl> - parser . errorsCount > 0 | | lexer . containsErrors ( ) ) ; <nl> + return new ParseResult ( <nl> + statements , parser . comments , parser . errorsCount > 0 | | lexer . containsErrors ( ) ) ; <nl> } <nl> <nl> / * * <nl> public static ParseResult parseFile ( <nl> * that are not part of the core BUILD language . <nl> * / <nl> public static ParseResult parseFileForSkylark ( <nl> - Lexer lexer , EventHandler eventHandler , CachingPackageLocator locator , <nl> + Lexer lexer , <nl> + EventHandler eventHandler , <nl> + CachingPackageLocator locator , <nl> ValidationEnvironment validationEnvironment ) { <nl> - Parser parser = new Parser ( lexer , eventHandler , locator ) . setSkylarkMode ( true ) ; <nl> + Parser parser = new Parser ( lexer , eventHandler , locator , SKYLARK ) ; <nl> List < Statement > statements = parser . parseFileInput ( ) ; <nl> boolean hasSemanticalErrors = false ; <nl> try { <nl> private int syncTo ( EnumSet < TokenKind > terminatingTokens ) { <nl> TokenKind . TRY , TokenKind . WITH , TokenKind . WHILE , TokenKind . YIELD ) ; <nl> <nl> private void checkForbiddenKeywords ( Token token ) { <nl> - if ( parsePython | | ! FORBIDDEN_KEYWORDS . contains ( token . kind ) ) { <nl> + if ( parsingMode = = PYTHON | | ! FORBIDDEN_KEYWORDS . contains ( token . kind ) ) { <nl> return ; <nl> } <nl> String error ; <nl> private Expression makeFuncallExpression ( Expression receiver , Ident function , <nl> final int start = token . left ; <nl> / / parse * * expr <nl> if ( token . kind = = TokenKind . STAR_STAR ) { <nl> - if ( ! skylarkMode ) { <nl> + if ( parsingMode ! = SKYLARK ) { <nl> reportError ( <nl> lexer . createLocation ( token . left , token . right ) , <nl> \" * * kwargs arguments are not allowed in BUILD files \" ) ; <nl> private Expression makeFuncallExpression ( Expression receiver , Ident function , <nl> } <nl> / / parse * expr <nl> if ( token . kind = = TokenKind . STAR ) { <nl> - if ( ! skylarkMode ) { <nl> + if ( parsingMode ! = SKYLARK ) { <nl> reportError ( <nl> lexer . createLocation ( token . left , token . right ) , <nl> \" * args arguments are not allowed in BUILD files \" ) ; <nl> private void include ( String labelName , List < Statement > list , Location location ) <nl> / / Insert call to the mocksubinclude function to get the dependencies right . <nl> list . add ( mocksubincludeExpression ( labelName , file . toString ( ) , location ) ) ; <nl> <nl> - Lexer lexer = new Lexer ( inputSource , eventHandler , parsePython ) ; <nl> - Parser parser = new Parser ( lexer , eventHandler , locator , parsePython ) ; <nl> + Lexer lexer = new Lexer ( inputSource , eventHandler , parsingMode = = PYTHON ) ; <nl> + Parser parser = new Parser ( lexer , eventHandler , locator , parsingMode ) ; <nl> parser . addIncludedFiles ( this . includedFiles ) ; <nl> list . addAll ( parser . parseFileInput ( ) ) ; <nl> } catch ( Label . SyntaxException e ) { <nl> private void parseTopLevelStatement ( List < Statement > list ) { <nl> Token identToken = token ; <nl> Ident ident = parseIdent ( ) ; <nl> <nl> - if ( ident . getName ( ) . equals ( \" include \" ) & & token . kind = = TokenKind . LPAREN & & ! skylarkMode ) { <nl> + if ( ident . getName ( ) . equals ( \" include \" ) <nl> + & & token . kind = = TokenKind . LPAREN <nl> + & & parsingMode = = BUILD ) { <nl> expect ( TokenKind . LPAREN ) ; <nl> if ( token . kind = = TokenKind . STRING ) { <nl> include ( ( String ) token . value , list , lexer . createLocation ( start , token . right ) ) ; <nl> private void skipSuite ( ) { <nl> / / stmt : : = simple_stmt <nl> / / | compound_stmt <nl> private void parseStatement ( List < Statement > list , boolean isTopLevel ) { <nl> - if ( token . kind = = TokenKind . DEF & & skylarkMode ) { <nl> + if ( token . kind = = TokenKind . DEF & & parsingMode = = SKYLARK ) { <nl> if ( ! isTopLevel ) { <nl> reportError ( lexer . createLocation ( token . left , token . right ) , <nl> \" nested functions are not allowed . Move the function to top - level \" ) ; <nl> } <nl> parseFunctionDefStatement ( list ) ; <nl> - } else if ( token . kind = = TokenKind . IF & & skylarkMode ) { <nl> + } else if ( token . kind = = TokenKind . IF & & parsingMode = = SKYLARK ) { <nl> list . add ( parseIfStatement ( ) ) ; <nl> - } else if ( token . kind = = TokenKind . FOR & & skylarkMode ) { <nl> + } else if ( token . kind = = TokenKind . FOR & & parsingMode = = SKYLARK ) { <nl> if ( isTopLevel ) { <nl> reportError ( lexer . createLocation ( token . left , token . right ) , <nl> \" for loops are not allowed on top - level . Put it into a function \" ) ; <nl> private void skipBlock ( ) { <nl> int start = token . left ; <nl> Token blockToken = token ; <nl> syncTo ( EnumSet . of ( TokenKind . COLON , TokenKind . EOF ) ) ; / / skip over expression or name <nl> - if ( ! parsePython ) { <nl> + if ( parsingMode = = BUILD ) { <nl> reportError ( lexer . createLocation ( start , token . right ) , \" syntax error at ' \" <nl> + blockToken + \" ' : This Python - style construct is not supported . \" <nl> + Constants . PARSER_ERROR_EXTENSION_NEEDED ) ; <nl>\n", "msg": "Parser cleanup : Introduce an enum instead of the booleans\n"}
{"diff_id": 28045, "repo": "signalapp/Signal-Android\n", "sha": "cb3cf7789ff8d5b90ca69c73764b92c82e41b9d9\n", "time": "2015-06-11T17:44:12Z\n", "diff": "mmm a / src / org / thoughtcrime / securesms / ShareActivity . java <nl> ppp b / src / org / thoughtcrime / securesms / ShareActivity . java <nl> <nl> import org . thoughtcrime . securesms . util . DynamicLanguage ; <nl> import org . thoughtcrime . securesms . util . DynamicTheme ; <nl> <nl> + import java . net . URLDecoder ; <nl> + <nl> import ws . com . google . android . mms . ContentType ; <nl> <nl> / * * <nl> private void createConversation ( long threadId , Recipients recipients , int distri <nl> startActivity ( intent ) ; <nl> } <nl> <nl> + private Uri getStreamExtra ( ) { <nl> + Uri streamUri = getIntent ( ) . getParcelableExtra ( Intent . EXTRA_STREAM ) ; <nl> + if ( streamUri . getAuthority ( ) . equals ( \" com . google . android . apps . photos . contentprovider \" ) & & <nl> + streamUri . toString ( ) . endsWith ( \" / ACTUAL \" ) ) <nl> + { <nl> + String [ ] parts = streamUri . toString ( ) . split ( \" / \" ) ; <nl> + if ( parts . length > 3 ) { <nl> + return Uri . parse ( URLDecoder . decode ( parts [ parts . length - 2 ] ) ) ; <nl> + } <nl> + } <nl> + return streamUri ; <nl> + } <nl> + <nl> private Intent getBaseShareIntent ( final Class < ? > target ) { <nl> final Intent intent = new Intent ( this , target ) ; <nl> final String textExtra = getIntent ( ) . getStringExtra ( Intent . EXTRA_TEXT ) ; <nl> - final Uri streamExtra = getIntent ( ) . getParcelableExtra ( Intent . EXTRA_STREAM ) ; <nl> + final Uri streamExtra = getStreamExtra ( ) ; <nl> final String type = streamExtra ! = null ? getMimeType ( streamExtra ) : getIntent ( ) . getType ( ) ; <nl> <nl> if ( ContentType . isImageType ( type ) ) { <nl>\n", "msg": "transform google photos nonsense URI scheme to something usable when necessary\n"}
{"diff_id": 28072, "repo": "spring-projects/spring-boot\n", "sha": "cd1a228210486963bb876b213115c7f42198333b\n", "time": "2013-12-18T18:03:30Z\n", "diff": "mmm a / spring - boot - actuator / src / main / java / org / springframework / boot / actuate / autoconfigure / EndpointMBeanExportAutoConfiguration . java <nl> ppp b / spring - boot - actuator / src / main / java / org / springframework / boot / actuate / autoconfigure / EndpointMBeanExportAutoConfiguration . java <nl> <nl> <nl> package org . springframework . boot . actuate . autoconfigure ; <nl> <nl> + import org . springframework . boot . actuate . endpoint . Endpoint ; <nl> import org . springframework . boot . actuate . endpoint . jmx . EndpointMBeanExporter ; <nl> import org . springframework . boot . autoconfigure . AutoConfigureAfter ; <nl> + import org . springframework . boot . autoconfigure . EnableAutoConfiguration ; <nl> import org . springframework . boot . autoconfigure . condition . ConditionalOnBean ; <nl> + import org . springframework . boot . autoconfigure . condition . ConditionalOnExpression ; <nl> import org . springframework . context . annotation . Bean ; <nl> import org . springframework . context . annotation . Configuration ; <nl> import org . springframework . jmx . export . MBeanExporter ; <nl> <nl> + / * * <nl> + * { @ link EnableAutoConfiguration Auto - configuration } to enable JMX export for <nl> + * { @ link Endpoint } s . <nl> + * <nl> + * @ author Christian Dupuis <nl> + * / <nl> @ Configuration <nl> @ ConditionalOnBean ( { MBeanExporter . class } ) <nl> @ AutoConfigureAfter ( { EndpointAutoConfiguration . class } ) <nl> + @ ConditionalOnExpression ( \" $ { endpoints . jmx . enabled : true } \" ) <nl> class EndpointMBeanExportAutoConfiguration { <nl> <nl> @ Bean <nl> public EndpointMBeanExporter endpointMBeanExporter ( ) { <nl> + / / TODO add configuration for domain name <nl> return new EndpointMBeanExporter ( ) ; <nl> } <nl> <nl>\n", "msg": "Allow Endpoint JMX export to be switched off\n"}
{"diff_id": 28075, "repo": "jenkinsci/jenkins\n", "sha": "d773642ed0e20dca4bb7ed384dc146e580e52c7f\n", "time": "2016-08-01T15:34:47Z\n", "diff": "mmm a / core / src / main / java / jenkins / util / SystemProperties . java <nl> ppp b / core / src / main / java / jenkins / util / SystemProperties . java <nl> <nl> <nl> import edu . umd . cs . findbugs . annotations . CheckForNull ; <nl> import edu . umd . cs . findbugs . annotations . Nullable ; <nl> + import edu . umd . cs . findbugs . annotations . SuppressFBWarnings ; <nl> import hudson . EnvVars ; <nl> import java . util . logging . Level ; <nl> import java . util . logging . Logger ; <nl> public SystemProperties ( ) { } <nl> * Called by the servlet container to initialize the { @ link ServletContext } . <nl> * / <nl> @ Override <nl> + @ SuppressFBWarnings ( value = \" ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD \" , <nl> + justification = \" Currently Jenkins instance may have one ond only one context \" ) <nl> public void contextInitialized ( ServletContextEvent event ) { <nl> theContext = event . getServletContext ( ) ; <nl> } <nl>\n", "msg": "Suppress warning about writing static SystemProperties # theContext from a non - static method\n"}
{"diff_id": 28081, "repo": "netty/netty\n", "sha": "4a18a143d2907812f5ab6ddeaa99063ecabc5614\n", "time": "2016-09-13T23:57:29Z\n", "diff": "mmm a / handler / src / main / java / io / netty / handler / timeout / IdleStateHandler . java <nl> ppp b / handler / src / main / java / io / netty / handler / timeout / IdleStateHandler . java <nl> public void channelRead ( ChannelHandlerContext ctx , Object msg ) throws Exception <nl> <nl> @ Override <nl> public void channelReadComplete ( ChannelHandlerContext ctx ) throws Exception { <nl> - if ( readerIdleTimeNanos > 0 | | allIdleTimeNanos > 0 ) { <nl> + if ( ( readerIdleTimeNanos > 0 | | allIdleTimeNanos > 0 ) & & reading ) { <nl> lastReadTime = System . nanoTime ( ) ; <nl> reading = false ; <nl> } <nl>\n", "msg": "Only set lastReadTime if an read actually happened before in IdleStateHandler .\n"}
{"diff_id": 28142, "repo": "oracle/graal\n", "sha": "b9bc63a57912b0993a4ac687a0deec83a1660f3b\n", "time": "2018-08-06T12:06:15Z\n", "diff": "mmm a / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / text / LLInstructionMapper . java <nl> ppp b / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / text / LLInstructionMapper . java <nl> <nl> import com . oracle . truffle . llvm . parser . model . symbols . instructions . ConditionalBranchInstruction ; <nl> import com . oracle . truffle . llvm . parser . model . symbols . instructions . DbgDeclareInstruction ; <nl> import com . oracle . truffle . llvm . parser . model . symbols . instructions . DbgValueInstruction ; <nl> + import com . oracle . truffle . llvm . parser . model . symbols . instructions . DebugTrapInstruction ; <nl> import com . oracle . truffle . llvm . parser . model . symbols . instructions . FenceInstruction ; <nl> import com . oracle . truffle . llvm . parser . model . symbols . instructions . IndirectBranchInstruction ; <nl> import com . oracle . truffle . llvm . parser . model . symbols . instructions . Instruction ; <nl> public void visit ( ReadModifyWriteInstruction inst ) { <nl> assignInstructionLocation ( inst , \" atomicrmw \" ) ; <nl> } <nl> <nl> + @ Override <nl> + public void visit ( DebugTrapInstruction inst ) { <nl> + assignInstructionLocation ( inst , \" tail \" , \" call \" ) ; <nl> + } <nl> + <nl> @ Override <nl> public void visit ( InstructionBlock block ) { <nl> block . accept ( this ) ; <nl>\n", "msg": "Support the @ llvm . debugtrap Intrinsic for IR - Level Debugging\n"}
{"diff_id": 28143, "repo": "google/ExoPlayer\n", "sha": "7f135f2cda7c4108bcb105a7dfad12e1c13a307d\n", "time": "2017-11-07T14:43:38Z\n", "diff": "mmm a / library / core / src / main / java / com / google / android / exoplayer2 / upstream / Loader . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / upstream / Loader . java <nl> public void handleMessage ( Message msg ) { <nl> callback . onLoadCanceled ( loadable , nowMs , durationMs , false ) ; <nl> break ; <nl> case MSG_END_OF_SOURCE : <nl> - callback . onLoadCompleted ( loadable , nowMs , durationMs ) ; <nl> + try { <nl> + callback . onLoadCompleted ( loadable , nowMs , durationMs ) ; <nl> + } catch ( RuntimeException e ) { <nl> + / / This should never happen , but handle it anyway . <nl> + Log . e ( TAG , \" Unexpected exception handling load completed \" , e ) ; <nl> + fatalError = new UnexpectedLoaderException ( e ) ; <nl> + } <nl> break ; <nl> case MSG_IO_EXCEPTION : <nl> currentError = ( IOException ) msg . obj ; <nl> public void handleMessage ( Message msg ) { <nl> start ( getRetryDelayMillis ( ) ) ; <nl> } <nl> break ; <nl> + default : <nl> + / / Never happens . <nl> + break ; <nl> } <nl> } <nl> <nl>\n", "msg": "Be more robust against load callback failures\n"}
{"diff_id": 28144, "repo": "netty/netty\n", "sha": "a92ed57b182a0e19f0de13a59f3a572034f8759f\n", "time": "2012-07-07T05:30:25Z\n", "diff": "mmm a / buffer / src / main / java / io / netty / buffer / CompositeByteBuf . java <nl> ppp b / buffer / src / main / java / io / netty / buffer / CompositeByteBuf . java <nl> private void copyTo ( int index , int length , int componentId , ByteBuf dst ) { <nl> dst . writerIndex ( dst . capacity ( ) ) ; <nl> } <nl> <nl> + / * * <nl> + * Gets the { @ link ByteBuf } used at the specified index . <nl> + * < p > <nl> + * Please note that since a { @ link CompositeByteBuf } is made up of <nl> + * multiple { @ link ByteBuf } s , this does < em > not < / em > return the full buffer . <nl> + * Instead , it only returns a portion of the composite buffer where the <nl> + * index is located <nl> + * < / p > <nl> + * <nl> + * < p > <nl> + * This is a method meant for use by < em > experts < / em > - Please be careful <nl> + * when using it . <nl> + * < / p > <nl> + * <nl> + * @ param index The index to use <nl> + * @ return The { @ link ByteBuf } used at the indes . <nl> + * @ throws IndexOutOfBoundsException <nl> + * / <nl> public ByteBuf getBufferFor ( int index ) throws IndexOutOfBoundsException { <nl> if ( index < 0 | | index > capacity ( ) ) { <nl> throw new IndexOutOfBoundsException ( \" Invalid index : \" + index <nl> + \" - Bytes needed : \" + ( index ) + \" , maximum is \" <nl> + capacity ( ) ) ; <nl> } <nl> - <nl> - int componentId = componentId ( index ) ; <nl> <nl> / / Return the component byte buffer <nl> - return components [ componentId ] . duplicate ( ) ; <nl> + return components [ componentId ( index ) ] ; <nl> <nl> } <nl> <nl>\n", "msg": "Add documentation and changes to ComposityByteBuf . getBufferFor ( index )\n"}
{"diff_id": 28158, "repo": "google/ExoPlayer\n", "sha": "e8072125144abb3dfebdaf37890ba500a21396ba\n", "time": "2018-07-07T16:28:58Z\n", "diff": "mmm a / library / core / src / main / java / com / google / android / exoplayer2 / extractor / mkv / MatroskaExtractor . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / extractor / mkv / MatroskaExtractor . java <nl> public int read ( ExtractorInput input , PositionHolder seekPosition ) throws IOExce <nl> currentTrack . number = ( int ) value ; <nl> break ; <nl> case ID_FLAG_DEFAULT : <nl> - currentTrack . flagForced = value = = 1 ; <nl> + currentTrack . flagDefault = value = = 1 ; <nl> break ; <nl> case ID_FLAG_FORCED : <nl> - currentTrack . flagDefault = value = = 1 ; <nl> + currentTrack . flagForced = value = = 1 ; <nl> break ; <nl> case ID_TRACK_TYPE : <nl> currentTrack . type = ( int ) value ; <nl>\n", "msg": "flip flag values to their proper names so that trackselector parameters can be useful\n"}
{"diff_id": 28201, "repo": "oracle/graal\n", "sha": "810293fb949bf462a21fc3a4489de9d2fb9c1fc1\n", "time": "2020-01-15T20:32:24Z\n", "diff": "mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / jni / JniEnv . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / jni / JniEnv . java <nl> public void ReleasePrimitiveArrayCritical ( @ Host ( Object . class ) StaticObject objec <nl> return instance ; <nl> } <nl> <nl> + / * * <nl> + * < h3 > jstring NewStringUTF ( JNIEnv * env , const char * bytes ) ; < / h3 > <nl> + * <nl> + * Constructs a new java . lang . String object from an array of characters in modified UTF - 8 <nl> + * encoding . <nl> + * <nl> + * @ param bytesPtr pointer to a modified UTF - 8 string . <nl> + * <nl> + * @ return a Java string object , or NULL if the string cannot be constructed . <nl> + * <nl> + * @ throws OutOfMemoryError if the system runs out of memory . <nl> + * / <nl> @ JniImpl <nl> - public @ Host ( String . class ) StaticObject NewStringUTF ( String hostString ) { <nl> - / / FIXME ( peterssen ) : This relies on TruffleNFI implicit char * - > String conversion that <nl> - / / uses host NewStringUTF . <nl> + public @ Host ( String . class ) StaticObject NewStringUTF ( @ Word long bytesPtr ) { <nl> + String hostString = fromUTF8Ptr ( bytesPtr ) ; <nl> return getMeta ( ) . toGuestString ( hostString ) ; <nl> } <nl> <nl> public int UnregisterNatives ( @ Host ( Class . class ) StaticObject clazz ) { <nl> throw EspressoError . shouldNotReachHere ( \" Field not found \" + field ) ; <nl> } <nl> <nl> + / * * <nl> + * < h3 > jobject NewDirectByteBuffer ( JNIEnv * env , void * address , jlong capacity ) ; < / h3 > <nl> + * <nl> + * Allocates and returns a direct java . nio . ByteBuffer referring to the block of memory starting <nl> + * at the memory address address and extending capacity bytes . <nl> + * <nl> + * Native code that calls this function and returns the resulting byte - buffer object to <nl> + * Java - level code should ensure that the buffer refers to a valid region of memory that is <nl> + * accessible for reading and , if appropriate , writing . An attempt to access an invalid memory <nl> + * location from Java code will either return an arbitrary value , have no visible effect , or <nl> + * cause an unspecified exception to be thrown . <nl> + * <nl> + * @ param address the starting address of the memory region ( must not be NULL ) <nl> + * <nl> + * @ param capacity the size in bytes of the memory region ( must be positive ) <nl> + * <nl> + * @ return a local reference to the newly - instantiated java . nio . ByteBuffer object . Returns NULL <nl> + * if an exception occurs , or if JNI access to direct buffers is not supported by this <nl> + * virtual machine . <nl> + * @ throws OutOfMemoryError if allocation of the ByteBuffer object fails <nl> + * / <nl> + @ JniImpl <nl> + public @ Host ( typeName = \" Ljava / nio / DirectByteBuffer ; \" ) StaticObject NewDirectByteBuffer ( @ Word long address , long capacity ) { <nl> + Meta meta = getMeta ( ) ; <nl> + StaticObject instance = meta . java_nio_DirectByteBuffer . allocateInstance ( ) ; <nl> + meta . java_nio_DirectByteBuffer_init_long_int . invokeDirect ( instance , address , ( int ) capacity ) ; <nl> + return instance ; <nl> + } <nl> + <nl> + / / region JNI handles <nl> + <nl> + / * * <nl> + * < h3 > jobject NewGlobalRef ( JNIEnv * env , jobject obj ) ; < / h3 > <nl> + * <nl> + * Creates a new global reference to the object referred to by the obj argument . The <nl> + * < b > handle < / b > argument may be a global or local reference . Global references must be <nl> + * explicitly disposed of by calling DeleteGlobalRef ( ) . <nl> + * <nl> + * @ param handle a global or local reference . <nl> + * @ return a global reference , or NULL if the system runs out of memory . <nl> + * / <nl> + @ JniImpl <nl> + public @ Word long NewGlobalRef ( @ Word long handle ) { <nl> + return getHandles ( ) . createGlobal ( getHandles ( ) . get ( Math . toIntExact ( handle ) ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * < h3 > void DeleteGlobalRef ( JNIEnv * env , jobject globalRef ) ; < / h3 > <nl> + * <nl> + * Deletes the global reference pointed to by globalRef . <nl> + * <nl> + * @ param handle a global reference . <nl> + * / <nl> + @ JniImpl <nl> + public void DeleteGlobalRef ( @ Word long handle ) { <nl> + getHandles ( ) . deleteGlobalRef ( Math . toIntExact ( handle ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * < h3 > void DeleteLocalRef ( JNIEnv * env , jobject localRef ) ; < / h3 > <nl> + * <nl> + * Deletes the local reference pointed to by localRef . <nl> + * <nl> + * < p > <nl> + * < b > Note : < / b > JDK / JRE 1 . 1 provides the DeleteLocalRef function above so that programmers can <nl> + * manually delete local references . For example , if native code iterates through a potentially <nl> + * large array of objects and uses one element in each iteration , it is a good practice to <nl> + * delete the local reference to the no - longer - used array element before a new local reference <nl> + * is created in the next iteration . <nl> + * <nl> + * As of JDK / JRE 1 . 2 an additional set of functions are provided for local reference lifetime <nl> + * management . They are the four functions listed below . <nl> + * <nl> + * @ param handle a local reference . <nl> + * / <nl> + @ JniImpl <nl> + public void DeleteLocalRef ( @ Word long handle ) { <nl> + getHandles ( ) . deleteLocalRef ( Math . toIntExact ( handle ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * < h3 > jweak NewWeakGlobalRef ( JNIEnv * env , jobject obj ) ; < / h3 > <nl> + * <nl> + * Creates a new weak global reference . Returns NULL if obj refers to null , or if the VM runs <nl> + * out of memory . If the VM runs out of memory , an OutOfMemoryError will be thrown . <nl> + * / <nl> + @ JniImpl <nl> + public @ Word long NewWeakGlobalRef ( @ Word long handle ) { <nl> + return getHandles ( ) . createWeakGlobal ( getHandles ( ) . get ( Math . toIntExact ( handle ) ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * < h3 > void DeleteWeakGlobalRef ( JNIEnv * env , jweak obj ) ; < / h3 > <nl> + * <nl> + * Delete the VM resources needed for the given weak global reference . <nl> + * / <nl> + @ JniImpl <nl> + public void DeleteWeakGlobalRef ( @ Word long handle ) { <nl> + getHandles ( ) . deleteGlobalRef ( Math . toIntExact ( handle ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * < h3 > jint PushLocalFrame ( JNIEnv * env , jint capacity ) ; < / h3 > <nl> + * < p > <nl> + * Creates a new local reference frame , in which at least a given number of local references can <nl> + * be created . Returns 0 on success , a negative number and a pending OutOfMemoryError on <nl> + * failure . <nl> + * < p > <nl> + * Note that local references already created in previous local frames are still valid in the <nl> + * current local frame . <nl> + * / <nl> + @ JniImpl <nl> + public int PushLocalFrame ( int capacity ) { <nl> + getHandles ( ) . pushFrame ( capacity ) ; <nl> + return JNI_OK ; <nl> + } <nl> + <nl> + / * * <nl> + * < h3 > jobject PopLocalFrame ( JNIEnv * env , jobject result ) ; < / h3 > <nl> + * < p > <nl> + * Pops off the current local reference frame , frees all the local references , and returns a <nl> + * local reference in the previous local reference frame for the given result object . <nl> + * < p > <nl> + * Pass NULL as result if you do not need to return a reference to the previous frame . <nl> + * / <nl> + @ JniImpl <nl> + public static @ Host ( Object . class ) StaticObject PopLocalFrame ( @ Host ( Object . class ) StaticObject result ) { <nl> + return result ; <nl> + } <nl> + <nl> + / * * <nl> + * < h3 > jboolean IsSameObject ( JNIEnv * env , jobject ref1 , jobject ref2 ) ; < / h3 > <nl> + * <nl> + * Tests whether two references refer to the same Java object . <nl> + * <nl> + * @ param ref1 a Java object . <nl> + * @ param ref2 a Java object . <nl> + * <nl> + * @ return JNI_TRUE if ref1 and ref2 refer to the same Java object , or are both NULL ; otherwise , <nl> + * returns JNI_FALSE . <nl> + * / <nl> + @ JniImpl <nl> + public static boolean IsSameObject ( @ Host ( Object . class ) StaticObject ref1 , @ Host ( Object . class ) StaticObject ref2 ) { <nl> + return ref1 = = ref2 ; <nl> + } <nl> + <nl> + / * * <nl> + * < h3 > jobjectRefType GetObjectRefType ( JNIEnv * env , jobject obj ) ; < / h3 > <nl> + * <nl> + * Returns the type of the object referred to by the obj argument . The argument obj can either <nl> + * be a local , global or weak global reference . <nl> + * <nl> + * < ul > <nl> + * < li > If the argument obj is a weak global reference type , the return will be <nl> + * { @ link # JNIWeakGlobalRefType } . <nl> + * <nl> + * < li > If the argument obj is a global reference type , the return value will be <nl> + * { @ link # JNIGlobalRefType } . <nl> + * <nl> + * < li > If the argument obj is a local reference type , the return will be <nl> + * { @ link # JNILocalRefType } . <nl> + * <nl> + * < li > If the obj argument is not a valid reference , the return value for this function will be <nl> + * { @ link # JNIInvalidRefType } . <nl> + * < / ul > <nl> + * <nl> + * <nl> + * An invalid reference is a reference which is not a valid handle . That is , the obj pointer <nl> + * address does not point to a location in memory which has been allocated from one of the Ref <nl> + * creation functions or returned from a JNI function . <nl> + * <nl> + * As such , NULL would be an invalid reference and GetObjectRefType ( env , NULL ) would return <nl> + * JNIInvalidRefType . <nl> + * <nl> + * On the other hand , a null reference , which is a reference that points to a null , would return <nl> + * the type of reference that the null reference was originally created as . <nl> + * <nl> + * GetObjectRefType cannot be used on deleted references . <nl> + * <nl> + * Since references are typically implemented as pointers to memory data structures that can <nl> + * potentially be reused by any of the reference allocation services in the VM , once deleted , it <nl> + * is not specified what value the GetObjectRefType will return . <nl> + * <nl> + * @ param handle a local , global or weak global reference . <nl> + * <nl> + * @ return one of the following enumerated values defined as a < b > jobjectRefType < / b > : <nl> + * < ul > <nl> + * < li > { @ link # JNIInvalidRefType } = 0 <nl> + * < li > { @ link # JNILocalRefType } = 1 <nl> + * < li > { @ link # JNIGlobalRefType } = 2 <nl> + * < li > { @ link # JNIWeakGlobalRefType } = 3 <nl> + * < / ul > <nl> + * / <nl> + @ JniImpl <nl> + public / * C enum * / int GetObjectRefType ( @ Word long handle ) { <nl> + return getHandles ( ) . getObjectRefType ( Math . toIntExact ( handle ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * < h3 > jint EnsureLocalCapacity ( JNIEnv * env , jint capacity ) ; < / h3 > <nl> + * <nl> + * Ensures that at least a given number of local references can be created in the current <nl> + * thread . Returns 0 on success ; otherwise returns a negative number and throws an <nl> + * OutOfMemoryError . <nl> + * <nl> + * Before it enters a native method , the VM automatically ensures that at least 16 local <nl> + * references can be created . <nl> + * <nl> + * For backward compatibility , the VM allocates local references beyond the ensured capacity . <nl> + * ( As a debugging support , the VM may give the user warnings that too many local references are <nl> + * being created . In the JDK , the programmer can supply the - verbose : jni command line option to <nl> + * turn on these messages . ) The VM calls FatalError if no more local references can be created <nl> + * beyond the ensured capacity . <nl> + * / <nl> + @ JniImpl <nl> + public int EnsureLocalCapacity ( int capacity ) { <nl> + if ( capacity > = 0 & & <nl> + ( ( MAX_JNI_LOCAL_CAPACITY < = 0 ) | | ( capacity < = MAX_JNI_LOCAL_CAPACITY ) ) ) { <nl> + return JNI_OK ; <nl> + } else { <nl> + return JNI_ERR ; <nl> + } <nl> + } <nl> + <nl> + / / endregion JNI handles <nl> + <nl> / / Checkstyle : resume method name check <nl> } <nl>\n", "msg": "Implement methods to manage handles and the native frame .\n"}
{"diff_id": 28251, "repo": "netty/netty\n", "sha": "5b2bdd844db56079e6cb75b0e1142d337723e1c3\n", "time": "2014-07-25T04:34:35Z\n", "diff": "mmm a / common / src / main / java / io / netty / util / HashedWheelTimer . java <nl> ppp b / common / src / main / java / io / netty / util / HashedWheelTimer . java <nl> <nl> import java . util . concurrent . ThreadFactory ; <nl> import java . util . concurrent . TimeUnit ; <nl> import java . util . concurrent . atomic . AtomicIntegerFieldUpdater ; <nl> - import java . util . concurrent . locks . Lock ; <nl> - import java . util . concurrent . locks . ReentrantLock ; <nl> <nl> / * * <nl> * A { @ link Timer } optimized for approximated I / O timeout scheduling . <nl> <nl> private final int mask ; <nl> private final CountDownLatch startTimeInitialized = new CountDownLatch ( 1 ) ; <nl> private final Queue < HashedWheelTimeout > timeouts = PlatformDependent . newMpscQueue ( ) ; <nl> + private final Queue < Runnable > cancelledTimeouts = PlatformDependent . newMpscQueue ( ) ; <nl> <nl> private volatile long startTime ; <nl> <nl> public void run ( ) { <nl> final long deadline = waitForNextTick ( ) ; <nl> if ( deadline > 0 ) { <nl> int idx = ( int ) ( tick & mask ) ; <nl> + processCancelledTasks ( ) ; <nl> HashedWheelBucket bucket = <nl> wheel [ idx ] ; <nl> - bucket . lock . lock ( ) ; <nl> - try { <nl> - transferTimeoutsToBuckets ( ) ; <nl> - bucket . expireTimeouts ( deadline ) ; <nl> - } finally { <nl> - bucket . lock . unlock ( ) ; <nl> - } <nl> + transferTimeoutsToBuckets ( ) ; <nl> + bucket . expireTimeouts ( deadline ) ; <nl> tick + + ; <nl> } <nl> } while ( WORKER_STATE_UPDATER . get ( HashedWheelTimer . this ) = = WORKER_STATE_STARTED ) ; <nl> public void run ( ) { <nl> if ( timeout = = null ) { <nl> break ; <nl> } <nl> - unprocessedTimeouts . add ( timeout ) ; <nl> + if ( ! timeout . isCancelled ( ) ) { <nl> + unprocessedTimeouts . add ( timeout ) ; <nl> + } <nl> } <nl> + processCancelledTasks ( ) ; <nl> } <nl> <nl> private void transferTimeoutsToBuckets ( ) { <nl> private void transferTimeoutsToBuckets ( ) { <nl> bucket . addTimeout ( timeout ) ; <nl> } <nl> } <nl> + <nl> + private void processCancelledTasks ( ) { <nl> + for ( ; ; ) { <nl> + Runnable task = cancelledTimeouts . poll ( ) ; <nl> + if ( task = = null ) { <nl> + / / all processed <nl> + break ; <nl> + } <nl> + try { <nl> + task . run ( ) ; <nl> + } catch ( Throwable t ) { <nl> + if ( logger . isWarnEnabled ( ) ) { <nl> + logger . warn ( \" An exception was thrown while process a cancellation task \" , t ) ; <nl> + } <nl> + } <nl> + } <nl> + } <nl> + <nl> / * * <nl> * calculate goal nanoTime from startTime and current tick number , <nl> * then wait until that goal has been reached . <nl> public boolean cancel ( ) { <nl> if ( ! compareAndSetState ( ST_INIT , ST_CANCELLED ) ) { <nl> return false ; <nl> } <nl> - HashedWheelBucket bucket = this . bucket ; <nl> - if ( bucket ! = null ) { <nl> - / / if tryLock fails it means that HashedWheelBucket is currently processed and so there is nothing for <nl> - / / us to do as the remove itself will be done while processing . <nl> - if ( bucket . lock . tryLock ( ) ) { <nl> - try { <nl> - bucket . remove ( this ) ; <nl> - } finally { <nl> - bucket . lock . unlock ( ) ; <nl> + / / If a task should be canceled we create a new Runnable for this to another queue which will <nl> + / / be processed on each tick . So this means that we will have a GC latency of max . 1 tick duration <nl> + / / which is good enough . This way we can make again use of our MpscLinkedQueue and so minimize the <nl> + / / locking / overhead as much as possible . <nl> + / / <nl> + / / It is important that we not just add the HashedWheelTimeout itself again as it extends <nl> + / / MpscLinkedQueueNode and so may still be used as tombstone . <nl> + timer . cancelledTimeouts . add ( new Runnable ( ) { <nl> + @ Override <nl> + public void run ( ) { <nl> + HashedWheelBucket bucket = HashedWheelTimeout . this . bucket ; <nl> + if ( bucket ! = null ) { <nl> + bucket . remove ( HashedWheelTimeout . this ) ; <nl> } <nl> } <nl> - } <nl> + } ) ; <nl> return true ; <nl> } <nl> <nl> public String toString ( ) { <nl> * extra object creation is needed . <nl> * / <nl> private static final class HashedWheelBucket { <nl> - <nl> - / / Lock used during processing of each HashedWheelBucket . The Lock will be acquired on each tick for the <nl> - / / current HashedWheelBucket and also tried to acquired when a HashedWheelTimeout should be cancelled . <nl> - / / This allows fast GC for cancelled HashedWheelTimeouts . <nl> - private final Lock lock = new ReentrantLock ( ) ; <nl> - <nl> / / Used for the linked - list datastructure <nl> private HashedWheelTimeout head ; <nl> private HashedWheelTimeout tail ; <nl>\n", "msg": "[ ] Fix race in cancellation of TimerTasks which could let to NPE\n"}
{"diff_id": 28349, "repo": "netty/netty\n", "sha": "26ed1a99721a8332108cf29a9fc7c18a1d344025\n", "time": "2012-06-29T07:03:47Z\n", "diff": "mmm a / codec - http / src / main / java / io / netty / handler / codec / http / HttpCodecUtil . java <nl> ppp b / codec - http / src / main / java / io / netty / handler / codec / http / HttpCodecUtil . java <nl> <nl> <nl> import java . util . List ; <nl> <nl> + / * * <nl> + * A utility class mainly for use with HTTP codec classes <nl> + * / <nl> final class HttpCodecUtil { <nl> <nl> - static void validateHeaderName ( String name ) { <nl> - if ( name = = null ) { <nl> - throw new NullPointerException ( \" name \" ) ; <nl> + / * * <nl> + * Validates the name of a header <nl> + * <nl> + * @ param headerName The header name being validated <nl> + * / <nl> + static void validateHeaderName ( String headerName ) { <nl> + / / Check to see if the name is null <nl> + if ( headerName = = null ) { <nl> + throw new NullPointerException ( \" Header names cannot be null \" ) ; <nl> } <nl> - for ( int i = 0 ; i < name . length ( ) ; i + + ) { <nl> - char c = name . charAt ( i ) ; <nl> - if ( c > 127 ) { <nl> + / / Go through each of the characters in the name <nl> + for ( int index = 0 ; index < headerName . length ( ) ; index + + ) { <nl> + / / Actually get the character <nl> + char character = headerName . charAt ( index ) ; <nl> + <nl> + / / Check to see if the character is not an ASCII character <nl> + if ( character > 127 ) { <nl> throw new IllegalArgumentException ( <nl> - \" name contains non - ascii character : \" + name ) ; <nl> + \" Header name cannot contain non - ASCII characters : \" + headerName ) ; <nl> } <nl> <nl> - / / Check prohibited characters . <nl> - switch ( c ) { <nl> + / / Check for prohibited characters . <nl> + switch ( character ) { <nl> case ' \\ t ' : case ' \\ n ' : case 0x0b : case ' \\ f ' : case ' \\ r ' : <nl> case ' ' : case ' , ' : case ' : ' : case ' ; ' : case ' = ' : <nl> throw new IllegalArgumentException ( <nl> - \" name contains one of the following prohibited characters : \" + <nl> - \" = , ; : \\ \\ t \\ \\ r \\ \\ n \\ \\ v \\ \\ f : \" + name ) ; <nl> + \" Header name cannot contain the following prohibited characters : \" + <nl> + \" = , ; : \\ \\ t \\ \\ r \\ \\ n \\ \\ v \\ \\ f : \" + headerName ) ; <nl> } <nl> } <nl> } <nl> <nl> - static void validateHeaderValue ( String value ) { <nl> - if ( value = = null ) { <nl> - throw new NullPointerException ( \" value \" ) ; <nl> + / * * <nl> + * Validates the specified header value <nl> + * <nl> + * @ param value The value being validated <nl> + * / <nl> + static void validateHeaderValue ( String headerValue ) { <nl> + / / Check to see if the value is null <nl> + if ( headerValue = = null ) { <nl> + throw new NullPointerException ( \" Header values cannot be null \" ) ; <nl> } <nl> <nl> - / / 0 - the previous character was neither CR nor LF <nl> - / / 1 - the previous character was CR <nl> - / / 2 - the previous character was LF <nl> + / * <nl> + * Set up the state of the validation <nl> + * <nl> + * States are as follows : <nl> + * <nl> + * 0 : Previous character was neither CR nor LF <nl> + * 1 : The previous character was CR <nl> + * 2 : The previous character was LF <nl> + * / <nl> int state = 0 ; <nl> <nl> - for ( int i = 0 ; i < value . length ( ) ; i + + ) { <nl> - char c = value . charAt ( i ) ; <nl> + / / Start looping through each of the character <nl> + <nl> + for ( int index = 0 ; index < headerValue . length ( ) ; index + + ) { <nl> + char character = headerValue . charAt ( index ) ; <nl> <nl> - / / Check the absolutely prohibited characters . <nl> - switch ( c ) { <nl> + / / Check the absolutely prohibited characters . <nl> + switch ( character ) { <nl> case 0x0b : / / Vertical tab <nl> throw new IllegalArgumentException ( <nl> - \" value contains a prohibited character ' \\ \\ v ' : \" + value ) ; <nl> + \" Header value contains a prohibited character ' \\ \\ v ' : \" + headerValue ) ; <nl> case ' \\ f ' : <nl> throw new IllegalArgumentException ( <nl> - \" value contains a prohibited character ' \\ \\ f ' : \" + value ) ; <nl> + \" Header value contains a prohibited character ' \\ \\ f ' : \" + headerValue ) ; <nl> } <nl> <nl> / / Check the CRLF ( HT | SP ) pattern <nl> switch ( state ) { <nl> case 0 : <nl> - switch ( c ) { <nl> + switch ( character ) { <nl> case ' \\ r ' : <nl> state = 1 ; <nl> break ; <nl> static void validateHeaderValue ( String value ) { <nl> } <nl> break ; <nl> case 1 : <nl> - switch ( c ) { <nl> + switch ( character ) { <nl> case ' \\ n ' : <nl> state = 2 ; <nl> break ; <nl> default : <nl> throw new IllegalArgumentException ( <nl> - \" Only ' \\ \\ n ' is allowed after ' \\ \\ r ' : \" + value ) ; <nl> + \" Only ' \\ \\ n ' is allowed after ' \\ \\ r ' : \" + headerValue ) ; <nl> } <nl> break ; <nl> case 2 : <nl> - switch ( c ) { <nl> + switch ( character ) { <nl> case ' \\ t ' : case ' ' : <nl> state = 0 ; <nl> break ; <nl> default : <nl> throw new IllegalArgumentException ( <nl> - \" Only ' ' and ' \\ \\ t ' are allowed after ' \\ \\ n ' : \" + value ) ; <nl> + \" Only ' ' and ' \\ \\ t ' are allowed after ' \\ \\ n ' : \" + headerValue ) ; <nl> } <nl> } <nl> } <nl> <nl> if ( state ! = 0 ) { <nl> throw new IllegalArgumentException ( <nl> - \" value must not end with ' \\ \\ r ' or ' \\ \\ n ' : \" + value ) ; <nl> + \" Header value must not end with ' \\ \\ r ' or ' \\ \\ n ' : \" + headerValue ) ; <nl> } <nl> } <nl> <nl> - static boolean isTransferEncodingChunked ( HttpMessage m ) { <nl> - List < String > chunked = m . getHeaders ( HttpHeaders . Names . TRANSFER_ENCODING ) ; <nl> - if ( chunked . isEmpty ( ) ) { <nl> + / * * <nl> + * Checks to see if the transfer encoding in a specified { @ link HttpMessage } is chunked <nl> + * <nl> + * @ param message The message to check <nl> + * @ return True if transfer encoding is chunked , otherwise false <nl> + * / <nl> + static boolean isTransferEncodingChunked ( HttpMessage message ) { <nl> + List < String > transferEncodingHeaders = message . getHeaders ( HttpHeaders . Names . TRANSFER_ENCODING ) ; <nl> + if ( transferEncodingHeaders . isEmpty ( ) ) { <nl> return false ; <nl> } <nl> <nl> - for ( String v : chunked ) { <nl> - if ( v . equalsIgnoreCase ( HttpHeaders . Values . CHUNKED ) ) { <nl> + for ( String value : transferEncodingHeaders ) { <nl> + if ( value . equalsIgnoreCase ( HttpHeaders . Values . CHUNKED ) ) { <nl> return true ; <nl> } <nl> } <nl> return false ; <nl> } <nl> <nl> + / * * <nl> + * A constructor to ensure that instances of this class are never made <nl> + * / <nl> private HttpCodecUtil ( ) { <nl> } <nl> } <nl>\n", "msg": "Documentation and slight internal refactoring of HttpCodecUtil\n"}
{"diff_id": 28357, "repo": "ReactiveX/RxJava\n", "sha": "38ad57c1e90f982a2715c350ce3994c4f4d5c0e7\n", "time": "2013-01-30T01:13:21Z\n", "diff": "mmm a / rxjava - core / src / main / java / rx / observables / Observable . java <nl> ppp b / rxjava - core / src / main / java / rx / observables / Observable . java <nl> <nl> import java . util . Map ; <nl> import java . util . concurrent . Future ; <nl> import java . util . concurrent . TimeUnit ; <nl> + import java . util . concurrent . TimeoutException ; <nl> <nl> import org . junit . Before ; <nl> import org . junit . Test ; <nl> public T call ( T t1 , T t2 ) { <nl> * <nl> * Any object that supports the { @ link Future } interface can be converted into a Observable that emits <nl> * the return value of the get ( ) method in the object , by passing the object into the < code > toObservable < / code > method . <nl> + * The subscribe method on this synchronously so the Subscription returned doesn ' t nothing . <nl> * <nl> * @ param future <nl> * the source { @ link Future } <nl> public T call ( T t1 , T t2 ) { <nl> * <nl> * Any object that supports the { @ link Future } interface can be converted into a Observable that emits <nl> * the return value of the get ( ) method in the object , by passing the object into the < code > toObservable < / code > method . <nl> + * The subscribe method on this synchronously so the Subscription returned doesn ' t nothing . <nl> + * If the future timesout the { @ link TimeoutException } exception is passed to the onError . <nl> * <nl> * @ param future <nl> * the source { @ link Future } <nl>\n", "msg": "adding more details about how the toObservable behaves .\n"}
{"diff_id": 28537, "repo": "jenkinsci/jenkins\n", "sha": "435f61040940242af563ef9032ad0f0768e9538e\n", "time": "2012-04-12T21:41:16Z\n", "diff": "mmm a / core / src / main / java / hudson / model / MyViewsProperty . java <nl> ppp b / core / src / main / java / hudson / model / MyViewsProperty . java <nl> <nl> import java . io . IOException ; <nl> import java . text . ParseException ; <nl> import java . util . Collection ; <nl> + import java . util . Collections ; <nl> import java . util . List ; <nl> import java . util . concurrent . CopyOnWriteArrayList ; <nl> <nl> <nl> import org . kohsuke . stapler . HttpRedirect ; <nl> import org . kohsuke . stapler . HttpResponse ; <nl> import org . kohsuke . stapler . QueryParameter ; <nl> + import org . kohsuke . stapler . StaplerFallback ; <nl> import org . kohsuke . stapler . StaplerRequest ; <nl> import org . kohsuke . stapler . StaplerResponse ; <nl> <nl> <nl> * <nl> * @ author Tom Huybrechts <nl> * / <nl> - public class MyViewsProperty extends UserProperty implements ViewGroup , Action { <nl> + public class MyViewsProperty extends UserProperty implements ViewGroup , Action , StaplerFallback { <nl> private String primaryViewName ; <nl> <nl> / * * <nl> public ViewsTabBar getViewsTabBar ( ) { <nl> } <nl> <nl> public ItemGroup < ? extends TopLevelItem > getItemGroup ( ) { <nl> - return Hudson . getInstance ( ) ; <nl> + return Jenkins . getInstance ( ) ; <nl> } <nl> <nl> public List < Action > getViewActions ( ) { <nl> - return Hudson . getInstance ( ) . getActions ( ) ; <nl> + / / Jenkins . getInstance ( ) . getViewActions ( ) are tempting but they are in a wrong scope <nl> + return Collections . emptyList ( ) ; <nl> + } <nl> + <nl> + public Object getStaplerFallback ( ) { <nl> + return getPrimaryView ( ) ; <nl> } <nl> <nl> public MyViewsTabBar getMyViewsTabBar ( ) { <nl>\n", "msg": "needs to delegate to primary view for actions\n"}
{"diff_id": 28619, "repo": "google/guava\n", "sha": "2769293fa44aeb60819a41150e6f20cd8f8ff0b4\n", "time": "2011-07-27T21:26:14Z\n", "diff": "new file mode 100644 <nl> index 0000000000 . . 27723dbfd6 <nl> mmm / dev / null <nl> ppp b / guava / src / com / google / common / collect / BstCountBasedBalancePolicies . java <nl> <nl> + / / Copyright 2011 Google Inc . All Rights Reserved . <nl> + <nl> + package com . google . common . collect ; <nl> + <nl> + import static com . google . common . base . Preconditions . checkNotNull ; <nl> + import static com . google . common . collect . BstNode . countOrZero ; <nl> + import static com . google . common . collect . BstSide . LEFT ; <nl> + import static com . google . common . collect . BstSide . RIGHT ; <nl> + import static com . google . common . collect . BstUtilities . extractMax ; <nl> + import static com . google . common . collect . BstUtilities . extractMin ; <nl> + import static com . google . common . collect . BstUtilities . insertMax ; <nl> + import static com . google . common . collect . BstUtilities . insertMin ; <nl> + <nl> + import com . google . common . annotations . GwtCompatible ; <nl> + <nl> + import javax . annotation . Nullable ; <nl> + <nl> + / * * <nl> + * A tree - size - based set of balancing policies , based on < a <nl> + * href = \" http : / / www . swiss . ai . mit . edu / ~ adams / BB / \" > Stephen Adams , \" Efficient sets : a balancing <nl> + * act . \" < / a > . <nl> + * <nl> + * @ author Louis Wasserman <nl> + * / <nl> + @ GwtCompatible <nl> + final class BstCountBasedBalancePolicies { <nl> + private BstCountBasedBalancePolicies ( ) { } <nl> + <nl> + private static final int SINGLE_ROTATE_RATIO = 4 ; <nl> + private static final int SECOND_ROTATE_RATIO = 2 ; <nl> + <nl> + / * * <nl> + * Returns a balance policy that does no balancing or the bare minimum ( for { @ code combine } ) . <nl> + * / <nl> + public static < N extends BstNode < ? , N > > BstBalancePolicy < N > noRebalancePolicy ( ) { <nl> + return new BstBalancePolicy < N > ( ) { <nl> + @ Override <nl> + public N balance ( <nl> + BstNodeFactory < N > nodeFactory , N source , @ Nullable N left , @ Nullable N right ) { <nl> + return checkNotNull ( nodeFactory ) . createNode ( source , left , right ) ; <nl> + } <nl> + <nl> + @ Nullable <nl> + @ Override <nl> + public N combine ( BstNodeFactory < N > nodeFactory , @ Nullable N left , @ Nullable N right ) { <nl> + if ( left = = null ) { <nl> + return right ; <nl> + } else if ( right = = null ) { <nl> + return left ; <nl> + } else if ( left . count ( ) > right . count ( ) ) { <nl> + return nodeFactory . createNode ( <nl> + left , left . childOrNull ( LEFT ) , combine ( nodeFactory , left . childOrNull ( RIGHT ) , right ) ) ; <nl> + } else { <nl> + return nodeFactory . createNode ( right , combine ( nodeFactory , left , right . childOrNull ( LEFT ) ) , <nl> + right . childOrNull ( RIGHT ) ) ; <nl> + } <nl> + } <nl> + } ; <nl> + } <nl> + <nl> + / * * <nl> + * Returns a balance policy that expects the sizes of each side to be at most one node ( added or <nl> + * removed ) away from being balanced . { @ code balance } takes { @ code O ( 1 ) } time , and { @ code <nl> + * combine } takes { @ code O ( log n ) } time . <nl> + * / <nl> + public static < K , N extends BstNode < K , N > > BstBalancePolicy < N > singleRebalancePolicy ( ) { <nl> + return new BstBalancePolicy < N > ( ) { <nl> + @ Override <nl> + public N balance ( <nl> + BstNodeFactory < N > nodeFactory , N source , @ Nullable N left , @ Nullable N right ) { <nl> + int countL = countOrZero ( left ) ; <nl> + int countR = countOrZero ( right ) ; <nl> + if ( countL + countR > 1 ) { <nl> + if ( countR > = SINGLE_ROTATE_RATIO * countL ) { <nl> + return rotateL ( nodeFactory , source , left , right ) ; <nl> + } else if ( countL > = SINGLE_ROTATE_RATIO * countR ) { <nl> + return rotateR ( nodeFactory , source , left , right ) ; <nl> + } <nl> + } <nl> + return nodeFactory . createNode ( source , left , right ) ; <nl> + } <nl> + <nl> + private N rotateL ( BstNodeFactory < N > nodeFactory , N source , @ Nullable N left , N right ) { <nl> + checkNotNull ( right ) ; <nl> + N rl = right . childOrNull ( LEFT ) ; <nl> + N rr = right . childOrNull ( RIGHT ) ; <nl> + if ( countOrZero ( rl ) > = SECOND_ROTATE_RATIO * countOrZero ( rr ) ) { <nl> + right = singleR ( nodeFactory , right , rl , rr ) ; <nl> + } <nl> + return singleL ( nodeFactory , source , left , right ) ; <nl> + } <nl> + <nl> + private N rotateR ( BstNodeFactory < N > nodeFactory , N source , N left , @ Nullable N right ) { <nl> + checkNotNull ( left ) ; <nl> + N lr = left . childOrNull ( RIGHT ) ; <nl> + N ll = left . childOrNull ( LEFT ) ; <nl> + if ( countOrZero ( lr ) > = SECOND_ROTATE_RATIO * countOrZero ( ll ) ) { <nl> + left = singleL ( nodeFactory , left , ll , lr ) ; <nl> + } <nl> + return singleR ( nodeFactory , source , left , right ) ; <nl> + } <nl> + <nl> + private N singleL ( BstNodeFactory < N > nodeFactory , N source , @ Nullable N left , N right ) { <nl> + checkNotNull ( right ) ; <nl> + return nodeFactory . createNode ( right , <nl> + nodeFactory . createNode ( source , left , right . childOrNull ( LEFT ) ) , <nl> + right . childOrNull ( RIGHT ) ) ; <nl> + } <nl> + <nl> + private N singleR ( BstNodeFactory < N > nodeFactory , N source , N left , @ Nullable N right ) { <nl> + checkNotNull ( left ) ; <nl> + return nodeFactory . createNode ( left , left . childOrNull ( LEFT ) , <nl> + nodeFactory . createNode ( source , left . childOrNull ( RIGHT ) , right ) ) ; <nl> + } <nl> + <nl> + @ Nullable <nl> + @ Override <nl> + public N combine ( BstNodeFactory < N > nodeFactory , @ Nullable N left , @ Nullable N right ) { <nl> + if ( left = = null ) { <nl> + return right ; <nl> + } else if ( right = = null ) { <nl> + return left ; <nl> + } <nl> + N newRootSource ; <nl> + if ( left . count ( ) > right . count ( ) ) { <nl> + BstMutationResult < K , N > extractLeftMax = extractMax ( left , nodeFactory , this ) ; <nl> + newRootSource = extractLeftMax . getOriginalTarget ( ) ; <nl> + left = extractLeftMax . getChangedRoot ( ) ; <nl> + } else { <nl> + BstMutationResult < K , N > extractRightMin = extractMin ( right , nodeFactory , this ) ; <nl> + newRootSource = extractRightMin . getOriginalTarget ( ) ; <nl> + right = extractRightMin . getChangedRoot ( ) ; <nl> + } <nl> + return nodeFactory . createNode ( newRootSource , left , right ) ; <nl> + } <nl> + } ; <nl> + } <nl> + <nl> + / * * <nl> + * Returns a balance policy that makes no assumptions on the relative balance of the two sides <nl> + * and performs a full rebalancing as necessary . Both { @ code balance } and { @ code combine } take <nl> + * { @ code O ( log n ) } time . <nl> + * / <nl> + public static < K , N extends BstNode < K , N > > BstBalancePolicy < N > fullRebalancePolicy ( ) { <nl> + final BstBalancePolicy < N > singleBalancePolicy = <nl> + BstCountBasedBalancePolicies . < K , N > singleRebalancePolicy ( ) ; <nl> + return new BstBalancePolicy < N > ( ) { <nl> + @ Override <nl> + public N balance ( <nl> + BstNodeFactory < N > nodeFactory , N source , @ Nullable N left , @ Nullable N right ) { <nl> + if ( left = = null ) { <nl> + return insertMin ( right , source , nodeFactory , singleBalancePolicy ) ; <nl> + } else if ( right = = null ) { <nl> + return insertMax ( left , source , nodeFactory , singleBalancePolicy ) ; <nl> + } <nl> + int countL = left . count ( ) ; <nl> + int countR = right . count ( ) ; <nl> + if ( SINGLE_ROTATE_RATIO * countL < = countR ) { <nl> + N resultLeft = balance ( nodeFactory , source , left , right . childOrNull ( LEFT ) ) ; <nl> + return singleBalancePolicy . balance ( <nl> + nodeFactory , right , resultLeft , right . childOrNull ( RIGHT ) ) ; <nl> + } else if ( SINGLE_ROTATE_RATIO * countR < = countL ) { <nl> + N resultRight = balance ( nodeFactory , source , left . childOrNull ( RIGHT ) , right ) ; <nl> + return singleBalancePolicy . balance ( <nl> + nodeFactory , left , left . childOrNull ( LEFT ) , resultRight ) ; <nl> + } else { <nl> + return nodeFactory . createNode ( source , left , right ) ; <nl> + } <nl> + } <nl> + <nl> + @ Nullable <nl> + @ Override <nl> + public N combine ( BstNodeFactory < N > nodeFactory , @ Nullable N left , @ Nullable N right ) { <nl> + if ( left = = null ) { <nl> + return right ; <nl> + } else if ( right = = null ) { <nl> + return left ; <nl> + } <nl> + int countL = left . count ( ) ; <nl> + int countR = right . count ( ) ; <nl> + if ( SINGLE_ROTATE_RATIO * countL < = countR ) { <nl> + N resultLeft = combine ( nodeFactory , left , right . childOrNull ( LEFT ) ) ; <nl> + return singleBalancePolicy . balance ( <nl> + nodeFactory , right , resultLeft , right . childOrNull ( RIGHT ) ) ; <nl> + } else if ( SINGLE_ROTATE_RATIO * countR < = countL ) { <nl> + N resultRight = combine ( nodeFactory , left . childOrNull ( RIGHT ) , right ) ; <nl> + return singleBalancePolicy . balance ( <nl> + nodeFactory , left , left . childOrNull ( LEFT ) , resultRight ) ; <nl> + } else { <nl> + return singleBalancePolicy . combine ( nodeFactory , left , right ) ; <nl> + } <nl> + } <nl> + } ; <nl> + } <nl> + } <nl>\n", "msg": "Implement BSTCountBasedBalancePolicies , which implements size - balancing of binary search trees .\n"}
{"diff_id": 28646, "repo": "elastic/elasticsearch\n", "sha": "fd19b42cbb303b26e3912926a16d575e4be91a1c\n", "time": "2014-07-02T20:13:44Z\n", "diff": "mmm a / src / test / java / org / elasticsearch / bwcompat / BasicBackwardsCompatibilityTest . java <nl> ppp b / src / test / java / org / elasticsearch / bwcompat / BasicBackwardsCompatibilityTest . java <nl> public void testIndexUpgradeSingleNode ( ) throws Exception { <nl> for ( int i = 0 ; i < numIters ; i + + ) { <nl> assertHitCount ( client ( ) . prepareCount ( ) . get ( ) , numDocs ) ; <nl> } <nl> - ensureGreen ( ) ; / / wait for all the relocation <nl> assertVersionCreated ( compatibilityVersion ( ) , \" test \" ) ; <nl> } <nl> <nl>\n", "msg": "[ TEST ] Don ' t wait for relocations - the ensureYellow ( ) call does that already\n"}
{"diff_id": 28672, "repo": "spring-projects/spring-framework\n", "sha": "ede9d535ea89b15e58efb11dfa4136659e6adf3c\n", "time": "2013-01-23T21:00:35Z\n", "diff": "mmm a / spring - context / src / main / java / org / springframework / context / support / AbstractRefreshableConfigApplicationContext . java <nl> ppp b / spring - context / src / main / java / org / springframework / context / support / AbstractRefreshableConfigApplicationContext . java <nl> <nl> / * <nl> - * Copyright 2002 - 2012 the original author or authors . <nl> + * Copyright 2002 - 2013 the original author or authors . <nl> * <nl> * Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> * you may not use this file except in compliance with the License . <nl> <nl> package org . springframework . context . support ; <nl> <nl> import org . springframework . beans . factory . BeanNameAware ; <nl> - <nl> import org . springframework . beans . factory . InitializingBean ; <nl> import org . springframework . context . ApplicationContext ; <nl> import org . springframework . util . Assert ; <nl> public void setConfigLocations ( String [ ] locations ) { <nl> <nl> / * * <nl> * Resolve the given path , replacing placeholders with corresponding <nl> - * system property values if necessary . Applied to config locations . <nl> + * environment property values if necessary . Applied to config locations . <nl> * @ param path the original file path <nl> * @ return the resolved file path <nl> + * @ see org . springframework . core . env . Environment # resolveRequiredPlaceholders ( String ) <nl> * / <nl> protected String resolvePath ( String path ) { <nl> - return this . getEnvironment ( ) . resolveRequiredPlaceholders ( path ) ; <nl> + return getEnvironment ( ) . resolveRequiredPlaceholders ( path ) ; <nl> } <nl> <nl> <nl>\n", "msg": "Updated resolvePath javadoc to reflect Environment - based placeholder resolution\n"}
{"diff_id": 28698, "repo": "oracle/graal\n", "sha": "73849375236bbca847949bd79c79b49a2f10f81f\n", "time": "2018-04-25T07:36:39Z\n", "diff": "mmm a / sdk / src / org . graalvm . launcher / src / org / graalvm / launcher / Launcher . java <nl> ppp b / sdk / src / org . graalvm . launcher / src / org / graalvm / launcher / Launcher . java <nl> boolean parsePolyglotOption ( String defaultOptionPrefix , Map < String , String > opti <nl> } catch ( IllegalArgumentException e ) { <nl> throw abort ( String . format ( \" Invalid argument % s specified . % s ' \" , arg , e . getMessage ( ) ) ) ; <nl> } <nl> - options . put ( key , value ) ; <nl> + / / use the full name of the found descriptor <nl> + options . put ( descriptor . getName ( ) , value ) ; <nl> return true ; <nl> } <nl> } <nl>\n", "msg": "Use the full name of the option when it ' s found using the default option prefix\n"}
{"diff_id": 28732, "repo": "netty/netty\n", "sha": "4f172c13bb25323894e45e3716e049809da14905\n", "time": "2019-07-16T11:08:09Z\n", "diff": "mmm a / codec - http2 / src / main / java / io / netty / handler / codec / http2 / Http2StreamChannelBootstrap . java <nl> ppp b / codec - http2 / src / main / java / io / netty / handler / codec / http2 / Http2StreamChannelBootstrap . java <nl> public Http2StreamChannelBootstrap ( Channel channel ) { <nl> / * * <nl> * the { @ link ChannelHandler } to use for serving the requests . <nl> * / <nl> - @ SuppressWarnings ( \" unchecked \" ) <nl> public Http2StreamChannelBootstrap handler ( ChannelHandler handler ) { <nl> this . handler = ObjectUtil . checkNotNull ( handler , \" handler \" ) ; <nl> return this ; <nl> } <nl> <nl> + / * * <nl> + * Open a new { @ link Http2StreamChannel } to use . <nl> + * @ return the { @ link Future } that will be notified once the channel was opened successfully or it failed . <nl> + * / <nl> public Future < Http2StreamChannel > open ( ) { <nl> return open ( channel . eventLoop ( ) . < Http2StreamChannel > newPromise ( ) ) ; <nl> } <nl> <nl> + / * * <nl> + * Open a new { @ link Http2StreamChannel } to use and notifies the given { @ link Promise } . <nl> + * @ return the { @ link Future } that will be notified once the channel was opened successfully or it failed . <nl> + * / <nl> + @ SuppressWarnings ( \" deprecation \" ) <nl> public Future < Http2StreamChannel > open ( final Promise < Http2StreamChannel > promise ) { <nl> ChannelHandlerContext ctx = channel . pipeline ( ) . context ( Http2MultiplexCodec . class ) ; <nl> if ( ctx = = null ) { <nl> public void run ( ) { <nl> return promise ; <nl> } <nl> <nl> + / * * <nl> + * @ deprecated should not be used directly . Use { @ link # open ( ) } or { @ link # open ( Promise ) } <nl> + * / <nl> + @ Deprecated <nl> public void open0 ( ChannelHandlerContext ctx , final Promise < Http2StreamChannel > promise ) { <nl> assert ctx . executor ( ) . inEventLoop ( ) ; <nl> final Http2StreamChannel streamChannel ; <nl> private void init ( Channel channel ) throws Exception { <nl> p . addLast ( handler ) ; <nl> } <nl> synchronized ( options ) { <nl> - setChannelOptions ( channel , options , logger ) ; <nl> + setChannelOptions ( channel , options ) ; <nl> } <nl> <nl> synchronized ( attrs ) { <nl> private void init ( Channel channel ) throws Exception { <nl> } <nl> <nl> private static void setChannelOptions ( <nl> - Channel channel , Map < ChannelOption < ? > , Object > options , InternalLogger logger ) { <nl> + Channel channel , Map < ChannelOption < ? > , Object > options ) { <nl> for ( Map . Entry < ChannelOption < ? > , Object > e : options . entrySet ( ) ) { <nl> - setChannelOption ( channel , e . getKey ( ) , e . getValue ( ) , logger ) ; <nl> + setChannelOption ( channel , e . getKey ( ) , e . getValue ( ) ) ; <nl> } <nl> } <nl> <nl> @ SuppressWarnings ( \" unchecked \" ) <nl> private static void setChannelOption ( <nl> - Channel channel , ChannelOption < ? > option , Object value , InternalLogger logger ) { <nl> + Channel channel , ChannelOption < ? > option , Object value ) { <nl> try { <nl> if ( ! channel . config ( ) . setOption ( ( ChannelOption < Object > ) option , value ) ) { <nl> logger . warn ( \" Unknown channel option ' { } ' for channel ' { } ' \" , option , channel ) ; <nl>\n", "msg": "Add deprecation to Http2StreamChannelBootstrap . open0 ( . . . ) as it was marked as public by mistake ( )\n"}
{"diff_id": 28790, "repo": "oracle/graal\n", "sha": "1c7f0de4396c32db4c50b8c275d4f6faf5c9e95b\n", "time": "2018-09-04T20:26:14Z\n", "diff": "mmm a / substratevm / src / com . oracle . svm . hosted / src / com / oracle / svm / hosted / image / DisallowedImageHeapObjectFeature . java <nl> ppp b / substratevm / src / com . oracle . svm . hosted / src / com / oracle / svm / hosted / image / DisallowedImageHeapObjectFeature . java <nl> public void duringSetup ( DuringSetupAccess access ) { <nl> } <nl> <nl> private static Object replacer ( Object original ) { <nl> - String message = \" The object was probably created by a class initializer and is reachable from a static field . \" + <nl> - \" By default , all class initialization is done during native image building . \" + <nl> - \" You can manually delay class initialization to image run time by using the option \" + <nl> - SubstrateOptionsParser . commandArgument ( ClassInitializationFeature . Options . DelayClassInitialization , \" < class - name > \" ) + \" . \" + <nl> - \" Or you can write your own initialization methods and call them explicitly from your main entry point . \" ; <nl> - <nl> / * Started Threads can not be in the image heap . * / <nl> if ( original instanceof Thread ) { <nl> final Thread asThread = ( Thread ) original ; <nl> if ( asThread . getState ( ) ! = Thread . State . NEW ) { <nl> - throw new UnsupportedFeatureException ( \" Detected a started Thread in the image heap . \" + <nl> - \" Threads running in the image generator are no longer running at image run time . \" + message ) ; <nl> + throw error ( \" Detected a started Thread in the image heap . \" + <nl> + \" Threads running in the image generator are no longer running at image run time . \" ) ; <nl> } <nl> } <nl> / * FileDescriptors can not be in the image heap . * / <nl> private static Object replacer ( Object original ) { <nl> final FileDescriptor asFileDescriptor = ( FileDescriptor ) original ; <nl> / * Except for a few well - known FileDescriptors . * / <nl> if ( ! ( ( asFileDescriptor = = FileDescriptor . in ) | | ( asFileDescriptor = = FileDescriptor . out ) | | ( asFileDescriptor = = FileDescriptor . err ) | | ( ! asFileDescriptor . valid ( ) ) ) ) { <nl> - throw new UnsupportedFeatureException ( \" Detected a FileDescriptor in the image heap . \" + <nl> - \" File descriptors opened during image generation are no longer open at image run time , and the files might not even be present anymore at image run time . \" + message ) ; <nl> + throw error ( \" Detected a FileDescriptor in the image heap . \" + <nl> + \" File descriptors opened during image generation are no longer open at image run time , and the files might not even be present anymore at image run time . \" ) ; <nl> } <nl> } <nl> / * Direct ByteBuffers can not be in the image heap . * / <nl> private static Object replacer ( Object original ) { <nl> * Targt_java_nio_DirectByteBuffer . <nl> * / <nl> if ( buffer . capacity ( ) ! = 0 | | getFileDescriptor ( buffer ) ! = null ) { <nl> - throw new UnsupportedFeatureException ( \" Detected a direct / mapped ByteBuffer in the image heap . \" + <nl> + throw error ( \" Detected a direct / mapped ByteBuffer in the image heap . \" + <nl> \" A direct ByteBuffer has a pointer to unmanaged C memory , and C memory from the image generator is not available at image run time . \" + <nl> - \" A mapped ByteBuffer references a file descriptor , which is no longer open and mapped at run time . \" + message ) ; <nl> + \" A mapped ByteBuffer references a file descriptor , which is no longer open and mapped at run time . \" ) ; <nl> } <nl> } <nl> <nl> / * ZipFiles can not be in the image heap . * / <nl> if ( original instanceof java . util . zip . ZipFile ) { <nl> - throw new UnsupportedFeatureException ( \" Detected a ZipFile object in the image heap . \" + <nl> - \" A ZipFile object contains pointers to unmanaged C memory and file descriptors , and these resources are no longer available at image run time . \" + message ) ; <nl> + throw error ( \" Detected a ZipFile object in the image heap . \" + <nl> + \" A ZipFile object contains pointers to unmanaged C memory and file descriptors , and these resources are no longer available at image run time . \" ) ; <nl> } <nl> <nl> return original ; <nl> } <nl> <nl> + private static RuntimeException error ( String msg ) { <nl> + throw new UnsupportedFeatureException ( msg + <nl> + \" The object was probably created by a class initializer and is reachable from a static field . \" + <nl> + \" By default , all class initialization is done during native image building . \" + <nl> + \" You can manually delay class initialization to image run time by using the option \" + <nl> + SubstrateOptionsParser . commandArgument ( ClassInitializationFeature . Options . DelayClassInitialization , \" < class - name > \" ) + \" . \" + <nl> + \" Or you can write your own initialization methods and call them explicitly from your main entry point . \" ) ; <nl> + } <nl> + <nl> private static final Field FILE_DESCRIPTOR_FIELD ; <nl> <nl> static { <nl>\n", "msg": "Build String for error message only in case of error\n"}
{"diff_id": 28832, "repo": "elastic/elasticsearch\n", "sha": "d9fffd32bef5ad3897cb08bdc2ba6351ebaff411\n", "time": "2014-10-29T17:08:50Z\n", "diff": "mmm a / src / test / java / org / elasticsearch / common / logging / LoggingConfigurationTests . java <nl> ppp b / src / test / java / org / elasticsearch / common / logging / LoggingConfigurationTests . java <nl> <nl> <nl> package org . elasticsearch . common . logging ; <nl> <nl> - import com . carrotsearch . ant . tasks . junit4 . dependencies . com . google . common . io . Files ; <nl> import org . apache . log4j . Appender ; <nl> import org . apache . log4j . Logger ; <nl> import org . elasticsearch . common . logging . log4j . Log4jESLogger ; <nl> <nl> <nl> import java . io . File ; <nl> import java . net . URL ; <nl> - import java . util . Enumeration ; <nl> <nl> import static org . hamcrest . Matchers . notNullValue ; <nl> <nl> <nl> public void testMultipleConfigs ( ) throws Exception { <nl> File configDir = resolveConfigDir ( ) ; <nl> logger . info ( \" Using config directory : { } \" , configDir . getAbsolutePath ( ) ) ; <nl> - File loggingFile = new File ( configDir , \" logging . yml \" ) ; <nl> - logger . info ( \" Contents of { } : { } \" , loggingFile , Files . toString ( loggingFile , UTF8 ) ) ; <nl> Settings settings = ImmutableSettings . builder ( ) <nl> . put ( \" path . conf \" , configDir . getAbsolutePath ( ) ) <nl> . build ( ) ; <nl> - logger . info ( \" LogConfigurator Settings : { } \" , settings . getAsMap ( ) ) ; <nl> LogConfigurator . configure ( settings ) ; <nl> <nl> ESLogger esLogger = Log4jESLoggerFactory . getLogger ( \" first \" ) ; <nl> Logger logger = ( ( Log4jESLogger ) esLogger ) . logger ( ) ; <nl> - this . logger . info ( \" Found following appenders : \" ) ; <nl> - for ( Enumeration allAppenders = logger . getAllAppenders ( ) ; allAppenders . hasMoreElements ( ) ; ) { <nl> - Appender appender = ( Appender ) allAppenders . nextElement ( ) ; <nl> - this . logger . info ( \" Found appender : { } \" , appender . getName ( ) ) ; <nl> - } <nl> Appender appender = logger . getAppender ( \" console1 \" ) ; <nl> assertThat ( appender , notNullValue ( ) ) ; <nl> <nl>\n", "msg": "Revert \" [ TEST ] added more additional logging to LoggingConfigurationTests \"\n"}
{"diff_id": 28937, "repo": "oracle/graal\n", "sha": "2281ecc36c4f26c0b483d607bc5c2a04ced36e64\n", "time": "2017-06-08T08:16:39Z\n", "diff": "mmm a / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / listeners / Function . java <nl> ppp b / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / listeners / Function . java <nl> private void createInvoke ( long [ ] args ) { <nl> if ( calleeType instanceof PointerType ) { <nl> functionType = ( FunctionType ) ( ( PointerType ) calleeType ) . getPointeeType ( ) ; <nl> } else { <nl> - throw new AssertionError ( \" Cannot find Type of invoked function ! \" ) ; <nl> + throw new AssertionError ( \" Cannot find Type of invoked function : \" + calleeType . toString ( ) ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "Improve error message when function type cannot be resolved .\n"}
{"diff_id": 28947, "repo": "bumptech/glide\n", "sha": "6b9c00de0816ffcf7fad77b3034db1fb0bca46df\n", "time": "2019-03-05T16:19:23Z\n", "diff": "mmm a / library / src / main / java / com / bumptech / glide / Glide . java <nl> ppp b / library / src / main / java / com / bumptech / glide / Glide . java <nl> private static void initializeGlide ( @ NonNull Context context , @ NonNull GlideBuil <nl> } <nl> Glide glide = builder . build ( applicationContext ) ; <nl> for ( com . bumptech . glide . module . GlideModule module : manifestModules ) { <nl> - module . registerComponents ( applicationContext , glide , glide . registry ) ; <nl> + try { <nl> + module . registerComponents ( applicationContext , glide , glide . registry ) ; <nl> + } catch ( AbstractMethodError e ) { <nl> + throw new IllegalStateException ( <nl> + \" Attempting to register a Glide v3 module . If you see this , you or one of your \" <nl> + + \" dependencies may be including Glide v3 even though you ' re using Glide v4 . \" <nl> + + \" You ' ll need to find and remove ( or update ) the offending dependency . \" <nl> + + \" The v3 module name is : \" + module . getClass ( ) . getName ( ) , e ) ; <nl> + } <nl> } <nl> if ( annotationGeneratedModule ! = null ) { <nl> annotationGeneratedModule . registerComponents ( applicationContext , glide , glide . registry ) ; <nl>\n", "msg": "Add a better error when v3 and v4 modules are used in the same app .\n"}
{"diff_id": 29009, "repo": "signalapp/Signal-Android\n", "sha": "270160781026de7a9fbed3a6d9e98faa24e2ecda\n", "time": "2019-04-16T13:52:12Z\n", "diff": "mmm a / src / org / thoughtcrime / securesms / jobmanager / JobSchedulerScheduler . java <nl> ppp b / src / org / thoughtcrime / securesms / jobmanager / JobSchedulerScheduler . java <nl> <nl> private static final String PREF_NAME = \" JobSchedulerScheduler_prefs \" ; <nl> private static final String PREF_NEXT_ID = \" pref_next_id \" ; <nl> <nl> - private static final int MAX_ID = 1000 ; <nl> + private static final int MAX_ID = 75 ; <nl> <nl> private final Application application ; <nl> <nl>\n", "msg": "Reduce the possible number of unique jobs to avoid crash .\n"}
{"diff_id": 29239, "repo": "elastic/elasticsearch\n", "sha": "a1c62759c90dc5cd52349f17888431632a606850\n", "time": "2013-04-19T10:36:12Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / common / DefaultCacheRecycler . java <nl> ppp b / src / main / java / org / elasticsearch / common / DefaultCacheRecycler . java <nl> <nl> <nl> public class DefaultCacheRecycler implements Recycler { <nl> <nl> - private static final int QUEUE_MAX_SIZE = 256 ; <nl> <nl> @ Override <nl> public void clear ( ) { <nl> public void clear ( ) { <nl> @ Override <nl> @ SuppressWarnings ( \" unchecked \" ) <nl> public < K , V > ExtTHashMap < K , V > popHashMap ( ) { <nl> - Queue < ExtTHashMap > ref = hashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new ExtTHashMap < K , V > ( ) ; <nl> - } <nl> - ExtTHashMap map = ref . poll ( ) ; <nl> + ExtTHashMap map = pop ( hashMap ) ; <nl> if ( map = = null ) { <nl> return new ExtTHashMap < K , V > ( ) ; <nl> } <nl> public void clear ( ) { <nl> * / <nl> @ Override <nl> public void pushHashMap ( ExtTHashMap map ) { <nl> - Queue < ExtTHashMap > ref = hashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - hashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( hashMap , map ) ; <nl> } <nl> <nl> / / mmm - - THashSet mmm - - <nl> public void pushHashMap ( ExtTHashMap map ) { <nl> @ Override <nl> @ SuppressWarnings ( \" unchecked \" ) <nl> public < T > THashSet < T > popHashSet ( ) { <nl> - Queue < THashSet > ref = hashSet . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new THashSet < T > ( ) ; <nl> - } <nl> - THashSet set = ref . poll ( ) ; <nl> + THashSet set = pop ( hashSet ) ; <nl> if ( set = = null ) { <nl> return new THashSet < T > ( ) ; <nl> } <nl> public void pushHashMap ( ExtTHashMap map ) { <nl> * / <nl> @ Override <nl> public void pushHashSet ( THashSet map ) { <nl> - Queue < THashSet > ref = hashSet . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - hashSet . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( hashSet , map ) ; <nl> } <nl> <nl> / / mmmmmm ExtTDoubleObjectHashMap mmm - - <nl> public void pushHashSet ( THashSet map ) { <nl> @ Override <nl> @ SuppressWarnings ( \" unchecked \" ) <nl> public < T > ExtTDoubleObjectHashMap < T > popDoubleObjectMap ( ) { <nl> - Queue < ExtTDoubleObjectHashMap > ref = doubleObjectHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new ExtTDoubleObjectHashMap ( ) ; <nl> - } <nl> - ExtTDoubleObjectHashMap map = ref . poll ( ) ; <nl> + ExtTDoubleObjectHashMap map = pop ( doubleObjectHashMap ) ; <nl> if ( map = = null ) { <nl> return new ExtTDoubleObjectHashMap ( ) ; <nl> } <nl> public void pushHashSet ( THashSet map ) { <nl> * / <nl> @ Override <nl> public void pushDoubleObjectMap ( ExtTDoubleObjectHashMap map ) { <nl> - Queue < ExtTDoubleObjectHashMap > ref = doubleObjectHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - doubleObjectHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( doubleObjectHashMap , map ) ; <nl> } <nl> <nl> / / mmm - - ExtTLongObjectHashMap mmm - <nl> public void pushDoubleObjectMap ( ExtTDoubleObjectHashMap map ) { <nl> @ Override <nl> @ SuppressWarnings ( \" unchecked \" ) <nl> public < T > ExtTLongObjectHashMap < T > popLongObjectMap ( ) { <nl> - Queue < ExtTLongObjectHashMap > ref = longObjectHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new ExtTLongObjectHashMap ( ) ; <nl> - } <nl> - ExtTLongObjectHashMap map = ref . poll ( ) ; <nl> - if ( map = = null ) { <nl> + ExtTLongObjectHashMap map = pop ( longObjectHashMap ) ; <nl> + if ( map = = null ) { <nl> return new ExtTLongObjectHashMap ( ) ; <nl> } <nl> return map ; <nl> } <nl> - <nl> + <nl> / * ( non - Javadoc ) <nl> * @ see org . elasticsearch . common . Recycler # pushLongObjectMap ( org . elasticsearch . common . trove . ExtTLongObjectHashMap ) <nl> * / <nl> @ Override <nl> public void pushLongObjectMap ( ExtTLongObjectHashMap map ) { <nl> - Queue < ExtTLongObjectHashMap > ref = longObjectHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - longObjectHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( longObjectHashMap , map ) ; <nl> } <nl> <nl> / / mmm - - TLongLongHashMap mmm - <nl> public void pushLongObjectMap ( ExtTLongObjectHashMap map ) { <nl> * / <nl> @ Override <nl> public TLongLongHashMap popLongLongMap ( ) { <nl> - Queue < TLongLongHashMap > ref = longLongHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new TLongLongHashMap ( ) ; <nl> - } <nl> - TLongLongHashMap map = ref . poll ( ) ; <nl> + TLongLongHashMap map = pop ( longLongHashMap ) ; <nl> if ( map = = null ) { <nl> return new TLongLongHashMap ( ) ; <nl> } <nl> public TLongLongHashMap popLongLongMap ( ) { <nl> * / <nl> @ Override <nl> public void pushLongLongMap ( TLongLongHashMap map ) { <nl> - Queue < TLongLongHashMap > ref = longLongHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - longLongHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> - } <nl> + map . clear ( ) ; <nl> + push ( longLongHashMap , map ) ; } <nl> <nl> / / mmm - - TIntIntHashMap mmm - <nl> <nl> public void pushLongLongMap ( TLongLongHashMap map ) { <nl> * / <nl> @ Override <nl> public TIntIntHashMap popIntIntMap ( ) { <nl> - Queue < TIntIntHashMap > ref = intIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new TIntIntHashMap ( ) ; <nl> - } <nl> - TIntIntHashMap map = ref . poll ( ) ; <nl> + TIntIntHashMap map = pop ( intIntHashMap ) ; <nl> if ( map = = null ) { <nl> return new TIntIntHashMap ( ) ; <nl> } <nl> public TIntIntHashMap popIntIntMap ( ) { <nl> * / <nl> @ Override <nl> public void pushIntIntMap ( TIntIntHashMap map ) { <nl> - Queue < TIntIntHashMap > ref = intIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - intIntHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( intIntHashMap , map ) ; <nl> } <nl> <nl> <nl> public void pushIntIntMap ( TIntIntHashMap map ) { <nl> * / <nl> @ Override <nl> public TFloatIntHashMap popFloatIntMap ( ) { <nl> - Queue < TFloatIntHashMap > ref = floatIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new TFloatIntHashMap ( ) ; <nl> - } <nl> - TFloatIntHashMap map = ref . poll ( ) ; <nl> + TFloatIntHashMap map = pop ( floatIntHashMap ) ; <nl> if ( map = = null ) { <nl> return new TFloatIntHashMap ( ) ; <nl> } <nl> public TFloatIntHashMap popFloatIntMap ( ) { <nl> * / <nl> @ Override <nl> public void pushFloatIntMap ( TFloatIntHashMap map ) { <nl> - Queue < TFloatIntHashMap > ref = floatIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - floatIntHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( floatIntHashMap , map ) ; <nl> } <nl> <nl> <nl> public void pushFloatIntMap ( TFloatIntHashMap map ) { <nl> * / <nl> @ Override <nl> public TDoubleIntHashMap popDoubleIntMap ( ) { <nl> - Queue < TDoubleIntHashMap > ref = doubleIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new TDoubleIntHashMap ( ) ; <nl> - } <nl> - TDoubleIntHashMap map = ref . poll ( ) ; <nl> + TDoubleIntHashMap map = pop ( doubleIntHashMap ) ; <nl> if ( map = = null ) { <nl> return new TDoubleIntHashMap ( ) ; <nl> } <nl> public TDoubleIntHashMap popDoubleIntMap ( ) { <nl> * / <nl> @ Override <nl> public void pushDoubleIntMap ( TDoubleIntHashMap map ) { <nl> - Queue < TDoubleIntHashMap > ref = doubleIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - doubleIntHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( doubleIntHashMap , map ) ; <nl> } <nl> <nl> <nl> public void pushDoubleIntMap ( TDoubleIntHashMap map ) { <nl> * / <nl> @ Override <nl> public TByteIntHashMap popByteIntMap ( ) { <nl> - Queue < TByteIntHashMap > ref = byteIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new TByteIntHashMap ( ) ; <nl> - } <nl> - TByteIntHashMap map = ref . poll ( ) ; <nl> + TByteIntHashMap map = pop ( byteIntHashMap ) ; <nl> if ( map = = null ) { <nl> return new TByteIntHashMap ( ) ; <nl> } <nl> public TByteIntHashMap popByteIntMap ( ) { <nl> * / <nl> @ Override <nl> public void pushByteIntMap ( TByteIntHashMap map ) { <nl> - Queue < TByteIntHashMap > ref = byteIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - byteIntHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( byteIntHashMap , map ) ; <nl> } <nl> - <nl> + <nl> + <nl> / / mmm - - TShortIntHashMap mmm <nl> <nl> private final SoftWrapper < Queue < TShortIntHashMap > > shortIntHashMap = new SoftWrapper < Queue < TShortIntHashMap > > ( ) ; <nl> public void pushByteIntMap ( TByteIntHashMap map ) { <nl> * / <nl> @ Override <nl> public TShortIntHashMap popShortIntMap ( ) { <nl> - Queue < TShortIntHashMap > ref = shortIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new TShortIntHashMap ( ) ; <nl> - } <nl> - TShortIntHashMap map = ref . poll ( ) ; <nl> + TShortIntHashMap map = pop ( shortIntHashMap ) ; <nl> if ( map = = null ) { <nl> return new TShortIntHashMap ( ) ; <nl> } <nl> public TShortIntHashMap popShortIntMap ( ) { <nl> * / <nl> @ Override <nl> public void pushShortIntMap ( TShortIntHashMap map ) { <nl> - Queue < TShortIntHashMap > ref = shortIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - shortIntHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( shortIntHashMap , map ) ; <nl> } <nl> <nl> <nl> public TLongIntHashMap popLongIntMap ( ) { <nl> if ( ref = = null ) { <nl> return new TLongIntHashMap ( ) ; <nl> } <nl> - TLongIntHashMap map = ref . poll ( ) ; <nl> + TLongIntHashMap map = pop ( longIntHashMap ) ; <nl> if ( map = = null ) { <nl> return new TLongIntHashMap ( ) ; <nl> } <nl> public TLongIntHashMap popLongIntMap ( ) { <nl> * / <nl> @ Override <nl> public void pushLongIntMap ( TLongIntHashMap map ) { <nl> - Queue < TLongIntHashMap > ref = longIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - longIntHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( longIntHashMap , map ) ; <nl> } <nl> <nl> / / mmmmmm TObjectIntHashMap mmm - - <nl> public void pushLongIntMap ( TLongIntHashMap map ) { <nl> @ Override <nl> @ SuppressWarnings ( { \" unchecked \" } ) <nl> public < T > TObjectIntHashMap < T > popObjectIntMap ( ) { <nl> - Queue < TObjectIntHashMap > ref = objectIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new TObjectIntHashMap ( ) ; <nl> - } <nl> - TObjectIntHashMap map = ref . poll ( ) ; <nl> + TObjectIntHashMap map = pop ( objectIntHashMap ) ; <nl> if ( map = = null ) { <nl> return new TObjectIntHashMap ( ) ; <nl> } <nl> public void pushLongIntMap ( TLongIntHashMap map ) { <nl> * / <nl> @ Override <nl> public < T > void pushObjectIntMap ( TObjectIntHashMap < T > map ) { <nl> - Queue < TObjectIntHashMap > ref = objectIntHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - objectIntHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( objectIntHashMap , map ) ; <nl> } <nl> <nl> / / mmmmmm TIntObjectHashMap mmm - - <nl> public void pushLongIntMap ( TLongIntHashMap map ) { <nl> @ Override <nl> @ SuppressWarnings ( { \" unchecked \" } ) <nl> public < T > TIntObjectHashMap < T > popIntObjectMap ( ) { <nl> - Queue < TIntObjectHashMap > ref = intObjectHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new TIntObjectHashMap < T > ( ) ; <nl> - } <nl> - TIntObjectHashMap < T > map = ref . poll ( ) ; <nl> + TIntObjectHashMap < T > map = pop ( intObjectHashMap ) ; <nl> if ( map = = null ) { <nl> return new TIntObjectHashMap < T > ( ) ; <nl> } <nl> public void pushLongIntMap ( TLongIntHashMap map ) { <nl> * / <nl> @ Override <nl> public < T > void pushIntObjectMap ( TIntObjectHashMap < T > map ) { <nl> - Queue < TIntObjectHashMap > ref = intObjectHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - intObjectHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( intObjectHashMap , map ) ; <nl> } <nl> <nl> / / mmmmmm TObjectFloatHashMap mmm - - <nl> public void pushLongIntMap ( TLongIntHashMap map ) { <nl> @ Override <nl> @ SuppressWarnings ( { \" unchecked \" } ) <nl> public < T > TObjectFloatHashMap < T > popObjectFloatMap ( ) { <nl> - Queue < TObjectFloatHashMap > ref = objectFloatHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - return new TObjectFloatHashMap ( ) ; <nl> - } <nl> - TObjectFloatHashMap map = ref . poll ( ) ; <nl> + final TObjectFloatHashMap map = pop ( objectFloatHashMap ) ; <nl> if ( map = = null ) { <nl> return new TObjectFloatHashMap ( ) ; <nl> } <nl> public void pushLongIntMap ( TLongIntHashMap map ) { <nl> * / <nl> @ Override <nl> public < T > void pushObjectFloatMap ( TObjectFloatHashMap < T > map ) { <nl> - Queue < TObjectFloatHashMap > ref = objectFloatHashMap . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - objectFloatHashMap . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - map . clear ( ) ; <nl> - ref . add ( map ) ; <nl> - } <nl> + map . clear ( ) ; <nl> + push ( objectFloatHashMap , map ) ; <nl> } <nl> <nl> / / mmm - - int [ ] mmm - - <nl> public void pushLongIntMap ( TLongIntHashMap map ) { <nl> * / <nl> @ Override <nl> public void pushObjectArray ( Object [ ] objects ) { <nl> - Queue < Object [ ] > ref = objectArray . get ( ) ; <nl> - if ( ref = = null ) { <nl> - ref = ConcurrentCollections . newQueue ( ) ; <nl> - objectArray . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - Arrays . fill ( objects , null ) ; <nl> - ref . add ( objects ) ; <nl> - } <nl> + Arrays . fill ( objects , null ) ; <nl> + push ( objectArray , objects ) ; <nl> } <nl> <nl> <nl> public void pushObjectArray ( Object [ ] objects ) { <nl> } <nl> return ints ; <nl> } <nl> - <nl> - / * ( non - Javadoc ) <nl> - * @ see org . elasticsearch . common . Recycler # pushIntArray ( int [ ] ) <nl> - * / <nl> + <nl> @ Override <nl> public void pushIntArray ( int [ ] ints ) { <nl> pushIntArray ( ints , 0 ) ; <nl> } <nl> <nl> - / * ( non - Javadoc ) <nl> - * @ see org . elasticsearch . common . Recycler # pushIntArray ( int [ ] , int ) <nl> - * / <nl> @ Override <nl> public void pushIntArray ( int [ ] ints , int sentinal ) { <nl> - Queue < int [ ] > ref = intArray . get ( ) ; <nl> + Arrays . fill ( ints , sentinal ) ; <nl> + push ( intArray , ints ) ; <nl> + } <nl> + <nl> + private static final < T > void push ( SoftWrapper < Queue < T > > wrapper , T obj ) { <nl> + Queue < T > ref = wrapper . get ( ) ; <nl> if ( ref = = null ) { <nl> ref = ConcurrentCollections . newQueue ( ) ; <nl> - intArray . set ( ref ) ; <nl> - } <nl> - if ( ref . size ( ) < QUEUE_MAX_SIZE ) { <nl> - Arrays . fill ( ints , sentinal ) ; <nl> - ref . add ( ints ) ; <nl> + wrapper . set ( ref ) ; <nl> } <nl> + ref . add ( obj ) ; <nl> } <nl> + <nl> + private static final < T > T pop ( SoftWrapper < Queue < T > > wrapper ) { <nl> + Queue < T > queue = wrapper . get ( ) ; <nl> + return queue = = null ? null : queue . poll ( ) ; <nl> + } <nl> + <nl> } <nl> \\ No newline at end of file <nl>\n", "msg": "remove size bound from cache recycler for performance reasons\n"}
{"diff_id": 29380, "repo": "oracle/graal\n", "sha": "043a761e931df9bad4b6eab004e357fd6acc5270\n", "time": "2014-08-22T00:20:00Z\n", "diff": "mmm a / graal / com . oracle . graal . replacements / src / com / oracle / graal / replacements / DefaultJavaLoweringProvider . java <nl> ppp b / graal / com . oracle . graal . replacements / src / com / oracle / graal / replacements / DefaultJavaLoweringProvider . java <nl> protected void lowerUnsafeLoadNode ( UnsafeLoadNode load , @ SuppressWarnings ( \" unuse <nl> protected ReadNode createUnsafeRead ( StructuredGraph graph , UnsafeLoadNode load , GuardingNode guard ) { <nl> boolean compressible = load . accessKind ( ) = = Kind . Object ; <nl> Kind readKind = load . accessKind ( ) ; <nl> - LocationNode location = createLocation ( load ) ; <nl> + ValueNode [ ] base = null ; <nl> + ValueNode object = load . object ( ) ; <nl> + if ( object . isConstant ( ) & & object . asConstant ( ) . isDefaultForKind ( ) ) { <nl> + base = new ValueNode [ 1 ] ; <nl> + } <nl> + LocationNode location = createLocation ( load , base ) ; <nl> + if ( base ! = null & & base [ 0 ] ! = null ) { <nl> + object = base [ 0 ] ; <nl> + } <nl> Stamp loadStamp = loadStamp ( load . stamp ( ) , readKind , compressible ) ; <nl> - ReadNode memoryRead = graph . add ( new ReadNode ( load . object ( ) , location , loadStamp , guard , BarrierType . NONE ) ) ; <nl> + ReadNode memoryRead = graph . add ( new ReadNode ( object , location , loadStamp , guard , BarrierType . NONE ) ) ; <nl> ValueNode readValue = implicitLoadConvert ( graph , readKind , memoryRead , compressible ) ; <nl> load . replaceAtUsages ( readValue ) ; <nl> return memoryRead ; <nl> protected ReadNode createUnsafeRead ( StructuredGraph graph , UnsafeLoadNode load , <nl> <nl> protected void lowerUnsafeStoreNode ( UnsafeStoreNode store ) { <nl> StructuredGraph graph = store . graph ( ) ; <nl> - LocationNode location = createLocation ( store ) ; <nl> ValueNode object = store . object ( ) ; <nl> + ValueNode [ ] base = null ; <nl> + if ( object . isConstant ( ) & & object . asConstant ( ) . isDefaultForKind ( ) ) { <nl> + base = new ValueNode [ 1 ] ; <nl> + } <nl> + LocationNode location = createLocation ( store , base ) ; <nl> + if ( base ! = null & & base [ 0 ] ! = null ) { <nl> + object = base [ 0 ] ; <nl> + } <nl> boolean compressible = store . value ( ) . getKind ( ) = = Kind . Object ; <nl> Kind valueKind = store . accessKind ( ) ; <nl> ValueNode value = implicitStoreConvert ( graph , valueKind , store . value ( ) , compressible ) ; <nl> protected ConstantLocationNode createFieldLocation ( StructuredGraph graph , Resolv <nl> } <nl> } <nl> <nl> - protected LocationNode createLocation ( UnsafeAccessNode access ) { <nl> - return createLocation ( access . offset ( ) , access . getLocationIdentity ( ) , access . accessKind ( ) ) ; <nl> + protected LocationNode createLocation ( UnsafeAccessNode access , ValueNode [ ] base ) { <nl> + return createLocation ( access . offset ( ) , access . getLocationIdentity ( ) , access . accessKind ( ) , base ) ; <nl> } <nl> <nl> protected LocationNode createLocation ( ValueNode offsetNode , LocationIdentity locationIdentity , Kind accessKind ) { <nl> + return createLocation ( offsetNode , locationIdentity , accessKind , null ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Try to unpack the operations in offsetNode into a LocationNode , taking advantage of <nl> + * addressing modes if possible . <nl> + * <nl> + * @ param offsetNode the computed offset into the base of the memory operation <nl> + * @ param locationIdentity <nl> + * @ param accessKind <nl> + * @ param base if non - null try to find a value that can be used as the base of the memory <nl> + * operation and return it as base [ 0 ] <nl> + * @ return the newly created LocationNode <nl> + * / <nl> + protected LocationNode createLocation ( ValueNode offsetNode , LocationIdentity locationIdentity , Kind accessKind , ValueNode [ ] base ) { <nl> ValueNode offset = offsetNode ; <nl> if ( offset . isConstant ( ) ) { <nl> long offsetValue = offset . asConstant ( ) . asLong ( ) ; <nl> protected LocationNode createLocation ( ValueNode offsetNode , LocationIdentity loc <nl> offset = integerAddNode . getX ( ) ; <nl> } <nl> } <nl> - <nl> + if ( base ! = null & & signExtend = = false & & offset instanceof IntegerAddNode ) { <nl> + / * <nl> + * Try to decompose the operation into base plus offset so the base can go into a new <nl> + * node . Prefer the unshifted side of an add as the base . <nl> + * / <nl> + IntegerAddNode integerAddNode = ( IntegerAddNode ) offset ; <nl> + if ( integerAddNode . getY ( ) instanceof LeftShiftNode ) { <nl> + base [ 0 ] = integerAddNode . getX ( ) ; <nl> + offset = integerAddNode . getY ( ) ; <nl> + } else { <nl> + base [ 0 ] = integerAddNode . getY ( ) ; <nl> + offset = integerAddNode . getX ( ) ; <nl> + } <nl> + if ( offset instanceof IntegerAddNode ) { <nl> + integerAddNode = ( IntegerAddNode ) offset ; <nl> + if ( integerAddNode . getY ( ) instanceof ConstantNode ) { <nl> + displacement = integerAddNode . getY ( ) . asConstant ( ) . asLong ( ) ; <nl> + offset = integerAddNode . getX ( ) ; <nl> + } <nl> + } <nl> + } <nl> if ( offset instanceof LeftShiftNode ) { <nl> LeftShiftNode leftShiftNode = ( LeftShiftNode ) offset ; <nl> if ( leftShiftNode . getY ( ) instanceof ConstantNode ) { <nl>\n", "msg": "Try to pull out a base for Unsafe C heap references\n"}
{"diff_id": 29615, "repo": "google/guava\n", "sha": "b9fdc929c6f19d8a4592643a637d9fd24e6976eb\n", "time": "2015-06-01T17:33:58Z\n", "diff": "mmm a / guava - tests / test / com / google / common / cache / LocalCacheTest . java <nl> ppp b / guava - tests / test / com / google / common / cache / LocalCacheTest . java <nl> <nl> import com . google . common . collect . ImmutableSet ; <nl> import com . google . common . collect . Lists ; <nl> import com . google . common . collect . Maps ; <nl> - import com . google . common . collect . testing . MapTestSuiteBuilder ; <nl> + import com . google . common . collect . testing . ConcurrentMapTestSuiteBuilder ; <nl> import com . google . common . collect . testing . TestStringMapGenerator ; <nl> import com . google . common . collect . testing . features . CollectionFeature ; <nl> import com . google . common . collect . testing . features . CollectionSize ; <nl> <nl> * @ author Charles Fry <nl> * / <nl> public class LocalCacheTest extends TestCase { <nl> + private static class TestStringCacheGenerator extends TestStringMapGenerator { <nl> + private final CacheBuilder < ? super String , ? super String > builder ; <nl> + <nl> + TestStringCacheGenerator ( CacheBuilder < ? super String , ? super String > builder ) { <nl> + this . builder = builder ; <nl> + } <nl> + <nl> + @ Override <nl> + protected Map < String , String > create ( Entry < String , String > [ ] entries ) { <nl> + LocalCache < String , String > map = makeLocalCache ( builder ) ; <nl> + for ( Entry < String , String > entry : entries ) { <nl> + map . put ( entry . getKey ( ) , entry . getValue ( ) ) ; <nl> + } <nl> + return map ; <nl> + } <nl> + } <nl> <nl> public static Test suite ( ) { <nl> TestSuite suite = new TestSuite ( ) ; <nl> suite . addTestSuite ( LocalCacheTest . class ) ; <nl> - suite . addTest ( MapTestSuiteBuilder . using ( new TestStringMapGenerator ( ) { <nl> - @ Override public Map < String , String > create ( <nl> - Entry < String , String > [ ] entries ) { <nl> - LocalCache < String , String > map = makeLocalCache ( createCacheBuilder ( ) ) ; <nl> - for ( Entry < String , String > entry : entries ) { <nl> - map . put ( entry . getKey ( ) , entry . getValue ( ) ) ; <nl> - } <nl> - return map ; <nl> - } <nl> - <nl> - } ) . named ( \" LocalCache with defaults \" ) <nl> + suite . addTest ( ConcurrentMapTestSuiteBuilder <nl> + . using ( new TestStringCacheGenerator ( createCacheBuilder ( ) ) ) <nl> + . named ( \" LocalCache with defaults \" ) <nl> + . withFeatures ( CollectionSize . ANY , MapFeature . GENERAL_PURPOSE , <nl> + CollectionFeature . SUPPORTS_ITERATOR_REMOVE ) <nl> + . createTestSuite ( ) ) ; <nl> + suite . addTest ( ConcurrentMapTestSuiteBuilder <nl> + . using ( new TestStringCacheGenerator ( <nl> + createCacheBuilder ( ) . concurrencyLevel ( 1 ) ) ) <nl> + . named ( \" LocalCache with concurrencyLevel [ 1 ] \" ) <nl> + . withFeatures ( CollectionSize . ANY , MapFeature . GENERAL_PURPOSE , <nl> + CollectionFeature . SUPPORTS_ITERATOR_REMOVE ) <nl> + . createTestSuite ( ) ) ; <nl> + suite . addTest ( ConcurrentMapTestSuiteBuilder <nl> + . using ( new TestStringCacheGenerator ( <nl> + createCacheBuilder ( ) . maximumSize ( Integer . MAX_VALUE ) ) ) <nl> + . named ( \" LocalCache with maximumSize \" ) <nl> + . withFeatures ( CollectionSize . ANY , MapFeature . GENERAL_PURPOSE , <nl> + CollectionFeature . SUPPORTS_ITERATOR_REMOVE ) <nl> + . createTestSuite ( ) ) ; <nl> + suite . addTest ( ConcurrentMapTestSuiteBuilder <nl> + . using ( new TestStringCacheGenerator ( <nl> + createCacheBuilder ( ) <nl> + . maximumWeight ( Integer . MAX_VALUE ) <nl> + . weigher ( new SerializableWeigher < String , String > ( ) ) ) ) <nl> + . named ( \" LocalCache with maximumWeight \" ) <nl> + . withFeatures ( CollectionSize . ANY , MapFeature . GENERAL_PURPOSE , <nl> + CollectionFeature . SUPPORTS_ITERATOR_REMOVE ) <nl> + . createTestSuite ( ) ) ; <nl> + suite . addTest ( ConcurrentMapTestSuiteBuilder <nl> + . using ( new TestStringCacheGenerator ( <nl> + createCacheBuilder ( ) . weakKeys ( ) ) ) <nl> + . named ( \" LocalCache with weakKeys \" ) / / keys are string literals and won ' t be GC ' d <nl> + . withFeatures ( CollectionSize . ANY , MapFeature . GENERAL_PURPOSE , <nl> + CollectionFeature . SUPPORTS_ITERATOR_REMOVE ) <nl> + . createTestSuite ( ) ) ; <nl> + suite . addTest ( ConcurrentMapTestSuiteBuilder <nl> + . using ( new TestStringCacheGenerator ( <nl> + createCacheBuilder ( ) . weakValues ( ) ) ) <nl> + . named ( \" LocalCache with weakValues \" ) / / values are string literals and won ' t be GC ' d <nl> + . withFeatures ( CollectionSize . ANY , MapFeature . GENERAL_PURPOSE , <nl> + CollectionFeature . SUPPORTS_ITERATOR_REMOVE ) <nl> + . createTestSuite ( ) ) ; <nl> + suite . addTest ( ConcurrentMapTestSuiteBuilder <nl> + . using ( new TestStringCacheGenerator ( <nl> + createCacheBuilder ( ) . softValues ( ) ) ) <nl> + . named ( \" LocalCache with softValues \" ) / / values are string literals and won ' t be GC ' d <nl> + . withFeatures ( CollectionSize . ANY , MapFeature . GENERAL_PURPOSE , <nl> + CollectionFeature . SUPPORTS_ITERATOR_REMOVE ) <nl> + . createTestSuite ( ) ) ; <nl> + suite . addTest ( ConcurrentMapTestSuiteBuilder <nl> + . using ( new TestStringCacheGenerator ( <nl> + createCacheBuilder ( ) . expireAfterAccess ( 1 , SECONDS ) . ticker ( new SerializableTicker ( ) ) ) ) <nl> + . named ( \" LocalCache with expireAfterAccess \" ) / / SerializableTicker never advances <nl> + . withFeatures ( CollectionSize . ANY , MapFeature . GENERAL_PURPOSE , <nl> + CollectionFeature . SUPPORTS_ITERATOR_REMOVE ) <nl> + . createTestSuite ( ) ) ; <nl> + suite . addTest ( ConcurrentMapTestSuiteBuilder <nl> + . using ( new TestStringCacheGenerator ( <nl> + createCacheBuilder ( ) . expireAfterWrite ( 1 , SECONDS ) . ticker ( new SerializableTicker ( ) ) ) ) <nl> + . named ( \" LocalCache with expireAfterWrite \" ) / / SerializableTicker never advances <nl> + . withFeatures ( CollectionSize . ANY , MapFeature . GENERAL_PURPOSE , <nl> + CollectionFeature . SUPPORTS_ITERATOR_REMOVE ) <nl> + . createTestSuite ( ) ) ; <nl> + suite . addTest ( ConcurrentMapTestSuiteBuilder <nl> + . using ( new TestStringCacheGenerator ( <nl> + createCacheBuilder ( ) <nl> + . removalListener ( new SerializableRemovalListener < String , String > ( ) ) ) ) <nl> + . named ( \" LocalCache with removalListener \" ) <nl> + . withFeatures ( CollectionSize . ANY , MapFeature . GENERAL_PURPOSE , <nl> + CollectionFeature . SUPPORTS_ITERATOR_REMOVE ) <nl> + . createTestSuite ( ) ) ; <nl> + suite . addTest ( ConcurrentMapTestSuiteBuilder <nl> + . using ( new TestStringCacheGenerator ( createCacheBuilder ( ) . recordStats ( ) ) ) <nl> + . named ( \" LocalCache with recordStats \" ) <nl> . withFeatures ( CollectionSize . ANY , MapFeature . GENERAL_PURPOSE , <nl> CollectionFeature . SUPPORTS_ITERATOR_REMOVE ) <nl> . createTestSuite ( ) ) ; <nl>\n", "msg": "Use ConcurrentMapTestSuiteBuilder to test CacheBuilder and its flavors\n"}
{"diff_id": 29619, "repo": "skylot/jadx\n", "sha": "b87d1a7fe1d0172d4ad728453b391491ddbee8b2\n", "time": "2014-12-21T23:11:37Z\n", "diff": "mmm a / jadx - core / src / main / java / jadx / core / xmlgen / BinaryXMLParser . java <nl> ppp b / jadx - core / src / main / java / jadx / core / xmlgen / BinaryXMLParser . java <nl> <nl> private String [ ] strings ; <nl> private int count ; <nl> private String nsPrefix = \" ERROR \" ; <nl> + private String nsURI = \" ERROR \" ; <nl> + private String currentTag = \" ERROR \" ; <nl> private int numtabs = - 1 ; <nl> + private boolean wasOneLiner = false ; <nl> PrintWriter writer ; <nl> public BinaryXMLParser ( String xmlfilepath , String xmloutfilepath ) { <nl> / / System . out . println ( xmlfilepath ) ; <nl> private void parseNameSpace ( ) { <nl> nsPrefix = strings [ beginPrefix ] ; <nl> int beginURI = cInt32 ( bytes , count ) ; <nl> / / System . out . println ( \" URI : \" + strings [ beginURI ] ) ; <nl> + nsURI = strings [ beginURI ] ; <nl> / / System . out . println ( \" COUNT : \" + Integer . toHexString ( count ) ) ; <nl> } <nl> <nl> private void parseNameSpaceEnd ( ) { <nl> / / System . out . println ( \" Prefix : \" + strings [ endPrefix ] ) ; <nl> nsPrefix = strings [ endPrefix ] ; <nl> int endURI = cInt32 ( bytes , count ) ; <nl> + nsURI = strings [ endURI ] ; <nl> / / System . out . println ( \" URI : \" + strings [ endURI ] ) ; <nl> } <nl> <nl> private void parseElement ( ) { <nl> if ( cInt16 ( bytes , count ) ! = 0x0010 ) die ( \" ELEMENT HEADER SIZE is not 0x10 \" ) ; <nl> / / if ( cInt32 ( bytes , count ) ! = 0x0060 ) die ( \" ELEMENT CHUNK SIZE is not 0x60 \" ) ; <nl> count + = 4 ; <nl> - int elementLineNumber = cInt32 ( bytes , count ) ; <nl> - / / System . out . println ( \" elementLineNumber : \" + elementLineNumber ) ; <nl> + int elementBegLineNumber = cInt32 ( bytes , count ) ; <nl> + / / System . out . println ( \" ELEMENT BEG Line : \" + elementBegLineNumber + \" of \" + strings [ startNSName ] ) ; <nl> int comment = cInt32 ( bytes , count ) ; <nl> / / System . out . println ( \" Comment : 0x \" + Integer . toHexString ( comment ) ) ; <nl> / / System . out . println ( \" COUNT : \" + Integer . toHexString ( count ) ) ; <nl> int startNS = cInt32 ( bytes , count ) ; <nl> / / System . out . println ( \" Namespace : 0x \" + Integer . toHexString ( startNS ) ) ; <nl> - int startNSName = cInt32 ( bytes , count ) ; / / what to do with this id ? <nl> + int startNSName = cInt32 ( bytes , count ) ; / / actually is elementName . . . <nl> / / System . out . println ( \" Namespace name : \" + strings [ startNSName ] ) ; <nl> + if ( ! wasOneLiner & & ! \" ERROR \" . equals ( currentTag ) & & ! currentTag . equals ( strings [ startNSName ] ) ) { <nl> + writer . println ( \" > \" ) ; <nl> + } <nl> + wasOneLiner = false ; <nl> + currentTag = strings [ startNSName ] ; <nl> for ( int i = 0 ; i < numtabs ; i + + ) writer . print ( \" \\ t \" ) ; <nl> writer . print ( \" < \" + strings [ startNSName ] ) ; <nl> int attributeStart = cInt16 ( bytes , count ) ; <nl> private void parseElement ( ) { <nl> / / System . out . println ( \" startNS : classIndex : \" + classIndex ) ; <nl> int styleIndex = cInt16 ( bytes , count ) ; <nl> / / System . out . println ( \" startNS : styleIndex : \" + styleIndex ) ; <nl> + if ( \" manifest \" . equals ( strings [ startNSName ] ) ) writer . print ( \" xmlns : \\ \" \" + nsURI + \" \\ \" \" ) ; <nl> if ( attributeCount > 0 ) writer . print ( \" \" ) ; <nl> for ( int i = 0 ; i < attributeCount ; i + + ) { <nl> int attributeNS = cInt32 ( bytes , count ) ; <nl> private void parseElement ( ) { <nl> if ( cInt8 ( bytes , count ) ! = 0 ) die ( \" res0 is not 0 \" ) ; <nl> int attrValDataType = cInt8 ( bytes , count ) ; <nl> int attrValData = cInt32 ( bytes , count ) ; <nl> - / * <nl> + / * ( <nl> System . out . println ( \" ai [ \" + i + \" ] ns : \" + attributeNS ) ; <nl> / / if ( attributeNS ! = - 1 ) System . out . println ( \" ai [ \" + i + \" ] Sns : \" + strings [ attributeNS ] ) ; <nl> System . out . println ( \" ai [ \" + i + \" ] name : \" + attributeName ) ; <nl> private void parseElement ( ) { <nl> System . out . println ( \" ai [ \" + i + \" ] d : \" + attrValData ) ; <nl> * / <nl> if ( attributeNS ! = - 1 ) writer . print ( nsPrefix + \" : \" ) ; <nl> + / / writer . print ( strings [ attributeName ] + \" = \\ \" \" ) ; <nl> if ( attrValDataType = = 0x3 ) writer . print ( strings [ attributeName ] + \" = \\ \" \" + strings [ attrValData ] + \" \\ \" \" ) ; <nl> else if ( attrValDataType = = 0x10 ) writer . print ( strings [ attributeName ] + \" = \\ \" \" + attrValData + \" \\ \" \" ) ; <nl> else if ( attrValDataType = = 0x12 ) { <nl> else if ( attrValDataType = = 0x12 ) { <nl> if ( attrValData = = 0 ) writer . print ( strings [ attributeName ] + \" = \\ \" false \\ \" \" ) ; <nl> else if ( attrValData = = 1 | | attrValData = = - 1 ) writer . print ( strings [ attributeName ] + \" = \\ \" true \\ \" \" ) ; <nl> else writer . print ( strings [ attributeName ] + \" = \\ \" UNKNOWN \\ \" \" ) ; <nl> - } <nl> + } else if ( attrValDataType = = 0x1 ) writer . print ( strings [ attributeName ] + \" = \\ \" 0x \" + Integer . toHexString ( attrValData ) + \" \\ \" \" ) ; <nl> else writer . print ( strings [ attributeName ] + \" = UNKNOWN DATA TYPE : \" + attrValDataType ) ; <nl> - writer . print ( \" \" ) ; <nl> + if ( ( i + 1 ) < attributeCount ) writer . print ( \" \" ) ; <nl> } <nl> - writer . println ( \" > \" ) ; <nl> + / / writer . println ( \" > \" ) ; <nl> + / / System . out . println ( \" ELEMENT BEG Line : \" + elementBegLineNumber + \" of \" + strings [ startNSName ] ) ; <nl> } <nl> <nl> private void parseElementEnd ( ) { <nl> private void parseElementEnd ( ) { <nl> if ( cInt32 ( bytes , count ) ! = 0x18 ) die ( \" ELEMENT END header chunk is not 0x18 big \" ) ; <nl> int endLineNumber = cInt32 ( bytes , count ) ; <nl> / / if ( endLineNumber ! = 2 ) die ( \" NAMESPACE beginning line number ! = 2 not supported yet \" ) ; <nl> - / / System . out . println ( \" ELEMENT END Line : \" + endLineNumber ) ; <nl> int comment = cInt32 ( bytes , count ) ; <nl> / / System . out . println ( \" Comment : 0x \" + Integer . toHexString ( comment ) ) ; <nl> int elementNS = cInt32 ( bytes , count ) ; <nl> int elementName = cInt32 ( bytes , count ) ; <nl> - for ( int i = 0 ; i < numtabs ; i + + ) writer . print ( \" \\ t \" ) ; <nl> - writer . print ( \" < / \" ) ; <nl> - if ( elementNS ! = - 1 ) writer . print ( strings [ elementNS ] + \" : \" ) ; <nl> - writer . println ( strings [ elementName ] + \" > \" ) ; <nl> + if ( currentTag = = strings [ elementName ] ) { <nl> + writer . println ( \" / > \" ) ; <nl> + wasOneLiner = true ; <nl> + } else { <nl> + for ( int i = 0 ; i < numtabs ; i + + ) writer . print ( \" \\ t \" ) ; <nl> + writer . print ( \" < / \" ) ; <nl> + if ( elementNS ! = - 1 ) writer . print ( strings [ elementNS ] + \" : \" ) ; <nl> + writer . println ( strings [ elementName ] + \" > \" ) ; <nl> + } <nl> numtabs - = 1 ; <nl> + / / System . out . println ( \" ELEMENT END Line : \" + endLineNumber + \" of \" + strings [ elementName ] ) ; <nl> + / / TODO : Mind linenumbers for real original file ; ) <nl> } <nl> <nl> private int cInt8 ( byte [ ] bytes , int offset ) { <nl>\n", "msg": "Fixed XML oneLiners . Added another attribute value data type\n"}
{"diff_id": 29740, "repo": "SeleniumHQ/selenium\n", "sha": "91898048198e4000f687a681741feb8dda46a167\n", "time": "2010-09-03T22:05:09Z\n", "diff": "mmm a / common / test / java / org / openqa / selenium / internal / InProject . java <nl> ppp b / common / test / java / org / openqa / selenium / internal / InProject . java <nl> <nl> + / * <nl> + Copyright 2010 WebDriver committers <nl> + Copyright 2010 Google Inc . <nl> + <nl> + Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> + you may not use this file except in compliance with the License . <nl> + You may obtain a copy of the License at <nl> + <nl> + http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + <nl> + Unless required by applicable law or agreed to in writing , software <nl> + distributed under the License is distributed on an \" AS IS \" BASIS , <nl> + WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + See the License for the specific language governing permissions and <nl> + limitations under the License . <nl> + * / <nl> + <nl> package org . openqa . selenium . internal ; <nl> <nl> import java . io . File ; <nl>\n", "msg": "SimonStewart : Adding missing copyright header\n"}
{"diff_id": 29783, "repo": "oracle/graal\n", "sha": "a30c17fc8891cd204b92fc5aae609aae42ee3429\n", "time": "2017-03-30T07:45:21Z\n", "diff": "mmm a / graal / org . graalvm . compiler . nodes / src / org / graalvm / compiler / nodes / GraphDecoder . java <nl> ppp b / graal / org . graalvm . compiler . nodes / src / org / graalvm / compiler / nodes / GraphDecoder . java <nl> public boolean isInlinedMethod ( ) { <nl> public final Node [ ] createdNodes ; <nl> / * * <nl> * Nodes that have been created in outer loop scopes and existed before starting to process <nl> - * this loop , indexed by the orderId . <nl> + * this loop , indexed by the orderId . Only used when { @ link MethodScope # loopExplosion } is <nl> + * not { @ link LoopExplosionKind # NONE } . <nl> * / <nl> public final Node [ ] initialCreatedNodes ; <nl> <nl> protected LoopScope ( MethodScope methodScope ) { <nl> <nl> int nodeCount = methodScope . encodedGraph . nodeStartOffsets . length ; <nl> this . nodesToProcess = new BitSet ( methodScope . maxFixedNodeOrderId ) ; <nl> - this . initialCreatedNodes = new Node [ nodeCount ] ; <nl> this . createdNodes = new Node [ nodeCount ] ; <nl> + this . initialCreatedNodes = null ; <nl> } <nl> <nl> protected LoopScope ( MethodScope methodScope , LoopScope outer , int loopDepth , int loopIteration , int loopBeginOrderId , Node [ ] initialCreatedNodes , Node [ ] createdNodes , <nl> protected LoopScope ( MethodScope methodScope , LoopScope outer , int loopDepth , int <nl> this . loopBeginOrderId = loopBeginOrderId ; <nl> this . nodesToProcess = new BitSet ( methodScope . maxFixedNodeOrderId ) ; <nl> this . initialCreatedNodes = initialCreatedNodes ; <nl> - this . createdNodes = Arrays . copyOf ( createdNodes , createdNodes . length ) ; <nl> + this . createdNodes = createdNodes ; <nl> } <nl> <nl> @ Override <nl> protected void finishInlining ( @ SuppressWarnings ( \" unused \" ) MethodScope inlineScop <nl> } <nl> <nl> private static void propagateCreatedNodes ( LoopScope loopScope ) { <nl> - if ( loopScope . outer = = null ) { <nl> + if ( loopScope . outer = = null | | loopScope . createdNodes ! = loopScope . outer . createdNodes ) { <nl> return ; <nl> } <nl> <nl> protected LoopScope processNextNode ( MethodScope methodScope , LoopScope loopScope <nl> LoopScope outerScope = loopScope . outer ; <nl> int nextIterationNumber = outerScope . nextIterations . isEmpty ( ) ? outerScope . loopIteration + 1 : outerScope . nextIterations . getLast ( ) . loopIteration + 1 ; <nl> successorAddScope = new LoopScope ( methodScope , outerScope . outer , outerScope . loopDepth , nextIterationNumber , outerScope . loopBeginOrderId , outerScope . initialCreatedNodes , <nl> - loopScope . initialCreatedNodes , outerScope . nextIterations , outerScope . iterationStates ) ; <nl> + Arrays . copyOf ( loopScope . initialCreatedNodes , loopScope . initialCreatedNodes . length ) , outerScope . nextIterations , outerScope . iterationStates ) ; <nl> checkLoopExplosionIteration ( methodScope , successorAddScope ) ; <nl> <nl> / * <nl> protected LoopScope processNextNode ( MethodScope methodScope , LoopScope loopScope <nl> if ( merge instanceof LoopBeginNode ) { <nl> assert phiNodeScope = = phiInputScope & & phiNodeScope = = loopScope ; <nl> resultScope = new LoopScope ( methodScope , loopScope , loopScope . loopDepth + 1 , 0 , mergeOrderId , <nl> - Arrays . copyOf ( loopScope . createdNodes , loopScope . createdNodes . length ) , loopScope . createdNodes , / / <nl> + methodScope . loopExplosion ! = LoopExplosionKind . NONE ? Arrays . copyOf ( loopScope . createdNodes , loopScope . createdNodes . length ) : null , <nl> + methodScope . loopExplosion ! = LoopExplosionKind . NONE ? Arrays . copyOf ( loopScope . createdNodes , loopScope . createdNodes . length ) : loopScope . createdNodes , / / <nl> methodScope . loopExplosion ! = LoopExplosionKind . NONE ? new ArrayDeque < > ( ) : null , / / <nl> methodScope . loopExplosion = = LoopExplosionKind . MERGE_EXPLODE ? EconomicMap . create ( Equivalence . DEFAULT ) : null ) ; <nl> phiInputScope = resultScope ; <nl> phiNodeScope = resultScope ; <nl> <nl> - registerNode ( loopScope , mergeOrderId , null , true , true ) ; <nl> + if ( methodScope . loopExplosion ! = LoopExplosionKind . NONE ) { <nl> + registerNode ( loopScope , mergeOrderId , null , true , true ) ; <nl> + } <nl> loopScope . nodesToProcess . clear ( mergeOrderId ) ; <nl> resultScope . nodesToProcess . set ( mergeOrderId ) ; <nl> } <nl> protected void handleLoopExplosionBegin ( MethodScope methodScope , LoopScope loopS <nl> if ( loopScope . createdNodes [ i ] = = frameStateValue ) { <nl> loopScope . createdNodes [ i ] = newFrameStateValue ; <nl> } <nl> - if ( loopScope . initialCreatedNodes [ i ] = = frameStateValue ) { <nl> - loopScope . initialCreatedNodes [ i ] = newFrameStateValue ; <nl> + } <nl> + <nl> + if ( loopScope . initialCreatedNodes ! = null ) { <nl> + for ( int i = 0 ; i < loopScope . initialCreatedNodes . length ; i + + ) { <nl> + if ( loopScope . initialCreatedNodes [ i ] = = frameStateValue ) { <nl> + loopScope . initialCreatedNodes [ i ] = newFrameStateValue ; <nl> + } <nl> } <nl> } <nl> } <nl> protected FixedNode handleLoopExplosionEnd ( MethodScope methodScope , LoopScope lo <nl> if ( methodScope . loopExplosion ! = LoopExplosionKind . FULL_UNROLL | | loopScope . nextIterations . isEmpty ( ) ) { <nl> int nextIterationNumber = loopScope . nextIterations . isEmpty ( ) ? loopScope . loopIteration + 1 : loopScope . nextIterations . getLast ( ) . loopIteration + 1 ; <nl> LoopScope nextIterationScope = new LoopScope ( methodScope , loopScope . outer , loopScope . loopDepth , nextIterationNumber , loopScope . loopBeginOrderId , loopScope . initialCreatedNodes , <nl> - loopScope . initialCreatedNodes , loopScope . nextIterations , loopScope . iterationStates ) ; <nl> + Arrays . copyOf ( loopScope . initialCreatedNodes , loopScope . initialCreatedNodes . length ) , loopScope . nextIterations , loopScope . iterationStates ) ; <nl> checkLoopExplosionIteration ( methodScope , nextIterationScope ) ; <nl> loopScope . nextIterations . addLast ( nextIterationScope ) ; <nl> registerNode ( nextIterationScope , loopScope . loopBeginOrderId , null , true , true ) ; <nl> protected void handleProxyNodes ( MethodScope methodScope , LoopScope loopScope , Lo <nl> * The ProxyNode transports a value from the loop to the outer scope . We therefore <nl> * register it in the outer scope . <nl> * / <nl> - registerNode ( loopScope . outer , proxyOrderId , proxy , false , false ) ; <nl> + if ( loopScope . outer . createdNodes ! = loopScope . createdNodes ) { <nl> + registerNode ( loopScope . outer , proxyOrderId , proxy , false , false ) ; <nl> + } <nl> } <nl> } <nl> <nl>\n", "msg": "Avoid unnecessary Node array allocations .\n"}
{"diff_id": 29991, "repo": "google/ExoPlayer\n", "sha": "ae82eb75906d97471242241f2209943959985eda\n", "time": "2018-03-07T15:30:57Z\n", "diff": "mmm a / library / core / src / main / java / com / google / android / exoplayer2 / drm / ErrorStateDrmSession . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / drm / ErrorStateDrmSession . java <nl> <nl> import com . google . android . exoplayer2 . util . Assertions ; <nl> import java . util . Map ; <nl> <nl> - / * * <nl> - * A { @ link DrmSession } that ' s in a terminal error state . <nl> - * / <nl> - / * package * / final class ErrorStateDrmSession < T extends ExoMediaCrypto > implements DrmSession < T > { <nl> + / * * A { @ link DrmSession } that ' s in a terminal error state . * / <nl> + public final class ErrorStateDrmSession < T extends ExoMediaCrypto > implements DrmSession < T > { <nl> <nl> private final DrmSessionException error ; <nl> <nl>\n", "msg": "Create a new package to fork exoplayer v2 DefaultDrmSessionManager and\n"}
{"diff_id": 30080, "repo": "bazelbuild/bazel\n", "sha": "a1a990e42bab1bed01a7dff02a8b214c23f3dae4\n", "time": "2018-05-23T16:50:05Z\n", "diff": "new file mode 100644 <nl> index 000000000000 . . fc1b7078e6be <nl> mmm / dev / null <nl> ppp b / src / test / java / com / google / devtools / build / lib / analysis / InterruptedExceptionTest . java <nl> <nl> + / / Copyright 2018 The Bazel Authors . All rights reserved . <nl> + / / <nl> + / / Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> + / / you may not use this file except in compliance with the License . <nl> + / / You may obtain a copy of the License at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + / / <nl> + / / Unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the License is distributed on an \" AS IS \" BASIS , <nl> + / / WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + / / See the License for the specific language governing permissions and <nl> + / / limitations under the License . <nl> + package com . google . devtools . build . lib . analysis ; <nl> + <nl> + import static org . junit . Assert . fail ; <nl> + <nl> + import com . google . devtools . build . lib . analysis . util . AnalysisTestCase ; <nl> + import com . google . devtools . build . lib . clock . BlazeClock ; <nl> + import com . google . devtools . build . lib . vfs . Dirent ; <nl> + import com . google . devtools . build . lib . vfs . FileSystem ; <nl> + import com . google . devtools . build . lib . vfs . Path ; <nl> + import com . google . devtools . build . lib . vfs . inmemoryfs . InMemoryFileSystem ; <nl> + import java . io . IOException ; <nl> + import java . util . Collection ; <nl> + import org . junit . Test ; <nl> + import org . junit . runner . RunWith ; <nl> + import org . junit . runners . JUnit4 ; <nl> + <nl> + / * * <nl> + * Tests verifying appropriate propagation of { @ link InterruptedException } during filesystem <nl> + * operations . <nl> + * / <nl> + @ RunWith ( JUnit4 . class ) <nl> + public class InterruptedExceptionTest extends AnalysisTestCase { <nl> + <nl> + private final Thread mainThread = Thread . currentThread ( ) ; <nl> + <nl> + @ Override <nl> + protected FileSystem createFileSystem ( ) { <nl> + return new InMemoryFileSystem ( BlazeClock . instance ( ) ) { <nl> + @ Override <nl> + protected Collection < Dirent > readdir ( Path path , boolean followSymlinks ) throws IOException { <nl> + if ( path . toString ( ) . contains ( \" causes_interrupt \" ) ) { <nl> + mainThread . interrupt ( ) ; <nl> + } <nl> + return super . readdir ( path , followSymlinks ) ; <nl> + } <nl> + } ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testGlobInterruptedException ( ) throws Exception { <nl> + scratch . file ( \" a / BUILD \" , \" sh_library ( name = ' a ' , srcs = glob ( [ ' * * / * ' ] ) ) \" ) ; <nl> + scratch . file ( \" a / b / foo . sh \" , \" testfile \" ) ; <nl> + scratch . file ( \" a / causes_interrupt / bar . sh \" , \" testfile \" ) ; <nl> + reporter . removeHandler ( failFastHandler ) ; <nl> + <nl> + try { <nl> + update ( \" / / a : a \" ) ; <nl> + fail ( \" Expected interrupted exception \" ) ; <nl> + } catch ( InterruptedException expected ) { <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> + public void testSkylarkGlobInterruptedException ( ) throws Exception { <nl> + scratch . file ( \" a / gen . bzl \" , <nl> + \" def gen ( ) : \" , <nl> + \" native . filegroup ( name = ' a ' , srcs = native . glob ( [ ' * * / * ' ] ) ) \" ) ; <nl> + scratch . file ( \" a / BUILD \" , <nl> + \" load ( ' / / a : gen . bzl ' , ' gen ' ) \" , <nl> + \" gen ( ) \" ) ; <nl> + <nl> + scratch . file ( \" a / b / foo . sh \" , \" testfile \" ) ; <nl> + scratch . file ( \" a / causes_interrupt / bar . sh \" , \" testfile \" ) ; <nl> + reporter . removeHandler ( failFastHandler ) ; <nl> + <nl> + try { <nl> + update ( \" / / a : a \" ) ; <nl> + fail ( \" Expected interrupted exception \" ) ; <nl> + } catch ( InterruptedException expected ) { <nl> + } <nl> + } <nl> + } <nl>\n", "msg": "Create tests verifying appropriate propagation of InterruptedException during filesystem operations .\n"}
{"diff_id": 30091, "repo": "oracle/graal\n", "sha": "d79d23d0dd635c89d6ec99fa2c016e01bb294929\n", "time": "2019-02-21T10:39:20Z\n", "diff": "mmm a / vm / src / com . oracle . graalvm . locator / src / com / oracle / graalvm / locator / GraalVMLocator . java <nl> ppp b / vm / src / com . oracle . graalvm . locator / src / com / oracle / graalvm / locator / GraalVMLocator . java <nl> <nl> public GraalVMLocator ( ) { <nl> } <nl> <nl> - private static List < URL > collectClassPath ( ) { <nl> - <nl> - HomeFinder homeFinder = HomeFinder . getInstance ( ) ; <nl> - if ( homeFinder = = null ) { <nl> - throw new IllegalStateException ( \" No HomeFinder instance . \" ) ; <nl> - } <nl> + private static void setGraalVMProperties ( HomeFinder homeFinder ) { <nl> Path homePath = homeFinder . getHomeFolder ( ) ; <nl> if ( homePath ! = null ) { <nl> String home = homePath . toString ( ) ; <nl> public GraalVMLocator ( ) { <nl> System . setProperty ( \" org . graalvm . home \" , home ) ; <nl> } <nl> } <nl> - <nl> String version = homeFinder . getVersion ( ) ; <nl> System . setProperty ( \" graalvm . version \" , version ) ; <nl> System . setProperty ( \" org . graalvm . version \" , version ) ; <nl> + for ( Map . Entry < String , Path > languageHome : homeFinder . getLanguageHomes ( ) . entrySet ( ) ) { <nl> + setLanguageHomeProperty ( languageHome . getKey ( ) , languageHome . getValue ( ) ) ; <nl> + } <nl> + for ( Map . Entry < String , Path > toolHome : homeFinder . getToolHomes ( ) . entrySet ( ) ) { <nl> + setLanguageHomeProperty ( toolHome . getKey ( ) , toolHome . getValue ( ) ) ; <nl> + } <nl> + } <nl> <nl> + private static void setLanguageHomeProperty ( String languageId , Path languageLocation ) { <nl> + if ( Files . isDirectory ( languageLocation ) ) { <nl> + final String homeFolderKey = languageId + \" . home \" ; <nl> + if ( System . getProperty ( homeFolderKey ) = = null ) { <nl> + System . setProperty ( homeFolderKey , languageLocation . toString ( ) ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + private static List < URL > collectClassPath ( HomeFinder homeFinder ) { <nl> List < URL > classPath = new ArrayList < > ( ) ; <nl> collectLanguageJars ( homeFinder . getLanguageHomes ( ) , classPath ) ; <nl> collectLanguageJars ( homeFinder . getToolHomes ( ) , classPath ) ; <nl> public GraalVMLocator ( ) { <nl> <nl> public static ClassLoader getLanguagesLoader ( ) { <nl> if ( loader = = null ) { <nl> - final List < URL > classPath = collectClassPath ( ) ; <nl> - loader = TruffleOptions . AOT ? null : new GuestLangToolsLoader ( classPath . toArray ( new URL [ 0 ] ) , GraalVMLocator . class . getClassLoader ( ) ) ; <nl> + HomeFinder homeFinder = HomeFinder . getInstance ( ) ; <nl> + if ( homeFinder = = null ) { <nl> + throw new IllegalStateException ( \" No HomeFinder instance . \" ) ; <nl> + } <nl> + setGraalVMProperties ( homeFinder ) ; <nl> + if ( ! TruffleOptions . AOT ) { <nl> + final List < URL > classPath = collectClassPath ( homeFinder ) ; <nl> + loader = new GuestLangToolsLoader ( classPath . toArray ( new URL [ 0 ] ) , GraalVMLocator . class . getClassLoader ( ) ) ; <nl> + } <nl> } <nl> return loader ; <nl> } <nl> public static ClassLoader getLanguagesLoader ( ) { <nl> <nl> private static void collectLanguageJars ( Map < String , Path > homes , List < URL > classPath ) { <nl> for ( Map . Entry < String , Path > languageHome : homes . entrySet ( ) ) { <nl> - final String languageId = languageHome . getKey ( ) ; <nl> final Path languageLocation = languageHome . getValue ( ) ; <nl> if ( Files . isDirectory ( languageLocation ) ) { <nl> - final String homeFolderKey = languageId + \" . home \" ; <nl> - if ( System . getProperty ( homeFolderKey ) = = null ) { <nl> - System . setProperty ( homeFolderKey , languageLocation . toString ( ) ) ; <nl> - } <nl> try ( DirectoryStream < Path > dirStream = Files . newDirectoryStream ( languageLocation ) ) { <nl> for ( Path file : dirStream ) { <nl> addJar ( classPath , file ) ; <nl>\n", "msg": "[ GR - 14010 ] Native image pulls GraalVMLocator . addJar method inside the image .\n"}
{"diff_id": 30399, "repo": "libgdx/libgdx\n", "sha": "9a8d8a072029cc8d39e7c2eb37a187d70e0de91f\n", "time": "2011-10-31T19:00:01Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / scenes / scene2d / ui / tablelayout / LibgdxToolkit . java <nl> ppp b / gdx / src / com / badlogic / gdx / scenes / scene2d / ui / tablelayout / LibgdxToolkit . java <nl> public void setProperty ( TableLayout layout , Actor object , String name , List < Str <nl> if ( layout . skin ! = null & & values . size ( ) = = 1 & & name . equalsIgnoreCase ( \" style \" ) ) { <nl> try { <nl> String styleName = values . get ( 0 ) ; <nl> - Class styleClass = Class . forName ( object . getClass ( ) . getName ( ) + \" Style \" ) ; <nl> + Class styleClass = Class . forName ( object . getClass ( ) . getName ( ) + \" $ \" + object . getClass ( ) . getSimpleName ( ) + \" Style \" ) ; <nl> if ( layout . skin . hasStyle ( styleName , styleClass ) ) { <nl> try { <nl> Method setStyleMethod = object . getClass ( ) . getMethod ( \" setStyle \" , styleClass ) ; <nl> public void addChild ( Actor parent , Actor child , String layoutString ) { <nl> if ( child . parent ! = null ) child . remove ( ) ; <nl> try { <nl> parent . getClass ( ) . getMethod ( \" setWidget \" , Actor . class ) . invoke ( parent , child ) ; <nl> + return ; <nl> } catch ( InvocationTargetException ex ) { <nl> throw new RuntimeException ( \" Error calling setWidget . \" , ex ) ; <nl> } catch ( Exception ignored ) { <nl>\n", "msg": "[ fixed ] LibgdxToolkit , setWidget and setStyle .\n"}
{"diff_id": 30443, "repo": "dbeaver/dbeaver\n", "sha": "97a60b744310c9dfa389c6190cdd748b97ecb146\n", "time": "2015-03-21T13:05:43Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . generic / src / org / jkiss / dbeaver / ext / generic / model / GenericTable . java <nl> ppp b / plugins / org . jkiss . dbeaver . generic / src / org / jkiss / dbeaver / ext / generic / model / GenericTable . java <nl> public synchronized Long getRowCount ( DBRProgressMonitor monitor ) <nl> } <nl> if ( rowCount = = null ) { <nl> / / Query row count <nl> - DBCSession session = getDataSource ( ) . openSession ( monitor , DBCExecutionPurpose . META , \" Read row count \" ) ; <nl> + DBCSession session = getDataSource ( ) . openSession ( monitor , DBCExecutionPurpose . UTIL , \" Read row count \" ) ; <nl> try { <nl> rowCount = countData ( session , null ) ; <nl> } <nl>\n", "msg": "Use main connection for generic table row count\n"}
{"diff_id": 30474, "repo": "elastic/elasticsearch\n", "sha": "d3978383a5876cafaef632679502e5c7a14f38cc\n", "time": "2010-09-28T12:53:37Z\n", "diff": "mmm a / modules / elasticsearch / src / main / java / org / elasticsearch / common / lucene / all / AllTokenStream . java <nl> ppp b / modules / elasticsearch / src / main / java / org / elasticsearch / common / lucene / all / AllTokenStream . java <nl> public AllEntries allEntries ( ) { <nl> if ( ! input . incrementToken ( ) ) { <nl> return false ; <nl> } <nl> - float boost = allEntries . current ( ) . boost ( ) ; <nl> - if ( boost ! = 1 . 0f ) { <nl> - payloadAttribute . setPayload ( new Payload ( encodeFloat ( boost ) ) ) ; <nl> - } else { <nl> - payloadAttribute . setPayload ( null ) ; <nl> + if ( allEntries . current ( ) ! = null ) { <nl> + float boost = allEntries . current ( ) . boost ( ) ; <nl> + if ( boost ! = 1 . 0f ) { <nl> + payloadAttribute . setPayload ( new Payload ( encodeFloat ( boost ) ) ) ; <nl> + } else { <nl> + payloadAttribute . setPayload ( null ) ; <nl> + } <nl> } <nl> return true ; <nl> } <nl>\n", "msg": "when using keyword based analayzer on _all , an NPE is thrown since there is no current entry , ignore it ( it does not make sense to have keywork analyzer on _all field . . . )\n"}
{"diff_id": 30507, "repo": "oracle/graal\n", "sha": "c23e11d20a4e2c557d0b62867d3fd5ead8b6d620\n", "time": "2016-04-17T13:11:16Z\n", "diff": "mmm a / projects / com . oracle . truffle . llvm . runtime / src / com / oracle / truffle / llvm / runtime / LLVMOptions . java <nl> ppp b / projects / com . oracle . truffle . llvm . runtime / src / com / oracle / truffle / llvm / runtime / LLVMOptions . java <nl> static int parseInteger ( Property prop ) { <nl> LLVMOptions : : parseString , <nl> PropertyCategory . TESTS ) , <nl> DYN_LIBRARY_PATHS ( \" DynamicNativeLibraryPath \" , \" The native library search paths delimited by \" + PATH_DELIMITER , null , LLVMOptions : : parseDynamicLibraryPath , PropertyCategory . GENERAL ) , <nl> + DYN_BITCODE_LIBRARIES ( \" DynamicBitcodeLibraries \" , \" The paths to shared bitcode libraries delimited by \" + PATH_DELIMITER , null , LLVMOptions : : parseDynamicLibraryPath , PropertyCategory . GENERAL ) , <nl> PROJECT_ROOT ( \" ProjectRoot \" , \" Overrides the root of the project . This option exists to set the project root from mx \" , \" . \" , LLVMOptions : : parseString , PropertyCategory . MX ) , <nl> OPTIMIZATIONS_DISABLE_SPECULATIVE ( <nl> \" DisableSpeculativeOptimizations \" , <nl> public static boolean performanceWarningsAreFatal ( ) { <nl> return getParsedProperty ( Property . PERFORMANCE_WARNING_ARE_FATAL ) ; <nl> } <nl> <nl> + public static String [ ] getDynamicBitcodeLibraries ( ) { <nl> + return getParsedProperty ( Property . DYN_BITCODE_LIBRARIES ) ; <nl> + } <nl> + <nl> } <nl>\n", "msg": "Add a new option to load shared bitcode libraries\n"}
{"diff_id": 30579, "repo": "eclipse-vertx/vert.x\n", "sha": "b94c0516fc977a1ba662f6927121f46d0284daee\n", "time": "2014-03-05T15:17:13Z\n", "diff": "mmm a / vertx - core / src / main / java / org / vertx / java / core / sockjs / EventBusBridge . java <nl> ppp b / vertx - core / src / main / java / org / vertx / java / core / sockjs / EventBusBridge . java <nl> <nl> private final int maxAddressLength ; <nl> private final int maxHandlersPerSocket ; <nl> private final long pingTimeout ; <nl> + private final long replyTimeout ; <nl> private final Vertx vertx ; <nl> private final EventBus eb ; <nl> private final Set < String > acceptedReplyAddresses = new HashSet < > ( ) ; <nl> public EventBusBridge ( Vertx vertx , JsonArray inboundPermitted , JsonArray outboun <nl> this . maxAddressLength = conf . getInteger ( \" max_address_length \" , DEFAULT_MAX_ADDRESS_LENGTH ) ; <nl> this . maxHandlersPerSocket = conf . getInteger ( \" max_handlers_per_socket \" , DEFAULT_MAX_HANDLERS_PER_SOCKET ) ; <nl> this . pingTimeout = conf . getLong ( \" ping_interval \" , DEFAULT_PING_TIMEOUT ) ; <nl> + this . replyTimeout = conf . getLong ( \" reply_timeout \" , DEFAULT_REPLY_TIMEOUT ) ; <nl> } <nl> <nl> private void handleSocketClosed ( SockJSSocket sock , Map < String , Handler < Message > > handlers ) { <nl> private void checkAddAccceptedReplyAddress ( final String replyAddress ) { <nl> / / So we cache the reply address , so we can check against it <nl> acceptedReplyAddresses . add ( replyAddress ) ; <nl> / / And we remove after timeout in case the reply never comes <nl> - vertx . setTimer ( DEFAULT_REPLY_TIMEOUT , new Handler < Long > ( ) { <nl> + vertx . setTimer ( replyTimeout , new Handler < Long > ( ) { <nl> public void handle ( Long id ) { <nl> acceptedReplyAddresses . remove ( replyAddress ) ; <nl> } <nl> private void checkAndSend ( boolean send , final String address , Object body , <nl> if ( replyAddress ! = null & & ! checkMaxHandlers ( info ) ) { <nl> return ; <nl> } <nl> - final Handler < Message > replyHandler ; <nl> + final Handler < AsyncResult < Message < Object > > > replyHandler ; <nl> if ( replyAddress ! = null ) { <nl> - replyHandler = new Handler < Message > ( ) { <nl> - public void handle ( Message message ) { <nl> - / / Note we don ' t check outbound matches for replies <nl> - / / Replies are always let through if the original message <nl> - / / was approved <nl> - checkAddAccceptedReplyAddress ( message . replyAddress ( ) ) ; <nl> - deliverMessage ( sock , replyAddress , message ) ; <nl> - info . handlerCount - - ; <nl> + replyHandler = new Handler < AsyncResult < Message < Object > > > ( ) { <nl> + public void handle ( AsyncResult < Message < Object > > result ) { <nl> + if ( result . succeeded ( ) ) { <nl> + Message message = result . result ( ) ; <nl> + / / Note we don ' t check outbound matches for replies <nl> + / / Replies are always let through if the original message <nl> + / / was approved <nl> + checkAddAccceptedReplyAddress ( message . replyAddress ( ) ) ; <nl> + deliverMessage ( sock , replyAddress , message ) ; <nl> + info . handlerCount - - ; <nl> + } <nl> } <nl> } ; <nl> } else { <nl> public void handle ( Message message ) { <nl> log . debug ( \" Forwarding message to address \" + address + \" on event bus \" ) ; <nl> } <nl> if ( send ) { <nl> - eb . send ( address , body , replyHandler ) ; <nl> + eb . sendWithTimeout ( address , body , replyTimeout , replyHandler ) ; <nl> if ( replyAddress ! = null ) { <nl> info . handlerCount + + ; <nl> } <nl>\n", "msg": "Use sendWithTimeout in EventBusBridge so reply handlers are cleaned up if a client does not reply .\n"}
{"diff_id": 30591, "repo": "SeleniumHQ/selenium\n", "sha": "8772fd8974f6a0bcb9b4f1d4f514d1d79f14d7c5\n", "time": "2010-09-23T23:49:03Z\n", "diff": "mmm a / firefox / src / java / org / openqa / selenium / firefox / FirefoxProfile . java <nl> ppp b / firefox / src / java / org / openqa / selenium / firefox / FirefoxProfile . java <nl> <nl> import java . util . Map ; <nl> <nl> import com . google . common . collect . Maps ; <nl> - import com . google . common . io . Files ; <nl> + import org . apache . commons . io . FileUtils ; <nl> import org . openqa . selenium . Proxy ; <nl> import org . openqa . selenium . Proxy . ProxyType ; <nl> import org . openqa . selenium . WebDriverException ; <nl> public File layoutOnDisk ( ) { <nl> } <nl> } <nl> <nl> - protected void copyModel ( File source , File profileDir ) throws IOException { <nl> - if ( source = = null | | ! source . exists ( ) ) { <nl> + protected void copyModel ( File sourceDir , File profileDir ) throws IOException { <nl> + if ( sourceDir = = null | | ! sourceDir . exists ( ) ) { <nl> return ; <nl> } <nl> <nl> - Files . copy ( source , profileDir ) ; <nl> + FileUtils . copyDirectory ( sourceDir , profileDir ) ; <nl> } <nl> <nl> protected void installExtensions ( File parentDir ) throws IOException { <nl>\n", "msg": "Use FileUtils . copyDirectory , which works on a directory source File , instead of Files . copy , which doesn ' t .\n"}
{"diff_id": 30779, "repo": "dbeaver/dbeaver\n", "sha": "14535c0d679488ab3ebbae3e87ece04aad3d6865\n", "time": "2018-08-12T15:01:02Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . ui / src / org / jkiss / dbeaver / ui / controls / TextWithOpenFolder . java <nl> ppp b / plugins / org . jkiss . dbeaver . ui / src / org / jkiss / dbeaver / ui / controls / TextWithOpenFolder . java <nl> public TextWithOpenFolder ( Composite parent , String title ) { <nl> <nl> protected void openBrowser ( ) { <nl> DirectoryDialog dialog = new DirectoryDialog ( getShell ( ) , SWT . NONE ) ; <nl> - dialog . setText ( title ) ; <nl> + if ( title ! = null ) { <nl> + dialog . setText ( title ) ; <nl> + } <nl> dialog . setFilterPath ( getText ( ) ) ; <nl> String selected = dialog . open ( ) ; <nl> if ( selected ! = null ) { <nl>\n", "msg": "Text with open folder control fix ( title is optional )\n"}
{"diff_id": 30799, "repo": "netty/netty\n", "sha": "cf4c464d99f0723d908151c2b4a2b9d2b203061c\n", "time": "2014-10-25T07:53:16Z\n", "diff": "mmm a / codec - http / src / main / java / io / netty / handler / codec / http / HttpObjectDecoder . java <nl> ppp b / codec - http / src / main / java / io / netty / handler / codec / http / HttpObjectDecoder . java <nl> <nl> <nl> import java . util . List ; <nl> <nl> - import static io . netty . buffer . ByteBufUtil . * ; <nl> - <nl> / * * <nl> * Decodes { @ link ByteBuf } s into { @ link HttpMessage } s and <nl> * { @ link HttpContent } s . <nl> <nl> * implement all abstract methods properly . <nl> * / <nl> public abstract class HttpObjectDecoder extends ReplayingDecoder < State > { <nl> + private static final String EMPTY_VALUE = \" \" ; <nl> <nl> - private final int maxInitialLineLength ; <nl> - private final int maxHeaderSize ; <nl> private final int maxChunkSize ; <nl> private final boolean chunkedSupported ; <nl> protected final boolean validateHeaders ; <nl> - private final AppendableCharSequence seq = new AppendableCharSequence ( 128 ) ; <nl> - private final HeaderParser headerParser = new HeaderParser ( seq ) ; <nl> - private final LineParser lineParser = new LineParser ( seq ) ; <nl> + private final HeaderParser headerParser ; <nl> + private final LineParser lineParser ; <nl> <nl> private HttpMessage message ; <nl> private long chunkSize ; <nl> - private int headerSize ; <nl> private long contentLength = Long . MIN_VALUE ; <nl> private volatile boolean resetRequested ; <nl> <nl> + / / These will be updated by splitHeader ( . . . ) <nl> + private CharSequence name ; <nl> + private CharSequence value ; <nl> + <nl> / * * <nl> * The internal state of { @ link HttpObjectDecoder } . <nl> * < em > Internal use only < / em > . <nl> protected HttpObjectDecoder ( <nl> \" maxChunkSize must be a positive integer : \" + <nl> maxChunkSize ) ; <nl> } <nl> - this . maxInitialLineLength = maxInitialLineLength ; <nl> - this . maxHeaderSize = maxHeaderSize ; <nl> this . maxChunkSize = maxChunkSize ; <nl> this . chunkedSupported = chunkedSupported ; <nl> this . validateHeaders = validateHeaders ; <nl> + AppendableCharSequence seq = new AppendableCharSequence ( 128 ) ; <nl> + lineParser = new LineParser ( seq , maxInitialLineLength ) ; <nl> + headerParser = new HeaderParser ( seq , maxHeaderSize ) ; <nl> } <nl> <nl> @ Override <nl> protected void decode ( ChannelHandlerContext ctx , ByteBuf buffer , List < Object > ou <nl> } finally { <nl> checkpoint ( ) ; <nl> } <nl> + / / fall - through <nl> } <nl> case READ_INITIAL : try { <nl> String [ ] initialLine = splitInitialLine ( lineParser . parse ( buffer ) ) ; <nl> protected void decode ( ChannelHandlerContext ctx , ByteBuf buffer , List < Object > ou <nl> <nl> message = createMessage ( initialLine ) ; <nl> checkpoint ( State . READ_HEADER ) ; <nl> - <nl> + / / fall - through <nl> } catch ( Exception e ) { <nl> out . add ( invalidMessage ( e ) ) ; <nl> return ; <nl> protected void decode ( ChannelHandlerContext ctx , ByteBuf buffer , List < Object > ou <nl> case READ_HEADER : try { <nl> State nextState = readHeaders ( buffer ) ; <nl> checkpoint ( nextState ) ; <nl> - if ( nextState = = State . READ_CHUNK_SIZE ) { <nl> - if ( ! chunkedSupported ) { <nl> - throw new IllegalArgumentException ( \" Chunked messages not supported \" ) ; <nl> - } <nl> - / / Chunked encoding - generate HttpMessage first . HttpChunks will follow . <nl> - out . add ( message ) ; <nl> - return ; <nl> - } <nl> - if ( nextState = = State . SKIP_CONTROL_CHARS ) { <nl> - / / No content is expected . <nl> - out . add ( message ) ; <nl> - out . add ( LastHttpContent . EMPTY_LAST_CONTENT ) ; <nl> - resetNow ( ) ; <nl> - return ; <nl> - } <nl> - long contentLength = contentLength ( ) ; <nl> - if ( contentLength = = 0 | | contentLength = = - 1 & & isDecodingRequest ( ) ) { <nl> - out . add ( message ) ; <nl> - out . add ( LastHttpContent . EMPTY_LAST_CONTENT ) ; <nl> - resetNow ( ) ; <nl> - return ; <nl> - } <nl> + switch ( nextState ) { <nl> + case SKIP_CONTROL_CHARS : <nl> + / / fast - path <nl> + / / No content is expected . <nl> + out . add ( message ) ; <nl> + out . add ( LastHttpContent . EMPTY_LAST_CONTENT ) ; <nl> + resetNow ( ) ; <nl> + return ; <nl> + case READ_CHUNK_SIZE : <nl> + if ( ! chunkedSupported ) { <nl> + throw new IllegalArgumentException ( \" Chunked messages not supported \" ) ; <nl> + } <nl> + / / Chunked encoding - generate HttpMessage first . HttpChunks will follow . <nl> + out . add ( message ) ; <nl> + return ; <nl> + default : <nl> + long contentLength = contentLength ( ) ; <nl> + if ( contentLength = = 0 | | contentLength = = - 1 & & isDecodingRequest ( ) ) { <nl> + out . add ( message ) ; <nl> + out . add ( LastHttpContent . EMPTY_LAST_CONTENT ) ; <nl> + resetNow ( ) ; <nl> + return ; <nl> + } <nl> <nl> - assert nextState = = State . READ_FIXED_LENGTH_CONTENT | | nextState = = State . READ_VARIABLE_LENGTH_CONTENT ; <nl> + assert nextState = = State . READ_FIXED_LENGTH_CONTENT | | <nl> + nextState = = State . READ_VARIABLE_LENGTH_CONTENT ; <nl> <nl> - out . add ( message ) ; <nl> + out . add ( message ) ; <nl> <nl> - if ( nextState = = State . READ_FIXED_LENGTH_CONTENT ) { <nl> - / / chunkSize will be decreased as the READ_FIXED_LENGTH_CONTENT state reads data chunk by chunk . <nl> - chunkSize = contentLength ; <nl> - } <nl> + if ( nextState = = State . READ_FIXED_LENGTH_CONTENT ) { <nl> + / / chunkSize will be decreased as the READ_FIXED_LENGTH_CONTENT state reads data chunk by chunk . <nl> + chunkSize = contentLength ; <nl> + } <nl> <nl> - / / We return here , this forces decode to be called again where we will decode the content <nl> - return ; <nl> + / / We return here , this forces decode to be called again where we will decode the content <nl> + return ; <nl> + } <nl> } catch ( Exception e ) { <nl> out . add ( invalidMessage ( e ) ) ; <nl> return ; <nl> protected void decode ( ChannelHandlerContext ctx , ByteBuf buffer , List < Object > ou <nl> / / Keep reading data as a chunk until the end of connection is reached . <nl> int toRead = Math . min ( actualReadableBytes ( ) , maxChunkSize ) ; <nl> if ( toRead > 0 ) { <nl> - ByteBuf content = readBytes ( ctx . alloc ( ) , buffer , toRead ) ; <nl> - if ( buffer . isReadable ( ) ) { <nl> - out . add ( new DefaultHttpContent ( content ) ) ; <nl> - } else { <nl> - / / End of connection . <nl> - out . add ( new DefaultLastHttpContent ( content , validateHeaders ) ) ; <nl> - resetNow ( ) ; <nl> - } <nl> - } else if ( ! buffer . isReadable ( ) ) { <nl> - / / End of connection . <nl> - out . add ( LastHttpContent . EMPTY_LAST_CONTENT ) ; <nl> - resetNow ( ) ; <nl> + ByteBuf content = buffer . readSlice ( toRead ) . retain ( ) ; <nl> + out . add ( new DefaultHttpContent ( content ) ) ; <nl> } <nl> return ; <nl> } <nl> protected void decode ( ChannelHandlerContext ctx , ByteBuf buffer , List < Object > ou <nl> if ( toRead > chunkSize ) { <nl> toRead = ( int ) chunkSize ; <nl> } <nl> - ByteBuf content = readBytes ( ctx . alloc ( ) , buffer , toRead ) ; <nl> + ByteBuf content = buffer . readSlice ( toRead ) . retain ( ) ; <nl> chunkSize - = toRead ; <nl> <nl> if ( chunkSize = = 0 ) { <nl> protected void decode ( ChannelHandlerContext ctx , ByteBuf buffer , List < Object > ou <nl> if ( chunkSize = = 0 ) { <nl> checkpoint ( State . READ_CHUNK_FOOTER ) ; <nl> return ; <nl> - } else { <nl> - checkpoint ( State . READ_CHUNKED_CONTENT ) ; <nl> } <nl> + checkpoint ( State . READ_CHUNKED_CONTENT ) ; <nl> + / / fall - through <nl> } catch ( Exception e ) { <nl> out . add ( invalidChunk ( e ) ) ; <nl> return ; <nl> protected void decode ( ChannelHandlerContext ctx , ByteBuf buffer , List < Object > ou <nl> case READ_CHUNKED_CONTENT : { <nl> assert chunkSize < = Integer . MAX_VALUE ; <nl> int toRead = Math . min ( ( int ) chunkSize , maxChunkSize ) ; <nl> - <nl> - HttpContent chunk = new DefaultHttpContent ( readBytes ( ctx . alloc ( ) , buffer , toRead ) ) ; <nl> + toRead = Math . min ( toRead , actualReadableBytes ( ) ) ; <nl> + if ( toRead = = 0 ) { <nl> + return ; <nl> + } <nl> + HttpContent chunk = new DefaultHttpContent ( buffer . readSlice ( toRead ) . retain ( ) ) ; <nl> chunkSize - = toRead ; <nl> <nl> out . add ( chunk ) ; <nl> <nl> - if ( chunkSize = = 0 ) { <nl> - / / Read all content . <nl> - checkpoint ( State . READ_CHUNK_DELIMITER ) ; <nl> - } else { <nl> + if ( chunkSize ! = 0 ) { <nl> return ; <nl> } <nl> + checkpoint ( State . READ_CHUNK_DELIMITER ) ; <nl> + / / fall - through <nl> } <nl> case READ_CHUNK_DELIMITER : { <nl> for ( ; ; ) { <nl> protected void decodeLast ( ChannelHandlerContext ctx , ByteBuf in , List < Object > ou <nl> <nl> / / Handle the last unfinished message . <nl> if ( message ! = null ) { <nl> - <nl> + boolean chunked = HttpHeaders . isTransferEncodingChunked ( message ) ; <nl> + if ( state ( ) = = State . READ_VARIABLE_LENGTH_CONTENT & & ! in . isReadable ( ) & & ! chunked ) { <nl> + / / End of connection . <nl> + out . add ( LastHttpContent . EMPTY_LAST_CONTENT ) ; <nl> + reset ( ) ; <nl> + return ; <nl> + } <nl> / / Check if the closure of the connection signifies the end of the content . <nl> boolean prematureClosure ; <nl> - if ( isDecodingRequest ( ) ) { <nl> + if ( isDecodingRequest ( ) | | chunked ) { <nl> / / The last request did not wait for a response . <nl> prematureClosure = true ; <nl> } else { <nl> public void reset ( ) { <nl> private void resetNow ( ) { <nl> HttpMessage message = this . message ; <nl> this . message = null ; <nl> + name = null ; <nl> + value = null ; <nl> contentLength = Long . MIN_VALUE ; <nl> + lineParser . reset ( ) ; <nl> + headerParser . reset ( ) ; <nl> if ( ! isDecodingRequest ( ) ) { <nl> HttpResponse res = ( HttpResponse ) message ; <nl> if ( res ! = null & & res . status ( ) . code ( ) = = 101 ) { <nl> private static void skipControlCharacters ( ByteBuf buffer ) { <nl> } <nl> <nl> private State readHeaders ( ByteBuf buffer ) { <nl> - headerSize = 0 ; <nl> final HttpMessage message = this . message ; <nl> final HttpHeaders headers = message . headers ( ) ; <nl> <nl> AppendableCharSequence line = headerParser . parse ( buffer ) ; <nl> - String name = null ; <nl> - String value = null ; <nl> if ( line . length ( ) > 0 ) { <nl> - headers . clear ( ) ; <nl> do { <nl> char firstChar = line . charAt ( 0 ) ; <nl> if ( name ! = null & & ( firstChar = = ' ' | | firstChar = = ' \\ t ' ) ) { <nl> - value = value + ' ' + line . toString ( ) . trim ( ) ; <nl> + value = value . toString ( ) + ' ' + line . toString ( ) . trim ( ) ; <nl> } else { <nl> if ( name ! = null ) { <nl> headers . add ( name , value ) ; <nl> } <nl> - String [ ] header = splitHeader ( line ) ; <nl> - name = header [ 0 ] ; <nl> - value = header [ 1 ] ; <nl> + splitHeader ( line ) ; <nl> } <nl> <nl> line = headerParser . parse ( buffer ) ; <nl> } while ( line . length ( ) > 0 ) ; <nl> + } <nl> <nl> - / / Add the last header . <nl> - if ( name ! = null ) { <nl> - headers . add ( name , value ) ; <nl> - } <nl> + / / Add the last header . <nl> + if ( name ! = null ) { <nl> + headers . add ( name , value ) ; <nl> } <nl> + / / reset name and value fields <nl> + name = null ; <nl> + value = null ; <nl> <nl> State nextState ; <nl> <nl> private long contentLength ( ) { <nl> } <nl> <nl> private LastHttpContent readTrailingHeaders ( ByteBuf buffer ) { <nl> - headerSize = 0 ; <nl> AppendableCharSequence line = headerParser . parse ( buffer ) ; <nl> - String lastHeader = null ; <nl> + CharSequence lastHeader = null ; <nl> if ( line . length ( ) > 0 ) { <nl> LastHttpContent trailer = new DefaultLastHttpContent ( Unpooled . EMPTY_BUFFER , validateHeaders ) ; <nl> do { <nl> private LastHttpContent readTrailingHeaders ( ByteBuf buffer ) { <nl> / / Content - Length , Transfer - Encoding , or Trailer <nl> } <nl> } else { <nl> - String [ ] header = splitHeader ( line ) ; <nl> - String name = header [ 0 ] ; <nl> - if ( ! AsciiString . equalsIgnoreCase ( name , HttpHeaders . Names . CONTENT_LENGTH ) & & <nl> - ! AsciiString . equalsIgnoreCase ( name , HttpHeaders . Names . TRANSFER_ENCODING ) & & <nl> - ! AsciiString . equalsIgnoreCase ( name , HttpHeaders . Names . TRAILER ) ) { <nl> - trailer . trailingHeaders ( ) . add ( name , header [ 1 ] ) ; <nl> + splitHeader ( line ) ; <nl> + CharSequence headerName = name ; <nl> + if ( ! AsciiString . equalsIgnoreCase ( headerName , HttpHeaders . Names . CONTENT_LENGTH ) & & <nl> + ! AsciiString . equalsIgnoreCase ( headerName , HttpHeaders . Names . TRANSFER_ENCODING ) & & <nl> + ! AsciiString . equalsIgnoreCase ( headerName , HttpHeaders . Names . TRAILER ) ) { <nl> + trailer . trailingHeaders ( ) . add ( headerName , value ) ; <nl> } <nl> lastHeader = name ; <nl> + / / reset name and value fields <nl> + name = null ; <nl> + value = null ; <nl> } <nl> <nl> line = headerParser . parse ( buffer ) ; <nl> private static int getChunkSize ( String hex ) { <nl> cStart < cEnd ? sb . substring ( cStart , cEnd ) : \" \" } ; <nl> } <nl> <nl> - private static String [ ] splitHeader ( AppendableCharSequence sb ) { <nl> + private void splitHeader ( AppendableCharSequence sb ) { <nl> final int length = sb . length ( ) ; <nl> int nameStart ; <nl> int nameEnd ; <nl> private static int getChunkSize ( String hex ) { <nl> } <nl> } <nl> <nl> + name = sb . substring ( nameStart , nameEnd ) ; <nl> valueStart = findNonWhitespace ( sb , colonEnd ) ; <nl> if ( valueStart = = length ) { <nl> - return new String [ ] { <nl> - sb . substring ( nameStart , nameEnd ) , <nl> - \" \" <nl> - } ; <nl> + value = EMPTY_VALUE ; <nl> + } else { <nl> + valueEnd = findEndOfString ( sb ) ; <nl> + value = sb . substring ( valueStart , valueEnd ) ; <nl> } <nl> - <nl> - valueEnd = findEndOfString ( sb ) ; <nl> - return new String [ ] { <nl> - sb . substring ( nameStart , nameEnd ) , <nl> - sb . substring ( valueStart , valueEnd ) <nl> - } ; <nl> } <nl> <nl> private static int findNonWhitespace ( CharSequence sb , int offset ) { <nl> private static int findEndOfString ( CharSequence sb ) { <nl> return result ; <nl> } <nl> <nl> - private final class HeaderParser implements ByteBufProcessor { <nl> + private class HeaderParser implements ByteBufProcessor { <nl> private final AppendableCharSequence seq ; <nl> + private final int maxLength ; <nl> + private int size ; <nl> <nl> - HeaderParser ( AppendableCharSequence seq ) { <nl> + HeaderParser ( AppendableCharSequence seq , int maxLength ) { <nl> this . seq = seq ; <nl> + this . maxLength = maxLength ; <nl> } <nl> <nl> public AppendableCharSequence parse ( ByteBuf buffer ) { <nl> seq . reset ( ) ; <nl> - headerSize = 0 ; <nl> int i = buffer . forEachByte ( this ) ; <nl> buffer . readerIndex ( i + 1 ) ; <nl> + <nl> + / / Call checkpoint to make sure the readerIndex is updated correctly <nl> + checkpoint ( ) ; <nl> return seq ; <nl> } <nl> <nl> + public void reset ( ) { <nl> + size = 0 ; <nl> + } <nl> + <nl> @ Override <nl> public boolean process ( byte value ) throws Exception { <nl> char nextByte = ( char ) value ; <nl> - headerSize + + ; <nl> if ( nextByte = = HttpConstants . CR ) { <nl> return true ; <nl> } <nl> if ( nextByte = = HttpConstants . LF ) { <nl> return false ; <nl> } <nl> - <nl> - / / Abort decoding if the header part is too large . <nl> - if ( headerSize > = maxHeaderSize ) { <nl> + if ( size > = maxLength ) { <nl> / / TODO : Respond with Bad Request and discard the traffic <nl> / / or close the connection . <nl> / / No need to notify the upstream handlers - just log . <nl> / / If decoding a response , just throw an exception . <nl> - throw new TooLongFrameException ( <nl> - \" HTTP header is larger than \" + <nl> - maxHeaderSize + \" bytes . \" ) ; <nl> + throw newException ( maxLength ) ; <nl> } <nl> - <nl> + size + + ; <nl> seq . append ( nextByte ) ; <nl> return true ; <nl> } <nl> + <nl> + protected TooLongFrameException newException ( int maxLength ) { <nl> + return new TooLongFrameException ( <nl> + \" HTTP header is larger than \" + maxLength + <nl> + \" bytes . \" ) ; <nl> + } <nl> } <nl> <nl> - private final class LineParser implements ByteBufProcessor { <nl> - private final AppendableCharSequence seq ; <nl> - private int size ; <nl> + private final class LineParser extends HeaderParser { <nl> <nl> - LineParser ( AppendableCharSequence seq ) { <nl> - this . seq = seq ; <nl> + LineParser ( AppendableCharSequence seq , int maxLength ) { <nl> + super ( seq , maxLength ) ; <nl> } <nl> <nl> + @ Override <nl> public AppendableCharSequence parse ( ByteBuf buffer ) { <nl> - seq . reset ( ) ; <nl> - size = 0 ; <nl> - int i = buffer . forEachByte ( this ) ; <nl> - buffer . readerIndex ( i + 1 ) ; <nl> - return seq ; <nl> + reset ( ) ; <nl> + return super . parse ( buffer ) ; <nl> } <nl> <nl> @ Override <nl> - public boolean process ( byte value ) throws Exception { <nl> - char nextByte = ( char ) value ; <nl> - if ( nextByte = = HttpConstants . CR ) { <nl> - return true ; <nl> - } else if ( nextByte = = HttpConstants . LF ) { <nl> - return false ; <nl> - } else { <nl> - if ( size > = maxInitialLineLength ) { <nl> - / / TODO : Respond with Bad Request and discard the traffic <nl> - / / or close the connection . <nl> - / / No need to notify the upstream handlers - just log . <nl> - / / If decoding a response , just throw an exception . <nl> - throw new TooLongFrameException ( <nl> - \" An HTTP line is larger than \" + maxInitialLineLength + <nl> - \" bytes . \" ) ; <nl> - } <nl> - size + + ; <nl> - seq . append ( nextByte ) ; <nl> - return true ; <nl> - } <nl> + protected TooLongFrameException newException ( int maxLength ) { <nl> + return new TooLongFrameException ( <nl> + \" An HTTP line is larger than \" + maxLength + <nl> + \" bytes . \" ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Modify HttpObjectDecoder to allow parsing the HTTP headers in multiple steps .\n"}
{"diff_id": 30855, "repo": "libgdx/libgdx\n", "sha": "5b63cdba8fd826e0e6252e8864e81cafd21d04a0\n", "time": "2017-05-22T19:42:27Z\n", "diff": "mmm a / gdx / src / com / badlogic / gdx / scenes / scene2d / ui / Dialog . java <nl> ppp b / gdx / src / com / badlogic / gdx / scenes / scene2d / ui / Dialog . java <nl> <nl> <nl> import static com . badlogic . gdx . scenes . scene2d . actions . Actions . * ; <nl> <nl> + import com . badlogic . gdx . Gdx ; <nl> import com . badlogic . gdx . Input . Keys ; <nl> import com . badlogic . gdx . math . Interpolation ; <nl> import com . badlogic . gdx . scenes . scene2d . Action ; <nl> private void focusChanged ( FocusEvent event ) { <nl> if ( isModal & & stage ! = null & & stage . getRoot ( ) . getChildren ( ) . size > 0 <nl> & & stage . getRoot ( ) . getChildren ( ) . peek ( ) = = Dialog . this ) { / / Dialog is top most actor . <nl> Actor newFocusedActor = event . getRelatedActor ( ) ; <nl> - if ( newFocusedActor ! = null & & ! newFocusedActor . isDescendantOf ( Dialog . this ) & & <nl> - ! ( newFocusedActor . equals ( previousKeyboardFocus ) | | newFocusedActor . equals ( previousScrollFocus ) ) ) <nl> + if ( newFocusedActor ! = null & & ! newFocusedActor . isDescendantOf ( Dialog . this ) <nl> + & & ! ( newFocusedActor . equals ( previousKeyboardFocus ) | | newFocusedActor . equals ( previousScrollFocus ) ) ) <nl> event . cancel ( ) ; <nl> } <nl> } <nl> public Dialog text ( Label label ) { <nl> return this ; <nl> } <nl> <nl> - / * * Adds a text button to the button table . Null will be passed to { @ link # result ( Object ) } if this button is clicked . The dialog <nl> - * must have been constructed with a skin to use this method . * / <nl> + / * * Adds a text button to the button table . Null will be passed to { @ link # result ( Object ) } if this button is clicked . The <nl> + * dialog must have been constructed with a skin to use this method . * / <nl> public Dialog button ( String text ) { <nl> return button ( text , null ) ; <nl> } <nl> public Dialog key ( final int keycode , final Object object ) { <nl> addListener ( new InputListener ( ) { <nl> public boolean keyDown ( InputEvent event , int keycode2 ) { <nl> if ( keycode = = keycode2 ) { <nl> - result ( object ) ; <nl> - if ( ! cancelHide ) hide ( ) ; <nl> - cancelHide = false ; <nl> + / / Delay a frame to eat the keyTyped event . <nl> + Gdx . app . postRunnable ( new Runnable ( ) { <nl> + public void run ( ) { <nl> + result ( object ) ; <nl> + if ( ! cancelHide ) hide ( ) ; <nl> + cancelHide = false ; <nl> + } <nl> + } ) ; <nl> } <nl> return false ; <nl> } <nl>\n", "msg": "[ scene2d ] Delay handling dialog key press 1 frame to avoid the key typed event being handled by whatever is behind the dialog .\n"}
{"diff_id": 30860, "repo": "eugenp/tutorials\n", "sha": "a66aeb11573a6b9c12f758175b9b61207d465338\n", "time": "2016-10-19T03:33:00Z\n", "diff": "mmm a / spring - cloud / spring - cloud - bootstrap / discovery / src / main / java / com / baeldung / spring / cloud / bootstrap / discovery / SecurityConfig . java <nl> ppp b / spring - cloud / spring - cloud - bootstrap / discovery / src / main / java / com / baeldung / spring / cloud / bootstrap / discovery / SecurityConfig . java <nl> <nl> <nl> import org . springframework . beans . factory . annotation . Autowired ; <nl> import org . springframework . context . annotation . Configuration ; <nl> + import org . springframework . core . annotation . Order ; <nl> import org . springframework . http . HttpMethod ; <nl> import org . springframework . security . config . annotation . authentication . builders . AuthenticationManagerBuilder ; <nl> import org . springframework . security . config . annotation . web . builders . HttpSecurity ; <nl> import org . springframework . security . config . annotation . web . configuration . EnableWebSecurity ; <nl> import org . springframework . security . config . annotation . web . configuration . WebSecurityConfigurerAdapter ; <nl> + import org . springframework . security . config . http . SessionCreationPolicy ; <nl> <nl> @ Configuration <nl> @ EnableWebSecurity <nl> + @ Order ( 1 ) <nl> public class SecurityConfig extends WebSecurityConfigurerAdapter { <nl> <nl> @ Autowired <nl> public void configureGlobal ( AuthenticationManagerBuilder auth ) throws Exception { <nl> @ Override <nl> protected void configure ( HttpSecurity http ) throws Exception { <nl> http <nl> + . sessionManagement ( ) <nl> + . sessionCreationPolicy ( SessionCreationPolicy . ALWAYS ) <nl> + . and ( ) <nl> + . requestMatchers ( ) <nl> + . antMatchers ( \" / eureka / * * \" ) <nl> + . and ( ) <nl> . authorizeRequests ( ) <nl> - . antMatchers ( \" / eureka / js / * * \" , \" / eureka / css / * * \" , \" / eureka / images / * * \" , \" / eureka / fonts / * * \" ) . authenticated ( ) <nl> . antMatchers ( \" / eureka / * * \" ) . hasRole ( \" SYSTEM \" ) <nl> - . antMatchers ( HttpMethod . GET , \" / \" ) . hasRole ( \" ADMIN \" ) <nl> - . anyRequest ( ) . authenticated ( ) <nl> - . and ( ) <nl> + . anyRequest ( ) . denyAll ( ) <nl> + . and ( ) <nl> + . httpBasic ( ) <nl> + . and ( ) <nl> + . csrf ( ) . disable ( ) ; <nl> + } <nl> + <nl> + @ Configuration <nl> + / / no order tag means this is the last security filter to be evaluated <nl> + public static class AdminSecurityConfig extends WebSecurityConfigurerAdapter { <nl> + <nl> + @ Autowired public void configureGlobal ( AuthenticationManagerBuilder auth ) throws Exception { <nl> + auth . inMemoryAuthentication ( ) ; <nl> + } <nl> + <nl> + @ Override protected void configure ( HttpSecurity http ) throws Exception { <nl> + http <nl> + . sessionManagement ( ) <nl> + . sessionCreationPolicy ( SessionCreationPolicy . NEVER ) <nl> + . and ( ) <nl> . httpBasic ( ) <nl> - . and ( ) <nl> + . disable ( ) <nl> + . authorizeRequests ( ) <nl> + . antMatchers ( HttpMethod . GET , \" / \" ) . hasRole ( \" ADMIN \" ) <nl> + . antMatchers ( \" / info \" , \" / health \" ) . authenticated ( ) <nl> + . antMatchers ( \" / eureka / js / * * \" , \" / eureka / css / * * \" , \" / eureka / images / * * \" , \" / eureka / fonts / * * \" ) . authenticated ( ) <nl> + . anyRequest ( ) . denyAll ( ) <nl> + . and ( ) <nl> . csrf ( ) . disable ( ) ; <nl> + } <nl> } <nl> } <nl>\n", "msg": "BAEL - 315 Change some security settings to allow discovery server operations . Copy static files from the eureka project to the zuul filter to display the discovery dashboard through the proxy .\n"}
{"diff_id": 30873, "repo": "elastic/elasticsearch\n", "sha": "2fa017db11b2c18e33fe2770fd6621c076f619f0\n", "time": "2012-10-05T16:21:58Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / index / query / TermsFilterParser . java <nl> ppp b / src / main / java / org / elasticsearch / index / query / TermsFilterParser . java <nl> <nl> import org . apache . lucene . search . XTermsFilter ; <nl> import org . elasticsearch . common . inject . Inject ; <nl> import org . elasticsearch . common . lucene . search . AndFilter ; <nl> + import org . elasticsearch . common . lucene . search . OrFilter ; <nl> import org . elasticsearch . common . lucene . search . TermFilter ; <nl> import org . elasticsearch . common . lucene . search . XBooleanFilter ; <nl> import org . elasticsearch . common . xcontent . XContentParser ; <nl> public Filter parse ( QueryParseContext parseContext ) throws IOException , QueryPar <nl> if ( cache = = null | | cache ) { <nl> filter = parseContext . cacheFilter ( filter , cacheKey ) ; <nl> } <nl> + } else if ( \" or \" . equals ( execution ) ) { <nl> + List < Filter > filters = Lists . newArrayList ( ) ; <nl> + if ( fieldMapper ! = null ) { <nl> + for ( String term : terms ) { <nl> + filters . add ( parseContext . cacheFilter ( fieldMapper . fieldFilter ( term , parseContext ) , null ) ) ; <nl> + } <nl> + } else { <nl> + for ( String term : terms ) { <nl> + filters . add ( parseContext . cacheFilter ( new TermFilter ( new Term ( fieldName , term ) ) , null ) ) ; <nl> + } <nl> + } <nl> + filter = new OrFilter ( filters ) ; <nl> + / / only cache if explicitly told to , since we cache inner filters <nl> + if ( cache ! = null & & cache ) { <nl> + filter = parseContext . cacheFilter ( filter , cacheKey ) ; <nl> + } <nl> + } else if ( \" or_nocache \" . equals ( execution ) ) { <nl> + List < Filter > filters = Lists . newArrayList ( ) ; <nl> + if ( fieldMapper ! = null ) { <nl> + for ( String term : terms ) { <nl> + filters . add ( fieldMapper . fieldFilter ( term , parseContext ) ) ; <nl> + } <nl> + } else { <nl> + for ( String term : terms ) { <nl> + filters . add ( new TermFilter ( new Term ( fieldName , term ) ) ) ; <nl> + } <nl> + } <nl> + filter = new OrFilter ( filters ) ; <nl> + / / cache the whole filter by default , or if explicitly told to <nl> + if ( cache = = null | | cache ) { <nl> + filter = parseContext . cacheFilter ( filter , cacheKey ) ; <nl> + } <nl> } else { <nl> throw new QueryParsingException ( parseContext . index ( ) , \" bool filter execution value [ \" + execution + \" ] not supported \" ) ; <nl> } <nl>\n", "msg": "Terms filter : Add ` or ` and ` or_nocache ` execution modes\n"}
{"diff_id": 30949, "repo": "oracle/graal\n", "sha": "faf1558b9ffd65e5d778cdb7753ea11baf9908e5\n", "time": "2019-05-13T08:23:02Z\n", "diff": "mmm a / substratevm / src / com . oracle . svm . core . graal / src / com / oracle / svm / core / graal / snippets / NonSnippetLowerings . java <nl> ppp b / substratevm / src / com . oracle . svm . core . graal / src / com / oracle / svm / core / graal / snippets / NonSnippetLowerings . java <nl> public void lower ( GetClassNode node , LoweringTool tool ) { <nl> StampProvider stampProvider = tool . getStampProvider ( ) ; <nl> LoadHubNode loadHub = node . graph ( ) . unique ( new LoadHubNode ( stampProvider , node . getObject ( ) ) ) ; <nl> node . replaceAtUsagesAndDelete ( loadHub ) ; <nl> + tool . getLowerer ( ) . lower ( loadHub , tool ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "Lower GetClass recursively as it can be used in a snippet .\n"}
{"diff_id": 30962, "repo": "material-components/material-components-android\n", "sha": "04c14f2b55ed0513bea83462c29d88e61772cb9a\n", "time": "2018-04-17T19:52:12Z\n", "diff": "mmm a / lib / java / android / support / design / snackbar / BaseTransientBottomBar . java <nl> ppp b / lib / java / android / support / design / snackbar / BaseTransientBottomBar . java <nl> public boolean handleMessage ( Message message ) { <nl> <nl> private List < BaseCallback < B > > callbacks ; <nl> <nl> + private BaseTransientBottomBar . Behavior behavior ; <nl> + <nl> private final AccessibilityManager accessibilityManager ; <nl> <nl> / * * @ hide * / <nl> public int getDuration ( ) { <nl> return duration ; <nl> } <nl> <nl> + / * * <nl> + * Set the { @ link BaseTransientBottomBar . Behavior } to be used in this <nl> + * { @ link BaseTransientBottomBar } . <nl> + * <nl> + * @ param behavior { @ link BaseTransientBottomBar . Behavior } to be applied . <nl> + * / <nl> + public B setBehavior ( BaseTransientBottomBar . Behavior behavior ) { <nl> + this . behavior = behavior ; <nl> + return ( B ) this ; <nl> + } <nl> + <nl> + / * * <nl> + * Return the behavior . <nl> + * <nl> + * @ see # setBehavior ( BaseTransientBottomBar . Behavior ) <nl> + * / <nl> + public BaseTransientBottomBar . Behavior getBehavior ( ) { <nl> + return behavior ; <nl> + } <nl> + <nl> / * * Returns the { @ link BaseTransientBottomBar } ' s context . * / <nl> @ NonNull <nl> public Context getContext ( ) { <nl> public void dismiss ( int event ) { <nl> } <nl> } ; <nl> <nl> - protected SwipeDismissBehavior < ? extends SnackbarBaseLayout > getNewBehavior ( ) { <nl> + protected SwipeDismissBehavior < ? extends View > getNewBehavior ( ) { <nl> return new Behavior ( ) ; <nl> } <nl> <nl> final void showView ( ) { <nl> / / If our LayoutParams are from a CoordinatorLayout , we ' ll setup our Behavior <nl> final CoordinatorLayout . LayoutParams clp = ( CoordinatorLayout . LayoutParams ) lp ; <nl> <nl> - final SwipeDismissBehavior < ? extends SnackbarBaseLayout > behavior = getNewBehavior ( ) ; <nl> - behavior . setStartAlphaSwipeDistance ( 0 . 1f ) ; <nl> - behavior . setEndAlphaSwipeDistance ( 0 . 6f ) ; <nl> - behavior . setSwipeDirection ( SwipeDismissBehavior . SWIPE_DIRECTION_START_TO_END ) ; <nl> + final SwipeDismissBehavior < ? extends View > behavior = <nl> + this . behavior = = null ? getNewBehavior ( ) : this . behavior ; <nl> + <nl> + if ( behavior instanceof BaseTransientBottomBar . Behavior ) { <nl> + ( ( BaseTransientBottomBar . Behavior ) behavior ) . setBaseTransientBottomBar ( this ) ; <nl> + } <nl> behavior . setListener ( <nl> new SwipeDismissBehavior . OnDismissListener ( ) { <nl> @ Override <nl> void setOnAttachStateChangeListener ( <nl> } <nl> } <nl> <nl> - / / TODO : make package private after the widget migration is finished <nl> - protected void handleBehaviorTouchEvent ( <nl> - CoordinatorLayout parent , SnackbarBaseLayout child , MotionEvent event ) { <nl> - switch ( event . getActionMasked ( ) ) { <nl> - case MotionEvent . ACTION_DOWN : <nl> - / / We want to make sure that we disable any Snackbar timeouts if the user is <nl> - / / currently touching the Snackbar . We restore the timeout when complete <nl> - if ( parent . isPointInChildBounds ( child , ( int ) event . getX ( ) , ( int ) event . getY ( ) ) ) { <nl> - SnackbarManager . getInstance ( ) . pauseTimeout ( managerCallback ) ; <nl> - } <nl> - break ; <nl> - case MotionEvent . ACTION_UP : <nl> - case MotionEvent . ACTION_CANCEL : <nl> - SnackbarManager . getInstance ( ) . restoreTimeoutIfPaused ( managerCallback ) ; <nl> - break ; <nl> - default : <nl> - break ; <nl> + / * * Behavior for { @ link BaseTransientBottomBar } . * / <nl> + public static class Behavior extends SwipeDismissBehavior < View > { <nl> + private final BehaviorDelegate delegate ; <nl> + <nl> + public Behavior ( ) { <nl> + delegate = new BehaviorDelegate ( this ) ; <nl> + } <nl> + <nl> + private void setBaseTransientBottomBar ( BaseTransientBottomBar < ? > baseTransientBottomBar ) { <nl> + delegate . setBaseTransientBottomBar ( baseTransientBottomBar ) ; <nl> } <nl> - } <nl> <nl> - / * * Behavior for { @ link BaseTransientBottomBar } . * / <nl> - / / TODO : make package private after the widget migration is finished <nl> - protected final class Behavior extends SwipeDismissBehavior < SnackbarBaseLayout > { <nl> @ Override <nl> public boolean canSwipeDismissView ( View child ) { <nl> - return child instanceof SnackbarBaseLayout ; <nl> + return delegate . canSwipeDismissView ( child ) ; <nl> } <nl> <nl> @ Override <nl> public boolean onInterceptTouchEvent ( <nl> - CoordinatorLayout parent , SnackbarBaseLayout child , MotionEvent event ) { <nl> - handleBehaviorTouchEvent ( parent , child , event ) ; <nl> + CoordinatorLayout parent , View child , MotionEvent event ) { <nl> + delegate . onInterceptTouchEvent ( parent , child , event ) ; <nl> return super . onInterceptTouchEvent ( parent , child , event ) ; <nl> } <nl> } <nl> + <nl> + / * * @ hide * / <nl> + @ RestrictTo ( LIBRARY_GROUP ) <nl> + / / TODO : Delegate can be rolled up into behavior after the widget migration is finished . <nl> + public static class BehaviorDelegate { <nl> + private SnackbarManager . Callback managerCallback ; <nl> + <nl> + public BehaviorDelegate ( SwipeDismissBehavior < ? > behavior ) { <nl> + behavior . setStartAlphaSwipeDistance ( 0 . 1f ) ; <nl> + behavior . setEndAlphaSwipeDistance ( 0 . 6f ) ; <nl> + behavior . setSwipeDirection ( SwipeDismissBehavior . SWIPE_DIRECTION_START_TO_END ) ; <nl> + } <nl> + <nl> + public void setBaseTransientBottomBar ( BaseTransientBottomBar < ? > baseTransientBottomBar ) { <nl> + this . managerCallback = baseTransientBottomBar . managerCallback ; <nl> + } <nl> + <nl> + public boolean canSwipeDismissView ( View child ) { <nl> + return child instanceof SnackbarBaseLayout ; <nl> + } <nl> + <nl> + public void onInterceptTouchEvent ( CoordinatorLayout parent , View child , MotionEvent event ) { <nl> + switch ( event . getActionMasked ( ) ) { <nl> + case MotionEvent . ACTION_DOWN : <nl> + / / We want to make sure that we disable any Snackbar timeouts if the user is <nl> + / / currently touching the Snackbar . We restore the timeout when complete <nl> + if ( parent . isPointInChildBounds ( child , ( int ) event . getX ( ) , ( int ) event . getY ( ) ) ) { <nl> + SnackbarManager . getInstance ( ) . pauseTimeout ( managerCallback ) ; <nl> + } <nl> + break ; <nl> + case MotionEvent . ACTION_UP : <nl> + case MotionEvent . ACTION_CANCEL : <nl> + SnackbarManager . getInstance ( ) . restoreTimeoutIfPaused ( managerCallback ) ; <nl> + break ; <nl> + default : <nl> + break ; <nl> + } <nl> + } <nl> + } <nl> } <nl>\n", "msg": "Allow users of Snackbars to set custom behaviors .\n"}
{"diff_id": 31064, "repo": "SeleniumHQ/selenium\n", "sha": "9d2e5e99209c8a2e4cef0b2474cc1391bf672c64\n", "time": "2009-12-07T12:59:15Z\n", "diff": "mmm a / remote / server / src / java / org / openqa / selenium / remote / server / DriverSessions . java <nl> ppp b / remote / server / src / java / org / openqa / selenium / remote / server / DriverSessions . java <nl> <nl> import java . util . concurrent . ConcurrentHashMap ; <nl> <nl> public class DriverSessions { <nl> - private DriverFactory factory ; <nl> + private DriverFactory factory = new DriverFactory ( ) ; <nl> <nl> private static Map < SessionId , Session > sessionIdToDriver = <nl> new ConcurrentHashMap < SessionId , Session > ( ) ; <nl>\n", "msg": "SimonStewart : Fixing the build . Lesson learned : never check in in a hurry .\n"}
{"diff_id": 31146, "repo": "elastic/elasticsearch\n", "sha": "5a001e1357ab8efa9864f88ed6d6e94184ce43e2\n", "time": "2014-11-24T12:28:55Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / index / query / SpanNotQueryParser . java <nl> ppp b / src / main / java / org / elasticsearch / index / query / SpanNotQueryParser . java <nl> <nl> <nl> public static final String NAME = \" span_not \" ; <nl> <nl> + public static final int NOT_SET = - 1 ; <nl> + <nl> @ Inject <nl> public SpanNotQueryParser ( ) { <nl> } <nl> public Query parse ( QueryParseContext parseContext ) throws IOException , QueryPars <nl> SpanQuery include = null ; <nl> SpanQuery exclude = null ; <nl> <nl> - int dist = - 1 ; <nl> - int pre = - 1 ; <nl> - int post = - 1 ; <nl> + int dist = NOT_SET ; <nl> + int pre = NOT_SET ; <nl> + int post = NOT_SET ; <nl> <nl> String queryName = null ; <nl> <nl> public Query parse ( QueryParseContext parseContext ) throws IOException , QueryPars <nl> if ( exclude = = null ) { <nl> throw new QueryParsingException ( parseContext . index ( ) , \" spanNot must have [ exclude ] span query clause \" ) ; <nl> } <nl> - if ( ( dist ! = - 1 & & ( pre ! = - 1 | | post ! = - 1 ) ) | | ( pre ! = - 1 & & post = = - 1 ) | | ( pre = = - 1 & & post ! = - 1 ) ) { <nl> + if ( dist ! = NOT_SET & & ( pre ! = NOT_SET | | post ! = NOT_SET ) ) { <nl> throw new QueryParsingException ( parseContext . index ( ) , \" spanNot can either use [ dist ] or [ pre ] & [ post ] ( or none ) \" ) ; <nl> } <nl> <nl> SpanNotQuery query ; <nl> - if ( pre ! = - 1 & & post ! = - 1 ) { <nl> + if ( pre ! = NOT_SET & & post ! = NOT_SET ) { <nl> query = new SpanNotQuery ( include , exclude , pre , post ) ; <nl> - } else if ( dist ! = - 1 ) { <nl> + } else if ( dist ! = NOT_SET ) { <nl> query = new SpanNotQuery ( include , exclude , dist ) ; <nl> } else { <nl> query = new SpanNotQuery ( include , exclude ) ; <nl>\n", "msg": "Cleaner error handling . Pre without post ( or vice versa ) is not an error condition . Set appropriate defaults for pre / post .\n"}
{"diff_id": 31225, "repo": "jenkinsci/jenkins\n", "sha": "c1adb4e628699c891de90c37e2071c61b7103ec5\n", "time": "2015-01-13T19:56:45Z\n", "diff": "mmm a / core / src / main / java / jenkins / model / DownloadSettings . java <nl> ppp b / core / src / main / java / jenkins / model / DownloadSettings . java <nl> public DailyCheck ( ) { <nl> if ( get ( ) . isUseBrowser ( ) ) { <nl> return ; <nl> } <nl> + boolean due = false ; <nl> + for ( UpdateSite site : Jenkins . getInstance ( ) . getUpdateCenter ( ) . getSites ( ) ) { <nl> + if ( site . isDue ( ) ) { <nl> + due = true ; <nl> + break ; <nl> + } <nl> + } <nl> + if ( ! due ) { <nl> + return ; <nl> + } <nl> HttpResponse rsp = Jenkins . getInstance ( ) . getPluginManager ( ) . doCheckUpdatesServer ( ) ; <nl> if ( rsp instanceof FormValidation ) { <nl> listener . error ( ( ( FormValidation ) rsp ) . renderHtml ( ) ) ; <nl>\n", "msg": "Only do a server - side metadata check if at least one update site claims to be due for a check .\n"}
{"diff_id": 31265, "repo": "elastic/elasticsearch\n", "sha": "7a6025784ddf754e3ee0c4cc623cb349f756d674\n", "time": "2016-05-10T06:23:32Z\n", "diff": "mmm a / elasticsearch / x - pack / watcher / src / main / java / org / elasticsearch / xpack / watcher / watch / Watch . java <nl> ppp b / elasticsearch / x - pack / watcher / src / main / java / org / elasticsearch / xpack / watcher / watch / Watch . java <nl> <nl> <nl> private final transient AtomicLong nonceCounter = new AtomicLong ( ) ; <nl> <nl> - private transient long version = Versions . NOT_SET ; <nl> + private transient long version = Versions . MATCH_ANY ; <nl> <nl> public Watch ( String id , Trigger trigger , ExecutableInput input , ExecutableCondition condition , @ Nullable ExecutableTransform transform , <nl> @ Nullable TimeValue throttlePeriod , ExecutableActions actions , @ Nullable Map < String , Object > metadata , <nl>\n", "msg": "Use Versions . MATCH_ANY rather than NOT_SET now that NOT_SET is gone .\n"}
{"diff_id": 31316, "repo": "jenkinsci/jenkins\n", "sha": "5055776cd81ec553fe4898c96361f8ea99896099\n", "time": "2015-03-27T21:20:02Z\n", "diff": "mmm a / cli / src / main / java / hudson / cli / CLI . java <nl> ppp b / cli / src / main / java / hudson / cli / CLI . java <nl> protected void onDead ( ) { <nl> <nl> private Channel connectViaCliPort ( URL jenkins , CliPort clip ) throws IOException { <nl> LOGGER . log ( FINE , \" Trying to connect directly via TCP / IP to { 0 } \" , clip . endpoint ) ; <nl> - final Socket s ; <nl> + final Socket s = new Socket ( ) ; <nl> + / / this prevents a connection from silently terminated by the router in between or the other peer <nl> + / / and that goes without unnoticed . However , the time out is often very long ( for example 2 hours <nl> + / / by default in Linux ) that this alone is enough to prevent that . <nl> + s . setKeepAlive ( true ) ; <nl> + / / we take care of buffering on our own <nl> + s . setTcpNoDelay ( true ) ; <nl> OutputStream out ; <nl> <nl> if ( httpsProxyTunnel ! = null ) { <nl> String [ ] tokens = httpsProxyTunnel . split ( \" : \" ) ; <nl> - s = new Socket ( tokens [ 0 ] , Integer . parseInt ( tokens [ 1 ] ) ) ; <nl> + s . connect ( new InetSocketAddress ( tokens [ 0 ] , Integer . parseInt ( tokens [ 1 ] ) ) ) ; <nl> PrintStream o = new PrintStream ( s . getOutputStream ( ) ) ; <nl> o . print ( \" CONNECT \" + clip . endpoint . getHostName ( ) + \" : \" + clip . endpoint . getPort ( ) + \" HTTP / 1 . 0 \\ r \\ n \\ r \\ n \" ) ; <nl> <nl> public void close ( ) throws IOException { <nl> } <nl> } ; <nl> } else { <nl> - s = new Socket ( ) ; <nl> s . connect ( clip . endpoint , 3000 ) ; <nl> out = SocketChannelStream . out ( s ) ; <nl> } <nl>\n", "msg": "Set proper socket parameters suitable for CLI communication\n"}
{"diff_id": 31339, "repo": "apache/flink\n", "sha": "cff417cb0cd4165f317990e5a12fb33635b4a03b\n", "time": "2011-07-15T18:28:24Z\n", "diff": "mmm a / pact / pact - runtime / src / main / java / eu / stratosphere / pact / runtime / task / DataSinkTask . java <nl> ppp b / pact / pact - runtime / src / main / java / eu / stratosphere / pact / runtime / task / DataSinkTask . java <nl> public int getMaximumNumberOfSubtasks ( ) <nl> return 1 ; <nl> } <nl> / / If the path points to a directory we allow an infinity number of subtasks <nl> - if ( f . isDir ( ) ) <nl> + if ( f . isDir ( ) ) { <nl> return - 1 ; <nl> - else <nl> + } <nl> + else { <nl> + / / path points to an existing file . delete it , to prevent errors appearing <nl> + / / when overwriting the file ( HDFS causes non - deterministic errors there ) <nl> + fs . delete ( path , false ) ; <nl> return 1 ; <nl> + } <nl> } <nl> catch ( FileNotFoundException fnfex ) { <nl> / / The exception is thrown if the requested file / directory does not exist . <nl>\n", "msg": "Existing files output files removed before program execution starts , to prevent overwrite errors\n"}
{"diff_id": 31379, "repo": "jenkinsci/jenkins\n", "sha": "cec56ab76b6ac97c4fa071e12836ea0796972a71\n", "time": "2007-03-29T04:24:43Z\n", "diff": "mmm a / core / src / main / java / hudson / util / ShiftedCategoryAxis . java <nl> ppp b / core / src / main / java / hudson / util / ShiftedCategoryAxis . java <nl> protected AxisState drawCategoryLabels ( Graphics2D g2 , <nl> g2 . setPaint ( getTickLabelPaint ( tick . getCategory ( ) ) ) ; <nl> <nl> CategoryLabelPosition position <nl> - = this . categoryLabelPositions . getLabelPosition ( edge ) ; <nl> + = this . getCategoryLabelPositions ( ) . getLabelPosition ( edge ) ; <nl> double x0 = 0 . 0 ; <nl> double x1 = 0 . 0 ; <nl> double y0 = 0 . 0 ; <nl> protected AxisState drawCategoryLabels ( Graphics2D g2 , <nl> dataArea , edge ) ; <nl> x1 = getCategoryEnd ( categoryIndex , ticks . size ( ) , dataArea , <nl> edge ) ; <nl> - y1 = state . getCursor ( ) - this . categoryLabelPositionOffset ; <nl> + y1 = state . getCursor ( ) - this . getCategoryLabelPositionOffset ( ) ; <nl> y0 = y1 - state . getMax ( ) ; <nl> } <nl> else if ( edge = = RectangleEdge . BOTTOM ) { <nl> else if ( edge = = RectangleEdge . BOTTOM ) { <nl> dataArea , edge ) ; <nl> x1 = getCategoryEnd ( categoryIndex , ticks . size ( ) , dataArea , <nl> edge ) ; <nl> - y0 = state . getCursor ( ) + this . categoryLabelPositionOffset ; <nl> + y0 = state . getCursor ( ) + this . getCategoryLabelPositionOffset ( ) ; <nl> y1 = y0 + state . getMax ( ) ; <nl> } <nl> else if ( edge = = RectangleEdge . LEFT ) { <nl> else if ( edge = = RectangleEdge . LEFT ) { <nl> dataArea , edge ) ; <nl> y1 = getCategoryEnd ( categoryIndex , ticks . size ( ) , dataArea , <nl> edge ) ; <nl> - x1 = state . getCursor ( ) - this . categoryLabelPositionOffset ; <nl> + x1 = state . getCursor ( ) - this . getCategoryLabelPositionOffset ( ) ; <nl> x0 = x1 - state . getMax ( ) ; <nl> } <nl> else if ( edge = = RectangleEdge . RIGHT ) { <nl> else if ( edge = = RectangleEdge . RIGHT ) { <nl> dataArea , edge ) ; <nl> y1 = getCategoryEnd ( categoryIndex , ticks . size ( ) , dataArea , <nl> edge ) ; <nl> - x0 = state . getCursor ( ) + this . categoryLabelPositionOffset ; <nl> + x0 = state . getCursor ( ) + this . getCategoryLabelPositionOffset ( ) ; <nl> x1 = x0 - state . getMax ( ) ; <nl> } <nl> Rectangle2D area = new Rectangle2D . Double ( x0 , y0 , ( x1 - x0 ) , <nl>\n", "msg": "removed compilation error now that some variables are not accessible .\n"}
{"diff_id": 31403, "repo": "bazelbuild/bazel\n", "sha": "90a55a994b5f5ae5ad928052ed77351055c28945\n", "time": "2019-08-01T18:25:56Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / actions / FileArtifactValue . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / actions / FileArtifactValue . java <nl> public long getModifiedTime ( ) { <nl> @ Override <nl> public String toString ( ) { <nl> return MoreObjects . toStringHelper ( this ) <nl> - . add ( \" digest \" , BaseEncoding . base16 ( ) . lowerCase ( ) . encode ( digest ) ) <nl> + . add ( <nl> + \" digest \" , <nl> + digest = = null ? \" ( null ) \" : BaseEncoding . base16 ( ) . lowerCase ( ) . encode ( digest ) ) <nl> . add ( \" size \" , size ) <nl> . add ( \" proxy \" , proxy ) <nl> . toString ( ) ; <nl> public String toString ( ) { <nl> <nl> @ Override <nl> public boolean couldBeModifiedSince ( FileArtifactValue o ) { <nl> + if ( digest ! = null & & o . getDigest ( ) ! = null ) { <nl> + / / TODO ( lberki ) : This sometimes compares between RemoteFileArtifactValue and <nl> + / / RegularFileArtifactValue . Pretty unintuitive , that . <nl> + return ! Arrays . equals ( digest , o . getDigest ( ) ) | | getSize ( ) ! = o . getSize ( ) ; <nl> + } <nl> + <nl> if ( ! ( o instanceof RegularFileArtifactValue ) ) { <nl> return true ; <nl> } <nl> public boolean couldBeModifiedSince ( FileArtifactValue o ) { <nl> return true ; <nl> } <nl> <nl> - if ( digest ! = null & & lastKnown . digest ! = null ) { <nl> - return ! Arrays . equals ( digest , lastKnown . digest ) ; <nl> - } else { <nl> - return ! Objects . equals ( proxy , lastKnown . proxy ) ; <nl> - } <nl> + return ! Objects . equals ( proxy , lastKnown . proxy ) ; <nl> } <nl> <nl> @ Override <nl> public FileContentsProxy getContentsProxy ( ) { <nl> throw new UnsupportedOperationException ( ) ; <nl> } <nl> <nl> + @ Override <nl> + public boolean couldBeModifiedSince ( FileArtifactValue o ) { <nl> + if ( digest ! = null & & o . getDigest ( ) ! = null ) { <nl> + / / TODO ( lberki ) : This sometimes compares between RemoteFileArtifactValue and <nl> + / / RegularFileArtifactValue . Pretty unintuitive , that . <nl> + return ! Arrays . equals ( digest , o . getDigest ( ) ) | | getSize ( ) ! = o . getSize ( ) ; <nl> + } <nl> + <nl> + return true ; <nl> + } <nl> + <nl> @ Override <nl> public long getSize ( ) { <nl> return size ; <nl>\n", "msg": "Fix even more fallout of https : / / github . com / bazelbuild / bazel / commit / f7eee1edc1f8dfc6d436894db2eb672bb11bc962 .\n"}
{"diff_id": 31414, "repo": "elastic/elasticsearch\n", "sha": "bb92d461632f72de42a01f27107e87fc45224b95\n", "time": "2014-07-08T17:06:59Z\n", "diff": "mmm a / src / test / java / org / elasticsearch / tribe / TribeTests . java <nl> ppp b / src / test / java / org / elasticsearch / tribe / TribeTests . java <nl> <nl> import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertAcked ; <nl> import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertHitCount ; <nl> import static org . hamcrest . Matchers . equalTo ; <nl> + import static org . hamcrest . Matchers . notNullValue ; <nl> <nl> / * * <nl> * Note , when talking to tribe client , no need to set the local flag on master read operations , it <nl> public void testTribeOnOneCluster ( ) throws Exception { <nl> logger . info ( \" verify they are there \" ) ; <nl> assertHitCount ( tribeClient . prepareCount ( ) . get ( ) , 2l ) ; <nl> assertHitCount ( tribeClient . prepareSearch ( ) . get ( ) , 2l ) ; <nl> - awaitBusy ( new Predicate < Object > ( ) { <nl> + assertBusy ( new Runnable ( ) { <nl> @ Override <nl> - public boolean apply ( Object o ) { <nl> + public void run ( ) { <nl> ClusterState tribeState = tribeNode . client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) ; <nl> - return tribeState . getMetaData ( ) . index ( \" test1 \" ) . mapping ( \" type1 \" ) ! = null & & <nl> - tribeState . getMetaData ( ) . index ( \" test2 \" ) . mapping ( \" type2 \" ) ! = null ; <nl> + assertThat ( tribeState . getMetaData ( ) . index ( \" test1 \" ) . mapping ( \" type1 \" ) , notNullValue ( ) ) ; <nl> + assertThat ( tribeState . getMetaData ( ) . index ( \" test2 \" ) . mapping ( \" type1 \" ) , notNullValue ( ) ) ; <nl> } <nl> } ) ; <nl> <nl> public boolean apply ( Object o ) { <nl> logger . info ( \" verify they are there \" ) ; <nl> assertHitCount ( tribeClient . prepareCount ( ) . get ( ) , 4l ) ; <nl> assertHitCount ( tribeClient . prepareSearch ( ) . get ( ) , 4l ) ; <nl> - awaitBusy ( new Predicate < Object > ( ) { <nl> + assertBusy ( new Runnable ( ) { <nl> @ Override <nl> - public boolean apply ( Object o ) { <nl> + public void run ( ) { <nl> ClusterState tribeState = tribeNode . client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) ; <nl> - return tribeState . getMetaData ( ) . index ( \" test1 \" ) . mapping ( \" type1 \" ) ! = null & & tribeState . getMetaData ( ) . index ( \" test1 \" ) . mapping ( \" type2 \" ) ! = null & & <nl> - tribeState . getMetaData ( ) . index ( \" test2 \" ) . mapping ( \" type1 \" ) ! = null & & tribeState . getMetaData ( ) . index ( \" test2 \" ) . mapping ( \" type2 \" ) ! = null ; <nl> + assertThat ( tribeState . getMetaData ( ) . index ( \" test1 \" ) . mapping ( \" type1 \" ) , notNullValue ( ) ) ; <nl> + assertThat ( tribeState . getMetaData ( ) . index ( \" test1 \" ) . mapping ( \" type2 \" ) , notNullValue ( ) ) ; <nl> + assertThat ( tribeState . getMetaData ( ) . index ( \" test2 \" ) . mapping ( \" type1 \" ) , notNullValue ( ) ) ; <nl> + assertThat ( tribeState . getMetaData ( ) . index ( \" test2 \" ) . mapping ( \" type2 \" ) , notNullValue ( ) ) ; <nl> } <nl> } ) ; <nl> <nl> public boolean apply ( Object o ) { <nl> <nl> logger . info ( \" delete an index , and make sure its reflected \" ) ; <nl> cluster2 . client ( ) . admin ( ) . indices ( ) . prepareDelete ( \" test2 \" ) . get ( ) ; <nl> - awaitBusy ( new Predicate < Object > ( ) { <nl> + assertBusy ( new Runnable ( ) { <nl> @ Override <nl> - public boolean apply ( Object o ) { <nl> + public void run ( ) { <nl> ClusterState tribeState = tribeNode . client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) ; <nl> - return tribeState . getMetaData ( ) . hasIndex ( \" test1 \" ) & & ! tribeState . getMetaData ( ) . hasIndex ( \" test2 \" ) & & <nl> - tribeState . getRoutingTable ( ) . hasIndex ( \" test1 \" ) & & ! tribeState . getRoutingTable ( ) . hasIndex ( \" test2 \" ) ; <nl> + assertTrue ( tribeState . getMetaData ( ) . hasIndex ( \" test1 \" ) ) ; <nl> + assertFalse ( tribeState . getMetaData ( ) . hasIndex ( \" test2 \" ) ) ; <nl> + assertTrue ( tribeState . getRoutingTable ( ) . hasIndex ( \" test1 \" ) ) ; <nl> + assertFalse ( tribeState . getRoutingTable ( ) . hasIndex ( \" test2 \" ) ) ; <nl> } <nl> } ) ; <nl> <nl> public boolean apply ( Object o ) { <nl> } <nl> <nl> private void awaitIndicesInClusterState ( final String . . . indices ) throws Exception { <nl> - awaitBusy ( new Predicate < Object > ( ) { <nl> + assertBusy ( new Runnable ( ) { <nl> @ Override <nl> - public boolean apply ( Object o ) { <nl> + public void run ( ) { <nl> ClusterState tribeState = tribeNode . client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) ; <nl> for ( String index : indices ) { <nl> - if ( ! tribeState . getMetaData ( ) . hasIndex ( index ) ) { <nl> - return false ; <nl> - } <nl> - if ( ! tribeState . getRoutingTable ( ) . hasIndex ( index ) ) { <nl> - return false ; <nl> - } <nl> + assertTrue ( tribeState . getMetaData ( ) . hasIndex ( index ) ) ; <nl> + assertTrue ( tribeState . getRoutingTable ( ) . hasIndex ( index ) ) ; <nl> } <nl> - return true ; <nl> } <nl> } ) ; <nl> } <nl> <nl> private void awaitSameNodeCounts ( ) throws Exception { <nl> - awaitBusy ( new Predicate < Object > ( ) { <nl> + assertBusy ( new Runnable ( ) { <nl> @ Override <nl> - public boolean apply ( Object o ) { <nl> + public void run ( ) { <nl> DiscoveryNodes tribeNodes = tribeNode . client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) . getNodes ( ) ; <nl> - return countDataNodesForTribe ( \" t1 \" , tribeNodes ) = = internalCluster ( ) . client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) . getNodes ( ) . dataNodes ( ) . size ( ) <nl> - & & countDataNodesForTribe ( \" t2 \" , tribeNodes ) = = cluster2 . client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) . getNodes ( ) . dataNodes ( ) . size ( ) ; <nl> + assertThat ( countDataNodesForTribe ( \" t1 \" , tribeNodes ) , equalTo ( internalCluster ( ) . client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) . getNodes ( ) . dataNodes ( ) . size ( ) ) ) ; <nl> + assertThat ( countDataNodesForTribe ( \" t2 \" , tribeNodes ) , equalTo ( cluster2 . client ( ) . admin ( ) . cluster ( ) . prepareState ( ) . get ( ) . getState ( ) . getNodes ( ) . dataNodes ( ) . size ( ) ) ) ; <nl> } <nl> } ) ; <nl> } <nl>\n", "msg": "[ TEST ] move tribe tests to use assertBusy\n"}
{"diff_id": 31431, "repo": "libgdx/libgdx\n", "sha": "898743b68bc5098a695d6c869191d20ce5691343\n", "time": "2016-02-16T22:40:44Z\n", "diff": "mmm a / extensions / gdx - setup / src / com / badlogic / gdx / setup / GdxSetup . java <nl> ppp b / extensions / gdx - setup / src / com / badlogic / gdx / setup / GdxSetup . java <nl> private String replace ( String txt , Map < String , String > values ) { <nl> <nl> private static void printHelp ( ) { <nl> System . out <nl> - . println ( \" Usage : GdxSetup - - dir < dir - name > - - name < app - name > - - package < package > - - mainClass < mainClass > - - sdkLocation < SDKLocation > \" ) ; <nl> + . println ( \" Usage : GdxSetup - - dir < dir - name > - - name < app - name > - - package < package > - - mainClass < mainClass > - - sdkLocation < SDKLocation > [ - - excludeModules < modules > ] \" ) ; <nl> System . out . println ( \" dir . . . the directory to write the project files to \" ) ; <nl> System . out . println ( \" name . . . the name of the application \" ) ; <nl> System . out . println ( \" package . . . the Java package name of the application \" ) ; <nl> System . out . println ( \" mainClass . . . the name of your main ApplicationListener \" ) ; <nl> - System . out . println ( \" sdkLocation . . . the location of your android SDK . Uses ANDROID_HOME if not specified \" ) ; <nl> + System . out . println ( \" sdkLocation . . . the location of your android SDK . Uses ANDROID_HOME if not specified . Ignored if android module is excluded \" ) ; <nl> + System . out . println ( \" excludeModules . . . the modules to exclude on the project generation separated by ' ; ' . Optional \" ) ; <nl> } <nl> <nl> private static Map < String , String > parseArgs ( String [ ] args ) { <nl> private static void printHelp ( ) { <nl> return params ; <nl> } <nl> <nl> + private static List < String > parseExcludedModules ( String excludedModules ) <nl> + { <nl> + List < String > excludedModulesList = new ArrayList < String > ( ) ; <nl> + <nl> + while ( excludedModules . contains ( \" ; \" ) ) { <nl> + excludedModulesList . add ( excludedModules . substring ( 0 , excludedModules . indexOf ( \" ; \" ) ) . toLowerCase ( ) ) ; <nl> + excludedModules = excludedModules . substring ( excludedModules . indexOf ( \" ; \" ) + 1 ) ; <nl> + } <nl> + excludedModulesList . add ( excludedModules . toLowerCase ( ) ) ; <nl> + <nl> + return excludedModulesList ; <nl> + } <nl> + <nl> private String parseGwtInherits ( ProjectBuilder builder ) { <nl> String parsed = \" \" ; <nl> <nl> private boolean containsDependency ( List < Dependency > dependencyList , ProjectDepe <nl> <nl> public static void main ( String [ ] args ) throws IOException { <nl> Map < String , String > params = parseArgs ( args ) ; <nl> + List < String > excludedModules = null ; <nl> + if ( params . containsKey ( \" excludeModules \" ) ) <nl> + excludedModules = parseExcludedModules ( params . get ( \" excludeModules \" ) ) ; <nl> + <nl> if ( ! params . containsKey ( \" dir \" ) | | <nl> ! params . containsKey ( \" name \" ) | | <nl> ! params . containsKey ( \" package \" ) | | <nl> ! params . containsKey ( \" mainClass \" ) | | <nl> - ( ( ! params . containsKey ( \" sdkLocation \" ) & & System . getenv ( \" ANDROID_HOME \" ) = = null ) ) ) { <nl> + ( ! params . containsKey ( \" sdkLocation \" ) & & System . getenv ( \" ANDROID_HOME \" ) = = null & & <nl> + ( excludedModules = = null | | ! excludedModules . contains ( \" android \" ) ) ) ) { <nl> new GdxSetupUI ( ) ; <nl> printHelp ( ) ; <nl> } else { <nl> String sdkLocation = \" \" ; <nl> - if ( System . getenv ( \" ANDROID_HOME \" ) ! = null & & ! params . containsKey ( \" sdkLocation \" ) ) { <nl> - sdkLocation = System . getenv ( \" ANDROID_HOME \" ) ; <nl> - } else { <nl> - sdkLocation = params . get ( \" sdkLocation \" ) ; <nl> + if ( excludedModules = = null | | ! excludedModules . contains ( \" android \" ) ) <nl> + { <nl> + if ( System . getenv ( \" ANDROID_HOME \" ) ! = null & & ! params . containsKey ( \" sdkLocation \" ) ) { <nl> + sdkLocation = System . getenv ( \" ANDROID_HOME \" ) ; <nl> + } else { <nl> + sdkLocation = params . get ( \" sdkLocation \" ) ; <nl> + } <nl> } <nl> <nl> DependencyBank bank = new DependencyBank ( ) ; <nl> ProjectBuilder builder = new ProjectBuilder ( bank ) ; <nl> List < ProjectType > projects = new ArrayList < ProjectType > ( ) ; <nl> + <nl> projects . add ( ProjectType . CORE ) ; <nl> - projects . add ( ProjectType . DESKTOP ) ; <nl> - projects . add ( ProjectType . ANDROID ) ; <nl> - projects . add ( ProjectType . IOS ) ; <nl> - projects . add ( ProjectType . HTML ) ; <nl> + if ( excludedModules = = null ) <nl> + { <nl> + projects . add ( ProjectType . DESKTOP ) ; <nl> + projects . add ( ProjectType . ANDROID ) ; <nl> + projects . add ( ProjectType . IOS ) ; <nl> + projects . add ( ProjectType . HTML ) ; <nl> + } else { <nl> + if ( ! excludedModules . contains ( \" desktop \" ) ) <nl> + projects . add ( ProjectType . DESKTOP ) ; <nl> + if ( ! excludedModules . contains ( \" android \" ) ) <nl> + projects . add ( ProjectType . ANDROID ) ; <nl> + if ( ! excludedModules . contains ( \" ios \" ) ) <nl> + projects . add ( ProjectType . IOS ) ; <nl> + if ( ! excludedModules . contains ( \" html \" ) ) <nl> + projects . add ( ProjectType . HTML ) ; <nl> + } <nl> <nl> List < Dependency > dependencies = new ArrayList < Dependency > ( ) ; <nl> dependencies . add ( bank . getDependency ( ProjectDependency . GDX ) ) ; <nl>\n", "msg": "Add support for selecting modules through command line\n"}
{"diff_id": 31480, "repo": "elastic/elasticsearch\n", "sha": "4fa1f83b2425caed5cc00a56494a8de59e2cbc9d\n", "time": "2020-09-23T16:17:12Z\n", "diff": "mmm a / server / src / internalClusterTest / java / org / elasticsearch / cluster / ClusterHealthIT . java <nl> ppp b / server / src / internalClusterTest / java / org / elasticsearch / cluster / ClusterHealthIT . java <nl> public void clusterStateProcessed ( String source , ClusterState oldState , ClusterS <nl> } <nl> } <nl> <nl> + @ AwaitsFix ( bugUrl = \" https : / / github . com / elastic / elasticsearch / issues / 62690 \" ) <nl> public void testHealthOnMasterFailover ( ) throws Exception { <nl> final String node = internalCluster ( ) . startDataOnlyNode ( ) ; <nl> boolean withIndex = randomBoolean ( ) ; <nl>\n", "msg": "Mute ClusterHealthIT . testHealthOnMasterFailover while we await a fix .\n"}
{"diff_id": 31511, "repo": "oracle/graal\n", "sha": "9204e97098f5895f7152dda4fa1ec28a10d8bc4e\n", "time": "2017-06-13T12:18:08Z\n", "diff": "mmm a / truffle / src / com . oracle . truffle . api . interop . java / src / com / oracle / truffle / api / interop / java / ToJavaNode . java <nl> ppp b / truffle / src / com . oracle . truffle . api . interop . java / src / com / oracle / truffle / api / interop / java / ToJavaNode . java <nl> private Object convertImpl ( Object value , TypeAndClass < ? > targetType , Object lang <nl> return convertedValue ; <nl> } <nl> } <nl> - if ( languageContext ! = null & & ( targetType . clazz = = Object . class | | targetType . clazz = = Value . class ) ) { <nl> + if ( languageContext ! = null & & targetType . clazz = = Value . class ) { <nl> convertedValue = value instanceof Value ? value : JavaInterop . toHostValue ( value , languageContext ) ; <nl> } else if ( JavaObject . isJavaInstance ( targetType . clazz , value ) ) { <nl> convertedValue = JavaObject . valueOf ( value ) ; <nl>\n", "msg": "JavaInterop : change semantics such that host objects are passed to Java methods unwrapped if the type is Object .\n"}
{"diff_id": 31572, "repo": "netty/netty\n", "sha": "c44f365ee7784dd3af2ecec73ed18b8f6239f674\n", "time": "2012-04-16T08:43:21Z\n", "diff": "mmm a / codec - http / src / main / java / io / netty / handler / codec / http / CookieEncoder . java <nl> ppp b / codec - http / src / main / java / io / netty / handler / codec / http / CookieEncoder . java <nl> public void addCookie ( Cookie cookie ) { <nl> * Encodes the { @ link Cookie } s which were added by { @ link # addCookie ( Cookie ) } <nl> * so far into an HTTP header value . If no { @ link Cookie } s were added , <nl> * an empty string is returned . <nl> + * <nl> + * < strong > Be aware that calling this method will clear the contends of the { @ link CookieEncoder } < / strong > <nl> * / <nl> public String encode ( ) { <nl> String answer ; <nl>\n", "msg": "Add some javadocs notes that explain the behavior of CookieEncoder . encode ( ) . See\n"}
{"diff_id": 31583, "repo": "bumptech/glide\n", "sha": "c06547b884163260b390afbb99a5b15349e7c8d9\n", "time": "2017-04-04T15:45:29Z\n", "diff": "mmm a / library / src / main / java / com / bumptech / glide / manager / RequestManagerRetriever . java <nl> ppp b / library / src / main / java / com / bumptech / glide / manager / RequestManagerRetriever . java <nl> <nl> import com . bumptech . glide . RequestManager ; <nl> import com . bumptech . glide . util . Preconditions ; <nl> import com . bumptech . glide . util . Util ; <nl> + import java . util . Collection ; <nl> import java . util . HashMap ; <nl> - import java . util . List ; <nl> import java . util . Map ; <nl> <nl> / * * <nl> public RequestManager get ( View view ) { <nl> return get ( fragment ) ; <nl> } <nl> <nl> - private static void findAllSupportFragmentsWithViews ( @ Nullable List < Fragment > topLevelFragments , <nl> + private static void findAllSupportFragmentsWithViews ( <nl> + @ Nullable Collection < Fragment > topLevelFragments , <nl> Map < View , Fragment > result ) { <nl> if ( topLevelFragments = = null ) { <nl> return ; <nl>\n", "msg": "Change findAllSupportFragmentsWithViews to return a collection instead of list .\n"}
{"diff_id": 31620, "repo": "elastic/elasticsearch\n", "sha": "36f76322326013009fb59ac62edb3941c4f5a65b\n", "time": "2016-06-14T21:12:23Z\n", "diff": "mmm a / modules / lang - painless / src / main / java / org / elasticsearch / painless / AnalyzerCaster . java <nl> ppp b / modules / lang - painless / src / main / java / org / elasticsearch / painless / AnalyzerCaster . java <nl> public static Cast getLegalCast ( Location location , Type actual , Type expected , b <nl> case DEF : <nl> return new Cast ( actual , Definition . DEF_TYPE , explicit , false , false , true , false ) ; <nl> case OBJECT : <nl> + if ( Definition . OBJECT_TYPE . equals ( expected ) & & internal ) <nl> + return new Cast ( actual , actual , explicit , false , false , false , true ) ; <nl> + <nl> + break ; <nl> case BOOL_OBJ : <nl> if ( internal ) <nl> return new Cast ( actual , actual , explicit , false , false , false , true ) ; <nl> public static Cast getLegalCast ( Location location , Type actual , Type expected , b <nl> case DEF : <nl> return new Cast ( actual , Definition . DEF_TYPE , explicit , false , false , true , false ) ; <nl> case OBJECT : <nl> + if ( Definition . OBJECT_TYPE . equals ( expected ) & & internal ) <nl> + return new Cast ( actual , actual , explicit , false , false , false , true ) ; <nl> + <nl> + break ; <nl> case NUMBER : <nl> case BYTE_OBJ : <nl> if ( internal ) <nl> public static Cast getLegalCast ( Location location , Type actual , Type expected , b <nl> case DEF : <nl> return new Cast ( actual , Definition . DEF_TYPE , explicit , false , false , true , false ) ; <nl> case OBJECT : <nl> + if ( Definition . OBJECT_TYPE . equals ( expected ) & & internal ) <nl> + return new Cast ( actual , actual , explicit , false , false , false , true ) ; <nl> + <nl> + break ; <nl> case NUMBER : <nl> case SHORT_OBJ : <nl> if ( internal ) <nl> public static Cast getLegalCast ( Location location , Type actual , Type expected , b <nl> case DEF : <nl> return new Cast ( actual , Definition . DEF_TYPE , explicit , false , false , true , false ) ; <nl> case OBJECT : <nl> + if ( Definition . OBJECT_TYPE . equals ( expected ) & & internal ) <nl> + return new Cast ( actual , actual , explicit , false , false , false , true ) ; <nl> + <nl> + break ; <nl> case NUMBER : <nl> case CHAR_OBJ : <nl> if ( internal ) <nl> public static Cast getLegalCast ( Location location , Type actual , Type expected , b <nl> case DEF : <nl> return new Cast ( actual , Definition . DEF_TYPE , explicit , false , false , true , false ) ; <nl> case OBJECT : <nl> + if ( Definition . OBJECT_TYPE . equals ( expected ) & & internal ) <nl> + return new Cast ( actual , actual , explicit , false , false , false , true ) ; <nl> + <nl> + break ; <nl> case NUMBER : <nl> case INT_OBJ : <nl> if ( internal ) <nl> public static Cast getLegalCast ( Location location , Type actual , Type expected , b <nl> case DEF : <nl> return new Cast ( actual , Definition . DEF_TYPE , explicit , false , false , true , false ) ; <nl> case OBJECT : <nl> + if ( Definition . OBJECT_TYPE . equals ( expected ) & & internal ) <nl> + return new Cast ( actual , actual , explicit , false , false , false , true ) ; <nl> + <nl> + break ; <nl> case NUMBER : <nl> case LONG_OBJ : <nl> if ( internal ) <nl> public static Cast getLegalCast ( Location location , Type actual , Type expected , b <nl> case DEF : <nl> return new Cast ( actual , Definition . DEF_TYPE , explicit , false , false , true , false ) ; <nl> case OBJECT : <nl> + if ( Definition . OBJECT_TYPE . equals ( expected ) & & internal ) <nl> + return new Cast ( actual , actual , explicit , false , false , false , true ) ; <nl> + <nl> + break ; <nl> case NUMBER : <nl> case FLOAT_OBJ : <nl> if ( internal ) <nl> public static Cast getLegalCast ( Location location , Type actual , Type expected , b <nl> case DEF : <nl> return new Cast ( actual , Definition . DEF_TYPE , explicit , false , false , true , false ) ; <nl> case OBJECT : <nl> + if ( Definition . OBJECT_TYPE . equals ( expected ) & & internal ) <nl> + return new Cast ( actual , actual , explicit , false , false , false , true ) ; <nl> + <nl> + break ; <nl> case NUMBER : <nl> case DOUBLE_OBJ : <nl> if ( internal ) <nl> public static Cast getLegalCast ( Location location , Type actual , Type expected , b <nl> <nl> break ; <nl> case OBJECT : <nl> + if ( Definition . OBJECT_TYPE . equals ( actual ) ) <nl> + switch ( expected . sort ) { <nl> + case BYTE : <nl> + if ( internal & & explicit ) <nl> + return new Cast ( actual , Definition . BYTE_OBJ_TYPE , true , false , true , false , false ) ; <nl> + <nl> + break ; <nl> + case SHORT : <nl> + if ( internal & & explicit ) <nl> + return new Cast ( actual , Definition . SHORT_OBJ_TYPE , true , false , true , false , false ) ; <nl> + <nl> + break ; <nl> + case CHAR : <nl> + if ( internal & & explicit ) <nl> + return new Cast ( actual , Definition . CHAR_OBJ_TYPE , true , false , true , false , false ) ; <nl> + <nl> + break ; <nl> + case INT : <nl> + if ( internal & & explicit ) <nl> + return new Cast ( actual , Definition . INT_OBJ_TYPE , true , false , true , false , false ) ; <nl> + <nl> + break ; <nl> + case LONG : <nl> + if ( internal & & explicit ) <nl> + return new Cast ( actual , Definition . LONG_OBJ_TYPE , true , false , true , false , false ) ; <nl> + <nl> + break ; <nl> + case FLOAT : <nl> + if ( internal & & explicit ) <nl> + return new Cast ( actual , Definition . FLOAT_OBJ_TYPE , true , false , true , false , false ) ; <nl> + <nl> + break ; <nl> + case DOUBLE : <nl> + if ( internal & & explicit ) <nl> + return new Cast ( actual , Definition . DOUBLE_OBJ_TYPE , true , false , true , false , false ) ; <nl> + <nl> + break ; <nl> + } <nl> + break ; <nl> case NUMBER : <nl> switch ( expected . sort ) { <nl> case BYTE : <nl>\n", "msg": "Correct type checking during casting related to Object .\n"}
{"diff_id": 31762, "repo": "bazelbuild/bazel\n", "sha": "eea9ec288856a61538b9204f2e0f9e3311cab6a8\n", "time": "2017-10-26T08:59:01Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / analysis / config / BuildConfiguration . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / analysis / config / BuildConfiguration . java <nl> public StrictDepsConverter ( ) { <nl> ) <nl> public boolean legacyExternalRunfiles ; <nl> <nl> + @ Deprecated <nl> @ Option ( <nl> name = \" check_fileset_dependencies_recursively \" , <nl> defaultValue = \" true \" , <nl> category = \" semantics \" , <nl> - documentationCategory = OptionDocumentationCategory . OUTPUT_SELECTION , <nl> + documentationCategory = OptionDocumentationCategory . UNDOCUMENTED , <nl> + deprecationWarning = \" Setting this to false is unsupported and will go away soon as it leads \" <nl> + + \" to incorrect results . Please contact kush @ with your use case if you need \" <nl> + + \" to continue setting this flag to false . If you ' re setting this to true then stop \" <nl> + + \" setting this flag to stop this warning . \" , <nl> effectTags = { OptionEffectTag . AFFECTS_OUTPUTS } , <nl> help = <nl> \" If false , fileset targets will , whenever possible , create \" <nl>\n", "msg": "Add a deprecation warning to the check_fileset_dependencies_resursively flag .\n"}
{"diff_id": 31768, "repo": "NationalSecurityAgency/ghidra\n", "sha": "23a05a41778f38a9956dcce0f9e9a4b7ebf74731\n", "time": "2019-06-06T19:35:13Z\n", "diff": "mmm a / Ghidra / Framework / Project / src / main / java / ghidra / framework / ToolUtils . java <nl> ppp b / Ghidra / Framework / Project / src / main / java / ghidra / framework / ToolUtils . java <nl> public static File getUserToolsDirectory ( ) { <nl> <nl> Set < String > toolNames = ResourceManager . getResourceNames ( \" defaultTools \" , \" . tool \" ) ; <nl> for ( String toolName : toolNames ) { <nl> + if ( skipTool ( toolName ) ) { <nl> + continue ; <nl> + } <nl> + <nl> ToolTemplate tool = readToolTemplate ( toolName ) ; <nl> if ( tool ! = null ) { <nl> set . add ( tool ) ; <nl> private static String removeLastExtension ( String filename ) { <nl> <nl> public static ToolTemplate readToolTemplate ( String resourceFileName ) { <nl> <nl> - if ( skipTool ( resourceFileName ) ) { <nl> - return null ; <nl> - } <nl> - <nl> try ( InputStream is = ResourceManager . getResourceAsStream ( resourceFileName ) ) { <nl> if ( is = = null ) { <nl> return null ; <nl> public static File getToolFile ( String name ) { <nl> } <nl> <nl> / * * <nl> - * Returns the user ' s personal tool chest directory path . <nl> + * Returns the user ' s personal tool chest directory path <nl> + * @ return the path <nl> * / <nl> public static String getApplicationToolDirPath ( ) { <nl> String userSettingsPath = Application . getUserSettingsDirectory ( ) . getAbsolutePath ( ) ; <nl>\n", "msg": "Screenshots - fixed broken screenshot generators\n"}
{"diff_id": 31828, "repo": "elastic/elasticsearch\n", "sha": "c0a6b6741e2e0add2ec17e3b75076a7589d9c2db\n", "time": "2017-03-27T12:52:18Z\n", "diff": "mmm a / plugin / src / main / java / org / elasticsearch / xpack / ml / datafeed / extractor / ExtractorUtils . java <nl> ppp b / plugin / src / main / java / org / elasticsearch / xpack / ml / datafeed / extractor / ExtractorUtils . java <nl> <nl> import org . elasticsearch . index . query . QueryBuilder ; <nl> import org . elasticsearch . index . query . RangeQueryBuilder ; <nl> import org . elasticsearch . rest . RestStatus ; <nl> + import org . elasticsearch . xpack . ml . utils . ExceptionsHelper ; <nl> <nl> import java . io . IOException ; <nl> import java . util . Arrays ; <nl> public static void checkSearchWasSuccessful ( String jobId , SearchResponse searchR <nl> ShardSearchFailure [ ] shardFailures = searchResponse . getShardFailures ( ) ; <nl> if ( shardFailures ! = null & & shardFailures . length > 0 ) { <nl> LOGGER . error ( \" [ { } ] Search request returned shard failures : { } \" , jobId , Arrays . toString ( shardFailures ) ) ; <nl> - throw new IOException ( \" [ \" + jobId + \" ] Search request returned shard failures ; see more info in the logs \" ) ; <nl> + throw new IOException ( ExceptionsHelper . shardFailuresToErrorMsg ( jobId , shardFailures ) ) ; <nl> } <nl> int unavailableShards = searchResponse . getTotalShards ( ) - searchResponse . getSuccessfulShards ( ) ; <nl> if ( unavailableShards > 0 ) { <nl>\n", "msg": "[ ML ] Improve notification message for shard failures in datafeed\n"}
{"diff_id": 31892, "repo": "jenkinsci/jenkins\n", "sha": "324881178c321dccf05c12dae39567c713d9eb11\n", "time": "2008-02-07T07:24:39Z\n", "diff": "mmm a / core / src / main / java / hudson / scm / SubversionSCM . java <nl> ppp b / core / src / main / java / hudson / scm / SubversionSCM . java <nl> <nl> import org . tmatesoft . svn . core . auth . SVNSSLAuthentication ; <nl> import org . tmatesoft . svn . core . auth . SVNUserNameAuthentication ; <nl> import org . tmatesoft . svn . core . internal . io . dav . DAVRepositoryFactory ; <nl> + import org . tmatesoft . svn . core . internal . io . dav . http . IHTTPConnectionFactory ; <nl> + import org . tmatesoft . svn . core . internal . io . dav . http . DefaultHTTPConnectionFactory ; <nl> import org . tmatesoft . svn . core . internal . io . fs . FSRepositoryFactory ; <nl> import org . tmatesoft . svn . core . internal . io . svn . SVNRepositoryFactoryImpl ; <nl> import org . tmatesoft . svn . core . internal . util . SVNPathUtil ; <nl> public boolean repositoryLocationsExist ( ) throws SVNException { <nl> <nl> private static final class Initializer { <nl> static { <nl> - DAVRepositoryFactory . setup ( ) ; / / http , https <nl> + if ( Boolean . getBoolean ( \" hudson . spool - svn \" ) ) <nl> + DAVRepositoryFactory . setup ( new DefaultHTTPConnectionFactory ( null , true , null ) ) ; <nl> + else <nl> + DAVRepositoryFactory . setup ( ) ; / / http , https <nl> SVNRepositoryFactoryImpl . setup ( ) ; / / svn , svn + xxx <nl> FSRepositoryFactory . setup ( ) ; / / file <nl> <nl>\n", "msg": "adding a test probe to see if the spooling works\n"}
{"diff_id": 32003, "repo": "jenkinsci/jenkins\n", "sha": "a8789db91f1b8b9f8daf5a5c07a947dbfd696c36\n", "time": "2015-11-03T21:50:38Z\n", "diff": "mmm a / core / src / main / java / hudson / console / AnnotatedLargeText . java <nl> ppp b / core / src / main / java / hudson / console / AnnotatedLargeText . java <nl> public long writeLogTo ( long start , OutputStream out ) throws IOException { <nl> <nl> / * * <nl> * Calls { @ link LargeText # writeLogTo ( long , OutputStream ) } without stripping annotations as { @ link # writeLogTo ( long , OutputStream ) } would . <nl> - * @ inheritDoc <nl> * @ since 1 . 577 <nl> * / <nl> public long writeRawLogTo ( long start , OutputStream out ) throws IOException { <nl>\n", "msg": "AnnotatedLargeText : remove invalid @ inheritDoc\n"}
{"diff_id": 32028, "repo": "oracle/graal\n", "sha": "67065befabd345696b48f9d8000991919fcd8bb8\n", "time": "2020-07-24T08:30:26Z\n", "diff": "mmm a / compiler / src / org . graalvm . compiler . truffle . test / src / org / graalvm / compiler / truffle / test / RewriteDuringCompilationTest . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . test / src / org / graalvm / compiler / truffle / test / RewriteDuringCompilationTest . java <nl> <nl> import org . graalvm . polyglot . Context ; <nl> import org . graalvm . polyglot . Source ; <nl> import org . junit . Assert ; <nl> - import org . junit . Ignore ; <nl> + import org . junit . Assume ; <nl> import org . junit . Test ; <nl> <nl> import com . oracle . truffle . api . CallTarget ; <nl> <nl> import com . oracle . truffle . api . nodes . RepeatingNode ; <nl> import com . oracle . truffle . api . nodes . RootNode ; <nl> import com . oracle . truffle . api . source . SourceSection ; <nl> + import com . oracle . truffle . api . test . CompileImmediatelyCheck ; <nl> import com . oracle . truffle . api . test . polyglot . AbstractPolyglotTest ; <nl> import com . oracle . truffle . api . test . polyglot . ProxyLanguage ; <nl> <nl> public void testRootCompilation ( ) throws IOException , InterruptedException , Exec <nl> testCompilation ( detectInvalidCodeNode , null , detectInvalidCodeNode , 1000 , 20 ) ; <nl> } <nl> <nl> - @ Ignore ( \" GR - 25000 \" ) <nl> @ Test <nl> public void testLoopCompilation ( ) throws IOException , InterruptedException , ExecutionException { <nl> + Assume . assumeFalse ( CompileImmediatelyCheck . isCompileImmediately ( ) ) ; <nl> DetectInvalidCodeNode detectInvalidCodeNode = new DetectInvalidCodeNode ( ) ; <nl> WhileLoopNode testedCode = new WhileLoopNode ( 10000000 , detectInvalidCodeNode ) ; <nl> testCompilation ( testedCode , testedCode . loop , detectInvalidCodeNode , 1000 , 40 ) ; <nl>\n", "msg": "Ignore testLoopCompilation test in case immediate compilation is enabled .\n"}
{"diff_id": 32446, "repo": "oracle/graal\n", "sha": "761825835dd2ae9b71e00579874d9f83925d33d1\n", "time": "2013-04-25T16:11:30Z\n", "diff": "mmm a / graal / com . oracle . graal . replacements / src / com / oracle / graal / replacements / nodes / BranchProbabilityNode . java <nl> ppp b / graal / com . oracle . graal . replacements / src / com / oracle / graal / replacements / nodes / BranchProbabilityNode . java <nl> <nl> * / <nl> package com . oracle . graal . replacements . nodes ; <nl> <nl> + import com . oracle . graal . graph . * ; <nl> import com . oracle . graal . nodes . * ; <nl> import com . oracle . graal . nodes . spi . * ; <nl> import com . oracle . graal . nodes . type . * ; <nl> <nl> * the if node ' s taken probability . Then the branch probability node will be removed . This node is <nl> * intended primarily for snippets , so that they can define their fast and slow paths . <nl> * / <nl> - public class BranchProbabilityNode extends FixedWithNextNode implements Simplifiable { <nl> + public class BranchProbabilityNode extends FixedWithNextNode implements Simplifiable , Lowerable { <nl> <nl> public static final double LIKELY_PROBABILITY = 0 . 6 ; <nl> public static final double NOT_LIKELY_PROBABILITY = 1 - LIKELY_PROBABILITY ; <nl> <nl> public static final double NOT_DEOPT_PATH_PROBABILITY = 0 . 999 ; <nl> public static final double DEOPT_PATH_PROBABILITY = 1 - NOT_DEOPT_PATH_PROBABILITY ; <nl> <nl> - private final double probability ; <nl> + @ Input private ValueNode probability ; <nl> <nl> - public BranchProbabilityNode ( double probability ) { <nl> + public BranchProbabilityNode ( ValueNode probability ) { <nl> super ( StampFactory . forVoid ( ) ) ; <nl> - assert probability > = 0 & & probability < = 1 ; <nl> this . probability = probability ; <nl> } <nl> <nl> @ Override <nl> public void simplify ( SimplifierTool tool ) { <nl> - FixedNode current = this ; <nl> - while ( ! ( current instanceof BeginNode ) ) { <nl> - current = ( FixedNode ) current . predecessor ( ) ; <nl> - } <nl> - BeginNode begin = ( BeginNode ) current ; <nl> - assert begin . predecessor ( ) instanceof IfNode : \" explicit branch probability cannot follow a merge , only if nodes \" ; <nl> - IfNode ifNode = ( IfNode ) begin . predecessor ( ) ; <nl> - if ( ifNode . trueSuccessor ( ) = = begin ) { <nl> - ifNode . setTrueSuccessorProbability ( probability ) ; <nl> - } else { <nl> - ifNode . setTrueSuccessorProbability ( 1 - probability ) ; <nl> - } <nl> + if ( probability . isConstant ( ) ) { <nl> + double probabilityValue = probability . asConstant ( ) . asDouble ( ) ; <nl> + if ( probabilityValue < 0 . 0 ) { <nl> + throw new GraalInternalError ( \" A negative probability of \" + probabilityValue + \" is not allowed ! \" ) ; <nl> + } else if ( probabilityValue > 1 . 0 ) { <nl> + throw new GraalInternalError ( \" A probability of more than 1 . 0 ( \" + probabilityValue + \" ) is not allowed ! \" ) ; <nl> + } <nl> + FixedNode current = this ; <nl> + while ( ! ( current instanceof BeginNode ) ) { <nl> + current = ( FixedNode ) current . predecessor ( ) ; <nl> + } <nl> + BeginNode begin = ( BeginNode ) current ; <nl> + if ( ! ( begin . predecessor ( ) instanceof IfNode ) ) { <nl> + throw new GraalInternalError ( \" Injected branch probability cannot follow a merge , only if nodes \" ) ; <nl> + } <nl> + IfNode ifNode = ( IfNode ) begin . predecessor ( ) ; <nl> + if ( ifNode . trueSuccessor ( ) = = begin ) { <nl> + ifNode . setTrueSuccessorProbability ( probabilityValue ) ; <nl> + } else { <nl> + ifNode . setTrueSuccessorProbability ( 1 - probabilityValue ) ; <nl> + } <nl> <nl> - FixedNode next = next ( ) ; <nl> - setNext ( null ) ; <nl> - ( ( FixedWithNextNode ) predecessor ( ) ) . setNext ( next ) ; <nl> - GraphUtil . killCFG ( this ) ; <nl> + FixedNode next = next ( ) ; <nl> + setNext ( null ) ; <nl> + ( ( FixedWithNextNode ) predecessor ( ) ) . setNext ( next ) ; <nl> + GraphUtil . killCFG ( this ) ; <nl> + } <nl> } <nl> <nl> @ SuppressWarnings ( \" unused \" ) <nl> @ NodeIntrinsic <nl> - public static void probability ( @ ConstantNodeParameter double probability ) { <nl> + public static void probability ( double probability ) { <nl> + } <nl> + <nl> + @ Override <nl> + public void lower ( LoweringTool tool , LoweringType loweringType ) { <nl> + throw new GraalInternalError ( \" Branch probability could not be injected , because the probability value did not reduce to a constant value . \" ) ; <nl> } <nl> <nl> } <nl>\n", "msg": "Allow lazy resolving of the constant input value of the node injecting probabilities into if nodes .\n"}
{"diff_id": 32450, "repo": "oracle/graal\n", "sha": "01434590016ab5506e89c1353b45338a207d9d37\n", "time": "2015-01-27T11:25:38Z\n", "diff": "mmm a / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / stubs / Stub . java <nl> ppp b / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / stubs / Stub . java <nl> <nl> * / <nl> public abstract class Stub { <nl> <nl> + private static final List < Stub > stubs = new ArrayList < > ( ) ; <nl> + <nl> / * * <nl> * The linkage information for a call to this stub from compiled code . <nl> * / <nl> public boolean preservesRegisters ( ) { <nl> public Stub ( HotSpotProviders providers , HotSpotForeignCallLinkage linkage ) { <nl> this . linkage = linkage ; <nl> this . providers = providers ; <nl> + stubs . add ( this ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Gets an immutable view of all stubs that have been created . <nl> + * / <nl> + public static Collection < Stub > getStubs ( ) { <nl> + return Collections . unmodifiableList ( stubs ) ; <nl> } <nl> <nl> / * * <nl>\n", "msg": "provide Stub . getStubs ( ) method to access all installed stubs\n"}
{"diff_id": 32456, "repo": "oracle/graal\n", "sha": "6f1717a4bb458d20eb74488c8a38391de78e542b\n", "time": "2014-07-18T11:08:29Z\n", "diff": "mmm a / graal / com . oracle . graal . compiler . common / src / com / oracle / graal / compiler / common / calc / Condition . java <nl> ppp b / graal / com . oracle . graal . compiler . common / src / com / oracle / graal / compiler / common / calc / Condition . java <nl> public boolean foldCondition ( Constant lt , Constant rt , ConstantReflectionProvide <nl> * false <nl> * / <nl> public boolean foldCondition ( Constant lt , Constant rt , ConstantReflectionProvider constantReflection , boolean unorderedIsTrue ) { <nl> - switch ( lt . getKind ( ) ) { <nl> - case Boolean : <nl> - case Byte : <nl> - case Char : <nl> - case Short : <nl> - case Int : { <nl> - int x = lt . asInt ( ) ; <nl> - int y = rt . asInt ( ) ; <nl> - switch ( this ) { <nl> - case EQ : <nl> - return x = = y ; <nl> - case NE : <nl> - return x ! = y ; <nl> - case LT : <nl> - return x < y ; <nl> - case LE : <nl> - return x < = y ; <nl> - case GT : <nl> - return x > y ; <nl> - case GE : <nl> - return x > = y ; <nl> - case AE : <nl> - return UnsignedMath . aboveOrEqual ( x , y ) ; <nl> - case BE : <nl> - return UnsignedMath . belowOrEqual ( x , y ) ; <nl> - case AT : <nl> - return UnsignedMath . aboveThan ( x , y ) ; <nl> - case BT : <nl> - return UnsignedMath . belowThan ( x , y ) ; <nl> - default : <nl> - throw new GraalInternalError ( \" expected condition : % s \" , this ) ; <nl> - } <nl> - } <nl> - case Long : { <nl> - long x = lt . asLong ( ) ; <nl> - long y = rt . asLong ( ) ; <nl> - switch ( this ) { <nl> - case EQ : <nl> - return x = = y ; <nl> - case NE : <nl> - return x ! = y ; <nl> - case LT : <nl> - return x < y ; <nl> - case LE : <nl> - return x < = y ; <nl> - case GT : <nl> - return x > y ; <nl> - case GE : <nl> - return x > = y ; <nl> - case AE : <nl> - return UnsignedMath . aboveOrEqual ( x , y ) ; <nl> - case BE : <nl> - return UnsignedMath . belowOrEqual ( x , y ) ; <nl> - case AT : <nl> - return UnsignedMath . aboveThan ( x , y ) ; <nl> - case BT : <nl> - return UnsignedMath . belowThan ( x , y ) ; <nl> - default : <nl> - throw new GraalInternalError ( \" expected condition : % s \" , this ) ; <nl> + if ( lt instanceof PrimitiveConstant ) { <nl> + switch ( lt . getKind ( ) ) { <nl> + case Boolean : <nl> + case Byte : <nl> + case Char : <nl> + case Short : <nl> + case Int : { <nl> + int x = lt . asInt ( ) ; <nl> + int y = rt . asInt ( ) ; <nl> + switch ( this ) { <nl> + case EQ : <nl> + return x = = y ; <nl> + case NE : <nl> + return x ! = y ; <nl> + case LT : <nl> + return x < y ; <nl> + case LE : <nl> + return x < = y ; <nl> + case GT : <nl> + return x > y ; <nl> + case GE : <nl> + return x > = y ; <nl> + case AE : <nl> + return UnsignedMath . aboveOrEqual ( x , y ) ; <nl> + case BE : <nl> + return UnsignedMath . belowOrEqual ( x , y ) ; <nl> + case AT : <nl> + return UnsignedMath . aboveThan ( x , y ) ; <nl> + case BT : <nl> + return UnsignedMath . belowThan ( x , y ) ; <nl> + default : <nl> + throw new GraalInternalError ( \" expected condition : % s \" , this ) ; <nl> + } <nl> } <nl> - } <nl> - case Object : { <nl> - Boolean equal = constantReflection . constantEquals ( lt , rt ) ; <nl> - if ( equal ! = null ) { <nl> + case Long : { <nl> + long x = lt . asLong ( ) ; <nl> + long y = rt . asLong ( ) ; <nl> switch ( this ) { <nl> case EQ : <nl> - return equal . booleanValue ( ) ; <nl> + return x = = y ; <nl> case NE : <nl> - return ! equal . booleanValue ( ) ; <nl> + return x ! = y ; <nl> + case LT : <nl> + return x < y ; <nl> + case LE : <nl> + return x < = y ; <nl> + case GT : <nl> + return x > y ; <nl> + case GE : <nl> + return x > = y ; <nl> + case AE : <nl> + return UnsignedMath . aboveOrEqual ( x , y ) ; <nl> + case BE : <nl> + return UnsignedMath . belowOrEqual ( x , y ) ; <nl> + case AT : <nl> + return UnsignedMath . aboveThan ( x , y ) ; <nl> + case BT : <nl> + return UnsignedMath . belowThan ( x , y ) ; <nl> default : <nl> throw new GraalInternalError ( \" expected condition : % s \" , this ) ; <nl> } <nl> } <nl> - } <nl> - case Float : { <nl> - float x = lt . asFloat ( ) ; <nl> - float y = rt . asFloat ( ) ; <nl> - if ( Float . isNaN ( x ) | | Float . isNaN ( y ) ) { <nl> - return unorderedIsTrue ; <nl> + case Float : { <nl> + float x = lt . asFloat ( ) ; <nl> + float y = rt . asFloat ( ) ; <nl> + if ( Float . isNaN ( x ) | | Float . isNaN ( y ) ) { <nl> + return unorderedIsTrue ; <nl> + } <nl> + switch ( this ) { <nl> + case EQ : <nl> + return x = = y ; <nl> + case NE : <nl> + return x ! = y ; <nl> + case LT : <nl> + return x < y ; <nl> + case LE : <nl> + return x < = y ; <nl> + case GT : <nl> + return x > y ; <nl> + case GE : <nl> + return x > = y ; <nl> + default : <nl> + throw new GraalInternalError ( \" expected condition : % s \" , this ) ; <nl> + } <nl> } <nl> - switch ( this ) { <nl> - case EQ : <nl> - return x = = y ; <nl> - case NE : <nl> - return x ! = y ; <nl> - case LT : <nl> - return x < y ; <nl> - case LE : <nl> - return x < = y ; <nl> - case GT : <nl> - return x > y ; <nl> - case GE : <nl> - return x > = y ; <nl> - default : <nl> - throw new GraalInternalError ( \" expected condition : % s \" , this ) ; <nl> + case Double : { <nl> + double x = lt . asDouble ( ) ; <nl> + double y = rt . asDouble ( ) ; <nl> + if ( Double . isNaN ( x ) | | Double . isNaN ( y ) ) { <nl> + return unorderedIsTrue ; <nl> + } <nl> + switch ( this ) { <nl> + case EQ : <nl> + return x = = y ; <nl> + case NE : <nl> + return x ! = y ; <nl> + case LT : <nl> + return x < y ; <nl> + case LE : <nl> + return x < = y ; <nl> + case GT : <nl> + return x > y ; <nl> + case GE : <nl> + return x > = y ; <nl> + default : <nl> + throw new GraalInternalError ( \" expected condition : % s \" , this ) ; <nl> + } <nl> } <nl> + default : <nl> + throw new GraalInternalError ( \" expected value kind % s while folding condition : % s \" , lt . getKind ( ) , this ) ; <nl> } <nl> - case Double : { <nl> - double x = lt . asDouble ( ) ; <nl> - double y = rt . asDouble ( ) ; <nl> - if ( Double . isNaN ( x ) | | Double . isNaN ( y ) ) { <nl> - return unorderedIsTrue ; <nl> - } <nl> - switch ( this ) { <nl> - case EQ : <nl> - return x = = y ; <nl> - case NE : <nl> - return x ! = y ; <nl> - case LT : <nl> - return x < y ; <nl> - case LE : <nl> - return x < = y ; <nl> - case GT : <nl> - return x > y ; <nl> - case GE : <nl> - return x > = y ; <nl> - default : <nl> - throw new GraalInternalError ( \" expected condition : % s \" , this ) ; <nl> - } <nl> + } else { <nl> + Boolean equal = constantReflection . constantEquals ( lt , rt ) ; <nl> + if ( equal = = null ) { <nl> + throw new GraalInternalError ( \" could not fold % s % s % s \" , lt , this , rt ) ; <nl> + } <nl> + switch ( this ) { <nl> + case EQ : <nl> + return equal . booleanValue ( ) ; <nl> + case NE : <nl> + return ! equal . booleanValue ( ) ; <nl> + default : <nl> + throw new GraalInternalError ( \" expected condition : % s \" , this ) ; <nl> } <nl> - default : <nl> - throw new GraalInternalError ( \" expected value kind % s while folding condition : % s \" , lt . getKind ( ) , this ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "use getKind ( ) only for primitive constants in Condition . foldCondition\n"}
{"diff_id": 32459, "repo": "facebook/fresco\n", "sha": "b535778f0565218048928763671b4dffd82bb6fd\n", "time": "2016-06-29T23:30:04Z\n", "diff": "mmm a / samples / zoomable / src / main / java / com / facebook / samples / zoomable / GestureListenerWrapper . java <nl> ppp b / samples / zoomable / src / main / java / com / facebook / samples / zoomable / GestureListenerWrapper . java <nl> <nl> / * * <nl> * Wrapper for SimpleOnGestureListener as GestureDetector does not allow changing its listener . <nl> * / <nl> - class GestureListenerWrapper extends GestureDetector . SimpleOnGestureListener { <nl> + public class GestureListenerWrapper extends GestureDetector . SimpleOnGestureListener { <nl> <nl> private GestureDetector . SimpleOnGestureListener mDelegate ; <nl> <nl>\n", "msg": "Bring zoomable control to dedupe gallery view\n"}
{"diff_id": 32608, "repo": "oracle/graal\n", "sha": "df03265a8c262ac443d514fd2d3b31a71547aed3\n", "time": "2020-08-26T10:04:48Z\n", "diff": "mmm a / substratevm / src / com . oracle . svm . hosted / src / com / oracle / svm / hosted / c / codegen / QueryCodeWriter . java <nl> ppp b / substratevm / src / com . oracle . svm . hosted / src / com / oracle / svm / hosted / c / codegen / QueryCodeWriter . java <nl> protected void visitNativeCodeInfo ( NativeCodeInfo nativeCodeInfo ) { <nl> / * Write general macro definitions . * / <nl> writer . appendln ( ) ; <nl> <nl> - / * <nl> - * On Posix systems we use the GNU C extension , typeof ( ) to prevent the type promotion ( to <nl> - * signed int ) caused by the inversion operation . On Windows we generate c + + files so we can <nl> - * use decltype . <nl> - * / <nl> - writer . appendln ( \" # ifndef _WIN64 \" ) ; <nl> - writer . appendln ( \" # define ISUNSIGNED ( a ) ( ( a ) > = 0L & & ( typeof ( a ) ) ~ ( a ) > = 0L ) \" ) ; <nl> - writer . appendln ( \" # else \" ) ; <nl> - writer . appendln ( \" # define ISUNSIGNED ( a ) ( ( a ) > = 0L & & ( decltype ( a ) ) ~ ( a ) > = 0L ) \" ) ; <nl> - writer . appendln ( \" # endif \" ) ; <nl> - writer . appendln ( \" # define IS_CONST_UNSIGNED ( a ) ( a > = 0 ? 1 : 0 ) \" ) ; <nl> - <nl> / * Write the main function with all the outputs for the children . * / <nl> String functionName = nativeCodeInfo . getName ( ) . replaceAll ( \" \\ \\ W \" , \" _ \" ) ; <nl> writer . appendln ( ) ; <nl> protected void visitStructFieldInfo ( StructFieldInfo fieldInfo ) { <nl> printUnsignedLong ( fieldInfo . getOffsetInfo ( ) , offsetOfField ( fieldInfo ) ) ; <nl> <nl> if ( fieldInfo . getKind ( ) = = ElementKind . INTEGER ) { <nl> - String tempVar = getUniqueTempVarName ( fieldInfo . getParent ( ) ) ; <nl> registerElementForCurrentLine ( fieldInfo . getParent ( ) . getAnnotatedElement ( ) ) ; <nl> writer . indents ( ) . appendln ( \" { \" ) ; <nl> writer . indent ( ) ; <nl> - writer . indents ( ) . appendln ( fieldInfo . getParent ( ) . getName ( ) + \" \" + tempVar + \" ; \" ) ; <nl> - writer . indents ( ) . appendln ( \" memset ( & \" + tempVar + \" , 0x0 , sizeof ( \" + tempVar + \" ) ) ; \" ) ; <nl> - printIsUnsigned ( fieldInfo . getSignednessInfo ( ) , isUnsigned ( tempVar + \" . \" + fieldInfo . getName ( ) ) ) ; <nl> + writer . indents ( ) . appendln ( fieldInfo . getParent ( ) . getName ( ) + \" fieldHolder ; \" ) ; <nl> + writer . indents ( ) . appendln ( \" memset ( & fieldHolder , 0x0 , sizeof ( fieldHolder ) ) ; \" ) ; <nl> + writer . indents ( ) . appendln ( \" unsigned long all_bits_set = - 1 ; \" ) ; <nl> + writer . indents ( ) . appendln ( \" fieldHolder . \" + fieldInfo . getName ( ) + \" = all_bits_set ; \" ) ; <nl> + writer . indents ( ) . appendln ( \" int is_unsigned = fieldHolder . \" + fieldInfo . getName ( ) + \" > = 0 ; \" ) ; <nl> + printIsUnsigned ( fieldInfo . getSignednessInfo ( ) , \" is_unsigned \" ) ; <nl> writer . outdent ( ) ; <nl> writer . indents ( ) . appendln ( \" } \" ) ; <nl> } <nl> protected void visitStructBitfieldInfo ( StructBitfieldInfo bitfieldInfo ) { <nl> writer . indents ( ) . appendln ( \" memset ( & w , 0x0 , sizeof ( w ) ) ; \" ) ; <nl> / * Fill the actual bitfield with 1 bits . Maximum size is 64 bits . * / <nl> registerElementForCurrentLine ( bitfieldInfo . getAnnotatedElement ( ) ) ; <nl> - writer . indents ( ) . appendln ( \" unsigned long one_bits64 = 0xffffffffffffffff ; \" ) ; <nl> - writer . indents ( ) . appendln ( \" w . s . \" + bitfieldName + \" = one_bits64 ; \" ) ; <nl> + writer . indents ( ) . appendln ( \" unsigned long all_bits_set = - 1 ; \" ) ; <nl> + writer . indents ( ) . appendln ( \" w . s . \" + bitfieldName + \" = all_bits_set ; \" ) ; <nl> / * All bits are set , so signed bitfields are < 0 ; * / <nl> - writer . indents ( ) . appendln ( \" is_unsigned = ( w . s . \" + bitfieldName + \" > = 0 ) ; \" ) ; <nl> + writer . indents ( ) . appendln ( \" is_unsigned = w . s . \" + bitfieldName + \" > = 0 ; \" ) ; <nl> / * Find the first byte that is used by the bitfield , i . e . , the first byte with a bit set . * / <nl> writer . indents ( ) . appendln ( \" p = ( char * ) & w . s ; \" ) ; <nl> writer . indents ( ) . appendln ( \" byte_offset = 0 ; \" ) ; <nl> protected void visitPointerToInfo ( PointerToInfo pointerToInfo ) { <nl> printUnsignedLong ( pointerToInfo . getSizeInfo ( ) , sizeOf ( pointerToInfo ) ) ; <nl> <nl> if ( pointerToInfo . getKind ( ) = = ElementKind . INTEGER ) { <nl> - String tempVar = getUniqueTempVarName ( pointerToInfo ) ; <nl> registerElementForCurrentLine ( pointerToInfo . getAnnotatedElement ( ) ) ; <nl> writer . indents ( ) . appendln ( \" { \" ) ; <nl> writer . indent ( ) ; <nl> - String init = \" = 0 \" ; <nl> - writer . indents ( ) . appendln ( pointerToInfo . getName ( ) + \" \" + tempVar + init + \" ; \" ) ; <nl> - printIsUnsigned ( pointerToInfo . getSignednessInfo ( ) , isUnsigned ( tempVar ) ) ; <nl> + writer . indents ( ) . appendln ( \" unsigned long all_bits_set = - 1 ; \" ) ; <nl> + writer . indents ( ) . appendln ( pointerToInfo . getName ( ) + \" fieldHolder = all_bits_set ; \" ) ; <nl> + writer . indents ( ) . appendln ( \" int is_unsigned = fieldHolder > = 0 ; \" ) ; <nl> + printIsUnsigned ( pointerToInfo . getSignednessInfo ( ) , \" is_unsigned \" ) ; <nl> writer . outdent ( ) ; <nl> writer . indents ( ) . appendln ( \" } \" ) ; <nl> } <nl> private void printIsUnsigned ( ElementInfo info , String arg ) { <nl> <nl> } <nl> <nl> - private int tempVarCounter ; <nl> - <nl> - private String getUniqueTempVarName ( ElementInfo info ) { <nl> - tempVarCounter + + ; <nl> - return \" tmp_ \" + info . getName ( ) . replaceAll ( \" \\ \\ W \" , \" _ \" ) + \" _ \" + tempVarCounter ; <nl> - } <nl> - <nl> private static String sizeOf ( ElementInfo element ) { <nl> String elementName = element . getName ( ) ; <nl> / * sizeof ( void ) is undefined and an error on some compilers * / <nl> private static String offsetOfField ( StructFieldInfo field ) { <nl> return \" offsetof ( \" + field . getParent ( ) . getName ( ) + \" , \" + field . getName ( ) + \" ) \" ; <nl> } <nl> <nl> - private static String isUnsigned ( String symbolName ) { <nl> - return \" ISUNSIGNED ( \" + symbolName + \" ) \" ; <nl> - } <nl> - <nl> private static String isConstUnsigned ( String symbolName ) { <nl> - return \" IS_CONST_UNSIGNED ( \" + symbolName + \" ) \" ; <nl> + return \" ( \" + symbolName + \" > = 0 ? 1 : 0 ) \" ; <nl> } <nl> <nl> private void registerElementForCurrentLine ( Object element ) { <nl>\n", "msg": "Remove ISUNSIGNED & IS_CONST_UNSIGNED macros and pointless getUniqueTempVarName\n"}
{"diff_id": 32687, "repo": "elastic/elasticsearch\n", "sha": "611ca3afd9d67699c7b5fb6cf67838e3f311c385\n", "time": "2019-02-12T09:39:18Z\n", "diff": "mmm a / x - pack / plugin / monitoring / src / test / java / org / elasticsearch / xpack / monitoring / MonitoringTestUtils . java <nl> ppp b / x - pack / plugin / monitoring / src / test / java / org / elasticsearch / xpack / monitoring / MonitoringTestUtils . java <nl> <nl> <nl> public final class MonitoringTestUtils { <nl> <nl> + / / maximum number of milliseconds before a five digit year comes in , which could change formatting <nl> + private static final long MAX_MILLIS_BEFORE_10000 = 253402300799999L ; <nl> + <nl> private MonitoringTestUtils ( ) { <nl> } <nl> <nl> private MonitoringTestUtils ( ) { <nl> final String host = fakeTransportAddress . address ( ) . getHostString ( ) ; <nl> final String transportAddress = fakeTransportAddress . toString ( ) ; <nl> final String ip = fakeTransportAddress . getAddress ( ) ; <nl> - final long timestamp = RandomNumbers . randomLongBetween ( random , 0 , Long . MAX_VALUE ) ; <nl> + final long timestamp = RandomNumbers . randomLongBetween ( random , 0 , MAX_MILLIS_BEFORE_10000 ) ; <nl> <nl> return new MonitoringDoc . Node ( id , host , transportAddress , ip , name , timestamp ) ; <nl> } <nl> public static MonitoringBulkDoc randomMonitoringBulkDoc ( final Random random , <nl> final MonitoredSystem system , <nl> final String type ) throws IOException { <nl> final String id = random . nextBoolean ( ) ? RandomStrings . randomAsciiLettersOfLength ( random , 5 ) : null ; <nl> - / / ending date is the last second of 9999 , should be sufficient <nl> - final long timestamp = RandomNumbers . randomLongBetween ( random , 0L , 253402300799000L ) ; <nl> + final long timestamp = RandomNumbers . randomLongBetween ( random , 0L , MAX_MILLIS_BEFORE_10000 ) ; <nl> final long interval = RandomNumbers . randomLongBetween ( random , 0L , Long . MAX_VALUE ) ; <nl> return new MonitoringBulkDoc ( system , type , id , timestamp , interval , source , xContentType ) ; <nl> } <nl>\n", "msg": "Fix exporter tests to have reasonable dates ( )\n"}
{"diff_id": 32723, "repo": "spring-projects/spring-framework\n", "sha": "83293b39df23d91c6ea18f520912c0c4fbb5f1c2\n", "time": "2019-03-27T21:05:38Z\n", "diff": "mmm a / spring - beans / src / main / java / org / springframework / beans / factory / xml / BeanDefinitionParserDelegate . java <nl> ppp b / spring - beans / src / main / java / org / springframework / beans / factory / xml / BeanDefinitionParserDelegate . java <nl> public BeanDefinitionHolder decorateIfRequired ( <nl> return decorated ; <nl> } <nl> } <nl> - else if ( namespaceUri . startsWith ( \" https : / / www . springframework . org / \" ) ) { <nl> + else if ( namespaceUri . startsWith ( \" http : / / www . springframework . org / \" ) ) { <nl> error ( \" Unable to locate Spring NamespaceHandler for XML schema namespace [ \" + namespaceUri + \" ] \" , node ) ; <nl> } <nl> else { <nl>\n", "msg": "URL Cleanup - fix undesirable code change\n"}
{"diff_id": 32738, "repo": "dbeaver/dbeaver\n", "sha": "510e41ab3f66c1239819f624e42d51973e77d71d\n", "time": "2016-11-05T19:51:13Z\n", "diff": "mmm a / plugins / org . jkiss . dbeaver . ext . exasol / src / org / jkiss / dbeaver / ext / exasol / ExasolSQLDialect . java <nl> ppp b / plugins / org . jkiss . dbeaver . ext . exasol / src / org / jkiss / dbeaver / ext / exasol / ExasolSQLDialect . java <nl> <nl> - / * <nl> - * DBeaver - Universal Database Manager <nl> - * Copyright ( C ) 2016 Karl Griesser ( fullref @ gmail . com ) <nl> - * Copyright ( C ) 2010 - 2016 Serge Rieder ( serge @ jkiss . org ) <nl> - * <nl> - * This program is free software ; you can redistribute it and / or modify <nl> - * it under the terms of the GNU General Public License ( version 2 ) <nl> - * as published by the Free Software Foundation . <nl> - * <nl> - * This program is distributed in the hope that it will be useful , <nl> - * but WITHOUT ANY WARRANTY ; without even the implied warranty of <nl> - * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE . See the <nl> - * GNU General Public License for more details . <nl> - * <nl> - * You should have received a copy of the GNU General Public License along <nl> - * with this program ; if not , write to the Free Software Foundation , Inc . , <nl> - * 51 Franklin Street , Fifth Floor , Boston , MA 02110 - 1301 USA . <nl> - * / <nl> - package org . jkiss . dbeaver . ext . exasol ; <nl> - <nl> - import org . jkiss . code . NotNull ; <nl> - import org . jkiss . dbeaver . Log ; <nl> - import org . jkiss . dbeaver . ext . exasol . model . ExasolDataSource ; <nl> - import org . jkiss . dbeaver . model . exec . jdbc . JDBCDatabaseMetaData ; <nl> - import org . jkiss . dbeaver . model . impl . jdbc . JDBCSQLDialect ; <nl> - <nl> - import java . sql . SQLException ; <nl> - <nl> - public class ExasolSQLDialect extends JDBCSQLDialect { <nl> - <nl> - private static final Log LOG = Log . getLog ( ExasolDataSource . class ) ; <nl> - public static final String [ ] EXEC_KEYWORDS = new String [ ] { \" execute script \" } ; <nl> - <nl> - <nl> - public ExasolSQLDialect ( JDBCDatabaseMetaData metaData ) { <nl> - super ( \" Exasol \" , metaData ) ; <nl> - try { <nl> - for ( String kw : metaData . getSQLKeywords ( ) . split ( \" , \" ) ) { <nl> - this . addSQLKeyword ( kw ) ; <nl> - } <nl> - } catch ( SQLException e ) { <nl> - LOG . warn ( \" Could not retrieve reserved keyword list from Exasol dictionary \" ) ; <nl> - } <nl> - <nl> - } <nl> - <nl> - @ NotNull <nl> - @ Override <nl> - public MultiValueInsertMode getMultiValueInsertMode ( ) { <nl> - return MultiValueInsertMode . GROUP_ROWS ; <nl> - } <nl> - <nl> - @ Override <nl> - public boolean supportsAliasInSelect ( ) { <nl> - return true ; <nl> - } <nl> - <nl> - @ NotNull <nl> - @ Override <nl> - public String [ ] getExecuteKeywords ( ) { <nl> - return EXEC_KEYWORDS ; <nl> - } <nl> - <nl> - } <nl> - <nl> + / * <nl> + * DBeaver - Universal Database Manager <nl> + * Copyright ( C ) 2016 Karl Griesser ( fullref @ gmail . com ) <nl> + * Copyright ( C ) 2010 - 2016 Serge Rieder ( serge @ jkiss . org ) <nl> + * <nl> + * This program is free software ; you can redistribute it and / or modify <nl> + * it under the terms of the GNU General Public License ( version 2 ) <nl> + * as published by the Free Software Foundation . <nl> + * <nl> + * This program is distributed in the hope that it will be useful , <nl> + * but WITHOUT ANY WARRANTY ; without even the implied warranty of <nl> + * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE . See the <nl> + * GNU General Public License for more details . <nl> + * <nl> + * You should have received a copy of the GNU General Public License along <nl> + * with this program ; if not , write to the Free Software Foundation , Inc . , <nl> + * 51 Franklin Street , Fifth Floor , Boston , MA 02110 - 1301 USA . <nl> + * / <nl> + package org . jkiss . dbeaver . ext . exasol ; <nl> + <nl> + import org . jkiss . code . NotNull ; <nl> + import org . jkiss . dbeaver . Log ; <nl> + import org . jkiss . dbeaver . ext . exasol . model . ExasolDataSource ; <nl> + import org . jkiss . dbeaver . model . exec . jdbc . JDBCDatabaseMetaData ; <nl> + import org . jkiss . dbeaver . model . impl . jdbc . JDBCSQLDialect ; <nl> + <nl> + import java . sql . SQLException ; <nl> + <nl> + public class ExasolSQLDialect extends JDBCSQLDialect { <nl> + <nl> + private static final Log LOG = Log . getLog ( ExasolDataSource . class ) ; <nl> + <nl> + / / Exasol does not support prepareCall <nl> + public static final String [ ] EXEC_KEYWORDS = new String [ ] { } ; <nl> + <nl> + <nl> + public ExasolSQLDialect ( JDBCDatabaseMetaData metaData ) { <nl> + super ( \" Exasol \" , metaData ) ; <nl> + try { <nl> + for ( String kw : metaData . getSQLKeywords ( ) . split ( \" , \" ) ) { <nl> + this . addSQLKeyword ( kw ) ; <nl> + } <nl> + } catch ( SQLException e ) { <nl> + LOG . warn ( \" Could not retrieve reserved keyword list from Exasol dictionary \" ) ; <nl> + } <nl> + <nl> + } <nl> + <nl> + @ NotNull <nl> + @ Override <nl> + public MultiValueInsertMode getMultiValueInsertMode ( ) { <nl> + return MultiValueInsertMode . GROUP_ROWS ; <nl> + } <nl> + <nl> + @ Override <nl> + public boolean supportsAliasInSelect ( ) { <nl> + return true ; <nl> + } <nl> + <nl> + @ NotNull <nl> + @ Override <nl> + public String [ ] getExecuteKeywords ( ) { <nl> + return new String [ ] { } ; <nl> + } <nl> + <nl> + } <nl> + <nl>\n", "msg": "remove ExecuteKeyword as Exasol has no PrepareCall Statement\n"}
{"diff_id": 32945, "repo": "apache/flink\n", "sha": "b2636247616fe152f85b3afeb03da3fa15689b09\n", "time": "2014-12-05T15:45:08Z\n", "diff": "new file mode 100644 <nl> index 000000000000 . . 81d01a4111cd <nl> mmm / dev / null <nl> ppp b / flink - addons / flink - streaming / flink - streaming - core / src / main / java / org / apache / flink / streaming / api / windowing / deltafunction / ExtractionAwareDeltaFunction . java <nl> <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one or more <nl> + * contributor license agreements . See the NOTICE file distributed with <nl> + * this work for additional information regarding copyright ownership . <nl> + * The ASF licenses this file to You under the Apache License , Version 2 . 0 <nl> + * ( the \" License \" ) ; you may not use this file except in compliance with <nl> + * the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , software <nl> + * distributed under the License is distributed on an \" AS IS \" BASIS , <nl> + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + * See the License for the specific language governing permissions and <nl> + * limitations under the License . <nl> + * / <nl> + <nl> + package org . apache . flink . streaming . api . windowing . deltafunction ; <nl> + <nl> + import org . apache . flink . streaming . api . windowing . extractor . Extractor ; <nl> + <nl> + / * * <nl> + * Extend this abstract class to implement a delta function which is aware of <nl> + * extracting the data on which the delta is calculated from a more complex data <nl> + * structure . For example in case you want to be able to run a delta only on one <nl> + * field of a Tuple type or only on some fields from an array . <nl> + * <nl> + * @ param < DATA > <nl> + * The input data type . The input of this type will be passed to the <nl> + * extractor which will transform into a TO - object . The delta <nl> + * function then runs on this TO - object . <nl> + * @ param < TO > <nl> + * The type on which the delta function runs . ( The type of the delta <nl> + * function ) <nl> + * / <nl> + public abstract class ExtractionAwareDeltaFunction < DATA , TO > implements DeltaFunction < DATA > { <nl> + <nl> + / * * <nl> + * Generated Version ID <nl> + * / <nl> + private static final long serialVersionUID = 6927486219702689554L ; <nl> + private Extractor < DATA , TO > converter ; <nl> + <nl> + public ExtractionAwareDeltaFunction ( Extractor < DATA , TO > converter ) { <nl> + this . converter = converter ; <nl> + } <nl> + <nl> + / * * <nl> + * This method takes the two data point and runs the set extractor on it . <nl> + * The delta function implemented at { @ link getNestedDelta } is then called <nl> + * with the extracted data . In case no extractor is set the input data gets <nl> + * passes to { @ link getNestedDelta } as - is . The return value is just <nl> + * forwarded from { @ link getNestedDelta } . <nl> + * <nl> + * @ param oldDataPoint <nl> + * the older data point as raw data ( before extraction ) . <nl> + * @ param newDataPoint <nl> + * the new data point as raw data ( before extraction ) . <nl> + * @ return the delta between the two points . <nl> + * / <nl> + @ SuppressWarnings ( \" unchecked \" ) <nl> + @ Override <nl> + public double getDelta ( DATA oldDataPoint , DATA newDataPoint ) { <nl> + if ( converter = = null ) { <nl> + / / In case no conversion / extraction is required , we can cast DATA to <nl> + / / TO <nl> + / / = > Therefore , \" unchecked \" warning is suppressed for this method . <nl> + return getNestedDelta ( ( TO ) oldDataPoint , ( TO ) newDataPoint ) ; <nl> + } else { <nl> + return getNestedDelta ( converter . extract ( oldDataPoint ) , converter . extract ( newDataPoint ) ) ; <nl> + } <nl> + <nl> + } <nl> + <nl> + / * * <nl> + * This method is exactly the same as <nl> + * { @ link DeltaFunction # getDelta ( Object , Object ) } except that it gets the <nl> + * result of the previously done extractions as input . Therefore , this <nl> + * method only does the actual calculation of the delta but no data <nl> + * extraction or conversion . <nl> + * <nl> + * @ param oldDataPoint <nl> + * the older data point . <nl> + * @ param newDataPoint <nl> + * the new data point . <nl> + * @ return the delta between the two points . <nl> + * / <nl> + public abstract double getNestedDelta ( TO oldDataPoint , TO newDataPoint ) ; <nl> + <nl> + } <nl>\n", "msg": "[ streaming ] Added abstract class ExtractionAwareDeltaFunction to enable easy extraction of data in pre - defined delta functions .\n"}
{"diff_id": 33046, "repo": "oracle/graal\n", "sha": "e9378039d68d79e0a5f353b5f3bbdfef6bffbc1c\n", "time": "2013-07-08T14:55:28Z\n", "diff": "mmm a / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / CompilationTask . java <nl> ppp b / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / CompilationTask . java <nl> public static CompilationTask create ( HotSpotGraalRuntime graalRuntime , PhasePlan <nl> } <nl> <nl> private CompilationTask ( HotSpotGraalRuntime graalRuntime , PhasePlan plan , OptimisticOptimizations optimisticOpts , HotSpotResolvedJavaMethod method , int entryBCI , int id , int priority ) { <nl> + assert id > = 0 ; <nl> this . graalRuntime = graalRuntime ; <nl> this . plan = plan ; <nl> this . suitesProvider = graalRuntime . getCapability ( SuitesProvider . class ) ; <nl> public ResolvedJavaMethod getMethod ( ) { <nl> return method ; <nl> } <nl> <nl> + public int getId ( ) { <nl> + return id ; <nl> + } <nl> + <nl> public int getPriority ( ) { <nl> return priority ; <nl> } <nl> public int getEntryBCI ( ) { <nl> public void run ( ) { <nl> withinEnqueue . set ( Boolean . FALSE ) ; <nl> try { <nl> - if ( ! tryToChangeStatus ( CompilationStatus . Queued , CompilationStatus . Running ) ) { <nl> - return ; <nl> - } <nl> if ( DynamicCompilePriority . getValue ( ) ) { <nl> int threadPriority = priority < VMToCompilerImpl . SlowQueueCutoff . getValue ( ) ? Thread . NORM_PRIORITY : Thread . MIN_PRIORITY ; <nl> if ( Thread . currentThread ( ) . getPriority ( ) ! = threadPriority ) { <nl> public void run ( ) { <nl> public static final DebugTimer CompilationTime = Debug . timer ( \" CompilationTime \" ) ; <nl> <nl> public void runCompilation ( ) { <nl> + if ( ! tryToChangeStatus ( CompilationStatus . Queued , CompilationStatus . Running ) | | method . hasCompiledCode ( ) ) { <nl> + return ; <nl> + } <nl> + <nl> CompilationStatistics stats = CompilationStatistics . create ( method , entryBCI ! = StructuredGraph . INVOCATION_ENTRY_BCI ) ; <nl> try ( TimerCloseable a = CompilationTime . start ( ) ) { <nl> final boolean printCompilation = PrintCompilation . getValue ( ) & & ! TTY . isSuppressed ( ) ; <nl> private boolean tryToChangeStatus ( CompilationStatus from , CompilationStatus to ) <nl> <nl> @ Override <nl> public int compareTo ( CompilationTask o ) { <nl> - if ( priority < o . priority ) { <nl> - return - 1 ; <nl> - } <nl> - if ( priority > o . priority ) { <nl> - return 1 ; <nl> + if ( priority ! = o . priority ) { <nl> + return priority - o . priority ; <nl> + } else { <nl> + return id - o . id ; <nl> } <nl> - return id < o . id ? - 1 : ( id > o . id ? 1 : 0 ) ; <nl> } <nl> <nl> @ Override <nl>\n", "msg": "Compilation policy fixes and changed default compilation policy .\n"}
{"diff_id": 33265, "repo": "jenkinsci/jenkins\n", "sha": "1c74641e9144d082206eca1f6973c3b90227915d\n", "time": "2015-05-21T11:49:12Z\n", "diff": "mmm a / core / src / main / java / hudson / util / PluginServletFilter . java <nl> ppp b / core / src / main / java / hudson / util / PluginServletFilter . java <nl> public void init ( FilterConfig config ) throws ServletException { <nl> <nl> public static void addFilter ( Filter filter ) throws ServletException { <nl> Jenkins j = Jenkins . getInstance ( ) ; <nl> - if ( j = = null ) { <nl> + / / https : / / marvelution . atlassian . net / browse / JJI - 188 <nl> + if ( j = = null | | getInstance ( j . servletContext ) = = null ) { <nl> / / report who is doing legacy registration <nl> LOGGER . log ( Level . WARNING , \" Filter instance is registered too early : \" + filter , new Exception ( ) ) ; <nl> LEGACY . add ( filter ) ; <nl> public static void addFilter ( Filter filter ) throws ServletException { <nl> <nl> public static void removeFilter ( Filter filter ) throws ServletException { <nl> Jenkins j = Jenkins . getInstance ( ) ; <nl> - if ( j = = null ) { <nl> + if ( j = = null | | getInstance ( j . servletContext ) = = null ) { <nl> LEGACY . remove ( filter ) ; <nl> } else { <nl> getInstance ( j . servletContext ) . list . remove ( filter ) ; <nl>\n", "msg": "* Add a more stable workaround for adding PluginServletFilter when they\n"}
{"diff_id": 33380, "repo": "apache/flink\n", "sha": "dd76c68b14e6191967a3ece98462e19ab9878d04\n", "time": "2011-11-22T11:27:54Z\n", "diff": "mmm a / pact / pact - compiler / src / main / java / eu / stratosphere / pact / compiler / plan / OptimizerNode . java <nl> ppp b / pact / pact - compiler / src / main / java / eu / stratosphere / pact / compiler / plan / OptimizerNode . java <nl> private PactType ( Class < ? extends Contract > clazz ) { <nl> public static PactType getType ( Class < ? extends Contract > pactClass ) { <nl> PactType [ ] values = PactType . values ( ) ; <nl> for ( int i = 0 ; i < values . length ; i + + ) { <nl> - if ( pactClass = = values [ i ] . clazz ) { <nl> + if ( values [ i ] . clazz . isAssignableFrom ( pactClass ) ) { <nl> return values [ i ] ; <nl> } <nl> } <nl>\n", "msg": "Made optimizer able to handle subclass contracts .\n"}
{"diff_id": 33500, "repo": "bazelbuild/bazel\n", "sha": "9a65c351797b455c736b1bf4c380486418c5bac7\n", "time": "2019-03-26T09:25:18Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / skyframe / SkyframeDependencyResolver . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / SkyframeDependencyResolver . java <nl> <nl> import com . google . devtools . build . lib . causes . Cause ; <nl> import com . google . devtools . build . lib . causes . LoadingFailedCause ; <nl> import com . google . devtools . build . lib . cmdline . Label ; <nl> + import com . google . devtools . build . lib . cmdline . PackageIdentifier ; <nl> import com . google . devtools . build . lib . collect . nestedset . NestedSetBuilder ; <nl> import com . google . devtools . build . lib . events . Event ; <nl> import com . google . devtools . build . lib . packages . NoSuchPackageException ; <nl> <nl> import com . google . devtools . build . skyframe . SkyKey ; <nl> import com . google . devtools . build . skyframe . ValueOrException ; <nl> import java . util . HashMap ; <nl> - import java . util . List ; <nl> import java . util . Map ; <nl> - import java . util . stream . Collectors ; <nl> import javax . annotation . Nullable ; <nl> <nl> / * * <nl> private void missingEdgeHook ( <nl> NestedSetBuilder < Cause > rootCauses ) <nl> throws InterruptedException { <nl> <nl> - List < PackageValue . Key > packageKeys = <nl> - labelMap . entries ( ) . stream ( ) <nl> - . map ( e - > e . getValue ( ) . getPackageIdentifier ( ) ) <nl> - . distinct ( ) <nl> - . map ( i - > PackageValue . key ( i ) ) <nl> - . collect ( Collectors . toList ( ) ) ; <nl> + Map < PackageIdentifier , SkyKey > packageKeys = new HashMap < > ( labelMap . size ( ) ) ; <nl> + for ( Label label : labelMap . values ( ) ) { <nl> + packageKeys . computeIfAbsent ( label . getPackageIdentifier ( ) , id - > PackageValue . key ( id ) ) ; <nl> + } <nl> <nl> Map < SkyKey , ValueOrException < NoSuchPackageException > > packages = <nl> - env . getValuesOrThrow ( packageKeys , NoSuchPackageException . class ) ; <nl> + env . getValuesOrThrow ( packageKeys . values ( ) , NoSuchPackageException . class ) ; <nl> <nl> / / As per the comment in SkyFunctionEnvironment . getValueOrUntypedExceptions ( ) , we are supposed <nl> / / to prefer reporting errors to reporting null , we first check for errors in our dependencies . <nl>\n", "msg": "Create less garbage when computing package keys . No functional changes intended .\n"}
{"diff_id": 33547, "repo": "eclipse-vertx/vert.x\n", "sha": "1fefee899a5597a695458e32f1c5f7ca65642c4a\n", "time": "2020-10-08T17:54:38Z\n", "diff": "mmm a / src / main / java / io / vertx / core / net / impl / ConnectionBase . java <nl> ppp b / src / main / java / io / vertx / core / net / impl / ConnectionBase . java <nl> <nl> private Object metric ; <nl> private SocketAddress remoteAddress ; <nl> private SocketAddress localAddress ; <nl> - private Promise < Void > closePromise ; <nl> + private ChannelPromise closePromise ; <nl> + private Future < Void > closeFuture ; <nl> private long remainingBytesRead ; <nl> private long remainingBytesWritten ; <nl> <nl> protected ConnectionBase ( ContextInternal context , ChannelHandlerContext chctx ) { <nl> this . chctx = chctx ; <nl> this . context = context ; <nl> this . voidPromise = new VoidChannelPromise ( chctx . channel ( ) , false ) ; <nl> - this . closePromise = context . promise ( ) ; <nl> + this . closePromise = chctx . newPromise ( ) ; <nl> + <nl> + PromiseInternal < Void > p = context . promise ( ) ; <nl> + closePromise . addListener ( p ) ; <nl> + closeFuture = p . future ( ) ; <nl> <nl> / / Add close handler callback <nl> - closePromise . future ( ) . onComplete ( this : : checkCloseHandler ) ; <nl> + closeFuture . onComplete ( this : : checkCloseHandler ) ; <nl> } <nl> <nl> / * * <nl> * @ return a promise that will be completed when the connection becomes closed <nl> * / <nl> public Future < Void > closeFuture ( ) { <nl> - return closePromise . future ( ) ; <nl> + return closeFuture ; <nl> } <nl> <nl> / * * <nl> protected void handleClosed ( ) { <nl> ( ( TCPMetrics ) metrics ) . disconnected ( metric ( ) , remoteAddress ( ) ) ; <nl> } <nl> } <nl> - closePromise . complete ( ) ; <nl> + closePromise . setSuccess ( ) ; <nl> } <nl> <nl> private void checkCloseHandler ( AsyncResult < Void > ar ) { <nl>\n", "msg": "Use a Netty promise for the ConnectionBase promise instead of a Vert . x promise\n"}
{"diff_id": 33563, "repo": "elastic/elasticsearch\n", "sha": "91d17892581e1df067e7fbdb8f760ae220554dbc\n", "time": "2015-07-27T08:39:04Z\n", "diff": "mmm a / core / src / test / java / org / elasticsearch / search / aggregations / bucket / IPv4RangeTests . java <nl> ppp b / core / src / test / java / org / elasticsearch / search / aggregations / bucket / IPv4RangeTests . java <nl> <nl> import org . elasticsearch . search . aggregations . bucket . histogram . Histogram ; <nl> import org . elasticsearch . search . aggregations . bucket . range . Range ; <nl> import org . elasticsearch . search . aggregations . bucket . range . Range . Bucket ; <nl> - import org . elasticsearch . search . aggregations . bucket . range . ipv4 . IPv4RangeBuilder ; <nl> import org . elasticsearch . search . aggregations . metrics . max . Max ; <nl> import org . elasticsearch . search . aggregations . metrics . sum . Sum ; <nl> import org . elasticsearch . test . ElasticsearchIntegrationTest ; <nl> public void setupSuiteScopeCluster ( ) throws Exception { <nl> } <nl> indexRandom ( true , builders . toArray ( new IndexRequestBuilder [ builders . size ( ) ] ) ) ; <nl> } <nl> + { <nl> + assertAcked ( prepareCreate ( \" range_idx \" ) <nl> + . addMapping ( \" type \" , \" ip \" , \" type = ip \" , \" ips \" , \" type = ip \" ) ) ; <nl> + IndexRequestBuilder [ ] builders = new IndexRequestBuilder [ 4 ] ; <nl> + <nl> + builders [ 0 ] = client ( ) . prepareIndex ( \" range_idx \" , \" type \" ) . setSource ( jsonBuilder ( ) <nl> + . startObject ( ) <nl> + . field ( \" ip \" , \" 0 . 0 . 0 . 0 \" ) <nl> + . endObject ( ) ) ; <nl> + <nl> + builders [ 1 ] = client ( ) . prepareIndex ( \" range_idx \" , \" type \" ) . setSource ( jsonBuilder ( ) <nl> + . startObject ( ) <nl> + . field ( \" ip \" , \" 0 . 0 . 0 . 255 \" ) <nl> + . endObject ( ) ) ; <nl> + <nl> + builders [ 2 ] = client ( ) . prepareIndex ( \" range_idx \" , \" type \" ) . setSource ( jsonBuilder ( ) <nl> + . startObject ( ) <nl> + . field ( \" ip \" , \" 255 . 255 . 255 . 0 \" ) <nl> + . endObject ( ) ) ; <nl> + <nl> + builders [ 3 ] = client ( ) . prepareIndex ( \" range_idx \" , \" type \" ) . setSource ( jsonBuilder ( ) <nl> + . startObject ( ) <nl> + . field ( \" ip \" , \" 255 . 255 . 255 . 255 \" ) <nl> + . endObject ( ) ) ; <nl> + <nl> + indexRandom ( true , builders ) ; <nl> + } <nl> ensureSearchable ( ) ; <nl> } <nl> <nl> public void mask0 ( ) { <nl> <nl> <nl> @ Test <nl> - public void mask0SpecialIps ( ) throws Exception { <nl> - assertAcked ( prepareCreate ( \" idx_range \" ) <nl> - . addMapping ( \" type \" , \" ip \" , \" type = ip \" , \" ips \" , \" type = ip \" ) ) ; <nl> - IndexRequestBuilder [ ] builders = new IndexRequestBuilder [ 4 ] ; <nl> - <nl> - builders [ 0 ] = client ( ) . prepareIndex ( \" idx_range \" , \" type \" ) . setSource ( jsonBuilder ( ) <nl> - . startObject ( ) <nl> - . field ( \" ip \" , \" 0 . 0 . 0 . 0 \" ) <nl> - . endObject ( ) ) ; <nl> - <nl> - builders [ 1 ] = client ( ) . prepareIndex ( \" idx_range \" , \" type \" ) . setSource ( jsonBuilder ( ) <nl> - . startObject ( ) <nl> - . field ( \" ip \" , \" 0 . 0 . 0 . 255 \" ) <nl> - . endObject ( ) ) ; <nl> - <nl> - builders [ 2 ] = client ( ) . prepareIndex ( \" idx_range \" , \" type \" ) . setSource ( jsonBuilder ( ) <nl> - . startObject ( ) <nl> - . field ( \" ip \" , \" 255 . 255 . 255 . 0 \" ) <nl> - . endObject ( ) ) ; <nl> - <nl> - builders [ 3 ] = client ( ) . prepareIndex ( \" idx_range \" , \" type \" ) . setSource ( jsonBuilder ( ) <nl> - . startObject ( ) <nl> - . field ( \" ip \" , \" 255 . 255 . 255 . 255 \" ) <nl> - . endObject ( ) ) ; <nl> - <nl> - indexRandom ( true , builders ) ; <nl> - ensureSearchable ( ) ; <nl> + public void mask0SpecialIps ( ) { <nl> <nl> - SearchResponse response = client ( ) . prepareSearch ( \" idx_range \" ) <nl> + SearchResponse response = client ( ) . prepareSearch ( \" range_idx \" ) <nl> . addAggregation ( ipRange ( \" range \" ) <nl> . field ( \" ip \" ) <nl> . addMaskRange ( \" 0 . 0 . 0 . 0 / 0 \" ) ) <nl>\n", "msg": "Move index creation to test setup method\n"}
{"diff_id": 33625, "repo": "elastic/elasticsearch\n", "sha": "2ca3433beac19584f2170789d09937d50de077d7\n", "time": "2016-01-28T08:56:06Z\n", "diff": "mmm a / core / src / main / java / org / elasticsearch / transport / local / LocalTransport . java <nl> ppp b / core / src / main / java / org / elasticsearch / transport / local / LocalTransport . java <nl> public void sendRequest ( final DiscoveryNode node , final long requestId , final St <nl> transportServiceAdapter . sent ( data . length ) ; <nl> transportServiceAdapter . onRequestSent ( node , requestId , action , request , options ) ; <nl> targetTransport . workers ( ) . execute ( ( ) - > { <nl> - ThreadContext threadContext = threadPool . getThreadContext ( ) ; <nl> + ThreadContext threadContext = targetTransport . threadPool . getThreadContext ( ) ; <nl> try ( ThreadContext . StoredContext context = threadContext . stashContext ( ) ) { <nl> targetTransport . messageReceived ( data , action , LocalTransport . this , version , requestId ) ; <nl> } <nl>\n", "msg": "Use targetTransport . threadPool to stash context not the local one\n"}
{"diff_id": 33906, "repo": "oracle/graal\n", "sha": "487759f848cb25889eb1482d4d3bd969390c0bb7\n", "time": "2017-02-13T19:58:18Z\n", "diff": "mmm a / graal / org . graalvm . compiler . printer / src / org / graalvm / compiler / printer / GraalDebugConfigCustomizer . java <nl> ppp b / graal / org . graalvm . compiler . printer / src / org / graalvm / compiler / printer / GraalDebugConfigCustomizer . java <nl> private static GraphPrinter createNetworkPrinter ( OptionValues options ) throws IO <nl> * / <nl> return null ; <nl> } catch ( IOException e ) { <nl> - throw new IOException ( String . format ( \" Could not connect to the IGV on % s : % d \" , host , port ) , e ) ; <nl> + if ( ! Options . PrintIdealGraphFile . hasBeenSet ( options ) ) { <nl> + TTY . println ( String . format ( \" Could not connect to the IGV on % s : % d - falling back to file dumping . . . \" , host , port ) ) ; <nl> + return createFilePrinter ( options ) ; <nl> + } else { <nl> + throw new IOException ( String . format ( \" Could not connect to the IGV on % s : % d \" , host , port ) , e ) ; <nl> + } <nl> } <nl> } <nl> <nl>\n", "msg": "automatically fall back to dumping graphs to files when IGV is unavailable / unreachable\n"}
{"diff_id": 34054, "repo": "oracle/graal\n", "sha": "fcb710607181988c638066624d96b33148990c8a\n", "time": "2015-07-08T09:49:59Z\n", "diff": "mmm a / truffle / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / LanguageRegistrationProcessor . java <nl> ppp b / truffle / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / LanguageRegistrationProcessor . java <nl> <nl> import com . oracle . truffle . api . * ; <nl> import com . oracle . truffle . api . TruffleLanguage . Registration ; <nl> <nl> - @ SupportedAnnotationTypes ( \" com . oracle . truffle . api . * \" ) <nl> + @ SupportedAnnotationTypes ( \" com . oracle . truffle . api . TruffleLanguage . Registration \" ) <nl> public final class LanguageRegistrationProcessor extends AbstractProcessor { <nl> private final List < TypeElement > registrations = new ArrayList < > ( ) ; <nl> <nl>\n", "msg": "Restrict LanguageRegistrationProcessor to process Registration annotation . \\ nFixes problems where it would consume DSL annotations .\n"}
{"diff_id": 34259, "repo": "bumptech/glide\n", "sha": "a1ae214c0236c35034e6f88185d96490b4eeac32\n", "time": "2017-09-19T18:23:17Z\n", "diff": "mmm a / library / src / main / java / com / bumptech / glide / RequestBuilder . java <nl> ppp b / library / src / main / java / com / bumptech / glide / RequestBuilder . java <nl> private Request buildRequestRecursive ( Target < TranscodeType > target , <nl> thumbPriority , <nl> thumbOverrideWidth , <nl> thumbOverrideHeight , <nl> - requestOptions ) ; <nl> + thumbnailBuilder . requestOptions ) ; <nl> isThumbnailBuilt = false ; <nl> coordinator . setRequests ( fullRequest , thumbRequest ) ; <nl> return coordinator ; <nl>\n", "msg": "Use the thumb builder  s RequestOptions when building the thumb request .\n"}
{"diff_id": 34929, "repo": "SeleniumHQ/selenium\n", "sha": "c57bf8f5fc78a2f54b0e77714d474f1a0c4055f6\n", "time": "2007-10-19T22:36:58Z\n", "diff": "mmm a / firefox / src / java / com / thoughtworks / webdriver / firefox / FirefoxLauncher . java <nl> ppp b / firefox / src / java / com / thoughtworks / webdriver / firefox / FirefoxLauncher . java <nl> public void createBaseWebDriverProfile ( String profileName ) { <nl> / / If there ' s a browser already running <nl> connectAndKill ( ) ; <nl> <nl> - <nl> File firefox = locateFirefoxBinary ( null ) ; <nl> <nl> System . out . println ( MessageFormat . format ( \" Creating { 0 } \" , profileName ) ) ; <nl> public void createBaseWebDriverProfile ( String profileName ) { <nl> System . out . println ( \" Deleting existing extensions cache ( if it already exists ) \" ) ; <nl> deleteExtensionsCacheIfItExists ( extensionsDir ) ; <nl> <nl> - System . out . println ( MessageFormat . format ( \" Firefox should now start and then quit . \\ n \\ n \" + <nl> - \" Once this has happened , please run firefox using : \\ n \\ n { 0 } - P { 1 } \\ n \\ n \" + <nl> - \" and go to the \\ \" Tools - > Add - ons \\ \" menu and confirm that an add - on called \\ \" Firefox WebDriver \\ \" has been \" + <nl> + System . out . println ( MessageFormat . format ( \" Firefox should now start . \\ n \\ n \" + <nl> + \" Please go to the \\ \" Tools - > Add - ons \\ \" menu and confirm that an add - on called \\ \" Firefox WebDriver \\ \" has been \" + <nl> \" successfully installed . \\ n \\ nIf this is not present , please quit all open instances of Firefox . \\ n \" , <nl> firefox . getAbsolutePath ( ) , profileName ) ) ; <nl> <nl> - File extensionsCache = new File ( extensionsDir , \" extensions . cache \" ) ; <nl> startFirefox ( firefox , profileName ) ; <nl> - <nl> - long until = System . currentTimeMillis ( ) + ( 30 * 1000 ) ; <nl> - while ( System . currentTimeMillis ( ) < until & & ! extensionsCache . exists ( ) ) { <nl> - wait ( 2 ) ; <nl> - } <nl> - <nl> - System . out . println ( \" Quitting \" ) ; <nl> - <nl> - connectAndKill ( ) ; <nl> } <nl> <nl> private void connectAndKill ( ) { <nl> private void connectAndKill ( ) { <nl> <nl> private void startFirefox ( File firefox , String profileName ) { <nl> try { <nl> - Runtime runtime = Runtime . getRuntime ( ) ; <nl> - Process process = runtime . exec ( new String [ ] { firefox . getAbsolutePath ( ) , \" - P \" , profileName } , new String [ ] { \" MOZ_NO_REMOTE = 1 \" } ) ; <nl> - process . waitFor ( ) ; <nl> + ProcessBuilder builder = new ProcessBuilder ( firefox . getAbsolutePath ( ) , \" - P \" , profileName ) . redirectErrorStream ( true ) ; <nl> + builder . environment ( ) . put ( \" MOZ_NO_REMOTE \" , \" 1 \" ) ; <nl> + Process process = builder . start ( ) ; <nl> } catch ( IOException e ) { <nl> throw new RuntimeException ( e ) ; <nl> - } catch ( InterruptedException e ) { <nl> - throw new RuntimeException ( e ) ; <nl> } <nl> } <nl> <nl> private void writeNewPrefs ( File userPrefs , Map < String , String > prefs ) { <nl> } <nl> } <nl> <nl> - / / Assumes that the prefs file is untouched by people . <nl> + / / Assumes that we only really care about the preferences , not the comments <nl> private Map < String , String > readExistingPrefs ( File userPrefs ) { <nl> Map < String , String > prefs = new HashMap < String , String > ( ) ; <nl> + <nl> BufferedReader reader = null ; <nl> try { <nl> reader = new BufferedReader ( new FileReader ( userPrefs ) ) ; <nl> String line = reader . readLine ( ) ; <nl> while ( line ! = null ) { <nl> if ( ! line . startsWith ( \" user_pref ( \\ \" \" ) ) { <nl> - line = reader . readLine ( ) ; <nl> + line = reader . readLine ( ) ; <nl> continue ; <nl> } <nl> line = line . substring ( \" user_pref ( \\ \" \" . length ( ) ) ; <nl> private void writeNewPrefs ( File userPrefs , Map < String , String > prefs ) { <nl> String [ ] parts = line . split ( \" , \" ) ; <nl> prefs . put ( parts [ 0 ] . trim ( ) , parts [ 1 ] . trim ( ) ) ; <nl> <nl> - line = reader . readLine ( ) ; <nl> + line = reader . readLine ( ) ; <nl> } <nl> } catch ( IOException e ) { <nl> throw new RuntimeException ( e ) ; <nl> public void startProfile ( String profileName , File firefoxBinary ) { <nl> try { <nl> File profileDir = createCopyOfDefaultProfile ( profileName ) ; <nl> <nl> - Runtime runtime = Runtime . getRuntime ( ) ; <nl> - runtime . exec ( new String [ ] { binary . getAbsolutePath ( ) , \" - Profile \" , profileDir . getAbsolutePath ( ) } , new String [ ] { \" MOZ_NO_REMOTE = 1 \" } ) ; <nl> + ProcessBuilder builder = new ProcessBuilder ( binary . getAbsolutePath ( ) , \" - profile \" , profileDir . getAbsolutePath ( ) ) . redirectErrorStream ( true ) ; <nl> + builder . environment ( ) . put ( \" MOZ_NO_REMOTE \" , \" 1 \" ) ; <nl> + builder . start ( ) ; <nl> } catch ( IOException e ) { <nl> throw new RuntimeException ( \" Cannot load firefox : \" + profileName ) ; <nl> } <nl>\n", "msg": "SimonStewart : More relable starting of the initial firefox profile . Using user . js for firefox specific settings\n"}
{"diff_id": 35029, "repo": "jenkinsci/jenkins\n", "sha": "89b1545e58ab176be4cf717012c86138fc109dc0\n", "time": "2014-04-01T23:50:05Z\n", "diff": "mmm a / core / src / main / java / jenkins / slaves / restarter / JnlpSlaveRestarterInstaller . java <nl> ppp b / core / src / main / java / jenkins / slaves / restarter / JnlpSlaveRestarterInstaller . java <nl> public void onOnline ( final Computer c , final TaskListener listener ) throws IOExc <nl> MasterComputer . threadPoolForRemoting . submit ( new java . util . concurrent . Callable < Void > ( ) { <nl> @ Override <nl> public Void call ( ) throws Exception { <nl> - try { <nl> - final List < SlaveRestarter > restarters = new ArrayList < SlaveRestarter > ( SlaveRestarter . all ( ) ) ; <nl> + install ( c , listener ) ; <nl> + return null ; <nl> + } <nl> + } ) ; <nl> + } <nl> <nl> - VirtualChannel ch = c . getChannel ( ) ; <nl> - if ( ch = = null ) return null ; / / defensive check <nl> + private void install ( Computer c , TaskListener listener ) { <nl> + try { <nl> + final List < SlaveRestarter > restarters = new ArrayList < SlaveRestarter > ( SlaveRestarter . all ( ) ) ; <nl> <nl> - List < SlaveRestarter > effective = ch . call ( new Callable < List < SlaveRestarter > , IOException > ( ) { <nl> - public List < SlaveRestarter > call ( ) throws IOException { <nl> - Engine e = Engine . current ( ) ; <nl> - if ( e = = null ) return null ; / / not running under Engine <nl> + VirtualChannel ch = c . getChannel ( ) ; <nl> + if ( ch = = null ) return ; / / defensive check <nl> <nl> - try { <nl> - Engine . class . getMethod ( \" addListener \" , EngineListener . class ) ; <nl> - } catch ( NoSuchMethodException _ ) { <nl> - return null ; / / running with older version of remoting that doesn ' t support adding listener <nl> - } <nl> + List < SlaveRestarter > effective = ch . call ( new Callable < List < SlaveRestarter > , IOException > ( ) { <nl> + public List < SlaveRestarter > call ( ) throws IOException { <nl> + Engine e = Engine . current ( ) ; <nl> + if ( e = = null ) return null ; / / not running under Engine <nl> <nl> - / / filter out ones that doesn ' t apply <nl> - for ( Iterator < SlaveRestarter > itr = restarters . iterator ( ) ; itr . hasNext ( ) ; ) { <nl> - SlaveRestarter r = itr . next ( ) ; <nl> - if ( ! r . canWork ( ) ) <nl> - itr . remove ( ) ; <nl> - } <nl> + try { <nl> + Engine . class . getMethod ( \" addListener \" , EngineListener . class ) ; <nl> + } catch ( NoSuchMethodException _ ) { <nl> + return null ; / / running with older version of remoting that doesn ' t support adding listener <nl> + } <nl> + <nl> + / / filter out ones that doesn ' t apply <nl> + for ( Iterator < SlaveRestarter > itr = restarters . iterator ( ) ; itr . hasNext ( ) ; ) { <nl> + SlaveRestarter r = itr . next ( ) ; <nl> + if ( ! r . canWork ( ) ) <nl> + itr . remove ( ) ; <nl> + } <nl> <nl> - e . addListener ( new EngineListenerAdapter ( ) { <nl> - @ Override <nl> - public void onDisconnect ( ) { <nl> + e . addListener ( new EngineListenerAdapter ( ) { <nl> + @ Override <nl> + public void onDisconnect ( ) { <nl> + try { <nl> + for ( SlaveRestarter r : restarters ) { <nl> try { <nl> - for ( SlaveRestarter r : restarters ) { <nl> - try { <nl> - LOGGER . info ( \" Restarting slave via \" + r ) ; <nl> - r . restart ( ) ; <nl> - } catch ( Exception x ) { <nl> - LOGGER . log ( SEVERE , \" Failed to restart slave with \" + r , x ) ; <nl> - } <nl> - } <nl> - } finally { <nl> - / / if we move on to the reconnection without restart , <nl> - / / don ' t let the current implementations kick in when the slave loses connection again <nl> - restarters . clear ( ) ; <nl> + LOGGER . info ( \" Restarting slave via \" + r ) ; <nl> + r . restart ( ) ; <nl> + } catch ( Exception x ) { <nl> + LOGGER . log ( SEVERE , \" Failed to restart slave with \" + r , x ) ; <nl> } <nl> } <nl> - } ) ; <nl> - <nl> - return restarters ; <nl> + } finally { <nl> + / / if we move on to the reconnection without restart , <nl> + / / don ' t let the current implementations kick in when the slave loses connection again <nl> + restarters . clear ( ) ; <nl> + } <nl> } <nl> } ) ; <nl> <nl> - / / TODO : report this to GUI <nl> - listener . getLogger ( ) . println ( \" Effective SlaveRestarter on \" + c . getDisplayName ( ) + \" : \" + effective ) ; <nl> - } catch ( Throwable e ) { <nl> - e . printStackTrace ( listener . error ( \" Failed to install restarter \" ) ) ; <nl> + return restarters ; <nl> } <nl> - return null ; <nl> - } <nl> - } ) ; <nl> + } ) ; <nl> + <nl> + listener . getLogger ( ) . println ( \" Effective SlaveRestarter on \" + c . getDisplayName ( ) + \" : \" + effective ) ; <nl> + } catch ( Throwable e ) { <nl> + e . printStackTrace ( listener . error ( \" Failed to install restarter \" ) ) ; <nl> + } <nl> } <nl> <nl> private static final Logger LOGGER = Logger . getLogger ( JnlpSlaveRestarterInstaller . class . getName ( ) ) ; <nl>\n", "msg": "moved to a separate function to reduce the serialization footprint\n"}
{"diff_id": 35093, "repo": "jenkinsci/jenkins\n", "sha": "9e86629c76b2c8772cb955d5b5ca66296df3b83f\n", "time": "2012-09-17T23:18:08Z\n", "diff": "mmm a / core / src / main / java / jenkins / model / lazy / AbstractLazyLoadRunMap . java <nl> ppp b / core / src / main / java / jenkins / model / lazy / AbstractLazyLoadRunMap . java <nl> <nl> * This implementation is in 2 states . An instance can be { @ linkplain # fullyLoaded fully loaded } state , <nl> * where everything that can be loaded gets loaded . Otherwise it ' s in a partially loaded state . <nl> * <nl> + * < p > <nl> + * Object lock of { @ code this } is used to make sure mutation occurs sequentially . <nl> + * That is , ensure that only one thread is actually calling { @ link # retrieve ( File ) } and <nl> + * updating { @ link # byNumber } and { @ link # byId } . <nl> + * <nl> * @ author Kohsuke Kawaguchi <nl> * / <nl> public abstract class AbstractLazyLoadRunMap < R > extends AbstractMap < Integer , R > implements SortedMap < Integer , R > { <nl> <nl> * / <nl> private File dir ; <nl> <nl> - / * * <nl> - * Used to ensure only one thread is actually calling { @ link # retrieve ( File ) } and <nl> - * updating { @ link # byNumber } and { @ link # byId } . <nl> - * / <nl> - private final Object loadLock = this ; <nl> - <nl> protected AbstractLazyLoadRunMap ( File dir ) { <nl> this . dir = dir ; <nl> initBaseDir ( dir ) ; <nl> public R put ( R value ) { <nl> } <nl> <nl> @ Override <nl> - public R put ( Integer key , R r ) { <nl> - synchronized ( loadLock ) { <nl> - copy ( ) ; <nl> - R old = byId . put ( getIdOf ( r ) , r ) ; <nl> - byNumber . put ( getNumberOf ( r ) , r ) ; <nl> - return old ; <nl> - } <nl> + public synchronized R put ( Integer key , R r ) { <nl> + copy ( ) ; <nl> + R old = byId . put ( getIdOf ( r ) , r ) ; <nl> + byNumber . put ( getNumberOf ( r ) , r ) ; <nl> + return old ; <nl> } <nl> <nl> @ Override <nl> - public void putAll ( Map < ? extends Integer , ? extends R > rhs ) { <nl> - synchronized ( loadLock ) { <nl> - copy ( ) ; <nl> - for ( R r : rhs . values ( ) ) { <nl> - byId . put ( getIdOf ( r ) , r ) ; <nl> - byNumber . put ( getNumberOf ( r ) , r ) ; <nl> - } <nl> + public synchronized void putAll ( Map < ? extends Integer , ? extends R > rhs ) { <nl> + copy ( ) ; <nl> + for ( R r : rhs . values ( ) ) { <nl> + byId . put ( getIdOf ( r ) , r ) ; <nl> + byNumber . put ( getNumberOf ( r ) , r ) ; <nl> } <nl> } <nl> <nl> public void putAll ( Map < ? extends Integer , ? extends R > rhs ) { <nl> * / <nl> private TreeMap < Integer , R > all ( ) { <nl> if ( ! fullyLoaded ) { <nl> - synchronized ( loadLock ) { <nl> + synchronized ( this ) { <nl> if ( ! fullyLoaded ) { <nl> copy ( ) ; <nl> for ( String id : idOnDisk ) { <nl> protected R load ( int n , boolean copy ) { <nl> R r = null ; <nl> File shortcut = new File ( dir , String . valueOf ( n ) ) ; <nl> if ( shortcut . isDirectory ( ) ) { <nl> - synchronized ( loadLock ) { <nl> + synchronized ( this ) { <nl> r = load ( shortcut , copy ) ; <nl> <nl> / / make sure what we actually loaded is # n , <nl> protected R load ( String id , boolean copy ) { <nl> return load ( new File ( dir , id ) , copy ) ; <nl> } <nl> <nl> - protected R load ( File dataDir , boolean copy ) { <nl> - synchronized ( loadLock ) { <nl> - try { <nl> - R r = retrieve ( dataDir ) ; <nl> - if ( r = = null ) return null ; <nl> - <nl> - if ( copy ) copy ( ) ; <nl> - byId . put ( getIdOf ( r ) , r ) ; <nl> - byNumber . put ( getNumberOf ( r ) , r ) ; <nl> - return r ; <nl> - } catch ( IOException e ) { <nl> - LOGGER . log ( Level . WARNING , \" Failed to load \" + dataDir , e ) ; <nl> - } <nl> - return null ; <nl> + protected synchronized R load ( File dataDir , boolean copy ) { <nl> + try { <nl> + R r = retrieve ( dataDir ) ; <nl> + if ( r = = null ) return null ; <nl> + <nl> + if ( copy ) copy ( ) ; <nl> + byId . put ( getIdOf ( r ) , r ) ; <nl> + byNumber . put ( getNumberOf ( r ) , r ) ; <nl> + return r ; <nl> + } catch ( IOException e ) { <nl> + LOGGER . log ( Level . WARNING , \" Failed to load \" + dataDir , e ) ; <nl> } <nl> + return null ; <nl> } <nl> <nl> protected abstract int getNumberOf ( R r ) ; <nl> protected R load ( File dataDir , boolean copy ) { <nl> * / <nl> protected abstract R retrieve ( File dir ) throws IOException ; <nl> <nl> - public boolean remove ( R run ) { <nl> - synchronized ( loadLock ) { <nl> - copy ( ) ; <nl> - byNumber . remove ( getNumberOf ( run ) ) ; <nl> - R old = byId . remove ( getIdOf ( run ) ) ; <nl> - return old ! = null ; <nl> - } <nl> + public synchronized boolean remove ( R run ) { <nl> + copy ( ) ; <nl> + byNumber . remove ( getNumberOf ( run ) ) ; <nl> + R old = byId . remove ( getIdOf ( run ) ) ; <nl> + return old ! = null ; <nl> } <nl> <nl> + / * * <nl> + * Replaces all the current loaded Rs with the given ones . <nl> + * / <nl> + public synchronized void reset ( TreeMap < Integer , R > builds ) { <nl> + TreeMap < Integer , R > byNumber = new TreeMap < Integer , R > ( builds ) ; <nl> + TreeMap < String , R > byId = new TreeMap < String , R > ( ) ; <nl> + for ( R r : builds . values ( ) ) { <nl> + byId . put ( getIdOf ( r ) , r ) ; <nl> + } <nl> + <nl> + this . byNumber = byNumber ; <nl> + this . byId = byId ; <nl> + } <nl> <nl> @ Override <nl> public int hashCode ( ) { <nl>\n", "msg": "Use ' this ' as a lock to remain compatible with RunMap\n"}
{"diff_id": 35166, "repo": "bazelbuild/bazel\n", "sha": "c3143bbed207fb316866f938676878eae31f121a\n", "time": "2020-03-31T11:47:21Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / bazel / rules / BazelStrategyModule . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / bazel / rules / BazelStrategyModule . java <nl> <nl> import com . google . devtools . build . lib . analysis . actions . TemplateExpansionContext ; <nl> import com . google . devtools . build . lib . buildtool . BuildRequest ; <nl> import com . google . devtools . build . lib . exec . ExecutionOptions ; <nl> - import com . google . devtools . build . lib . exec . ExecutorBuilder ; <nl> + import com . google . devtools . build . lib . exec . ModuleActionContextRegistry ; <nl> import com . google . devtools . build . lib . exec . SpawnCache ; <nl> + import com . google . devtools . build . lib . exec . SpawnStrategyRegistry ; <nl> import com . google . devtools . build . lib . remote . RemoteModule ; <nl> import com . google . devtools . build . lib . remote . options . RemoteOptions ; <nl> import com . google . devtools . build . lib . rules . cpp . CppIncludeExtractionContext ; <nl> <nl> } <nl> <nl> @ Override <nl> - public void executorInit ( CommandEnvironment env , BuildRequest request , ExecutorBuilder builder ) { <nl> + public void registerActionContexts ( <nl> + ModuleActionContextRegistry . Builder registryBuilder , <nl> + CommandEnvironment env , <nl> + BuildRequest buildRequest ) { <nl> + registryBuilder <nl> + . restrictTo ( CppIncludeExtractionContext . class , \" \" ) <nl> + . restrictTo ( CppIncludeScanningContext . class , \" \" ) <nl> + . restrictTo ( FileWriteActionContext . class , \" \" ) <nl> + . restrictTo ( TemplateExpansionContext . class , \" \" ) <nl> + . restrictTo ( SpawnCache . class , \" \" ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public void registerSpawnStrategies ( <nl> + SpawnStrategyRegistry . Builder registryBuilder , CommandEnvironment env ) { <nl> ExecutionOptions options = env . getOptions ( ) . getOptions ( ExecutionOptions . class ) ; <nl> RemoteOptions remoteOptions = env . getOptions ( ) . getOptions ( RemoteOptions . class ) ; <nl> <nl> public void executorInit ( CommandEnvironment env , BuildRequest request , ExecutorB <nl> } <nl> spawnStrategies . add ( \" local \" ) ; <nl> } <nl> + registryBuilder . setDefaultStrategies ( spawnStrategies ) ; <nl> <nl> - / / Allow genrule_strategy to also be overridden by - - strategy = flags . <nl> - builder . addStrategyByMnemonic ( \" Genrule \" , options . genruleStrategy ) ; <nl> + / / By adding this filter before the ones derived from - - strategy the latter can override the <nl> + / / former . <nl> + registryBuilder . addMnemonicFilter ( \" Genrule \" , options . genruleStrategy ) ; <nl> <nl> for ( Map . Entry < String , List < String > > strategy : options . strategy ) { <nl> - builder . addStrategyByMnemonic ( strategy . getKey ( ) , strategy . getValue ( ) ) ; <nl> + registryBuilder . addMnemonicFilter ( strategy . getKey ( ) , strategy . getValue ( ) ) ; <nl> } <nl> <nl> - builder . addStrategyByMnemonic ( \" \" , spawnStrategies ) ; <nl> - <nl> for ( Map . Entry < RegexFilter , List < String > > entry : options . strategyByRegexp ) { <nl> - builder . addStrategyByRegexp ( entry . getKey ( ) , entry . getValue ( ) ) ; <nl> + registryBuilder . addDescriptionFilter ( entry . getKey ( ) , entry . getValue ( ) ) ; <nl> } <nl> - <nl> - builder <nl> - . addStrategyByContext ( CppIncludeExtractionContext . class , \" \" ) <nl> - . addStrategyByContext ( CppIncludeScanningContext . class , \" \" ) <nl> - . addStrategyByContext ( FileWriteActionContext . class , \" \" ) <nl> - . addStrategyByContext ( TemplateExpansionContext . class , \" \" ) <nl> - . addStrategyByContext ( SpawnCache . class , \" \" ) ; <nl> } <nl> } <nl>\n", "msg": "Update BazelStrategyModule to use registry methods instead of executorInit where possible .\n"}
{"diff_id": 35443, "repo": "material-components/material-components-android\n", "sha": "633b5a32c27107eb07a85fe435ef63afa5b4674a\n", "time": "2019-06-18T17:52:05Z\n", "diff": "new file mode 100644 <nl> index 000000000 . . fa18a20c6 <nl> mmm / dev / null <nl> ppp b / lib / java / com / google / android / material / ripple / RippleDrawableCompat . java <nl> <nl> + / * <nl> + * Copyright 2019 The Android Open Source Project <nl> + * <nl> + * Licensed under the Apache License , Version 2 . 0 ( the \" License \" ) ; <nl> + * you may not use this file except in compliance with the License . <nl> + * You may obtain a copy of the License at <nl> + * <nl> + * https : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , software <nl> + * distributed under the License is distributed on an \" AS IS \" BASIS , <nl> + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + * See the License for the specific language governing permissions and <nl> + * limitations under the License . <nl> + * / <nl> + <nl> + package com . google . android . material . ripple ; <nl> + <nl> + import android . graphics . Canvas ; <nl> + import androidx . annotation . RestrictTo ; <nl> + import androidx . annotation . RestrictTo . Scope ; <nl> + import com . google . android . material . shape . MaterialShapeDrawable ; <nl> + import com . google . android . material . shape . ShapeAppearanceModel ; <nl> + <nl> + / * * <nl> + * A compat { @ link android . graphics . drawable . Drawable } to be used pre - Lollipop for drawing an <nl> + * overlay on top of a background for pressed , focused , and hovered states . <nl> + * <nl> + * < p > This Drawable is a { @ link MaterialShapeDrawable } so that it can be shaped to match a <nl> + * MaterialShapeDrawable background . <nl> + * <nl> + * < p > Unlike the framework { @ link android . graphics . drawable . RippleDrawable } , this will < b > not < / b > <nl> + * apply different alphas for pressed , focused , and hovered states and it does not provide a ripple <nl> + * animation for the pressed state . <nl> + * / <nl> + @ RestrictTo ( Scope . LIBRARY_GROUP ) <nl> + public class RippleDrawableCompat extends MaterialShapeDrawable { <nl> + <nl> + / * * <nl> + * Whether this compat ripple should be drawn . True when enabled and ( pressed , focused , or <nl> + * enabled ) . <nl> + * / <nl> + private boolean shouldDrawRipple = false ; <nl> + <nl> + / * * <nl> + * Creates a { @ link RippleDrawableCompat } with the given shape . <nl> + * <nl> + * @ param shapeAppearanceModel the { @ link ShapeAppearanceModel } containing the path that will be <nl> + * rendered in this drawable . <nl> + * / <nl> + public RippleDrawableCompat ( ShapeAppearanceModel shapeAppearanceModel ) { <nl> + super ( shapeAppearanceModel ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public void draw ( Canvas canvas ) { <nl> + if ( shouldDrawRipple ) { <nl> + super . draw ( canvas ) ; <nl> + } <nl> + } <nl> + <nl> + @ Override <nl> + protected boolean onStateChange ( int [ ] stateSet ) { <nl> + final boolean changed = super . onStateChange ( stateSet ) ; <nl> + boolean enabled = false ; <nl> + boolean pressed = false ; <nl> + boolean focused = false ; <nl> + boolean hovered = false ; <nl> + <nl> + for ( int state : stateSet ) { <nl> + if ( state = = android . R . attr . state_enabled ) { <nl> + enabled = true ; <nl> + } else if ( state = = android . R . attr . state_focused ) { <nl> + focused = true ; <nl> + } else if ( state = = android . R . attr . state_pressed ) { <nl> + pressed = true ; <nl> + } else if ( state = = android . R . attr . state_hovered ) { <nl> + hovered = true ; <nl> + } <nl> + } <nl> + shouldDrawRipple = enabled & & ( pressed | | focused | | hovered ) ; <nl> + return changed ; <nl> + } <nl> + } <nl>\n", "msg": "Create compat ripples that are based on MaterialShapeDrawable and only draw when enabled and in the pressed , focused , or hovered states .\n"}
{"diff_id": 35573, "repo": "bazelbuild/bazel\n", "sha": "c88e69013f9b45cf969d64fdf760eba1537bcf78\n", "time": "2020-03-27T22:54:11Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / standalone / StandaloneModule . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / standalone / StandaloneModule . java <nl> <nl> package com . google . devtools . build . lib . standalone ; <nl> <nl> import com . google . common . collect . ImmutableList ; <nl> - import com . google . devtools . build . lib . actions . SpawnStrategy ; <nl> import com . google . devtools . build . lib . analysis . actions . FileWriteActionContext ; <nl> import com . google . devtools . build . lib . analysis . actions . LocalTemplateExpansionStrategy ; <nl> import com . google . devtools . build . lib . analysis . actions . TemplateExpansionContext ; <nl> <nl> import com . google . devtools . build . lib . buildtool . BuildRequest ; <nl> import com . google . devtools . build . lib . dynamic . DynamicExecutionOptions ; <nl> import com . google . devtools . build . lib . exec . ExecutionOptions ; <nl> - import com . google . devtools . build . lib . exec . ExecutorBuilder ; <nl> import com . google . devtools . build . lib . exec . FileWriteStrategy ; <nl> + import com . google . devtools . build . lib . exec . ModuleActionContextRegistry ; <nl> import com . google . devtools . build . lib . exec . RunfilesTreeUpdater ; <nl> import com . google . devtools . build . lib . exec . SpawnRunner ; <nl> + import com . google . devtools . build . lib . exec . SpawnStrategyRegistry ; <nl> import com . google . devtools . build . lib . exec . StandaloneTestStrategy ; <nl> import com . google . devtools . build . lib . exec . TestStrategy ; <nl> import com . google . devtools . build . lib . exec . local . LocalEnvProvider ; <nl> public void beforeCommand ( CommandEnvironment env ) throws AbruptExitException { <nl> } <nl> <nl> @ Override <nl> - public void executorInit ( CommandEnvironment env , BuildRequest request , ExecutorBuilder builder ) { <nl> + public void registerActionContexts ( <nl> + ModuleActionContextRegistry . Builder registryBuilder , <nl> + CommandEnvironment env , <nl> + BuildRequest buildRequest ) { <nl> / / TODO ( ulfjack ) : Move this to another module . <nl> - builder . addActionContext ( <nl> + registryBuilder . register ( <nl> CppIncludeExtractionContext . class , new DummyCppIncludeExtractionContext ( env ) ) ; <nl> - builder . addActionContext ( CppIncludeScanningContext . class , new DummyCppIncludeScanningContext ( ) ) ; <nl> + registryBuilder . register ( CppIncludeScanningContext . class , new DummyCppIncludeScanningContext ( ) ) ; <nl> <nl> ExecutionOptions executionOptions = env . getOptions ( ) . getOptions ( ExecutionOptions . class ) ; <nl> Path testTmpRoot = <nl> public void executorInit ( CommandEnvironment env , BuildRequest request , ExecutorB <nl> executionOptions , <nl> env . getBlazeWorkspace ( ) . getBinTools ( ) , <nl> testTmpRoot ) ; <nl> + registryBuilder . register ( TestActionContext . class , testStrategy , \" standalone \" ) ; <nl> + registryBuilder . register ( <nl> + TestActionContext . class , new ExclusiveTestStrategy ( testStrategy ) , \" exclusive \" ) ; <nl> + registryBuilder . register ( FileWriteActionContext . class , new FileWriteStrategy ( ) , \" local \" ) ; <nl> + registryBuilder . register ( <nl> + TemplateExpansionContext . class , new LocalTemplateExpansionStrategy ( ) , \" local \" ) ; <nl> + } <nl> <nl> + @ Override <nl> + public void registerSpawnStrategies ( <nl> + SpawnStrategyRegistry . Builder registryBuilder , CommandEnvironment env ) { <nl> SpawnRunner localSpawnRunner = <nl> new LocalSpawnRunner ( <nl> env . getExecRoot ( ) , <nl> public void executorInit ( CommandEnvironment env , BuildRequest request , ExecutorB <nl> / / Order of strategies passed to builder is significant - when there are many strategies that <nl> / / could potentially be used and a spawnActionContext doesn ' t specify which one it wants , the <nl> / / last one from strategies list will be used <nl> - builder . addActionContext ( <nl> - SpawnStrategy . class , <nl> - new StandaloneSpawnStrategy ( env . getExecRoot ( ) , localSpawnRunner ) , <nl> - \" standalone \" , <nl> - \" local \" ) ; <nl> - builder . addActionContext ( TestActionContext . class , testStrategy , \" standalone \" ) ; <nl> - builder . addActionContext ( <nl> - TestActionContext . class , new ExclusiveTestStrategy ( testStrategy ) , \" exclusive \" ) ; <nl> - builder . addActionContext ( FileWriteActionContext . class , new FileWriteStrategy ( ) , \" local \" ) ; <nl> - builder . addActionContext ( <nl> - TemplateExpansionContext . class , new LocalTemplateExpansionStrategy ( ) , \" local \" ) ; <nl> + registryBuilder . registerStrategy ( <nl> + new StandaloneSpawnStrategy ( env . getExecRoot ( ) , localSpawnRunner ) , \" standalone \" , \" local \" ) ; <nl> <nl> / / This makes the \" sandboxed \" strategy the default Spawn strategy , unless it is overridden by a <nl> / / later BlazeModule . <nl> - builder . addStrategyByMnemonic ( \" \" , ImmutableList . of ( \" standalone \" ) ) ; <nl> - <nl> - / / This makes the \" standalone \" strategy available via - - spawn_strategy = standalone , but it is not <nl> - / / necessarily the default . <nl> - builder . addStrategyByContext ( SpawnStrategy . class , \" standalone \" ) ; <nl> + registryBuilder . setDefaultStrategies ( ImmutableList . of ( \" standalone \" ) ) ; <nl> } <nl> } <nl>\n", "msg": "Update StandaloneModule to use registry methods instead of executorInit where possible .\n"}
{"diff_id": 35781, "repo": "eclipse-vertx/vert.x\n", "sha": "5c55981283fc9c750f4f7ed1e7a0f264a2a11b13\n", "time": "2018-04-11T16:21:08Z\n", "diff": "mmm a / src / main / java / io / vertx / core / http / impl / Http1xServerConnection . java <nl> ppp b / src / main / java / io / vertx / core / http / impl / Http1xServerConnection . java <nl> synchronized void resume ( ) { <nl> } <nl> <nl> synchronized void handleMessage ( Object msg ) { <nl> - if ( queueing | | ! processMessage ( msg ) ) { <nl> + if ( queueing ) { <nl> enqueue ( msg ) ; <nl> + } else { <nl> + processMessage ( msg ) ; <nl> } <nl> } <nl> <nl> synchronized void responseComplete ( ) { <nl> } <nl> } <nl> pendingResponse = null ; <nl> - checkNextTick ( ) ; <nl> + if ( currentRequest = = null & & paused ) { <nl> + resume ( ) ; <nl> + } <nl> } <nl> <nl> synchronized void requestHandlers ( HttpHandlers handlers ) { <nl> private void handleError ( HttpObject obj ) { <nl> } <nl> } <nl> <nl> - private boolean processMessage ( Object msg ) { <nl> + private void processMessage ( Object msg ) { <nl> if ( msg instanceof HttpRequest ) { <nl> - if ( pendingResponse ! = null ) { <nl> - return false ; <nl> - } <nl> HttpRequest request = ( HttpRequest ) msg ; <nl> if ( request . decoderResult ( ) . isFailure ( ) ) { <nl> handleError ( request ) ; <nl> - return false ; <nl> + return ; <nl> } <nl> if ( options . isHandle100ContinueAutomatically ( ) & & HttpUtil . is100ContinueExpected ( request ) ) { <nl> write100Continue ( ) ; <nl> private boolean processMessage ( Object msg ) { <nl> } else { <nl> handleOther ( msg ) ; <nl> } <nl> - return true ; <nl> } <nl> <nl> private void handleContent ( Object msg ) { <nl> private void handleLastHttpContent ( ) { <nl> bytesRead = 0 ; <nl> } <nl> currentRequest = null ; <nl> + if ( pendingResponse ! = null ) { <nl> + pause ( ) ; <nl> + } <nl> } <nl> <nl> private void handleOther ( Object msg ) { <nl> private void checkNextTick ( ) { <nl> / / The only place we poll the pending queue , so we are sure that pending . size ( ) > 0 <nl> / / since we got there because queueing was true <nl> Object msg = pending . poll ( ) ; <nl> - if ( processMessage ( msg ) ) { <nl> - if ( pending . isEmpty ( ) ) { <nl> - unsetQueueing ( ) ; <nl> - } else { <nl> - checkNextTick ( ) ; <nl> - } <nl> - } else { <nl> - pending . addFirst ( msg ) ; <nl> + if ( pending . isEmpty ( ) ) { <nl> + / / paused = = false & & pending . size ( ) = = 0 = > queueing = false <nl> + unsetQueueing ( ) ; <nl> } <nl> + / / Process message , it might pause the connection <nl> + processMessage ( msg ) ; <nl> + / / Check next tick in case we still have pending messages and the connection is not paused <nl> + checkNextTick ( ) ; <nl> } <nl> } <nl> } ) ; <nl>\n", "msg": "Always process a message in Http1xServerConnection and don ' t put it back on the queue , instead when the HttpRequest ends and the corresponding response is still in progress then we pause the connection to avoid processing pipelined requests concurrently\n"}
{"diff_id": 35853, "repo": "EnterpriseQualityCoding/FizzBuzzEnterpriseEdition\n", "sha": "549f6633c50feddf804024f329f0006d0b5991d3\n", "time": "2014-03-04T23:15:11Z\n", "diff": "new file mode 100644 <nl> index 0000000 . . 37b4fb3 <nl> mmm / dev / null <nl> ppp b / src / main / java / com / seriouscompany / business / java / fizzbuzz / packagenamingpackage / impl / factories / SystemOutFizzBuzzOutputStrategyFactory . java <nl> <nl> + package com . seriouscompany . business . java . fizzbuzz . packagenamingpackage . impl . factories ; <nl> + <nl> + import com . seriouscompany . business . java . fizzbuzz . packagenamingpackage . impl . strategies . SystemOutFizzBuzzOutputStrategy ; <nl> + import com . seriouscompany . business . java . fizzbuzz . packagenamingpackage . interfaces . factories . FizzBuzzOutputStrategyFactory ; <nl> + import com . seriouscompany . business . java . fizzbuzz . packagenamingpackage . interfaces . strategies . FizzBuzzOutputStrategy ; <nl> + <nl> + public class SystemOutFizzBuzzOutputStrategyFactory implements <nl> + FizzBuzzOutputStrategyFactory { <nl> + <nl> + @ Override <nl> + public FizzBuzzOutputStrategy createOutputStrategy ( ) { <nl> + <nl> + return new SystemOutFizzBuzzOutputStrategy ( ) ; <nl> + <nl> + } <nl> + <nl> + } <nl>\n", "msg": "Creating a concrete factory for our output straetgy . Freedom is only a few commits away .\n"}
{"diff_id": 35923, "repo": "oracle/graal\n", "sha": "4bc3da93d1af7001db2cb704c6b0f43243704292\n", "time": "2019-03-20T10:36:57Z\n", "diff": "mmm a / sdk / src / org . graalvm . polyglot / src / org / graalvm / polyglot / HostAccess . java <nl> ppp b / sdk / src / org . graalvm . polyglot / src / org / graalvm / polyglot / HostAccess . java <nl> boolean allowAccess ( AnnotatedElement member ) { <nl> } <nl> if ( annotations ! = null ) { <nl> for ( Class < ? extends Annotation > ann : annotations ) { <nl> - if ( member . getAnnotation ( ann ) ! = null ) { <nl> + if ( hasAnnotation ( member , ann ) ) { <nl> return true ; <nl> } <nl> } <nl> public String toString ( ) { <nl> return name = = null ? super . toString ( ) : name ; <nl> } <nl> <nl> + private static boolean hasAnnotation ( AnnotatedElement member , Class < ? extends Annotation > annotationType ) { <nl> + if ( member instanceof Field ) { <nl> + Field f = ( Field ) member ; <nl> + return f . getAnnotation ( annotationType ) ! = null ; <nl> + } <nl> + if ( member instanceof Method ) { <nl> + Method m = ( Method ) member ; <nl> + return m . getAnnotation ( annotationType ) ! = null ; <nl> + } <nl> + if ( member instanceof Constructor ) { <nl> + Constructor < ? > c = ( Constructor < ? > ) member ; <nl> + return c . getAnnotation ( annotationType ) ! = null ; <nl> + } <nl> + return false ; <nl> + } <nl> + <nl> / * * <nl> * Annotation used by the predefined { @ link # EXPLICIT } access policy to mark public <nl> * constructors , methods and fields in public classes that should be accessible by the guest <nl>\n", "msg": "Explicitly limit the support AnnotatedElement subclasses to make SVM happier\n"}
{"diff_id": 35955, "repo": "oracle/graal\n", "sha": "5ace0883f417efa8d2eee85f6552799508d90f84\n", "time": "2014-09-19T12:24:09Z\n", "diff": "mmm a / graal / com . oracle . graal . truffle . hotspot / src / com / oracle / graal / truffle / hotspot / HotSpotTruffleRuntime . java <nl> ppp b / graal / com . oracle . graal . truffle . hotspot / src / com / oracle / graal / truffle / hotspot / HotSpotTruffleRuntime . java <nl> public void run ( ) { <nl> } <nl> } <nl> } ; <nl> - if ( mayBeAsynchronous ) { <nl> - Future < ? > future = compileQueue . submit ( r ) ; <nl> - this . compilations . put ( optimizedCallTarget , future ) ; <nl> - } else { <nl> - r . run ( ) ; <nl> + Future < ? > future = compileQueue . submit ( r ) ; <nl> + this . compilations . put ( optimizedCallTarget , future ) ; <nl> + <nl> + if ( ! mayBeAsynchronous ) { <nl> + try { <nl> + future . get ( ) ; <nl> + } catch ( InterruptedException | ExecutionException e ) { <nl> + / / silently ignored <nl> + } <nl> } <nl> } <nl> <nl>\n", "msg": "use compilation thread even for synchronous Truffle compilations\n"}
{"diff_id": 36056, "repo": "oracle/graal\n", "sha": "2c36a736cc8d5370a7d8b1c4caa77d104716d280\n", "time": "2013-01-12T21:05:07Z\n", "diff": "mmm a / graal / com . oracle . graal . snippets / src / com / oracle / graal / snippets / ClassSubstitution . java <nl> ppp b / graal / com . oracle . graal . snippets / src / com / oracle / graal / snippets / ClassSubstitution . java <nl> <nl> <nl> import java . lang . annotation . * ; <nl> <nl> + import com . oracle . graal . api . meta . * ; <nl> + <nl> / * * <nl> * Denotes a class that substitutes methods of another specified class with snippets . <nl> + * The substitute methods are exactly those annotated by { @ link MethodSubstitution } . <nl> * / <nl> @ Retention ( RetentionPolicy . RUNTIME ) <nl> @ Target ( ElementType . TYPE ) <nl> <nl> String className ( ) default \" \" ; <nl> <nl> / * * <nl> - * Used to map a substitute method to an original method where the default mapping <nl> - * of name and signature is not possible due to name clashes with final methods in <nl> - * { @ link Object } or signature types that are not public . <nl> + * Denotes a substitute method . <nl> * / <nl> @ Retention ( RetentionPolicy . RUNTIME ) <nl> @ Target ( ElementType . METHOD ) <nl> public @ interface MethodSubstitution { <nl> / * * <nl> - * Get the name of the original method . <nl> + * Gets the name of the substituted method . <nl> + * < p > <nl> + * If the default value is specified for this element , then the <nl> + * name of the substituted method is same as the substitute method . <nl> * / <nl> String value ( ) default \" \" ; <nl> <nl> / * * <nl> - * Determine if the substituted method is static . <nl> + * Determines if the substituted method is static . <nl> * / <nl> boolean isStatic ( ) default true ; <nl> + <nl> + / * * <nl> + * Gets the { @ linkplain Signature # getString ( ) signature } of the substituted method . <nl> + * < p > <nl> + * If the default value is specified for this element , then the <nl> + * signature of the substituted method is the same as the substitute method . <nl> + * / <nl> + String signature ( ) default \" \" ; <nl> } <nl> } <nl>\n", "msg": "added support for supplying an explicit signature in @ MethodAnnotation to private types in the signature of the substituted method\n"}
{"diff_id": 36286, "repo": "oracle/graal\n", "sha": "23c3e4cfbe9e8441ca3d8ae92eb4cc2b1a0981c1\n", "time": "2013-08-16T17:07:10Z\n", "diff": "mmm a / graal / com . oracle . graal . phases . common / src / com / oracle / graal / phases / common / ConditionalEliminationPhase . java <nl> ppp b / graal / com . oracle . graal . phases . common / src / com / oracle / graal / phases / common / ConditionalEliminationPhase . java <nl> <nl> import com . oracle . graal . nodes . extended . * ; <nl> import com . oracle . graal . nodes . java . * ; <nl> import com . oracle . graal . nodes . java . MethodCallTargetNode . InvokeKind ; <nl> + import com . oracle . graal . nodes . spi . * ; <nl> import com . oracle . graal . nodes . type . * ; <nl> import com . oracle . graal . nodes . util . * ; <nl> import com . oracle . graal . phases . * ; <nl> protected void node ( FixedNode node ) { <nl> boolean nonNull = state . isNonNull ( object ) ; <nl> GuardingNode replacementAnchor = null ; <nl> if ( nonNull ) { <nl> - / / Search for valid instanceof anchor . <nl> - for ( InstanceOfNode instanceOfNode : object . usages ( ) . filter ( InstanceOfNode . class ) ) { <nl> - if ( instanceOfNode . type ( ) = = checkCast . type ( ) & & state . trueConditions . containsKey ( instanceOfNode ) ) { <nl> - ValueNode v = state . trueConditions . get ( instanceOfNode ) ; <nl> - if ( v instanceof GuardingNode ) { <nl> - replacementAnchor = ( GuardingNode ) v ; <nl> - } <nl> - } <nl> - } <nl> + replacementAnchor = searchAnchor ( GraphUtil . unproxify ( object ) , type ) ; <nl> } <nl> ValueAnchorNode anchor = null ; <nl> if ( replacementAnchor = = null ) { <nl> protected void node ( FixedNode node ) { <nl> <nl> } <nl> } <nl> + <nl> + private GuardingNode searchAnchor ( ValueNode value , ResolvedJavaType type ) { <nl> + for ( Node n : value . usages ( ) ) { <nl> + if ( n instanceof InstanceOfNode ) { <nl> + InstanceOfNode instanceOfNode = ( InstanceOfNode ) n ; <nl> + if ( instanceOfNode . type ( ) = = type & & state . trueConditions . containsKey ( instanceOfNode ) ) { <nl> + ValueNode v = state . trueConditions . get ( instanceOfNode ) ; <nl> + if ( v instanceof GuardingNode ) { <nl> + return ( GuardingNode ) v ; <nl> + } <nl> + } <nl> + } <nl> + } <nl> + <nl> + for ( Node n : value . usages ( ) ) { <nl> + if ( n instanceof ValueProxy ) { <nl> + ValueProxy proxyNode = ( ValueProxy ) n ; <nl> + if ( proxyNode . getOriginalValue ( ) = = value ) { <nl> + GuardingNode result = searchAnchor ( ( ValueNode ) n , type ) ; <nl> + if ( result ! = null ) { <nl> + return result ; <nl> + } <nl> + } <nl> + <nl> + } <nl> + } <nl> + <nl> + return null ; <nl> + } <nl> } <nl> } <nl>\n", "msg": "Search through tree of proxies for replacement anchor in ConditionalEliminationPhase .\n"}
{"diff_id": 36431, "repo": "iluwatar/java-design-patterns\n", "sha": "41593774c6c15a4fe321b4ac3cc3d5fdababd560\n", "time": "2015-12-28T21:56:41Z\n", "diff": "mmm a / delegation / src / main / java / com / iluwatar / delegation / simple / printers / HPPrinter . java <nl> ppp b / delegation / src / main / java / com / iluwatar / delegation / simple / printers / HPPrinter . java <nl> <nl> <nl> / * * <nl> * Specialised Implementation of { @ link Printer } for a HP Printer , in <nl> - * this case the message to be printed is appended to \" HP Printer : \" <nl> + * this case the message to be printed is appended to \" HP Printer : \" <nl> * <nl> * @ see Printer <nl> * / <nl>\n", "msg": "CheckStyle reporting strange error about classname , suspect caching , forcing a clean build\n"}
{"diff_id": 36436, "repo": "facebook/fresco\n", "sha": "c4731bc98203d88c0c4109f0d57619656a9d0cbc\n", "time": "2017-02-22T13:34:56Z\n", "diff": "mmm a / samples / showcase / src / main / java / com / facebook / fresco / samples / showcase / MainActivity . java <nl> ppp b / samples / showcase / src / main / java / com / facebook / fresco / samples / showcase / MainActivity . java <nl> private void handleNavigationItemClick ( int itemId ) { <nl> fragment = new SettingsFragment ( ) ; <nl> break ; <nl> default : <nl> - throw new IllegalArgumentException ( \" No example with this id ! \" ) ; <nl> + / / Default to the welcome fragment <nl> + fragment = new WelcomeFragment ( ) ; <nl> } <nl> showFragment ( fragment ) ; <nl> <nl>\n", "msg": "Default Showcase app to the welcome screen if fragment ID invalid\n"}
{"diff_id": 36674, "repo": "apache/flink\n", "sha": "86e61edb9b4c9247b84f7243ff84c726801ef2f9\n", "time": "2012-06-21T09:57:41Z\n", "diff": "mmm a / pact / pact - tests / src / test / java / eu / stratosphere / pact / test / util / minicluster / NepheleMiniCluster . java <nl> ppp b / pact / pact - tests / src / test / java / eu / stratosphere / pact / test / util / minicluster / NepheleMiniCluster . java <nl> private void initJobManager ( ) throws Exception <nl> \" < property > \" , <nl> \" < key > \" + ConfigConstants . JOB_EXECUTION_RETRIES_KEY + \" < / key > \" , <nl> \" < value > 0 < / value > \" , <nl> - \" < / property > \" , <nl> + \" < / property > \" , <nl> \" < property > \" , <nl> \" < key > taskmanager . setup . usediscovery < / key > \" , <nl> \" < value > false < / value > \" , <nl>\n", "msg": "Pact Tests now run with disabled fault tolerance , for immediate visibility of failures .\n"}
{"diff_id": 36754, "repo": "Netflix/Hystrix\n", "sha": "840e63c63d5c79d6bf719e3743c347cbcb1f4bee\n", "time": "2018-04-09T06:46:49Z\n", "diff": "mmm a / hystrix - core / src / test / java / com / netflix / hystrix / UnsubscribedTasksRequestCacheTest . java <nl> ppp b / hystrix - core / src / test / java / com / netflix / hystrix / UnsubscribedTasksRequestCacheTest . java <nl> protected CommandUsingRequestCache ( int value ) { <nl> @ Override <nl> protected Boolean run ( ) { <nl> numOfExecutions . getAndIncrement ( ) ; <nl> - try { <nl> - Thread . sleep ( 500 ) ; <nl> - } <nl> - catch ( InterruptedException e ) { <nl> - e . printStackTrace ( ) ; <nl> - } <nl> System . out . println ( Thread . currentThread ( ) . getName ( ) + \" run ( ) \" ) ; <nl> return value = = 0 | | value % 2 = = 0 ; <nl> } <nl> public void testOneCommandIsUnsubscribed ( ) throws ExecutionException , Interrupte <nl> final HystrixRequestContext context = HystrixRequestContext . initializeContext ( ) ; <nl> final AtomicInteger numCacheResponses = new AtomicInteger ( 0 ) ; <nl> <nl> - <nl> try { <nl> - ExecutorService executorService = Executors . newFixedThreadPool ( 2 ) ; <nl> - <nl> - Future futureCommand2a = executorService . submit ( new Runnable ( ) { <nl> - <nl> - public void run ( ) { <nl> - <nl> - HystrixRequestContext . setContextOnCurrentThread ( context ) ; <nl> - <nl> - CommandUsingRequestCache command2a = new CommandUsingRequestCache ( 2 ) ; <nl> - Future < Boolean > resultCommand2a = command2a . queue ( ) ; <nl> - <nl> - try { <nl> - assertTrue ( resultCommand2a . get ( ) ) ; <nl> - System . out . println ( Thread . currentThread ( ) + \" \" + command2a . isResponseFromCache ( ) ) ; <nl> - if ( command2a . isResponseFromCache ( ) ) { <nl> - numCacheResponses . getAndIncrement ( ) ; <nl> - } <nl> - } catch ( Exception e ) { <nl> - fail ( \" Exception : \" + e . getMessage ( ) ) ; <nl> - } <nl> - } <nl> - } ) ; <nl> - <nl> - Future futureCommand2b = executorService . submit ( new Runnable ( ) { <nl> - <nl> - public void run ( ) { <nl> - <nl> - HystrixRequestContext . setContextOnCurrentThread ( context ) ; <nl> + ExecutorService executorService = Executors . newSingleThreadExecutor ( ) ; <nl> <nl> - CommandUsingRequestCache command2b = new CommandUsingRequestCache ( 2 ) ; <nl> - Future < Boolean > resultCommand2b = command2b . queue ( ) ; <nl> - <nl> - try { <nl> - assertTrue ( resultCommand2b . get ( ) ) ; <nl> - System . out . println ( Thread . currentThread ( ) + \" \" + command2b . isResponseFromCache ( ) ) ; <nl> - if ( command2b . isResponseFromCache ( ) ) { <nl> - numCacheResponses . getAndIncrement ( ) ; <nl> - } <nl> - } catch ( Exception e ) { <nl> - fail ( \" Exception : \" + e . getMessage ( ) ) ; <nl> - } <nl> - } <nl> - } ) ; <nl> + Future futureCommand2a = executorService . submit ( createCommandRunnable ( context , numCacheResponses ) ) ; <nl> + Future futureCommand2b = executorService . submit ( createCommandRunnable ( context , numCacheResponses ) ) ; <nl> <nl> futureCommand2a . get ( ) ; <nl> - Thread . sleep ( 500 ) ; <nl> futureCommand2b . get ( ) ; <nl> <nl> assertEquals ( 1 , numCacheResponses . get ( ) ) ; <nl> assertEquals ( 1 , numOfExecutions . get ( ) ) ; <nl> - assertEquals ( false , encounteredCommandException . get ( ) ) ; <nl> - <nl> + assertFalse ( encounteredCommandException . get ( ) ) ; <nl> } finally { <nl> context . shutdown ( ) ; <nl> } <nl> } <nl> <nl> + private Runnable createCommandRunnable ( final HystrixRequestContext context , final AtomicInteger numCacheResponses ) { <nl> + return new Runnable ( ) { <nl> + <nl> + public void run ( ) { <nl> + <nl> + HystrixRequestContext . setContextOnCurrentThread ( context ) ; <nl> + <nl> + CommandUsingRequestCache command2a = new CommandUsingRequestCache ( 2 ) ; <nl> + Future < Boolean > resultCommand2a = command2a . queue ( ) ; <nl> + <nl> + try { <nl> + assertTrue ( resultCommand2a . get ( ) ) ; <nl> + System . out . println ( Thread . currentThread ( ) + \" \" + command2a . isResponseFromCache ( ) ) ; <nl> + if ( command2a . isResponseFromCache ( ) ) { <nl> + numCacheResponses . getAndIncrement ( ) ; <nl> + } <nl> + } catch ( Exception e ) { <nl> + fail ( \" Exception : \" + e . getMessage ( ) ) ; <nl> + } <nl> + } <nl> + } ; <nl> + } <nl> + <nl> } <nl>\n", "msg": "Run command runnables on a single thread executor to get deterministic results\n"}
{"diff_id": 37162, "repo": "oracle/graal\n", "sha": "cc93cf016cfb5553ad0372c9944d0f67d8f95c3b\n", "time": "2018-07-02T15:34:06Z\n", "diff": "mmm a / projects / com . oracle . truffle . llvm . nodes / src / com / oracle / truffle / llvm / nodes / intrinsics / llvm / x86 / LLVMX86_64VAStart . java <nl> ppp b / projects / com . oracle . truffle . llvm . nodes / src / com / oracle / truffle / llvm / nodes / intrinsics / llvm / x86 / LLVMX86_64VAStart . java <nl> <nl> @ Child private LLVMStoreNode i64RegSaveAreaStore ; <nl> @ Child private LLVMStoreNode i32RegSaveAreaStore ; <nl> @ Child private LLVMStoreNode fp80bitRegSaveAreaStore ; <nl> + @ Child private LLVMStoreNode pointerRegSaveAreaStore ; <nl> @ Child private LLVMIncrementPointerNode pointerArithmeticRegSaveArea ; <nl> <nl> @ Child private LLVMStoreNode i64OverflowArgAreaStore ; <nl> @ Child private LLVMStoreNode i32OverflowArgAreaStore ; <nl> @ Child private LLVMStoreNode fp80bitOverflowArgAreaStore ; <nl> + @ Child private LLVMStoreNode pointerOverflowArgAreaStore ; <nl> @ Child private LLVMIncrementPointerNode pointerArithmeticOverflowArea ; <nl> <nl> @ Child private LLVMIncrementPointerNode pointerArithmeticStructInit ; <nl> public LLVMX86_64VAStart ( int numberOfExplicitArguments , LLVMSourceLocation sourc <nl> this . i64RegSaveAreaStore = LLVMI64StoreNodeGen . create ( null , null ) ; <nl> this . i32RegSaveAreaStore = LLVMI32StoreNodeGen . create ( null , null ) ; <nl> this . fp80bitRegSaveAreaStore = LLVM80BitFloatStoreNodeGen . create ( null , null ) ; <nl> + this . pointerRegSaveAreaStore = LLVMPointerStoreNodeGen . create ( null , null ) ; <nl> this . pointerArithmeticRegSaveArea = LLVMIncrementPointerNodeGen . create ( ) ; <nl> <nl> this . i64OverflowArgAreaStore = LLVMI64StoreNodeGen . create ( null , null ) ; <nl> this . i32OverflowArgAreaStore = LLVMI32StoreNodeGen . create ( null , null ) ; <nl> this . fp80bitOverflowArgAreaStore = LLVM80BitFloatStoreNodeGen . create ( null , null ) ; <nl> + this . pointerOverflowArgAreaStore = LLVMPointerStoreNodeGen . create ( null , null ) ; <nl> this . pointerArithmeticOverflowArea = LLVMIncrementPointerNodeGen . create ( ) ; <nl> <nl> this . pointerArithmeticStructInit = LLVMIncrementPointerNodeGen . create ( ) ; <nl> protected Object vaStart ( VirtualFrame frame , Object targetAddress ) { <nl> final VarArgArea area = getVarArgArea ( object ) ; <nl> <nl> if ( area = = VarArgArea . GP_AREA & & gpOffset < X86_64BitVarArgs . GP_LIMIT ) { <nl> - storeArgument ( regSaveArea , gpOffset , memmove , pointerArithmeticRegSaveArea , i64RegSaveAreaStore , i32RegSaveAreaStore , fp80bitRegSaveAreaStore , object ) ; <nl> + storeArgument ( regSaveArea , gpOffset , memmove , pointerArithmeticRegSaveArea , i64RegSaveAreaStore , i32RegSaveAreaStore , fp80bitRegSaveAreaStore , pointerRegSaveAreaStore , object ) ; <nl> gpOffset + = X86_64BitVarArgs . GP_STEP ; <nl> } else if ( area = = VarArgArea . FP_AREA & & fpOffset < X86_64BitVarArgs . FP_LIMIT ) { <nl> - storeArgument ( regSaveArea , fpOffset , memmove , pointerArithmeticRegSaveArea , i64RegSaveAreaStore , i32RegSaveAreaStore , fp80bitRegSaveAreaStore , object ) ; <nl> + storeArgument ( regSaveArea , fpOffset , memmove , pointerArithmeticRegSaveArea , i64RegSaveAreaStore , i32RegSaveAreaStore , fp80bitRegSaveAreaStore , pointerRegSaveAreaStore , object ) ; <nl> fpOffset + = X86_64BitVarArgs . FP_STEP ; <nl> } else { <nl> assert overflowArgAreaSize > = overflowOffset ; <nl> overflowOffset + = storeArgument ( overflowArgArea , overflowOffset , memmove , pointerArithmeticOverflowArea , i64OverflowArgAreaStore , i32OverflowArgAreaStore , <nl> - fp80bitOverflowArgAreaStore , object ) ; <nl> + fp80bitOverflowArgAreaStore , pointerOverflowArgAreaStore , object ) ; <nl> } <nl> } <nl> } <nl> public LLVMSourceLocation getSourceLocation ( ) { <nl> } <nl> <nl> private static int storeArgument ( Object ptr , long offset , LLVMMemMoveNode memmove , LLVMIncrementPointerNode pointerArithmetic , LLVMStoreNode storeI64Node , <nl> - LLVMStoreNode storeI32Node , <nl> - LLVMStoreNode storeFP80Node , Object object ) { <nl> + LLVMStoreNode storeI32Node , LLVMStoreNode storeFP80Node , LLVMStoreNode storePointerNode , Object object ) { <nl> if ( object instanceof Number ) { <nl> return doPrimitiveWrite ( ptr , offset , pointerArithmetic , storeI64Node , object ) ; <nl> } else if ( object instanceof LLVMVarArgCompoundValue ) { <nl> private static int storeArgument ( Object ptr , long offset , LLVMMemMoveNode memmov <nl> return obj . getSize ( ) ; <nl> } else if ( LLVMPointer . isInstance ( object ) | | object instanceof LLVMFunctionDescriptor | | object instanceof LLVMGlobal ) { <nl> Object currentPtr = pointerArithmetic . executeWithTarget ( ptr , offset ) ; <nl> - storeI64Node . executeWithTarget ( currentPtr , object ) ; <nl> + storePointerNode . executeWithTarget ( currentPtr , object ) ; <nl> return X86_64BitVarArgs . STACK_STEP ; <nl> } else if ( object instanceof LLVM80BitFloat ) { <nl> Object currentPtr = pointerArithmetic . executeWithTarget ( ptr , offset ) ; <nl>\n", "msg": "Use pointer store node when storing pointers to a varargs area .\n"}
{"diff_id": 37287, "repo": "SeleniumHQ/selenium\n", "sha": "ed325ca68004a4acc5e798c4fb2acfc0b54850fc\n", "time": "2013-01-24T02:25:04Z\n", "diff": "mmm a / java / client / test / org / openqa / selenium / testing / drivers / SauceDriver . java <nl> ppp b / java / client / test / org / openqa / selenium / testing / drivers / SauceDriver . java <nl> <nl> private static final String SAUCE_USERNAME_ENV_NAME = \" SAUCE_USERNAME \" ; <nl> private static final String DESIRED_BROWSER_VERSION_ENV_NAME = \" SAUCE_BROWSER_VERSION \" ; <nl> private static final String SAUCE_DISABLE_VIDEO_ENV_NAME = \" SAUCE_DISABLE_VIDEO \" ; <nl> + private static final String SAUCE_BUILD_ENV_NAME = \" BUILD_NUMBER \" ; <nl> <nl> private static final String USE_SAUCE_ENV_NAME = \" USE_SAUCE \" ; <nl> <nl> private static Capabilities munge ( Capabilities desiredCapabilities , String selen <nl> mungedCapabilities . setCapability ( \" idle - timeout \" , 180 ) ; <nl> mungedCapabilities . setCapability ( \" disable - popup - handler \" , true ) ; <nl> mungedCapabilities . setCapability ( \" record - video \" , shouldRecordVideo ( ) ) ; <nl> + mungedCapabilities . setCapability ( \" build \" , System . getenv ( SAUCE_BUILD_ENV_NAME ) ) ; <nl> <nl> mungedCapabilities . setCapability ( \" prevent - requeue \" , true ) ; <nl> <nl>\n", "msg": "Pass build number to Sauce for better reporting\n"}
{"diff_id": 37432, "repo": "SeleniumHQ/selenium\n", "sha": "e50915bfecaf85bad41e5a4c0cf5c0817815399e\n", "time": "2011-11-24T15:55:12Z\n", "diff": "mmm a / java / client / test / org / openqa / selenium / environment / DomainHelper . java <nl> ppp b / java / client / test / org / openqa / selenium / environment / DomainHelper . java <nl> private boolean isIpv4Address ( String string ) { <nl> } <nl> <nl> public boolean isValidHostname ( String hostname ) { <nl> - return ! isIpv4Address ( hostname ) & & ! \" localhost \" . equals ( hostname ) ; <nl> + return isIpv4Address ( hostname ) | | \" localhost \" . equals ( hostname ) ; <nl> } <nl> <nl> public String getHostName ( ) { <nl>\n", "msg": "SimonStewart : Making the logic for isValidHostname support short - circuiting\n"}
{"diff_id": 37442, "repo": "oracle/graal\n", "sha": "d7ac83b4061870b2803f4861d8731f8025c80489\n", "time": "2014-08-23T14:53:47Z\n", "diff": "mmm a / graal / com . oracle . graal . graph / src / com / oracle / graal / graph / NodeClass . java <nl> ppp b / graal / com . oracle . graal . graph / src / com / oracle / graal / graph / NodeClass . java <nl> <nl> * / <nl> @ SuppressWarnings ( \" unchecked \" ) <nl> public static NodeClass get ( Class < ? > c ) { <nl> - Class < ? extends Node > key = ( Class < ? extends Node > ) c ; <nl> + GeneratedNode gen = c . getAnnotation ( GeneratedNode . class ) ; <nl> + Class < ? extends Node > key = gen = = null ? ( Class < ? extends Node > ) c : ( Class < ? extends Node > ) gen . value ( ) ; <nl> + <nl> NodeClass value = ( NodeClass ) allClasses . get ( key ) ; <nl> / / The fact that { @ link ConcurrentHashMap # put } and { @ link ConcurrentHashMap # get } <nl> / / are used makes the double - checked locking idiom work . <nl> public NodeClass ( Class < ? > clazz , CalcOffset calcOffset , int [ ] presetIterableIds , <nl> if ( ! info . nameTemplate ( ) . isEmpty ( ) ) { <nl> newNameTemplate = info . nameTemplate ( ) ; <nl> } <nl> + } else { <nl> + System . out . println ( \" No NodeInfo for \" + clazz ) ; <nl> } <nl> EnumSet < InputType > newAllowedUsageTypes = EnumSet . noneOf ( InputType . class ) ; <nl> Class < ? > current = clazz ; <nl> protected void rescanFieldOffsets ( CalcOffset calc ) { <nl> fieldTypes . putAll ( scanner . fieldTypes ) ; <nl> } <nl> <nl> + private boolean isNodeClassFor ( Node n ) { <nl> + GeneratedNode gen = n . getClass ( ) . getAnnotation ( GeneratedNode . class ) ; <nl> + assert gen ! = null ; <nl> + return gen . value ( ) = = getClazz ( ) ; <nl> + } <nl> + <nl> public String shortName ( ) { <nl> return shortName ; <nl> } <nl> public void clearSuccessors ( Node node ) { <nl> * @ param newNode the node to which the inputs should be copied . <nl> * / <nl> public void copyInputs ( Node node , Node newNode ) { <nl> - assert node . getClass ( ) = = getClazz ( ) & & newNode . getClass ( ) = = getClazz ( ) ; <nl> + assert isNodeClassFor ( node ) & & isNodeClassFor ( newNode ) ; <nl> <nl> int index = 0 ; <nl> while ( index < directInputCount ) { <nl> public void copyInputs ( Node node , Node newNode ) { <nl> * @ param newNode the node to which the successors should be copied . <nl> * / <nl> public void copySuccessors ( Node node , Node newNode ) { <nl> - assert node . getClass ( ) = = getClazz ( ) & & newNode . getClass ( ) = = getClazz ( ) ; <nl> + assert isNodeClassFor ( node ) & & isNodeClassFor ( newNode ) ; <nl> <nl> int index = 0 ; <nl> while ( index < directSuccessorCount ) { <nl> public boolean edgesEqual ( Node node , Node other ) { <nl> } <nl> <nl> public boolean inputsEqual ( Node node , Node other ) { <nl> - assert node . getClass ( ) = = getClazz ( ) & & other . getClass ( ) = = getClazz ( ) ; <nl> + assert isNodeClassFor ( node ) & & isNodeClassFor ( other ) ; <nl> int index = 0 ; <nl> while ( index < directInputCount ) { <nl> if ( getNode ( other , inputOffsets [ index ] ) ! = getNode ( node , inputOffsets [ index ] ) ) { <nl> public boolean inputsEqual ( Node node , Node other ) { <nl> } <nl> <nl> public boolean successorsEqual ( Node node , Node other ) { <nl> - assert node . getClass ( ) = = getClazz ( ) & & other . getClass ( ) = = getClazz ( ) ; <nl> + assert isNodeClassFor ( node ) & & isNodeClassFor ( other ) ; <nl> int index = 0 ; <nl> while ( index < directSuccessorCount ) { <nl> if ( getNode ( other , successorOffsets [ index ] ) ! = getNode ( node , successorOffsets [ index ] ) ) { <nl> public boolean successorsEqual ( Node node , Node other ) { <nl> } <nl> <nl> public boolean inputContains ( Node node , Node other ) { <nl> - assert node . getClass ( ) = = getClazz ( ) ; <nl> + assert isNodeClassFor ( node ) ; <nl> <nl> int index = 0 ; <nl> while ( index < directInputCount ) { <nl> public boolean inputContains ( Node node , Node other ) { <nl> } <nl> <nl> public boolean successorContains ( Node node , Node other ) { <nl> - assert node . getClass ( ) = = getClazz ( ) ; <nl> + assert isNodeClassFor ( node ) ; <nl> <nl> int index = 0 ; <nl> while ( index < directSuccessorCount ) { <nl>\n", "msg": "bind a generated Node class to the NodeClass instance of the generated - from Node class\n"}
{"diff_id": 37599, "repo": "oracle/graal\n", "sha": "eb20cead5844a75d467cfba0e36ccd882c3f1fbf\n", "time": "2013-06-05T09:44:53Z\n", "diff": "mmm a / graal / com . oracle . graal . loop / src / com / oracle / graal / loop / phases / LoopSafepointEliminationPhase . java <nl> ppp b / graal / com . oracle . graal . loop / src / com / oracle / graal / loop / phases / LoopSafepointEliminationPhase . java <nl> protected void run ( StructuredGraph graph , MidTierContext context ) { <nl> loops . detectedCountedLoops ( ) ; <nl> for ( LoopEx loop : loops . countedLoops ( ) ) { <nl> if ( loop . lirLoop ( ) . children . isEmpty ( ) & & loop . counted ( ) . getKind ( ) = = Kind . Int ) { <nl> - loop . counted ( ) . createOverFlowGuard ( ) ; <nl> + boolean hasSafepoint = false ; <nl> for ( LoopEndNode loopEnd : loop . loopBegin ( ) . loopEnds ( ) ) { <nl> - loopEnd . disableSafepoint ( ) ; <nl> + hasSafepoint | = loopEnd . canSafepoint ( ) ; <nl> + } <nl> + if ( hasSafepoint ) { <nl> + loop . counted ( ) . createOverFlowGuard ( ) ; <nl> + for ( LoopEndNode loopEnd : loop . loopBegin ( ) . loopEnds ( ) ) { <nl> + loopEnd . disableSafepoint ( ) ; <nl> + } <nl> } <nl> } <nl> } <nl>\n", "msg": "only create overflow guards for loops that have safepoints\n"}
{"diff_id": 37687, "repo": "oracle/graal\n", "sha": "3339438b4a4e310d74e6f4b41bd9c506c8aa23c3\n", "time": "2015-02-05T13:34:36Z\n", "diff": "mmm a / graal / com . oracle . graal . java / src / com / oracle / graal / java / GraalDirectivePlugins . java <nl> ppp b / graal / com . oracle . graal . java / src / com / oracle / graal / java / GraalDirectivePlugins . java <nl> <nl> <nl> public class GraalDirectivePlugins { <nl> <nl> - private static ResolvedJavaMethod lookup ( MetaAccessProvider metaAccess , String name , Class < ? > . . . parameterTypes ) { <nl> - return Registration . resolve ( metaAccess , GraalDirectives . class , name , parameterTypes ) ; <nl> - } <nl> - <nl> public static void registerPlugins ( MetaAccessProvider metaAccess , GraphBuilderPlugins plugins ) { <nl> - plugins . register ( lookup ( metaAccess , \" deoptimize \" ) , new InvocationPlugin ( ) { <nl> + Registration r = new Registration ( plugins , metaAccess , GraalDirectives . class ) ; <nl> + r . register0 ( \" deoptimize \" , new InvocationPlugin ( ) { <nl> public boolean apply ( GraphBuilderContext builder ) { <nl> builder . append ( new DeoptimizeNode ( DeoptimizationAction . None , DeoptimizationReason . TransferToInterpreter ) ) ; <nl> return true ; <nl> } <nl> } ) ; <nl> <nl> - plugins . register ( lookup ( metaAccess , \" deoptimizeAndInvalidate \" ) , new InvocationPlugin ( ) { <nl> + r . register0 ( \" deoptimizeAndInvalidate \" , new InvocationPlugin ( ) { <nl> public boolean apply ( GraphBuilderContext builder ) { <nl> builder . append ( new DeoptimizeNode ( DeoptimizationAction . InvalidateReprofile , DeoptimizationReason . TransferToInterpreter ) ) ; <nl> return true ; <nl> } <nl> } ) ; <nl> <nl> - plugins . register ( lookup ( metaAccess , \" inCompiledCode \" ) , new InvocationPlugin ( ) { <nl> + r . register0 ( \" inCompiledCode \" , new InvocationPlugin ( ) { <nl> public boolean apply ( GraphBuilderContext builder ) { <nl> builder . push ( Kind . Int , builder . append ( ConstantNode . forInt ( 1 ) ) ) ; <nl> return true ; <nl> } <nl> } ) ; <nl> <nl> - plugins . register ( lookup ( metaAccess , \" controlFlowAnchor \" ) , new InvocationPlugin ( ) { <nl> + r . register0 ( \" controlFlowAnchor \" , new InvocationPlugin ( ) { <nl> public boolean apply ( GraphBuilderContext builder ) { <nl> builder . append ( new ControlFlowAnchorNode ( ) ) ; <nl> return true ; <nl> } <nl> } ) ; <nl> <nl> - plugins . register ( lookup ( metaAccess , \" injectBranchProbability \" , double . class , boolean . class ) , new InvocationPlugin ( ) { <nl> + r . register2 ( \" injectBranchProbability \" , double . class , boolean . class , new InvocationPlugin ( ) { <nl> public boolean apply ( GraphBuilderContext builder , ValueNode probability , ValueNode condition ) { <nl> builder . push ( Kind . Int , builder . append ( new BranchProbabilityNode ( probability , condition ) ) ) ; <nl> return true ; <nl> public boolean apply ( GraphBuilderContext builder , ValueNode value ) { <nl> cls = kind . toJavaClass ( ) ; <nl> } <nl> <nl> - plugins . register ( lookup ( metaAccess , \" blackhole \" , cls ) , blackholePlugin ) ; <nl> + r . register1 ( \" blackhole \" , cls , blackholePlugin ) ; <nl> <nl> final Kind stackKind = kind . getStackKind ( ) ; <nl> - plugins . register ( lookup ( metaAccess , \" opaque \" , cls ) , new InvocationPlugin ( ) { <nl> + r . register1 ( \" opaque \" , cls , new InvocationPlugin ( ) { <nl> public boolean apply ( GraphBuilderContext builder , ValueNode value ) { <nl> builder . push ( stackKind , builder . append ( new OpaqueNode ( value ) ) ) ; <nl> return true ; <nl>\n", "msg": "Use GraphBuilderPlugins . Registration mechanism to register GraalDirectivePlugins .\n"}
{"diff_id": 37983, "repo": "bazelbuild/bazel\n", "sha": "833fd12fd86ddc32e89b1b0cff57b248a58dc8ab\n", "time": "2017-03-31T15:11:03Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / packages / PackageFactory . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / packages / PackageFactory . java <nl> public static BuildFileAST parseBuildFile ( PackageIdentifier packageId , ParserInp <nl> try { <nl> / / At this point the package is guaranteed to exist . It may have parse or <nl> / / evaluation errors , resulting in a diminished number of rules . <nl> - prefetchGlobs ( packageId , astAfterPreprocessing . ast , astAfterPreprocessing . preprocessed , <nl> - buildFile , globber , defaultVisibility , makeEnv ) ; <nl> + prefetchGlobs ( <nl> + packageId , <nl> + astAfterPreprocessing . ast , <nl> + astAfterPreprocessing . preprocessed , <nl> + buildFile , <nl> + globber , <nl> + defaultVisibility , <nl> + makeEnv , <nl> + imports ) ; <nl> return evaluateBuildFile ( <nl> workspaceName , <nl> packageId , <nl> private ClassObject newNativeModule ( ) { <nl> builder . build ( ) , \" no native function or rule ' % s ' \" ) ; <nl> } <nl> <nl> - private void buildPkgEnv ( Environment pkgEnv , PackageContext context , RuleFactory ruleFactory ) { <nl> + / * * A function that does nothing and ignores the arguments . * / <nl> + private final BaseFunction noopFunction = <nl> + new BaseFunction ( \" noop \" , FunctionSignature . KWARGS ) { <nl> + @ Override <nl> + public Object call ( Object [ ] arguments , FuncallExpression ast , Environment env ) <nl> + throws EvalException { <nl> + return Runtime . NONE ; <nl> + } <nl> + } ; <nl> + <nl> + / * * @ param fakeEnv specify if we declare no - op functions , or real functions . * / <nl> + private void buildPkgEnv ( <nl> + Environment pkgEnv , <nl> + PackageContext context , <nl> + RuleFactory ruleFactory , <nl> + PackageIdentifier packageId , <nl> + boolean fakeEnv ) { <nl> / / TODO ( bazel - team ) : remove the naked functions that are redundant with the nativeModule , <nl> / / or if not possible , at least make them straight copies from the native module variant . <nl> / / or better , use a common Environment . Frame for these common bindings <nl> private void buildPkgEnv ( Environment pkgEnv , PackageContext context , RuleFactory <nl> <nl> for ( String ruleClass : ruleFactory . getRuleClassNames ( ) ) { <nl> BaseFunction ruleFunction = newRuleFunction ( ruleFactory , ruleClass ) ; <nl> - pkgEnv . setup ( ruleClass , ruleFunction ) ; <nl> + if ( fakeEnv ) { <nl> + pkgEnv . setup ( ruleClass , ruleFunction ) ; <nl> + } else { <nl> + pkgEnv . setup ( ruleClass , noopFunction ) ; <nl> + } <nl> } <nl> <nl> for ( EnvironmentExtension extension : environmentExtensions ) { <nl> extension . update ( pkgEnv ) ; <nl> } <nl> + <nl> + pkgEnv . setupDynamic ( PKG_CONTEXT , context ) ; <nl> + pkgEnv . setupDynamic ( Runtime . PKG_NAME , packageId . getPackageFragment ( ) . getPathString ( ) ) ; <nl> + pkgEnv . setupDynamic ( Runtime . REPOSITORY_NAME , packageId . getRepository ( ) . toString ( ) ) ; <nl> } <nl> <nl> / * * <nl> public void afterDoneLoadingPackage ( Package pkg ) { <nl> PackageContext context = <nl> new PackageContext ( <nl> pkgBuilder , globber , eventHandler , ruleFactory . getAttributeContainerFactory ( ) ) ; <nl> - buildPkgEnv ( pkgEnv , context , ruleFactory ) ; <nl> - pkgEnv . setupDynamic ( PKG_CONTEXT , context ) ; <nl> - pkgEnv . setupDynamic ( Runtime . PKG_NAME , packageId . getPackageFragment ( ) . getPathString ( ) ) ; <nl> - pkgEnv . setupDynamic ( Runtime . REPOSITORY_NAME , packageId . getRepository ( ) . toString ( ) ) ; <nl> + buildPkgEnv ( pkgEnv , context , ruleFactory , packageId , true ) ; <nl> <nl> if ( containsError ) { <nl> pkgBuilder . setContainsErrors ( ) ; <nl> public void afterDoneLoadingPackage ( Package pkg ) { <nl> return pkgBuilder ; <nl> } <nl> <nl> - / * * <nl> - * Visit all targets and expand the globs in parallel . <nl> - * / <nl> - private void prefetchGlobs ( PackageIdentifier packageId , BuildFileAST buildFileAST , <nl> - boolean wasPreprocessed , Path buildFilePath , Globber globber , <nl> - RuleVisibility defaultVisibility , MakeEnvironment . Builder pkgMakeEnv ) <nl> + / * * Visit all targets and expand the globs in parallel . * / <nl> + private void prefetchGlobs ( <nl> + PackageIdentifier packageId , <nl> + BuildFileAST buildFileAST , <nl> + boolean wasPreprocessed , <nl> + Path buildFilePath , <nl> + Globber globber , <nl> + RuleVisibility defaultVisibility , <nl> + MakeEnvironment . Builder pkgMakeEnv , <nl> + Map < String , Extension > imports ) <nl> throws InterruptedException { <nl> if ( wasPreprocessed & & preprocessorFactory . considersGlobs ( ) ) { <nl> / / All the globs have either already been evaluated and they aren ' t in the ast anymore , or <nl> private void prefetchGlobs ( PackageIdentifier packageId , BuildFileAST buildFileAS <nl> Environment . builder ( mutability ) <nl> . setGlobals ( BazelLibrary . GLOBALS ) <nl> . setEventHandler ( NullEventHandler . INSTANCE ) <nl> + . setImportedExtensions ( imports ) <nl> . setPhase ( Phase . LOADING ) <nl> . build ( ) ; <nl> SkylarkUtils . setToolsRepository ( pkgEnv , ruleClassProvider . getToolsRepository ( ) ) ; <nl> private void prefetchGlobs ( PackageIdentifier packageId , BuildFileAST buildFileAS <nl> globber , <nl> NullEventHandler . INSTANCE , <nl> ruleFactory . getAttributeContainerFactory ( ) ) ; <nl> - buildPkgEnv ( pkgEnv , context , ruleFactory ) ; <nl> + buildPkgEnv ( pkgEnv , context , ruleFactory , packageId , false ) ; <nl> + <nl> try { <nl> pkgEnv . update ( \" glob \" , newGlobFunction . apply ( context , / * async = * / true ) ) ; <nl> / / The Fileset function is heavyweight in that it can run glob ( ) . Avoid this during the <nl> / / preloading phase . <nl> - pkgEnv . update ( \" FilesetEntry \" , Runtime . NONE ) ; <nl> + pkgEnv . update ( \" FilesetEntry \" , noopFunction ) ; <nl> + pkgEnv . update ( \" vardef \" , noopFunction ) ; <nl> } catch ( EvalException e ) { <nl> throw new AssertionError ( e ) ; <nl> } <nl>\n", "msg": "Improve glob prefetching performance by providing a more realistic environment .\n"}
{"diff_id": 38003, "repo": "oracle/graal\n", "sha": "89f4c62464e7023223536434b46ecdbc86bc1fb3\n", "time": "2015-09-23T00:38:07Z\n", "diff": "mmm a / graal / com . oracle . graal . graphbuilderconf / src / com / oracle / graal / graphbuilderconf / InvocationPlugins . java <nl> ppp b / graal / com . oracle . graal . graphbuilderconf / src / com / oracle / graal / graphbuilderconf / InvocationPlugins . java <nl> <nl> import java . util . * ; <nl> import java . util . stream . * ; <nl> <nl> + import jdk . internal . jvmci . common . JVMCIError ; <nl> import jdk . internal . jvmci . meta . * ; <nl> <nl> import com . oracle . graal . graph . Node ; <nl> public Registration ( InvocationPlugins plugins , Class < ? > declaringClass ) { <nl> this . declaringClass = declaringClass ; <nl> } <nl> <nl> + / * * <nl> + * Creates an object for registering { @ link InvocationPlugin } s for methods declared by a <nl> + * given class . <nl> + * <nl> + * @ param plugins where to register the plugins <nl> + * @ param declaringClassName the name of the class class declaring the methods for which <nl> + * plugins will be registered via this object <nl> + * / <nl> + public Registration ( InvocationPlugins plugins , String declaringClassName ) { <nl> + this . plugins = plugins ; <nl> + try { <nl> + this . declaringClass = Class . forName ( declaringClassName ) ; <nl> + } catch ( ClassNotFoundException ex ) { <nl> + throw JVMCIError . shouldNotReachHere ( ex ) ; <nl> + } <nl> + } <nl> + <nl> / * * <nl> * Configures this registration to allow or disallow overwriting of invocation plugins . <nl> * / <nl>\n", "msg": "Allow invocation plugin registry to be created with class name instead of java . lang . Class\n"}
{"diff_id": 38079, "repo": "jenkinsci/jenkins\n", "sha": "dfacf6eab5a1f539c5d8936e097bec8b1eabcbce\n", "time": "2009-09-10T20:40:25Z\n", "diff": "mmm a / core / src / main / java / hudson / model / AbstractItem . java <nl> ppp b / core / src / main / java / hudson / model / AbstractItem . java <nl> public synchronized void delete ( ) throws IOException , InterruptedException { <nl> * Does the real job of deleting the item . <nl> * / <nl> protected void performDelete ( ) throws IOException , InterruptedException { <nl> + getConfigFile ( ) . delete ( ) ; <nl> Util . deleteRecursive ( getRootDir ( ) ) ; <nl> } <nl> <nl>\n", "msg": "delete the config file first , so that even if the request doesn ' t fully complete , the job won ' t be resurrected .\n"}
{"diff_id": 38475, "repo": "bazelbuild/bazel\n", "sha": "adda51294125a335e9b3fad9c72c00b8de54b766\n", "time": "2017-08-29T16:53:08Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / syntax / Environment . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / syntax / Environment . java <nl> <nl> * was defined . When the function is called from other { @ code Environment } s ( possibly <nl> * simultaneously ) , that global frame must already be frozen ; a new local { @ code Frame } is created <nl> * to represent the lexical scope of the function . <nl> + * <nl> + * A { @ code Frame } can also be constructed in a two - phase process . To do this , call the nullary <nl> + * constructor to create an uninitialized { @ code Frame } , then call { @ link # initialize } . It is <nl> + * illegal to use any other method in - between these two calls , or to call { @ link # initialize } on <nl> + * an already initialized { @ code Frame } . <nl> * / <nl> public static final class Frame implements Freezable { <nl> <nl> - private final Mutability mutability ; <nl> + / * * <nl> + * Final , except that it may be initialized after instantiation . Null mutability indicates that <nl> + * this Frame is uninitialized . <nl> + * / <nl> + @ Nullable <nl> + private Mutability mutability ; <nl> <nl> + / * * Final , except that it may be initialized after instantiation . * / <nl> @ Nullable <nl> - private final Frame parent ; <nl> + private Frame parent ; <nl> <nl> - / / If this frame is a global frame , the label for the corresponding target , e . g . / / foo : bar . bzl . <nl> + / * * <nl> + * If this frame is a global frame , the label for the corresponding target , e . g . { @ code <nl> + * / / foo : bar . bzl } . <nl> + * <nl> + * < p > Final , except that it may be initialized after instantiation . <nl> + * / <nl> @ Nullable <nl> - private final Label label ; <nl> + private Label label ; <nl> <nl> private final Map < String , Object > bindings ; <nl> <nl> + / * * Constructs an uninitialized instance ; caller must call { @ link # initialize } before use . * / <nl> + public Frame ( ) { <nl> + this . mutability = null ; <nl> + this . parent = null ; <nl> + this . label = null ; <nl> + this . bindings = new LinkedHashMap < > ( ) ; <nl> + } <nl> + <nl> + public Frame ( Mutability mutability , @ Nullable Frame parent , @ Nullable Label label ) { <nl> + this . mutability = Preconditions . checkNotNull ( mutability ) ; <nl> + this . parent = parent ; <nl> + this . label = label ; <nl> + this . bindings = new LinkedHashMap < > ( ) ; <nl> + } <nl> + <nl> public Frame ( Mutability mutability ) { <nl> this ( mutability , null , null ) ; <nl> } <nl> public Frame ( Mutability mutability , Frame parent ) { <nl> this ( mutability , parent , null ) ; <nl> } <nl> <nl> - public Frame ( Mutability mutability , Frame parent , Label label ) { <nl> - this . mutability = mutability ; <nl> - this . parent = parent ; <nl> - this . label = label ; <nl> - this . bindings = new LinkedHashMap < > ( ) ; <nl> + private void checkInitialized ( ) { <nl> + Preconditions . checkNotNull ( mutability , \" Attempted to use Frame before initializing it \" ) ; <nl> } <nl> <nl> - public Frame ( Mutability mutability , Frame parent , Label label , Map < String , Object > bindings ) { <nl> - this ( mutability , parent , label ) ; <nl> + public void initialize ( <nl> + Mutability mutability , @ Nullable Frame parent , <nl> + @ Nullable Label label , Map < String , Object > bindings ) { <nl> + Preconditions . checkState ( this . mutability = = null , <nl> + \" Attempted to initialize an already initialized Frame \" ) ; <nl> + this . mutability = Preconditions . checkNotNull ( mutability ) ; <nl> + this . parent = parent ; <nl> + this . label = label ; <nl> this . bindings . putAll ( bindings ) ; <nl> } <nl> <nl> public Frame ( Mutability mutability , Frame parent , Label label , Map < String , Objec <nl> * given value . <nl> * / <nl> public Frame withLabel ( Label label ) { <nl> + checkInitialized ( ) ; <nl> return new Frame ( mutability , this , label ) ; <nl> } <nl> <nl> public Frame withLabel ( Label label ) { <nl> * / <nl> @ Override <nl> public Mutability mutability ( ) { <nl> + checkInitialized ( ) ; <nl> return mutability ; <nl> } <nl> <nl> / * * Returns the parent { @ code Frame } , if it exists . * / <nl> @ Nullable <nl> public Frame getParent ( ) { <nl> + checkInitialized ( ) ; <nl> return parent ; <nl> } <nl> <nl> public Frame getParent ( ) { <nl> * / <nl> @ Nullable <nl> public Label getLabel ( ) { <nl> + checkInitialized ( ) ; <nl> return label ; <nl> } <nl> <nl> public Label getLabel ( ) { <nl> * / <nl> @ Nullable <nl> public Label getTransitiveLabel ( ) { <nl> + checkInitialized ( ) ; <nl> if ( label ! = null ) { <nl> return label ; <nl> } else if ( parent ! = null ) { <nl> public Label getTransitiveLabel ( ) { <nl> * invalidated by any subsequent modification to the { @ code Frame } ' s bindings . <nl> * / <nl> public Map < String , Object > getBindings ( ) { <nl> + checkInitialized ( ) ; <nl> return Collections . unmodifiableMap ( bindings ) ; <nl> } <nl> <nl> public Label getTransitiveLabel ( ) { <nl> * taking into account shadowing precedence . <nl> * / <nl> public Map < String , Object > getTransitiveBindings ( ) { <nl> + checkInitialized ( ) ; <nl> / / Can ' t use ImmutableMap . Builder because it doesn ' t allow duplicates . <nl> HashMap < String , Object > collectedBindings = new HashMap < > ( ) ; <nl> accumulateTransitiveBindings ( collectedBindings ) ; <nl> public Label getTransitiveLabel ( ) { <nl> } <nl> <nl> private void accumulateTransitiveBindings ( Map < String , Object > accumulator ) { <nl> + checkInitialized ( ) ; <nl> / / Put parents first , so child bindings take precedence . <nl> if ( parent ! = null ) { <nl> parent . accumulateTransitiveBindings ( accumulator ) ; <nl> private void accumulateTransitiveBindings ( Map < String , Object > accumulator ) { <nl> * @ return the value bound to the variable , or null if no binding is found <nl> * / <nl> public Object get ( String varname ) { <nl> + checkInitialized ( ) ; <nl> if ( bindings . containsKey ( varname ) ) { <nl> return bindings . get ( varname ) ; <nl> } <nl> public Object get ( String varname ) { <nl> * / <nl> public void put ( Environment env , String varname , Object value ) <nl> throws MutabilityException { <nl> + checkInitialized ( ) ; <nl> Mutability . checkMutable ( this , env . mutability ( ) ) ; <nl> bindings . put ( varname , value ) ; <nl> } <nl> public void put ( Environment env , String varname , Object value ) <nl> * be part of the public interface . <nl> * / <nl> void remove ( Environment env , String varname ) throws MutabilityException { <nl> + checkInitialized ( ) ; <nl> Mutability . checkMutable ( this , env . mutability ( ) ) ; <nl> bindings . remove ( varname ) ; <nl> } <nl> <nl> @ Override <nl> public String toString ( ) { <nl> - return String . format ( \" < Frame % s > \" , mutability ( ) ) ; <nl> + if ( mutability = = null ) { <nl> + return \" < Uninitialized Frame > \" ; <nl> + } else { <nl> + return String . format ( \" < Frame % s > \" , mutability ( ) ) ; <nl> + } <nl> } <nl> } <nl> <nl>\n", "msg": "Add a way to construct Frames in a two - step process\n"}
{"diff_id": 38661, "repo": "oracle/graal\n", "sha": "552f2ec57765db6c55ba72869fe81613e41b6db1\n", "time": "2015-04-09T04:59:42Z\n", "diff": "mmm a / graal / com . oracle . graal . options / src / com / oracle / graal / options / OptionUtils . java <nl> ppp b / graal / com . oracle . graal . options / src / com / oracle / graal / options / OptionUtils . java <nl> public static boolean parseOption ( SortedMap < String , OptionDescriptor > options , S <nl> } else if ( optionType = = Double . class ) { <nl> value = Double . parseDouble ( valueString ) ; <nl> } else if ( optionType = = Integer . class ) { <nl> - value = Integer . parseInt ( valueString ) ; <nl> + value = Integer . valueOf ( ( int ) parseLong ( valueString ) ) ; <nl> + } else if ( optionType = = Long . class ) { <nl> + value = Long . valueOf ( parseLong ( valueString ) ) ; <nl> } else if ( optionType = = String . class ) { <nl> value = valueString ; <nl> } <nl> public static boolean parseOption ( SortedMap < String , OptionDescriptor > options , S <nl> return true ; <nl> } <nl> <nl> + private static long parseLong ( String v ) { <nl> + String valueString = v . toLowerCase ( ) ; <nl> + long scale = 1 ; <nl> + if ( valueString . endsWith ( \" k \" ) ) { <nl> + scale = 1024L ; <nl> + } else if ( valueString . endsWith ( \" m \" ) ) { <nl> + scale = 1024L * 1024L ; <nl> + } else if ( valueString . endsWith ( \" g \" ) ) { <nl> + scale = 1024L * 1024L * 1024L ; <nl> + } else if ( valueString . endsWith ( \" t \" ) ) { <nl> + scale = 1024L * 1024L * 1024L * 1024L ; <nl> + } <nl> + <nl> + if ( scale ! = 1 ) { <nl> + / * Remove trailing scale character . * / <nl> + valueString = valueString . substring ( 0 , valueString . length ( ) - 1 ) ; <nl> + } <nl> + <nl> + return Long . parseLong ( valueString ) * scale ; <nl> + } <nl> + <nl> public static void printNoMatchMessage ( SortedMap < String , OptionDescriptor > options , String optionName , String prefix ) { <nl> OptionDescriptor desc = options . get ( optionName ) ; <nl> if ( desc ! = null ) { <nl>\n", "msg": "Allow scaling factors in integer options ; add support for Long values in addition to Integer values\n"}
{"diff_id": 38706, "repo": "eclipse-vertx/vert.x\n", "sha": "dc1157b3bb2fba6b23f2af4e3999c15bcc91554c\n", "time": "2017-09-20T08:15:33Z\n", "diff": "mmm a / src / test / java / io / vertx / test / core / DatagramTest . java <nl> ppp b / src / test / java / io / vertx / test / core / DatagramTest . java <nl> public void testSendAfterCloseFails ( ) { <nl> <nl> @ Test <nl> public void testBroadcast ( ) { <nl> + if ( USE_NATIVE_TRANSPORT ) { <nl> + return ; <nl> + } <nl> peer1 = vertx . createDatagramSocket ( new DatagramSocketOptions ( ) . setBroadcast ( true ) ) ; <nl> peer2 = vertx . createDatagramSocket ( new DatagramSocketOptions ( ) . setBroadcast ( true ) ) ; <nl> peer2 . exceptionHandler ( t - > fail ( t . getMessage ( ) ) ) ; <nl> public void testPause ( ) { <nl> <nl> @ Test <nl> public void testMulticastJoinLeave ( ) throws Exception { <nl> + if ( USE_NATIVE_TRANSPORT ) { <nl> + return ; <nl> + } <nl> Buffer buffer = TestUtils . randomBuffer ( 128 ) ; <nl> String groupAddress = \" 230 . 0 . 0 . 1 \" ; <nl> String iface = NetworkInterface . getByInetAddress ( InetAddress . getByName ( \" 127 . 0 . 0 . 1 \" ) ) . getName ( ) ; <nl>\n", "msg": "Exclude broadcast / multicast datagram tests for native transports\n"}
{"diff_id": 39868, "repo": "SeleniumHQ/selenium\n", "sha": "bbd077478864f5f5cd18162d6eaeee53397982fd\n", "time": "2018-09-06T12:13:26Z\n", "diff": "mmm a / java / client / src / org / openqa / selenium / remote / http / W3CHttpCommandCodec . java <nl> ppp b / java / client / src / org / openqa / selenium / remote / http / W3CHttpCommandCodec . java <nl> public W3CHttpCommandCodec ( ) { <nl> \" if ( ! form . ownerDocument ) { throw Error ( ' Unable to find owning document ' ) ; } \\ n \" + <nl> \" var e = form . ownerDocument . createEvent ( ' Event ' ) ; \\ n \" + <nl> \" e . initEvent ( ' submit ' , true , true ) ; \\ n \" + <nl> - \" if ( form . dispatchEvent ( e ) ) { HTMLFormElement . prototype . submit . call ( form ) } \\ n \" , <nl> + \" if ( form . ownerDocument . dispatchEvent ( e ) ) { HTMLFormElement . prototype . submit . call ( form ) } \\ n \" , <nl> asElement ( parameters . get ( \" id \" ) ) ) ; <nl> <nl> default : <nl>\n", "msg": "[ java ] Dispatch form \" submit \" event on window to prevent a form double submission\n"}
{"diff_id": 39912, "repo": "bazelbuild/bazel\n", "sha": "9c0fceb531a240e19f0d583025bea0e069ba1fc9\n", "time": "2016-11-02T08:28:36Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / rules / proto / ProtoCompileActionBuilder . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / proto / ProtoCompileActionBuilder . java <nl> private FilesToRunProvider getLangPluginTarget ( ) { <nl> * / <nl> public static void registerActions ( <nl> RuleContext ruleContext , <nl> - Map < String , ToolchainInvocation > toolchainInvocations , <nl> + ImmutableMap < String , ToolchainInvocation > toolchainInvocations , <nl> SupportData supportData , <nl> Iterable < Artifact > outputs , <nl> String flavorName , <nl> public static void registerActions ( <nl> * / <nl> @ VisibleForTesting <nl> static CustomCommandLine createCommandLineFromToolchains ( <nl> - Map < String , ToolchainInvocation > toolchainInvocations , <nl> + ImmutableMap < String , ToolchainInvocation > toolchainInvocations , <nl> SupportData supportData , <nl> boolean allowServices , <nl> ImmutableList < String > protocOpts ) { <nl>\n", "msg": "ProtoCompileActionBuilder takes ImmutableMap for toolchains , which has a predictable iteration order .\n"}
{"diff_id": 39926, "repo": "jenkinsci/jenkins\n", "sha": "f7840f428f0ae3aac688858228bea980bc1846a6\n", "time": "2014-09-19T20:09:42Z\n", "diff": "mmm a / core / src / main / java / jenkins / security / CallableDirectionChecker . java <nl> ppp b / core / src / main / java / jenkins / security / CallableDirectionChecker . java <nl> <nl> * @ since TODO <nl> * / <nl> public class CallableDirectionChecker extends CallableDecorator { <nl> + <nl> + private static final String BYPASS_PROP = \" jenkins . security . CallableDirectionChecker . allowUnmarkedCallables \" ; <nl> + <nl> private final SlaveComputer computer ; <nl> <nl> public CallableDirectionChecker ( SlaveComputer computer ) { <nl> public CallableDirectionChecker ( SlaveComputer computer ) { <nl> @ Override <nl> public < V , T extends Throwable > Callable < V , T > userRequest ( Callable < V , T > op , Callable < V , T > stem ) { <nl> Class < ? > c = op . getClass ( ) ; <nl> + String name = c . getName ( ) ; <nl> <nl> - if ( c . getName ( ) . startsWith ( \" hudson . remoting \" ) ) / / TODO probably insecure <nl> + if ( name . startsWith ( \" hudson . remoting \" ) ) { / / TODO probably insecure <nl> return stem ; / / lower level services provided by remoting , such IOSyncer , RPCRequest , Ping , etc . that we allow <nl> + } <nl> <nl> if ( c . isAnnotationPresent ( SlaveToMaster . class ) ) { <nl> return stem ; / / known to be safe <nl> } <nl> <nl> + String node = computer . getName ( ) ; <nl> if ( c . isAnnotationPresent ( MasterToSlave . class ) ) { <nl> - throw new SecurityException ( String . format ( \" Invocation of % s is prohibited \" , c ) ) ; <nl> + throw new SecurityException ( \" Sending \" + name + \" from \" + node + \" to master is prohibited \" ) ; <nl> } else { <nl> - / / no annotation provided , so we don ' t know . <nl> - / / to err on the correctness we ' d let it pass with reporting , which <nl> - / / provides auditing trail . <nl> - LOGGER . log ( Level . WARNING , \" Unchecked callable from { 0 } : { 1 } \" , new Object [ ] { computer . getName ( ) , c } ) ; <nl> - return stem ; <nl> + / / No annotation provided , so we do not know whether it is safe or not . <nl> + if ( Boolean . getBoolean ( BYPASS_PROP ) ) { <nl> + LOGGER . log ( Level . FINE , \" Allowing { 0 } to be sent from { 1 } to master \" , new Object [ ] { name , node } ) ; <nl> + return stem ; <nl> + } else if ( Boolean . getBoolean ( BYPASS_PROP + \" . \" + name ) ) { <nl> + LOGGER . log ( Level . FINE , \" Explicitly allowing { 0 } to be sent from { 1 } to master \" , new Object [ ] { name , node } ) ; <nl> + return stem ; <nl> + } else { <nl> + throw new SecurityException ( \" Sending from \" + node + \" to master is prohibited unless you run with : - D \" + BYPASS_PROP + \" . \" + name ) ; <nl> + } <nl> } <nl> } <nl> <nl>\n", "msg": "Enforcing callable checking by default , with system properties to selectively or globally disable .\n"}
{"diff_id": 39959, "repo": "jenkinsci/jenkins\n", "sha": "cfa6087d0f5354c9fbdb8a0e8d86a25282bb2723\n", "time": "2007-04-27T05:27:39Z\n", "diff": "mmm a / core / src / main / java / hudson / model / Run . java <nl> ppp b / core / src / main / java / hudson / model / Run . java <nl> public void setResult ( Result r ) { <nl> / / result can only get worse <nl> if ( result = = null ) { <nl> result = r ; <nl> - LOGGER . info ( toString ( ) + \" : result is set to \" + r + \" by \" + caller ) ; <nl> + LOGGER . fine ( toString ( ) + \" : result is set to \" + r + \" by \" + caller ) ; <nl> } else { <nl> if ( r . isWorseThan ( result ) ) { <nl> - LOGGER . info ( toString ( ) + \" : result is set to \" + r + \" by \" + caller ) ; <nl> + LOGGER . fine ( toString ( ) + \" : result is set to \" + r + \" by \" + caller ) ; <nl> result = r ; <nl> } <nl> } <nl>\n", "msg": "reducing these log levels because they tend to fill up the log view .\n"}
{"diff_id": 40166, "repo": "eclipse-vertx/vert.x\n", "sha": "728320045ddac3f4cbcab9ac3a57b2834a9a4886\n", "time": "2018-04-08T08:02:06Z\n", "diff": "mmm a / src / main / java / io / vertx / core / http / impl / HttpClientImpl . java <nl> ppp b / src / main / java / io / vertx / core / http / impl / HttpClientImpl . java <nl> void getConnectionForRequest ( String peerHost , boolean ssl , int port , String host <nl> / * * <nl> * @ return the vertx , for use in package related classes only . <nl> * / <nl> - VertxInternal getVertx ( ) { <nl> + public VertxInternal getVertx ( ) { <nl> return vertx ; <nl> } <nl> <nl>\n", "msg": "Provide access to the Vertx instance so WebClient can use it\n"}
{"diff_id": 40300, "repo": "spring-projects/spring-framework\n", "sha": "ba946c08dd4a8c010ff82126476a4c8d994ec8a4\n", "time": "2010-09-06T22:56:05Z\n", "diff": "mmm a / org . springframework . web . portlet / src / main / java / org / springframework / web / portlet / DispatcherPortlet . java <nl> ppp b / org . springframework . web . portlet / src / main / java / org / springframework / web / portlet / DispatcherPortlet . java <nl> <nl> import javax . portlet . RenderResponse ; <nl> import javax . portlet . ResourceRequest ; <nl> import javax . portlet . ResourceResponse ; <nl> + import javax . portlet . StateAwareResponse ; <nl> import javax . portlet . UnavailableException ; <nl> <nl> import org . apache . commons . logging . Log ; <nl> protected void doActionService ( ActionRequest request , ActionResponse response ) t <nl> triggerAfterActionCompletion ( mappedHandler , interceptorIndex , processedRequest , response , ex ) ; <nl> / / Forward the exception to the render phase to be displayed . <nl> try { <nl> - / / Copy all parameters unless overridden in the action handler . <nl> - Enumeration < String > paramNames = request . getParameterNames ( ) ; <nl> - while ( paramNames . hasMoreElements ( ) ) { <nl> - String paramName = paramNames . nextElement ( ) ; <nl> - String [ ] paramValues = request . getParameterValues ( paramName ) ; <nl> - if ( paramValues ! = null & & ! response . getRenderParameterMap ( ) . containsKey ( paramName ) ) { <nl> - response . setRenderParameter ( paramName , paramValues ) ; <nl> - } <nl> - } <nl> - response . setRenderParameter ( ACTION_EXCEPTION_RENDER_PARAMETER , Boolean . TRUE . toString ( ) ) ; <nl> - request . getPortletSession ( ) . setAttribute ( ACTION_EXCEPTION_SESSION_ATTRIBUTE , ex ) ; <nl> + exposeActionException ( request , response , ex ) ; <nl> logger . debug ( \" Caught exception during action phase - forwarding to render phase \" , ex ) ; <nl> } <nl> catch ( IllegalStateException ex2 ) { <nl> protected void doEventService ( EventRequest request , EventResponse response ) thro <nl> triggerAfterEventCompletion ( mappedHandler , interceptorIndex , request , response , ex ) ; <nl> / / Forward the exception to the render phase to be displayed . <nl> try { <nl> - response . setRenderParameter ( ACTION_EXCEPTION_RENDER_PARAMETER , Boolean . TRUE . toString ( ) ) ; <nl> - request . getPortletSession ( ) . setAttribute ( ACTION_EXCEPTION_SESSION_ATTRIBUTE , ex ) ; <nl> + exposeActionException ( request , response , ex ) ; <nl> logger . debug ( \" Caught exception during event phase - forwarding to render phase \" , ex ) ; <nl> } <nl> catch ( IllegalStateException ex2 ) { <nl> protected HandlerAdapter getHandlerAdapter ( Object handler ) throws PortletExcepti <nl> \" ] : Does your handler implement a supported interface like Controller ? \" ) ; <nl> } <nl> <nl> + / * * <nl> + * Expose the given action exception to the given response . <nl> + * @ param request current portlet request <nl> + * @ param response current portlet response <nl> + * @ param ex the action exception ( may also come from an event phase ) <nl> + * / <nl> + protected void exposeActionException ( PortletRequest request , StateAwareResponse response , Exception ex ) { <nl> + / / Copy all parameters unless overridden in the action handler . <nl> + Enumeration < String > paramNames = request . getParameterNames ( ) ; <nl> + while ( paramNames . hasMoreElements ( ) ) { <nl> + String paramName = paramNames . nextElement ( ) ; <nl> + String [ ] paramValues = request . getParameterValues ( paramName ) ; <nl> + if ( paramValues ! = null & & ! response . getRenderParameterMap ( ) . containsKey ( paramName ) ) { <nl> + response . setRenderParameter ( paramName , paramValues ) ; <nl> + } <nl> + } <nl> + response . setRenderParameter ( ACTION_EXCEPTION_RENDER_PARAMETER , Boolean . TRUE . toString ( ) ) ; <nl> + request . getPortletSession ( ) . setAttribute ( ACTION_EXCEPTION_SESSION_ATTRIBUTE , ex ) ; <nl> + } <nl> + <nl> <nl> / * * <nl> * Render the given ModelAndView . This is the last stage in handling a request . <nl>\n", "msg": "copy event parameters to render parameters in case of an action exception as well ( SPR - 7495 )\n"}
{"diff_id": 40460, "repo": "oracle/graal\n", "sha": "599d2708ddc7c276ad98fe3897e22428f9be8620\n", "time": "2012-02-10T12:58:04Z\n", "diff": "mmm a / graal / com . oracle . max . graal . lir / src / com / oracle / max / graal / lir / asm / TargetMethodAssembler . java <nl> ppp b / graal / com . oracle . max . graal . lir / src / com / oracle / max / graal / lir / asm / TargetMethodAssembler . java <nl> public CiTargetMethod finishTargetMethod ( Object name , boolean isStub ) { <nl> Debug . metric ( \" DataPatches \" ) . add ( targetMethod . dataReferences . size ( ) ) ; <nl> Debug . metric ( \" ExceptionHandlersEmitted \" ) . add ( targetMethod . exceptionHandlers . size ( ) ) ; <nl> <nl> - Debug . log ( \" Finished target method % s , isStub % d \" , name , isStub ) ; <nl> + Debug . log ( \" Finished target method % s , isStub % b \" , name , isStub ) ; <nl> / * <nl> if ( GraalOptions . PrintAssembly & & ! TTY . isSuppressed ( ) & & ! isStub ) { <nl> Util . printSection ( \" Target Method \" , Util . SECTION_CHARACTER ) ; <nl>\n", "msg": "explicitly exclude com . oracle . max . graal . tests from graal class path to make JUnit tests work\n"}
{"diff_id": 40480, "repo": "bazelbuild/bazel\n", "sha": "dac4d5189e4ef9dbb62dcac835ed4a8e90bf3504\n", "time": "2018-05-02T23:28:00Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / query2 / SkyQueryEnvironment . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / query2 / SkyQueryEnvironment . java <nl> public boolean apply ( Target target ) { <nl> @ ThreadSafe <nl> @ Override <nl> public ThreadSafeMutableSet < Target > getBuildFiles ( <nl> - QueryExpression caller , <nl> - ThreadSafeMutableSet < Target > nodes , <nl> - boolean buildFiles , <nl> - boolean loads ) <nl> - throws QueryException { <nl> + QueryExpression caller , ThreadSafeMutableSet < Target > nodes , boolean buildFiles , boolean loads ) <nl> + throws QueryException , InterruptedException { <nl> ThreadSafeMutableSet < Target > dependentFiles = createThreadSafeMutableSet ( ) ; <nl> Set < PackageIdentifier > seenPackages = new HashSet < > ( ) ; <nl> / / Keep track of seen labels , to avoid adding a fake subinclude label that also exists as a <nl>\n", "msg": "Declare QueryEnvironment # getBuildFiles to throw InterruptedException\n"}
{"diff_id": 40524, "repo": "oracle/graal\n", "sha": "e8b0489b4e69108949049e887145d45293eff0e5\n", "time": "2020-09-29T14:13:17Z\n", "diff": "mmm a / sulong / projects / com . oracle . truffle . llvm . runtime / src / com / oracle / truffle / llvm / runtime / interop / LLVMForeignCallNode . java <nl> ppp b / sulong / projects / com . oracle . truffle . llvm . runtime / src / com / oracle / truffle / llvm / runtime / interop / LLVMForeignCallNode . java <nl> public LLVMForeignCallNode ( LLVMLanguage language , LLVMFunctionDescriptor functio <nl> this . returnBaseType = getReturnBaseType ( interopType ) ; <nl> this . getStack = LLVMGetStackFromThreadNode . create ( ) ; <nl> this . callNode = DirectCallNode . create ( getCallTarget ( function ) ) ; <nl> - this . callNode . forceInlining ( ) ; <nl> this . prepareValueForEscape = LLVMDataEscapeNode . create ( function . getLLVMFunction ( ) . getType ( ) . getReturnType ( ) ) ; <nl> this . packArguments = PackForeignArgumentsNodeGen . create ( function . getLLVMFunction ( ) . getType ( ) , interopType , sourceType ) ; <nl> } <nl>\n", "msg": "Do not force - inline call to function in foreign call node\n"}
{"diff_id": 40615, "repo": "material-components/material-components-android\n", "sha": "5c9e250c46c2cf891f69fe4178cb845678172fd6\n", "time": "2020-08-04T01:32:38Z\n", "diff": "mmm a / lib / java / com / google / android / material / tabs / TabLayoutMediator . java <nl> ppp b / lib / java / com / google / android / material / tabs / TabLayoutMediator . java <nl> public void detach ( ) { <nl> attached = false ; <nl> } <nl> <nl> + / * * <nl> + * Returns whether the { @ link TabLayout } and the { @ link ViewPager2 } are linked together . <nl> + * / <nl> + public boolean isAttached ( ) { <nl> + return attached ; <nl> + } <nl> + <nl> @ SuppressWarnings ( \" WeakerAccess \" ) <nl> void populateTabsFromPagerAdapter ( ) { <nl> tabLayout . removeAllTabs ( ) ; <nl>\n", "msg": "[ Tab ] Added getter in TabLayoutMediator to return whether a TabLayout and a ViewPager2 are linked together .\n"}
{"diff_id": 40616, "repo": "elastic/elasticsearch\n", "sha": "3b987f9ee080bd0a9405d60f56fc06ab706f6721\n", "time": "2011-08-12T11:58:06Z\n", "diff": "mmm a / modules / test / integration / src / test / java / org / elasticsearch / test / integration / gateway / local / SimpleRecoveryLocalGatewayTests . java <nl> ppp b / modules / test / integration / src / test / java / org / elasticsearch / test / integration / gateway / local / SimpleRecoveryLocalGatewayTests . java <nl> <nl> <nl> import org . elasticsearch . action . admin . cluster . health . ClusterHealthResponse ; <nl> import org . elasticsearch . action . admin . cluster . health . ClusterHealthStatus ; <nl> + import org . elasticsearch . action . admin . indices . status . IndexShardStatus ; <nl> + import org . elasticsearch . action . admin . indices . status . IndicesStatusResponse ; <nl> + import org . elasticsearch . action . admin . indices . status . ShardStatus ; <nl> + import org . elasticsearch . common . settings . ImmutableSettings ; <nl> import org . elasticsearch . gateway . Gateway ; <nl> import org . elasticsearch . node . Node ; <nl> import org . elasticsearch . node . internal . InternalNode ; <nl> <nl> assertThat ( node1 . client ( ) . prepareCount ( ) . setQuery ( matchAllQuery ( ) ) . execute ( ) . actionGet ( ) . count ( ) , equalTo ( 3l ) ) ; <nl> } <nl> } <nl> + <nl> + @ Test public void testReusePeerRecovery ( ) throws Exception { <nl> + buildNode ( \" node1 \" , settingsBuilder ( ) . put ( \" gateway . type \" , \" local \" ) . build ( ) ) ; <nl> + buildNode ( \" node2 \" , settingsBuilder ( ) . put ( \" gateway . type \" , \" local \" ) . build ( ) ) ; <nl> + buildNode ( \" node3 \" , settingsBuilder ( ) . put ( \" gateway . type \" , \" local \" ) . build ( ) ) ; <nl> + buildNode ( \" node4 \" , settingsBuilder ( ) . put ( \" gateway . type \" , \" local \" ) . build ( ) ) ; <nl> + cleanAndCloseNodes ( ) ; <nl> + <nl> + <nl> + ImmutableSettings . Builder settings = ImmutableSettings . settingsBuilder ( ) <nl> + . put ( \" action . admin . cluster . node . shutdown . delay \" , \" 10ms \" ) <nl> + . put ( \" gateway . recover_after_nodes \" , 4 ) <nl> + . put ( \" gateway . type \" , \" local \" ) ; <nl> + startNode ( \" node1 \" , settings ) ; <nl> + startNode ( \" node2 \" , settings ) ; <nl> + startNode ( \" node3 \" , settings ) ; <nl> + startNode ( \" node4 \" , settings ) ; <nl> + <nl> + logger . info ( \" - - > indexing docs \" ) ; <nl> + for ( int i = 0 ; i < 1000 ; i + + ) { <nl> + client ( \" node1 \" ) . prepareIndex ( \" test \" , \" type \" ) . setSource ( \" field \" , \" value \" ) . execute ( ) . actionGet ( ) ; <nl> + if ( ( i % 200 ) = = 0 ) { <nl> + client ( \" node1 \" ) . admin ( ) . indices ( ) . prepareFlush ( ) . execute ( ) . actionGet ( ) ; <nl> + } <nl> + } <nl> + logger . info ( \" Running Cluster Health \" ) ; <nl> + ClusterHealthResponse clusterHealth = client ( \" node1 \" ) . admin ( ) . cluster ( ) . health ( clusterHealthRequest ( ) . waitForGreenStatus ( ) . waitForRelocatingShards ( 0 ) ) . actionGet ( ) ; <nl> + logger . info ( \" Done Cluster Health , status \" + clusterHealth . status ( ) ) ; <nl> + assertThat ( clusterHealth . timedOut ( ) , equalTo ( false ) ) ; <nl> + assertThat ( clusterHealth . status ( ) , equalTo ( ClusterHealthStatus . GREEN ) ) ; <nl> + <nl> + logger . info ( \" - - > shutting down the nodes \" ) ; <nl> + client ( \" node1 \" ) . admin ( ) . cluster ( ) . prepareNodesShutdown ( ) . setDelay ( \" 10ms \" ) . setExit ( false ) . execute ( ) . actionGet ( ) ; <nl> + Thread . sleep ( 2000 ) ; <nl> + logger . info ( \" - - > start the nodes back up \" ) ; <nl> + startNode ( \" node1 \" , settings ) ; <nl> + startNode ( \" node2 \" , settings ) ; <nl> + startNode ( \" node3 \" , settings ) ; <nl> + startNode ( \" node4 \" , settings ) ; <nl> + <nl> + logger . info ( \" Running Cluster Health \" ) ; <nl> + clusterHealth = client ( \" node1 \" ) . admin ( ) . cluster ( ) . health ( clusterHealthRequest ( ) . waitForGreenStatus ( ) . waitForActiveShards ( 10 ) ) . actionGet ( ) ; <nl> + logger . info ( \" Done Cluster Health , status \" + clusterHealth . status ( ) ) ; <nl> + assertThat ( clusterHealth . timedOut ( ) , equalTo ( false ) ) ; <nl> + assertThat ( clusterHealth . status ( ) , equalTo ( ClusterHealthStatus . GREEN ) ) ; <nl> + <nl> + logger . info ( \" - - > shutting down the nodes \" ) ; <nl> + client ( \" node1 \" ) . admin ( ) . cluster ( ) . prepareNodesShutdown ( ) . setDelay ( \" 10ms \" ) . setExit ( false ) . execute ( ) . actionGet ( ) ; <nl> + Thread . sleep ( 2000 ) ; <nl> + <nl> + logger . info ( \" - - > start the nodes back up \" ) ; <nl> + startNode ( \" node1 \" , settings ) ; <nl> + startNode ( \" node2 \" , settings ) ; <nl> + startNode ( \" node3 \" , settings ) ; <nl> + startNode ( \" node4 \" , settings ) ; <nl> + <nl> + logger . info ( \" Running Cluster Health \" ) ; <nl> + clusterHealth = client ( \" node1 \" ) . admin ( ) . cluster ( ) . health ( clusterHealthRequest ( ) . waitForGreenStatus ( ) . waitForActiveShards ( 10 ) ) . actionGet ( ) ; <nl> + logger . info ( \" Done Cluster Health , status \" + clusterHealth . status ( ) ) ; <nl> + assertThat ( clusterHealth . timedOut ( ) , equalTo ( false ) ) ; <nl> + assertThat ( clusterHealth . status ( ) , equalTo ( ClusterHealthStatus . GREEN ) ) ; <nl> + <nl> + IndicesStatusResponse statusResponse = client ( \" node1 \" ) . admin ( ) . indices ( ) . prepareStatus ( \" test \" ) . setRecovery ( true ) . execute ( ) . actionGet ( ) ; <nl> + for ( IndexShardStatus indexShardStatus : statusResponse . index ( \" test \" ) ) { <nl> + for ( ShardStatus shardStatus : indexShardStatus ) { <nl> + if ( ! shardStatus . shardRouting ( ) . primary ( ) ) { <nl> + logger . info ( \" - - > shard { } , recovered { } , reuse { } \" , shardStatus . shardId ( ) , shardStatus . peerRecoveryStatus ( ) . recoveredIndexSize ( ) , shardStatus . peerRecoveryStatus ( ) . reusedIndexSize ( ) ) ; <nl> + assertThat ( shardStatus . peerRecoveryStatus ( ) . recoveredIndexSize ( ) . bytes ( ) , greaterThan ( 0l ) ) ; <nl> + assertThat ( shardStatus . peerRecoveryStatus ( ) . reusedIndexSize ( ) . bytes ( ) , greaterThan ( 0l ) ) ; <nl> + assertThat ( shardStatus . peerRecoveryStatus ( ) . reusedIndexSize ( ) . bytes ( ) , greaterThan ( shardStatus . peerRecoveryStatus ( ) . recoveredIndexSize ( ) . bytes ( ) ) ) ; <nl> + } <nl> + } <nl> + } <nl> + } <nl> } <nl>\n", "msg": "add a more complex test for peer recovery reuse\n"}
{"diff_id": 40627, "repo": "bazelbuild/bazel\n", "sha": "cb2eecc044c856a930f55cf767295d42a271533b\n", "time": "2020-05-11T21:47:47Z\n", "diff": "mmm a / src / main / java / com / google / devtools / build / lib / rules / repository / WorkspaceBaseRule . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / repository / WorkspaceBaseRule . java <nl> <nl> <nl> import static com . google . devtools . build . lib . packages . Attribute . attr ; <nl> import static com . google . devtools . build . lib . packages . Type . STRING ; <nl> + import static com . google . devtools . build . lib . packages . Type . STRING_DICT ; <nl> <nl> import com . google . devtools . build . lib . analysis . BaseRuleClasses . RootRule ; <nl> import com . google . devtools . build . lib . analysis . RuleDefinition ; <nl> public RuleClass build ( RuleClass . Builder builder , RuleDefinitionEnvironment envi <nl> attr ( \" generator_location \" , STRING ) <nl> . undocumented ( \" internal \" ) <nl> . nonconfigurable ( \" internal attributes are non - configurable \" ) ) <nl> + / * < ! - - # BLAZE_RULE ( $ workspace_base_rule ) . ATTRIBUTE ( repo_mapping ) - - > <nl> + A dictionary from local repository name to global repository name . This allows controls over <nl> + workspace dependency resolution for dependencies of this repository . <nl> + <nl> + < p > For example , an entry < code > \" @ foo \" : \" @ bar \" < / code > declares that , for any time this <nl> + repository depends on < code > \" @ foo \" < / code > ( such as a dependency on <nl> + < code > \" @ foo / / some : target \" < / code > ) , it should actually resolve that dependency within <nl> + globally - declared < code > \" @ bar \" < / code > ( < code > \" @ bar / / some : target \" < / code > ) . <nl> + < ! - - # END_BLAZE_RULE . ATTRIBUTE - - > * / <nl> + . add ( attr ( \" repo_mapping \" , STRING_DICT ) ) <nl> . build ( ) ; <nl> } <nl> <nl>\n", "msg": "Document ` repo_mapping ` for native repository rules\n"}
{"diff_id": 40722, "repo": "elastic/elasticsearch\n", "sha": "9126d118246157e59f0ce3ffeb66491a1a9935d0\n", "time": "2013-08-12T22:19:50Z\n", "diff": "mmm a / src / main / java / org / elasticsearch / index / gateway / none / NoneIndexShardGateway . java <nl> ppp b / src / main / java / org / elasticsearch / index / gateway / none / NoneIndexShardGateway . java <nl> public void recover ( boolean indexShouldExists , RecoveryStatus recoveryStatus ) th <nl> / / in the none case , we simply start the shard <nl> / / clean the store , there should be nothing there . . . <nl> try { <nl> - logger . info ( \" deleting shard content \" ) ; <nl> + logger . debug ( \" cleaning shard content before creation \" ) ; <nl> indexShard . store ( ) . deleteContent ( ) ; <nl> } catch ( IOException e ) { <nl> logger . warn ( \" failed to clean store before starting shard \" , e ) ; <nl>\n", "msg": "better log message for none gateway , also make it debug level\n"}
{"diff_id": 40897, "repo": "oracle/graal\n", "sha": "78bc3442b2ca5d22995507c5f3bd05f12a297ad5\n", "time": "2018-10-29T12:12:41Z\n", "diff": "mmm a / sulong / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / metadata / debuginfo / DIScopeBuilder . java <nl> ppp b / sulong / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / metadata / debuginfo / DIScopeBuilder . java <nl> public LLVMSourceLocation build ( ) { <nl> <nl> @ Override <nl> public void visit ( MDLocation md ) { <nl> - if ( md . getInlinedAt ( ) ! = MDVoidNode . INSTANCE ) { <nl> - loc = buildLocation ( md . getInlinedAt ( ) ) ; <nl> - localCache . put ( md , loc ) ; <nl> - return ; <nl> - } <nl> - <nl> parent = buildLocation ( md . getScope ( ) ) ; <nl> kind = LLVMSourceLocation . Kind . LINE ; <nl> file = fileExtractor . extractFile ( md ) ; <nl>\n", "msg": "Remove workaround for source location reporting of inlined functions .\n"}
{"diff_id": 40900, "repo": "oracle/graal\n", "sha": "ba7b3eabddf36848c1eda54a16fddaaab062577d\n", "time": "2016-08-26T13:31:16Z\n", "diff": "mmm a / truffle / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / parser / NodeParser . java <nl> ppp b / truffle / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / parser / NodeParser . java <nl> private NodeData parseNodeData ( TypeElement templateType , List < TypeElement > typeH <nl> child = children . get ( childIndex ) ; <nl> shortCircuit = shortCircuits . contains ( NodeExecutionData . createIndexedName ( child , varArgsIndex ) ) ; <nl> } <nl> - executions . add ( new NodeExecutionData ( child , i , varArgsIndex , shortCircuit ) ) ; <nl> + if ( child ! = null ) { <nl> + executions . add ( new NodeExecutionData ( child , i , varArgsIndex , shortCircuit ) ) ; <nl> + } <nl> } <nl> return executions ; <nl> } <nl>\n", "msg": "Make parsing more robust against errors .\n"}
{"diff_id": 41020, "repo": "oracle/graal\n", "sha": "8cc030770f72ce4e787c86be47a72649a9c2d942\n", "time": "2017-01-04T11:08:01Z\n", "diff": "mmm a / projects / com . oracle . truffle . llvm . parser . api / src / com / oracle / truffle / llvm / parser / api / model / functions / FunctionDefinition . java <nl> ppp b / projects / com . oracle . truffle . llvm . parser . api / src / com / oracle / truffle / llvm / parser / api / model / functions / FunctionDefinition . java <nl> <nl> import java . util . Set ; <nl> import java . util . stream . Collectors ; <nl> <nl> + import com . oracle . truffle . api . CompilerAsserts ; <nl> import com . oracle . truffle . llvm . parser . api . model . blocks . InstructionBlock ; <nl> import com . oracle . truffle . llvm . parser . api . model . blocks . InstructionGenerator ; <nl> import com . oracle . truffle . llvm . parser . api . model . blocks . MetadataBlock ; <nl> public InstructionGenerator generateBlock ( ) { <nl> } <nl> <nl> public Type getType ( String instructionName ) { <nl> + CompilerAsserts . neverPartOfCompilation ( ) ; <nl> return namesToTypes . get ( instructionName ) ; <nl> } <nl> <nl> public InstructionBlock getBlock ( long idx ) { <nl> + CompilerAsserts . neverPartOfCompilation ( ) ; <nl> return blocks [ ( int ) idx ] ; <nl> } <nl> <nl> public int getBlockCount ( ) { <nl> + CompilerAsserts . neverPartOfCompilation ( ) ; <nl> return blocks . length ; <nl> } <nl> <nl> public List < InstructionBlock > getBlocks ( ) { <nl> + CompilerAsserts . neverPartOfCompilation ( ) ; <nl> return Arrays . asList ( blocks ) ; <nl> } <nl> <nl> public List < FunctionParameter > getParameters ( ) { <nl> + CompilerAsserts . neverPartOfCompilation ( ) ; <nl> return parameters ; <nl> } <nl> <nl> public Symbols getSymbols ( ) { <nl> + CompilerAsserts . neverPartOfCompilation ( ) ; <nl> return symbols ; <nl> } <nl> <nl> public void createUndefined ( Type type ) { <nl> <nl> @ Override <nl> public MetadataBlock getMetadata ( ) { <nl> + CompilerAsserts . neverPartOfCompilation ( ) ; <nl> return metadata ; <nl> } <nl> <nl> @ Override <nl> public int hashCode ( ) { <nl> + CompilerAsserts . neverPartOfCompilation ( ) ; <nl> int hash = super . hashCode ( ) ; <nl> hash = 43 * hash + ( ( parameters = = null ) ? 0 : parameters . hashCode ( ) ) ; <nl> hash = 43 * hash + ( ( symbols = = null ) ? 0 : symbols . hashCode ( ) ) ; <nl> public int hashCode ( ) { <nl> <nl> @ Override <nl> public boolean equals ( Object obj ) { <nl> + CompilerAsserts . neverPartOfCompilation ( ) ; <nl> if ( obj instanceof FunctionDefinition ) { <nl> FunctionDefinition other = ( FunctionDefinition ) obj ; <nl> return super . equals ( other ) & & Objects . equals ( parameters , other . parameters ) & & Objects . equals ( symbols , other . symbols ) & & Arrays . equals ( blocks , other . blocks ) & & <nl> public boolean equals ( Object obj ) { <nl> <nl> @ Override <nl> public String toString ( ) { <nl> + CompilerAsserts . neverPartOfCompilation ( ) ; <nl> return \" FunctionDefinition [ symbolCount = \" + symbols . getSize ( ) + \" , parameters = \" + parameters + \" , blocks = \" + blocks . length + \" , currentBlock = \" + currentBlock + \" , name = \" + getName ( ) + \" ] \" ; <nl> } <nl> } <nl>\n", "msg": "[ merge ] Add asserts in FunctionDefinition getters to ensure that they are only used in the slow path\n"}
{"diff_id": 41048, "repo": "NationalSecurityAgency/ghidra\n", "sha": "d9d78926a678a9927dcb8dfa72a4f779fb7f6210\n", "time": "2020-07-07T23:54:26Z\n", "diff": "mmm a / Ghidra / Features / Base / src / main / java / ghidra / app / plugin / core / graph / AddressBasedGraphDisplayListener . java <nl> ppp b / Ghidra / Features / Base / src / main / java / ghidra / app / plugin / core / graph / AddressBasedGraphDisplayListener . java <nl> private boolean isMyProgram ( Program p ) { <nl> <nl> @ Override <nl> public void domainObjectChanged ( DomainObjectChangedEvent ev ) { <nl> - if ( ! ev . containsEvent ( ChangeManager . DOCR_SYMBOL_RENAMED ) ) { <nl> + if ( ! ( ev . containsEvent ( ChangeManager . DOCR_SYMBOL_ADDED ) | | <nl> + ev . containsEvent ( ChangeManager . DOCR_SYMBOL_RENAMED ) | | <nl> + ev . containsEvent ( ChangeManager . DOCR_SYMBOL_REMOVED ) ) ) { <nl> return ; <nl> } <nl> + <nl> for ( DomainObjectChangeRecord record : ev ) { <nl> - if ( record . getEventType ( ) = = ChangeManager . DOCR_SYMBOL_RENAMED ) { <nl> + if ( record instanceof ProgramChangeRecord ) { <nl> ProgramChangeRecord programRecord = ( ProgramChangeRecord ) record ; <nl> - handleSymbolRenamed ( programRecord ) ; <nl> + Address address = programRecord . getStart ( ) ; <nl> + <nl> + if ( record . getEventType ( ) = = ChangeManager . DOCR_SYMBOL_RENAMED ) { <nl> + handleSymbolAddedOrRenamed ( address , ( Symbol ) programRecord . getObject ( ) ) ; <nl> + } <nl> + else if ( record . getEventType ( ) = = ChangeManager . DOCR_SYMBOL_ADDED ) { <nl> + handleSymbolAddedOrRenamed ( address , ( Symbol ) programRecord . getNewValue ( ) ) ; <nl> + } <nl> + else if ( record . getEventType ( ) = = ChangeManager . DOCR_SYMBOL_REMOVED ) { <nl> + handleSymbolRemoved ( address ) ; <nl> + } <nl> } <nl> } <nl> } <nl> <nl> - private void handleSymbolRenamed ( ProgramChangeRecord programRecord ) { <nl> - Symbol symbol = ( Symbol ) programRecord . getObject ( ) ; <nl> - String newName = symbol . getName ( ) ; <nl> - Address address = symbol . getAddress ( ) ; <nl> + private void handleSymbolAddedOrRenamed ( Address address , Symbol symbol ) { <nl> + String id = getVertexIdForAddress ( address ) ; <nl> + graphDisplay . updateVertexName ( id , symbol . getName ( ) ) ; <nl> + } <nl> + <nl> + private void handleSymbolRemoved ( Address address ) { <nl> String id = getVertexIdForAddress ( address ) ; <nl> - graphDisplay . updateVertexName ( id , newName ) ; <nl> + Symbol symbol = program . getSymbolTable ( ) . getPrimarySymbol ( address ) ; <nl> + String displayName = symbol = = null ? address . toString ( ) : symbol . getName ( ) ; <nl> + graphDisplay . updateVertexName ( id , displayName ) ; <nl> } <nl> <nl> private void dispose ( ) { <nl>\n", "msg": "fixed to handle more types of events that can affect graph labels .\n"}
{"diff_id": 41218, "repo": "eugenp/tutorials\n", "sha": "5dffa1931f004a13ec8e0f36dac2bed86d51e022\n", "time": "2016-04-27T13:53:57Z\n", "diff": "new file mode 100644 <nl> index 00000000000 . . 24f1f991def <nl> mmm / dev / null <nl> ppp b / mockito / src / test / java / org / baeldung / mockito / MockitoMockTest . java <nl> <nl> + package org . baeldung . mockito ; <nl> + <nl> + import static org . mockito . Mockito . * ; <nl> + import static org . junit . Assert . assertThat ; <nl> + import static org . hamcrest . Matchers . is ; <nl> + import static org . hamcrest . Matchers . containsString ; <nl> + import static org . apache . commons . lang3 . RandomStringUtils . randomAlphabetic ; <nl> + <nl> + import org . junit . Test ; <nl> + import org . junit . Rule ; <nl> + import org . junit . rules . ExpectedException ; <nl> + import org . mockito . MockSettings ; <nl> + import org . mockito . exceptions . verification . TooLittleActualInvocations ; <nl> + import org . mockito . invocation . InvocationOnMock ; <nl> + import org . mockito . stubbing . Answer ; <nl> + <nl> + public class MockitoMockTest { <nl> + static class CustomAnswer implements Answer < Boolean > { <nl> + @ Override <nl> + public Boolean answer ( InvocationOnMock invocation ) throws Throwable { <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> + @ Rule <nl> + public ExpectedException thrown = ExpectedException . none ( ) ; <nl> + <nl> + @ Test <nl> + public void whenUsingSimpleMock_thenCorrect ( ) { <nl> + MyList listMock = mock ( MyList . class ) ; <nl> + when ( listMock . add ( anyString ( ) ) ) . thenReturn ( false ) ; <nl> + boolean added = listMock . add ( randomAlphabetic ( 6 ) ) ; <nl> + <nl> + verify ( listMock ) . add ( anyString ( ) ) ; <nl> + assertThat ( added , is ( false ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void whenUsingMockWithName_thenCorrect ( ) { <nl> + MyList listMock = mock ( MyList . class , \" myMock \" ) ; <nl> + when ( listMock . add ( anyString ( ) ) ) . thenReturn ( false ) ; <nl> + listMock . add ( randomAlphabetic ( 6 ) ) ; <nl> + <nl> + thrown . expect ( TooLittleActualInvocations . class ) ; <nl> + thrown . expectMessage ( containsString ( \" myMock . add \" ) ) ; <nl> + <nl> + verify ( listMock , times ( 2 ) ) . add ( anyString ( ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void whenUsingMockWithAnswer_thenCorrect ( ) { <nl> + MyList listMock = mock ( MyList . class , new CustomAnswer ( ) ) ; <nl> + boolean added = listMock . add ( randomAlphabetic ( 6 ) ) ; <nl> + <nl> + verify ( listMock ) . add ( anyString ( ) ) ; <nl> + assertThat ( added , is ( false ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void whenUsingMockWithSettings_thenCorrect ( ) { <nl> + MockSettings customSettings = withSettings ( ) . defaultAnswer ( new CustomAnswer ( ) ) ; <nl> + MyList listMock = mock ( MyList . class , customSettings ) ; <nl> + boolean added = listMock . add ( randomAlphabetic ( 6 ) ) ; <nl> + <nl> + verify ( listMock ) . add ( anyString ( ) ) ; <nl> + assertThat ( added , is ( false ) ) ; <nl> + } <nl> + } <nl> \\ No newline at end of file <nl>\n", "msg": "initial commit for mockito mock methods\n"}
{"diff_id": 41275, "repo": "elastic/elasticsearch\n", "sha": "2704ab3d6934dea2a88b54037ae7f29baacc99c3\n", "time": "2010-07-14T07:34:22Z\n", "diff": "mmm a / modules / elasticsearch / src / main / java / org / elasticsearch / discovery / zen / ZenDiscovery . java <nl> ppp b / modules / elasticsearch / src / main / java / org / elasticsearch / discovery / zen / ZenDiscovery . java <nl> private void handleLeaveRequest ( final DiscoveryNode node ) { <nl> } <nl> } <nl> <nl> - private void handleJoinRequest ( final DiscoveryNode node ) { <nl> + private ClusterState handleJoinRequest ( final DiscoveryNode node ) { <nl> if ( ! master ) { <nl> throw new ElasticSearchIllegalStateException ( \" Node [ \" + localNode + \" ] not master for join request from [ \" + node + \" ] \" ) ; <nl> } <nl> + <nl> + ClusterState state = clusterService . state ( ) ; <nl> if ( ! transportService . addressSupported ( node . address ( ) . getClass ( ) ) ) { <nl> / / TODO , what should we do now ? Maybe inform that node that its crap ? <nl> logger . warn ( \" received a wrong address type from [ { } ] , ignoring . . . \" , node ) ; <nl> } else { <nl> / / try and connect to the node , if it fails , we can raise an exception back to the client . . . <nl> transportService . connectToNode ( node ) ; <nl> + state = clusterService . state ( ) ; <nl> <nl> clusterService . submitStateUpdateTask ( \" zen - disco - receive ( from node [ \" + node + \" ] ) \" , new ClusterStateUpdateTask ( ) { <nl> @ Override public ClusterState execute ( ClusterState currentState ) { <nl> private void handleJoinRequest ( final DiscoveryNode node ) { <nl> } <nl> } ) ; <nl> } <nl> + return state ; <nl> } <nl> <nl> private DiscoveryNode findMaster ( ) { <nl> private void sendInitialStateEventIfNeeded ( ) { <nl> <nl> private class MembershipListener implements MembershipAction . MembershipListener { <nl> @ Override public ClusterState onJoin ( DiscoveryNode node ) { <nl> - handleJoinRequest ( node ) ; <nl> - return clusterService . state ( ) ; <nl> + return handleJoinRequest ( node ) ; <nl> } <nl> <nl> @ Override public void onLeave ( DiscoveryNode node ) { <nl>\n", "msg": "improve join process in cluster , fetch the cluster meta - data on join and handle new meta data\n"}
